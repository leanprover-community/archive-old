[
    {
        "content": "<p>Is there a way to verify that a particular lemma has been proven in a particular lean file, in a way that is 'unhackable'? This would have applications, say, if a teacher wanted to have students submit some kind of homework in lean that would be verified automatically.</p>",
        "id": 200776106,
        "sender_full_name": "Kevin Shu",
        "timestamp": 1592068725
    },
    {
        "content": "<p>This has been discussed in the context of coding contests, but we don't have a bullet-proof workflow.</p>",
        "id": 200776211,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1592068920
    },
    {
        "content": "<p>You can discuss this with <span class=\"user-mention\" data-user-id=\"264734\">@Donald Sebastian Leung</span>. I don't remember what was the other similar thing.</p>",
        "id": 200776263,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1592068959
    },
    {
        "content": "<p>The way used in codewars is to have a separate file (which the student cannot edit) which contains the theorem statement, and proof given by referencing the name of the student's proof; then use <code>#print axioms</code> on this</p>",
        "id": 200776667,
        "sender_full_name": "Bhavik Mehta",
        "timestamp": 1592069565
    },
    {
        "content": "<p>This way you can verify that the student has proved what they were meant to prove, and the print axioms list should only contain the valid axioms in lean</p>",
        "id": 200776690,
        "sender_full_name": "Bhavik Mehta",
        "timestamp": 1592069608
    },
    {
        "content": "<p>I don't know of a convincing hack for this</p>",
        "id": 200776696,
        "sender_full_name": "Bhavik Mehta",
        "timestamp": 1592069625
    },
    {
        "content": "<p>IIRC it was mentioned that the <code>#print axioms</code> method used by Codewars could still be subverted in principle by redefining the <code>#print axioms</code> notation. The other similar thing mentioned by <span class=\"user-mention\" data-user-id=\"110031\">@Patrick Massot</span> is probably <a href=\"https://competition.isabelle.systems\">Proving for Fun</a> where Codewars derived its testing setup from (for Lean). The only difference in the setup between Codewars and Proving for Fun AFAIK is that for the latter, instead of using <code>#print axioms</code>, they inspect the output of running <code>leanchecker</code> on the check file instead which closes off any known loopholes (there was a brief period where they discovered a loophole with <code>leanchecker</code> itself but I believe it has been fixed since).</p>\n<p><span class=\"user-mention\" data-user-id=\"296764\">@Kevin Shu</span> You may wish to refer to selected comments on <a href=\"https://github.com/codewars/codewars-runner-cli/issues/773\">Codewars/codewars-runner-cli#773</a> for an extended discussion on automating the process of checking Lean submissions and cheat detection / prevention techniques.</p>",
        "id": 200796702,
        "sender_full_name": "Donald Sebastian Leung",
        "timestamp": 1592102724
    },
    {
        "content": "<p>Lean can do arbitrary I/O in tactics. It should be easy to use this to subvert any fully automated testing harness. The Proving for Fun method, for example, could be tricked by replacing the <code>leanchecker</code> executable. Further, this is a major security risk -- running arbitrary untrusted code -- which needs to be mitigated by proper sandboxing.</p>\n<p>All this could be addressed by adding a flag to Lean which disables I/O in tactics (i.e. makes <code>tactic.unsafe_run_io</code> a noop). This shouldn't break anything; neither the Lean standard library nor mathlib uses this function.</p>",
        "id": 200820147,
        "sender_full_name": "Jannis Limperg",
        "timestamp": 1592147126
    },
    {
        "content": "<p>Language-based sandboxing is hard to design and almost impossible to make 100% sound - just look at the mess in the JVM. If you want sandboxing, put the entire Lean process in a proper sandbox.</p>",
        "id": 200821399,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1592149013
    },
    {
        "content": "<p>At a minimum, you'd have to take away <code>unchecked_cast</code>, but then the hunt is on for exploitable interpreter bugs, and this is not a road worth going down...</p>",
        "id": 200822365,
        "sender_full_name": "Reid Barton",
        "timestamp": 1592150552
    },
    {
        "content": "<p>Yes, language sandboxes in general are hard and I wouldn't rely on a hypothetical \"safe Lean\" to run untrusted code without any additional measures. But for the purposes of this thread,  I think (without knowing much at all about this part of Lean) you could just disable Lean's I/O functionality entirely, i.e. all IO-related primitives are replaced with runtime errors. That would at least make exploitation much less trivial. Call it defence in depth if you will.</p>",
        "id": 200825077,
        "sender_full_name": "Jannis Limperg",
        "timestamp": 1592155002
    },
    {
        "content": "<p>I don't know anything about this stuff, but someone recently was talking about overriding existing overrides. Can we \"shut down\" things like <code>unchecked_cast</code> and <code>unsafe_run_io</code> from Lean?</p>",
        "id": 200839035,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1592178090
    }
]