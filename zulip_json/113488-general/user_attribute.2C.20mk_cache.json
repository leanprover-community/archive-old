[
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110026\">@Simon Hudon</span>, is there any chance you could quickly explain how <code>user_attribute X Y</code> works?</p>\n<p>I'm struggling to work out what's going on in attribute caching. In particular, in <code>cache_cfg</code>, the <code>mk_cache</code> field is meant to be a <code>list name -&gt; tactic X</code>. When is this function invoked? What is the list of names passed to it?</p>",
        "id": 160992849,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1552817531
    },
    {
        "content": "<p>It seems that the type <code>X</code> is some global cache object associated with the attribute, and the type <code>Y</code> is a \"decorator\" on every name that has been tagged with the attribute, that you can recover using <code>attr.get_param name</code>, which is a <code>tactic Y</code>.</p>",
        "id": 160992861,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1552817631
    },
    {
        "content": "<p>But how do you interact with the <code>X</code>?</p>",
        "id": 160992901,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1552817644
    },
    {
        "content": "<p>... Okay, I think I understand.</p>",
        "id": 160993432,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1552818828
    },
    {
        "content": "<p>the function in <code>mk_cache</code> is called some subset of the times that <code>attr.get_cache</code> is called.</p>",
        "id": 160993474,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1552818864
    },
    {
        "content": "<p>Certainly if <code>attr.get_cache</code> hasn't been called before, <code>mk_cache</code> runs. If any declarations have had the attribute added since the last call to <code>attr.get_cache</code>, <code>mk_cache</code> runs.</p>",
        "id": 160993484,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1552818911
    },
    {
        "content": "<p>When nothing has changed since the last call to <code>attr.get_cache</code>, <code>mk_cache</code> may or may not run...! I'm guessing this nondeterministic behaviour might be a race condition.</p>",
        "id": 160993487,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1552818954
    },
    {
        "content": "<p>This seems.... not very useful. :-) In particular, when you add the attribute to a new declaration, there's no way to update the old value of the cache, because <code>mk_cache</code> ... oh, can <code>mk_cache</code> call <code>get_cache</code>? But still, it seems there's no way to know which declarations have newly received the attribute since the last call to <code>mk_cache</code>, as <code>mk_cache</code> is just passed the entire list of names, so you're still having to look at all the names that carry the attribute.</p>",
        "id": 160993601,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1552819170
    },
    {
        "content": "<p>and in any case, <strong>no</strong>, <code>mk_cache</code> cannot call <code>get_cache</code> (unless your goal is SIGBUS).</p>",
        "id": 160993657,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1552819255
    },
    {
        "content": "<p>Interesting. I didn't know the last bit.</p>",
        "id": 160998301,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1552828323
    },
    {
        "content": "<p>I haven't confirmed it but I believe this works on cache invalidation logic. Every time you add the attribute, you invalidate the cache. Then, when you call <code>get_cache</code>, you rebuild the cache. The idea is that you can add the attribute on a few lemmas and if you don't query the cache in between, it should fairly fast. After that, you can use the cache many time. The first time is going to be the most expensive but after that, every invocation will be very fast.</p>",
        "id": 160998407,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1552828527
    },
    {
        "content": "<p>And I suspect that not building the cache incrementally is done to make the cache more reliable: <code>mk_cache</code> expresses a simple relation between the set of declaration that has the attribute and what the cache should be. If you make it incremental it's much harder to use</p>",
        "id": 160998466,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1552828616
    },
    {
        "content": "<p>And very easy to get it wrong</p>",
        "id": 160998475,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1552828630
    },
    {
        "content": "<p>The slowest thing you can do from that perspective (which I do not think is any slower than not having a cache) is have a long sequence where you set an attribute, then query the cache, then set an attribute and so on. If you want to make those faster, you can do as follows:</p>\n<div class=\"codehilite\"><pre><span></span><span class=\"kn\">lemma</span> <span class=\"n\">foo1</span> <span class=\"bp\">...</span>\n<span class=\"kn\">lemma</span> <span class=\"n\">foo2</span> <span class=\"bp\">...</span>\n<span class=\"kn\">lemma</span> <span class=\"n\">foo3</span> <span class=\"bp\">...</span>\n<span class=\"kn\">lemma</span> <span class=\"n\">foo4</span> <span class=\"bp\">...</span>\n<span class=\"kn\">lemma</span> <span class=\"n\">foo5</span> <span class=\"bp\">...</span>\n\n<span class=\"n\">attribute</span> <span class=\"o\">[</span><span class=\"n\">my_attribute</span><span class=\"o\">]</span> <span class=\"n\">foo1</span> <span class=\"n\">foo2</span> <span class=\"n\">foo3</span> <span class=\"n\">foo4</span> <span class=\"n\">foo5</span>\n</pre></div>\n\n\n<p>I don't think it will be much of a gain unless you have a lot of  lemmas that don't depend on each other through your tactic.</p>",
        "id": 160998602,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1552828838
    },
    {
        "content": "<p>I would wager to guess that <code>mk_cache</code> is run 1) as soon as the tagged declaration is parsed 2) when you call <code>get_cache</code> and it can't find a cache 3) when you call <code>get_cache</code> and more declarations have been marked with the user attribute since the last time the cache was computed.</p>",
        "id": 161012233,
        "sender_full_name": "Koundinya Vajjha",
        "timestamp": 1552852293
    },
    {
        "content": "<p>I was more interested in the following scenario: If I have two declarations in two files which do not import each other, both marked with the user attribute, is there any way that running <code>get_cache</code> in one file will also include the cached declaration in the other file?</p>",
        "id": 161012824,
        "sender_full_name": "Koundinya Vajjha",
        "timestamp": 1552853346
    },
    {
        "content": "<p>Or do I have to have a master file which imports both files? And the cache has to be recomputed in that file?</p>",
        "id": 161012828,
        "sender_full_name": "Koundinya Vajjha",
        "timestamp": 1552853389
    },
    {
        "content": "<blockquote>\n<p>Or do I have to have a master file which imports both files? And the cache has to be recomputed in that file?</p>\n</blockquote>\n<p>I'm pretty certain you need a master file, and the cache will be recomputed there. Anything else would require global mutable state in the environment, and that seems unlikely.</p>",
        "id": 161014541,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1552856243
    },
    {
        "content": "<p>The fact that there is a race condition is and the computation of the cache is nondeterministic it pretty easy to verify. Run the following in VSCode, and read the trace messages:</p>\n<div class=\"codehilite\"><pre><span></span>-- open native\nopen tactic\n\n@[user_attribute]\nmeta def example_attribute : user_attribute unit unit := {\n  name := `example,\n  descr := &quot;An example attribute&quot;,\n  cache_cfg :=\n   { mk_cache := λ ls, (do trace format!&quot;names: {ls}&quot;),\n     dependencies := [] },\n  after_set := some $ λ name priority persistent, (do trace format!&quot;set {name}&quot;),\n  before_unset := some $ λ name persistent, (do trace format!&quot;unset {name}&quot;)\n}\n\ndef f := 3\ndef g := 4\n\nsection\nlocal attribute [example] f\nlocal attribute [-example] f\nlocal attribute [example] f\nend -- Notice no &quot;unset&quot; at the end of the section?\n\nsection\nrun_cmd success_if_fail (example_attribute.get_param `f &gt;&gt;= trace)\n\nlocal attribute [example] f\nrun_cmd example_attribute.get_param `f &gt;&gt;= trace\nend\n\nset_option trace.user_attributes_cache true\nattribute [example] f\n\nrun_cmd example_attribute.get_cache &gt;&gt;= trace\n\n-- it seems non-deterministic whether this next line finds a cached value\nrun_cmd example_attribute.get_cache &gt;&gt;= trace\n\nattribute [example] g\n\nrun_cmd example_attribute.get_cache &gt;&gt;= trace\nrun_cmd example_attribute.get_cache &gt;&gt;= trace\n\nattribute [example] g\n\nrun_cmd example_attribute.get_cache &gt;&gt;= trace\nrun_cmd example_attribute.get_cache &gt;&gt;= trace\n</pre></div>",
        "id": 161014597,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1552856295
    },
    {
        "content": "<p>In any case... The reason I'm currently interested in this is my <code>library_search</code> tactic, which requires looking over ever declaration in the library. It actually seems to be (incredibly?) fast already, but I was hoping to see if I could use attribute caching to make it even faster. My idea had been to make an auxiliary attribute \"has_been_indexed\", or something, and to progressively update the map of \"lemmas arranged by head symbols\" I need every time someone runs <code>library_search</code>. But for this is help, we'd need to be able to reuse previous map, and just add to it the all the lemmas which have been added to the environment since the last call to <code>library_search</code>. That isn't possible, it seems. Given that I'd expect there to be a new declaration roughly every time <code>library_search</code> is called, the cache wouldn't be hit often: only ever for multiple invocations of <code>library_search</code> within the same proof block.</p>",
        "id": 161014830,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1552856644
    },
    {
        "content": "<p>In any case, this isn't a roadblock. It looks like <code>library_search</code> may be fast enough to be usable.</p>",
        "id": 161014836,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1552856659
    },
    {
        "content": "<p>Hi <span class=\"user-mention\" data-user-id=\"110087\">@Scott Morrison</span>, essentially just because <code>get_options</code> and <code>set_options</code> are <code>tactic_state</code> local, I have a way to have the lemma cache be generated only the first time <code>library_search</code> is used in particular a tactic block.</p>",
        "id": 161135447,
        "sender_full_name": "Keeley Hoek",
        "timestamp": 1552989292
    },
    {
        "content": "<p>Here's a working demo: <a href=\"https://github.com/khoek/lean-local-cache\" target=\"_blank\" title=\"https://github.com/khoek/lean-local-cache\">https://github.com/khoek/lean-local-cache</a></p>",
        "id": 161220913,
        "sender_full_name": "Keeley Hoek",
        "timestamp": 1553065300
    },
    {
        "content": "<p>Does that require modifying core?</p>",
        "id": 161221440,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1553066000
    },
    {
        "content": "<p>No, all above board</p>",
        "id": 161223477,
        "sender_full_name": "Keeley Hoek",
        "timestamp": 1553068494
    },
    {
        "content": "<p>Ok, cool!</p>",
        "id": 161224041,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1553069048
    },
    {
        "content": "<p>And in a second begin end block of the same file, it is regenerated again, right?</p>",
        "id": 161225494,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1553070704
    },
    {
        "content": "<p>Yes</p>",
        "id": 161225725,
        "sender_full_name": "Keeley Hoek",
        "timestamp": 1553070916
    },
    {
        "content": "<p><a href=\"https://github.com/leanprover-community/mathlib/pull/837\" target=\"_blank\" title=\"https://github.com/leanprover-community/mathlib/pull/837\">https://github.com/leanprover-community/mathlib/pull/837</a><br>\nI'm rocking some tests</p>",
        "id": 161225748,
        "sender_full_name": "Keeley Hoek",
        "timestamp": 1553070962
    }
]