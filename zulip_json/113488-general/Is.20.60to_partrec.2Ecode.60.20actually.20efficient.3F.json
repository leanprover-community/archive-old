[
    {
        "content": "<p>Is the basis given in <code>to_partrec.code</code> \"efficient\" -- i.e. does it simulate polynomial-time turing machines in polynomial time? I see that the reduction is good the other way -- TM's can simulate a step of <code>to_partrec.code</code> in polytime. Presumably, based on the preliminary work in <a href=\"https://github.com/leanprover-community/mathlib/pull/11046\">https://github.com/leanprover-community/mathlib/pull/11046</a>, the other way holds as well. However, when actually trying to write some code using <code>to_partrec.code</code>, I'm finding that this is actually quite difficult.</p>\n<p>First of all, it is clear that if we treat the size of the numbers as having size in binary rather than unary, then it does not encode all polytime algorithms. For example, doubling a number represented in a single cell (i.e. <code>[N]</code>) requires <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><mi>N</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(N)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mclose\">)</span></span></span></span> time, since  each step allows you to increment the cell at most once. In a traditional representation, the size of the input is <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><mi>log</mi><mo>⁡</mo><mi>N</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(\\log N)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mclose\">)</span></span></span></span>, however. This can be fixed if we treat the size of each natural number as if it were encoded in unary (even though this isn't how the actual reduction to turing machines works). Note that currently, the branch at <a href=\"https://github.com/leanprover-community/mathlib/pull/11046/files\">https://github.com/leanprover-community/mathlib/pull/11046/files</a> has <code>time_bound</code> that doesn't consider the size of the nat's at all, only the length of the list, but I understand it's a work in progress still.</p>\n<p>However, I'm not sure even some simple functions can be written in poly-time: for example, consider finding the <code>init</code> of a list of numbers (all but the last element). While this is obviously possible, because it is shown in that file that all computable functions have a code, I'm not sure it is possible when each nat is bounded by <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><mi>log</mi><mo>⁡</mo><mi>n</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(\\log n)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">n</span><span class=\"mclose\">)</span></span></span></span>, where <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">n</span></span></span></span> is the length of the list. In this case, we have essentially no storage capabilities, so any time we call <code>fix</code> on a function, if it is able to \"modify\" the end, it has already forgotten the beginning.</p>\n<p>I have some work that copies a lot of <code>to_partrec.code</code> but uses <code>list bool</code> and different basis functions. I'm wondering if we are eventually planning on replacing <code>tm_to_partrec</code> to better support complexity theory.</p>",
        "id": 276439783,
        "sender_full_name": "Praneeth Kolichala",
        "timestamp": 1648106693
    },
    {
        "content": "<p>I think you are right that <code>to_partrec.code</code> is not efficient. It was primarily intended to be a reduction of <code>partrec</code> to involve operations on lists which are easier to encode in a turing machine, but the reduction is coming from a representation of partial recursive functions that is itself not efficient (since everything is based on unary recursion), and the list support in <code>to_partrec.code</code> is very barebones, and only really supports lists of fixed length in a useful way.</p>",
        "id": 276468869,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648125574
    },
    {
        "content": "<p>The connection to partial recursive functions is only intended to preserve computability. For defining P, I think the basis should be more explicitly related to turing machines, and a variation on <code>to_partrec.code</code> that uses <code>list bool</code> sounds like a fine idea to get something that is structurally closer to partial recursive functions which is polytime.</p>",
        "id": 276469383,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648125840
    },
    {
        "content": "<p>Here was the justification I gave in my head as to why I thought <code>to_partrec.code</code> should be able to simulate a TM with polynomial slowdown. If I encode a TM tape as a list of nats, then I can write a code to take in a list and return the list after one step of the TM. Presumably, that code runs in time linear in the distance of the TM head from the start of the list. Then I can use the <code>code.fix</code> to repeat this until the turing machine halts (I instruct the machine head to walk back to the left when it does this so I can detect it). Since this distance is only at most as long as the number of steps, the total number of steps is at most quadratic in the TM runtime. Perhaps my presumption about being able to write this linear time is wrong though.</p>",
        "id": 276477627,
        "sender_full_name": "Bolton Bailey",
        "timestamp": 1648129702
    },
    {
        "content": "<p>Indeed, in <a href=\"https://github.com/leanprover-community/mathlib/pull/11406\">#11406</a> I haven't been considering the size of the numbers, only the length of the list. I was envisioning encoding data structures in lists where all the numbers in size were bounded, and then immediately terminating in failure if a number too large was detected. I guess the question is, if I'm doing that, does it make sense to have the base type of the list be Nats at all, perhaps it should just be an arbitrary type or fintype or bools as Mario suggests, and we should introduce yet another code type to which evaluates functions on lists for those.</p>",
        "id": 276478717,
        "sender_full_name": "Bolton Bailey",
        "timestamp": 1648130253
    },
    {
        "content": "<blockquote>\n<p>If I encode a TM tape as a list of nats, then I can write a code to take in a list and return the list after one step of the TM.</p>\n</blockquote>\n<p>This seems to be the crux of the issue. Suppose that we encode the TM tape using nats of bounded size. (This is a reasonable assumption since we can't afford to access this data efficiently.) If we don't use <code>fix</code>, then I believe we can prove that every function we can encode either does not inspect <code>drop n v</code> and passes it along to the output for some fixed <code>n</code>, or discards this tail entirely. Thus <code>fix</code>'s control condition cannot be a function of more than a fixed number of places in the input, which means that it's either a finite state automaton producing output in the inaccessible tail, or it consumes input from the tail and has nowhere to put output. So anything like <code>init</code> isn't going to be expressible.</p>",
        "id": 276484359,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648132602
    },
    {
        "content": "<p>Hmm, is it that the initial segment of the tape must go \"on the stack\" as it were?</p>",
        "id": 276486864,
        "sender_full_name": "Bolton Bailey",
        "timestamp": 1648133556
    },
    {
        "content": "<p>What is needed is a function that </p>\n<ul>\n<li>If the initial (four elements say) segment of the list contains the TM head, computes the new initial segment for the list from a lookup table.</li>\n<li>If the initial segment of the list encodes a tape element, recursively calls itself on the tail, then appends the head back to the result and returns that.</li>\n</ul>",
        "id": 276488075,
        "sender_full_name": "Bolton Bailey",
        "timestamp": 1648134019
    },
    {
        "content": "<p>the issue is that there isn't a \"stack\" to put things on in the first place. You need to multiplex the input and output on the same tape, and this requires list operations that are apparently not expressible.</p>",
        "id": 276490040,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648134788
    },
    {
        "content": "<p>Seems like what might have to be done to salvage this is to make another code type with a more expressive recursion operation. I'm not sure we want that though, so I might take this opportunity to abandon this approach though and either go the TM2 route that I've now started in <a href=\"https://github.com/leanprover-community/mathlib/pull/12993\">#12993</a> or the lambda calculus route that was suggested in the complexity theory thread.</p>",
        "id": 276807866,
        "sender_full_name": "Bolton Bailey",
        "timestamp": 1648415204
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"282271\">@Bolton Bailey</span> I ported some of your code from your PR to here: <a href=\"https://github.com/prakol16/lean_complexity_theory_polytime_defs\">https://github.com/prakol16/lean_complexity_theory_polytime_defs</a></p>\n<p>but now it uses <code>bitstring = list bool</code> instead of <code>list nat</code>. This does mean we will have to redo the compilation to TM's though (but I think that is inevitable).</p>\n<p>I think ideally, this code would actually replace <code>tm_to_partrec</code>, since so much of the code is duplicated with only slight differences. There is also the issue that we have lots of different kinds of encodings (<code>encodable</code>, <code>primcodeable</code>, <code>encoding</code>, <code>fun_encoding</code>, <code>boolcodeable</code>) which we might want to somehow unify.</p>",
        "id": 276966255,
        "sender_full_name": "Praneeth Kolichala",
        "timestamp": 1648538231
    },
    {
        "content": "<p>I don't think there is a need for <code>boolcodable</code> to be a separate type from <code>primcodable</code>; you can encode to nats with a binary translation to list bool</p>",
        "id": 276976431,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648544665
    },
    {
        "content": "<p>In particular, if <code>primcodable</code> and <code>primrec</code> need to change then that will go against the literature definition</p>",
        "id": 276977103,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648545046
    },
    {
        "content": "<p>keeping in mind that <code>primcodable</code> and <code>primrec</code> are not making any attempt to characterize polytime computability</p>",
        "id": 276977167,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648545086
    },
    {
        "content": "<p>but polytime computable functions should be primitive recursive</p>",
        "id": 276977192,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648545106
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span> The only issue is that there are already definitions for many items being <code>primcodable</code>, but they are not consistent with polytime encodings. For example, I believe that the encoding of a list takes exponential time in the length of the list. Another thing we could do is rename <code>boolcodeable</code> to <code>fastcodable</code> (note that the encodings should be \"good\" in general, not just polytime but ideally logspace to retrieve a particular item in a list etc. as well) but still make it <code>N -&gt; N</code> instead of <code>list bool -&gt; list bool</code>. Note that this is slightly harder because most of these encodings are more natural as <code>list bool</code> than as nat's, but  as you say, there is an equivalence between them.</p>\n<p>I think if we want good unification with the existing <code>primrec</code> stuff, what we should do is have a separate class,  (<code>fastcodable</code>?, which replaces <code>boolcodable</code>), which doesn't use the default encodable encoding (because this won't work typically if we want something with low overhead). Then, we have <code>primcodable</code> extend <code>fastcodable</code> (or maybe be a mixin?), and use <code>fastcodable</code>'s pairing function for consistency with the code that will be polynomial time. I assume that <code>primrec</code> does not rely on any arithmetic properties of the pairing function, only it encodes pairs somehow and can decode them, right?</p>",
        "id": 277031923,
        "sender_full_name": "Praneeth Kolichala",
        "timestamp": 1648571507
    },
    {
        "content": "<p>I believe the pairing function is polytime when interpreted on list bool, not quite linear time since it involves arithmetic. The only encoding that isn't <code>fastcodable</code> is the one for lists</p>",
        "id": 277072027,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648592289
    },
    {
        "content": "<p>I think <code>fastcodable</code> should extend <code>primcodable</code> and require that the function in question is polytime computable (which means some of the slow encodings have to be replaced). Logspace is a lot harder and needs a computational model other than TMs to be useful, so I would stay away from it for the present.</p>",
        "id": 277072385,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648592562
    },
    {
        "content": "<p>I believe that the only place that directly interacts with the list encoding is in the proof that <code>list.cons</code> is primrec and <code>list.foldr</code> is primrec and everything else is proven from that</p>",
        "id": 277072672,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648592778
    },
    {
        "content": "<p>While it's true that the pairing function <code>nat.mkpair</code> is polytime, it's very convenient to have the list representation be built off of the the pairing function so that <code>[a, b, c, ...]</code> is represented as <code>(a, (b, (c, ...)))</code>, (and <code>mkpair</code> doesn't work for this). The main issue is I want to avoid having duplicate instances of <code>[primcodable (list α)]</code>, because that might make things confusing. So if we want to keep the polytime and primcodable encodings consistent, do we want to break (a) <code>primcodable</code> using <code>nat.mkpair</code> for pairs or (b) <code>[a, b,c, ...]</code> being encoded as <code>(a, (b, (c, ...)))</code>? To be, (a) seems like the easier sacrifice, but I don't know how much effort it would take to convert this.</p>\n<p>My original idea for <code>fastcodable</code> was to actually not put any formal requirements at all on it, just have them be reasonably good encodings. Then, we add prop mix-ins like <code>[primcodable α]</code> which is true of a type <code>α</code> with <code>[fastcodable α]</code> when <code>encode(decode(x))</code> is primitive recursive. Similarly, <code>[polycodable α]</code> when <code>encode(decode(x))</code> is poly-time. Both proposals (mix-ins, extending) are similar I think.</p>",
        "id": 277081300,
        "sender_full_name": "Praneeth Kolichala",
        "timestamp": 1648600099
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"437861\">@Praneeth Kolichala</span> </p>\n<blockquote>\n<p>While it's true that the pairing function nat.mkpair is polytime, it's very convenient to have the list representation be built off of the the pairing function so that [a, b, c, ...] is represented as (a, (b, (c, ...))), (and mkpair doesn't work for this).</p>\n</blockquote>\n<p>The relevant property you need for an efficient pairing function is that pairing <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>a</mi></mrow><annotation encoding=\"application/x-tex\">a</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">a</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">b</span></span></span></span> results in a number of size <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mn>2</mn><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><mi>log</mi><mo>⁡</mo><mi>a</mi><mo>+</mo><mi>log</mi><mo>⁡</mo><mi>b</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">2^{O(\\log a+\\log b)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.888em;\"></span><span class=\"mord\"><span class=\"mord\">2</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.888em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen mtight\">(</span><span class=\"mop mtight\"><span class=\"mtight\">l</span><span class=\"mtight\">o</span><span class=\"mtight\" style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace mtight\" style=\"margin-right:0.1952em;\"></span><span class=\"mord mathnormal mtight\">a</span><span class=\"mbin mtight\">+</span><span class=\"mop mtight\"><span class=\"mtight\">l</span><span class=\"mtight\">o</span><span class=\"mtight\" style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace mtight\" style=\"margin-right:0.1952em;\"></span><span class=\"mord mathnormal mtight\">b</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span>. <code>mkpair</code> only satisfies this in the case where the sizes of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>a</mi></mrow><annotation encoding=\"application/x-tex\">a</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">a</span></span></span></span> and <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">b</span></span></span></span> are approximately equal; it has unacceptable waste when one is much larger than the other, which leads to bad behavior in the nested case. Your implementation achieves this, although it is somewhat heavy on the left side (it is <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mn>2</mn><mrow><mn>2</mn><mi>log</mi><mo>⁡</mo><mi>a</mi><mo>+</mo><mi>log</mi><mo>⁡</mo><mi>b</mi><mo>+</mo><mi>O</mi><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">2^{2\\log a+\\log b+O(1)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.888em;\"></span><span class=\"mord\"><span class=\"mord\">2</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.888em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span><span class=\"mspace mtight\" style=\"margin-right:0.1952em;\"></span><span class=\"mop mtight\"><span class=\"mtight\">l</span><span class=\"mtight\">o</span><span class=\"mtight\" style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace mtight\" style=\"margin-right:0.1952em;\"></span><span class=\"mord mathnormal mtight\">a</span><span class=\"mbin mtight\">+</span><span class=\"mop mtight\"><span class=\"mtight\">l</span><span class=\"mtight\">o</span><span class=\"mtight\" style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace mtight\" style=\"margin-right:0.1952em;\"></span><span class=\"mord mathnormal mtight\">b</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen mtight\">(</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span>). Not sure how much it is worth optimizing this though.</p>",
        "id": 277082273,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648601340
    },
    {
        "content": "<blockquote>\n<p>The main issue is I want to avoid having duplicate instances of [primcodable (list α)], because that might make things confusing.</p>\n</blockquote>\n<p>I think we're agreed on that. If we do change out the encoding (and I think there is good reason to do so), it should replace the original one and primrec will have to be modified to prove that the constructors and recursors are also primrec in the new encoding.</p>",
        "id": 277082373,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648601440
    },
    {
        "content": "<blockquote>\n<p>My original idea for fastcodable was to actually not put any formal requirements at all on it, just have them be reasonably good encodings.</p>\n</blockquote>\n<p>It's fine to just have reasonably good encodings (indeed that was my aim with <code>primcodable</code> as well), but you will eventually need actual runtime bounds on the constructors and destructors like polytime. The only aspect of this that is formally part of the <code>primcodable</code> structure is that <code>encode o decode</code> needs to be primrec; you can't express anything else about the two functions generically since they essentially become primrec by definition.</p>",
        "id": 277082512,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648601599
    },
    {
        "content": "<p>if you aren't putting any constraints at all on <code>fastcodable</code>, then that's just the <code>encodable</code> typeclass.</p>",
        "id": 277082591,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648601703
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/Is.20.60to_partrec.2Ecode.60.20actually.20efficient.3F/near/277082591\">said</a>:</p>\n<blockquote>\n<p>if you aren't putting any constraints at all on <code>fastcodable</code>, then that's just the <code>encodable</code> typeclass.</p>\n</blockquote>\n<p>Yeah, what I was thinking was something that would be used like (untested):</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">class</span> <span class=\"n\">polycodable</span> <span class=\"o\">{</span><span class=\"n\">α</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span><span class=\"o\">}</span> <span class=\"o\">[</span><span class=\"n\">fastcodable</span> <span class=\"n\">α</span><span class=\"o\">]</span> <span class=\"o\">:=</span>\n<span class=\"o\">(</span><span class=\"n\">encode_decode</span> <span class=\"o\">:</span> <span class=\"n\">encode</span><span class=\"o\">(</span><span class=\"n\">decode</span><span class=\"o\">(</span><span class=\"n\">x</span><span class=\"o\">))</span> <span class=\"n\">is</span> <span class=\"n\">polytime</span>\n</code></pre></div>\n<p>which would be used like:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">theorem</span> <span class=\"n\">polytime_comp</span> <span class=\"o\">{</span><span class=\"n\">α</span> <span class=\"n\">β</span> <span class=\"n\">γ</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span><span class=\"o\">}</span> <span class=\"o\">[</span><span class=\"n\">fastcodable</span> <span class=\"n\">α</span><span class=\"o\">]</span> <span class=\"o\">[</span><span class=\"n\">fastcodable</span> <span class=\"n\">β</span><span class=\"o\">]</span> <span class=\"o\">[</span><span class=\"n\">fastcodable</span> <span class=\"n\">γ</span><span class=\"o\">]</span> <span class=\"o\">[</span><span class=\"n\">polycodable</span> <span class=\"n\">α</span><span class=\"o\">]</span> <span class=\"o\">[</span><span class=\"n\">polycodable</span> <span class=\"n\">β</span><span class=\"o\">]</span> <span class=\"o\">[</span><span class=\"n\">polycodable</span> <span class=\"n\">γ</span><span class=\"o\">]</span>\n  <span class=\"o\">(</span><span class=\"n\">f</span> <span class=\"o\">:</span> <span class=\"n\">α</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">β</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">g</span> <span class=\"o\">:</span> <span class=\"n\">β</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">γ</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">hf</span> <span class=\"o\">:</span> <span class=\"n\">polytime</span> <span class=\"n\">f</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">hg</span> <span class=\"o\">:</span> <span class=\"n\">polytime</span> <span class=\"n\">g</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">polytime</span> <span class=\"o\">(</span><span class=\"n\">f</span> <span class=\"bp\">∘</span> <span class=\"n\">g</span><span class=\"o\">)</span>\n</code></pre></div>\n<p>The only reason being that if <code>polycodable</code> extends <code>primcodable</code>, then there are redundantly two requirements (<code>encode_decode</code> being primitive recursive and also polynomial time). Of course this can be fixed with a lemma showing that you only need one. Otherwise they are pretty similar I think.</p>\n<p>Then, the only differences between <code>fastcodable</code> and <code>encodable</code> would be how the encodings are implemented.</p>",
        "id": 277082944,
        "sender_full_name": "Praneeth Kolichala",
        "timestamp": 1648602059
    },
    {
        "content": "<blockquote>\n<p>The only reason being that if polycodable extends primcodable, then there are redundantly two requirements (encode_decode being primitive recursive and also polynomial time). Of course this can be fixed with a lemma showing that you only need one. Otherwise they are pretty similar I think.</p>\n</blockquote>\n<p>That's fine, there are plenty of such redundant requirements in the algebraic hierarchy. You can use smart constructors to work around it.</p>",
        "id": 277083024,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648602128
    },
    {
        "content": "<p>I don't think these need to be mixins since they form a strict inclusion hierarchy</p>",
        "id": 277083035,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648602158
    },
    {
        "content": "<blockquote>\n<p>Then, the only differences between fastcodable and encodable would be how the encodings are implemented.</p>\n</blockquote>\n<p>That's exactly what I want to avoid, this would yield multiple implementations of <code>encodable</code></p>",
        "id": 277083061,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648602197
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/Is.20.60to_partrec.2Ecode.60.20actually.20efficient.3F/near/277082373\">said</a>:</p>\n<blockquote>\n<p>I think we're agreed on that. If we do change out the encoding (and I think there is good reason to do so), it should replace the original one and primrec will have to be modified to prove that the constructors and recursors are also primrec in the new encoding.</p>\n</blockquote>\n<p>So should we replace just list encodings or both list and tuple encodings (in order to preserve the property <code>[a, b, c...]</code> = <code>(a, (b, (c, ...)</code>?)</p>",
        "id": 277083072,
        "sender_full_name": "Praneeth Kolichala",
        "timestamp": 1648602215
    },
    {
        "content": "<p>It is possible to replace just the list encoding with something more balanced, but I don't think that fixes the root cause. If you use a tuple encoding that adapts to the sizes of numbers then you can use it in lists and also in trees or other kinds of tupling (which is important for supporting general inductive types), and the list encoding will not have to change</p>",
        "id": 277083250,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648602386
    },
    {
        "content": "<p>In fact, I think your tuple encoding isn't good enough, because <code>(a, ())</code> has size <code>2|a|+O(1)</code> so <code>((((a, ()), ()), ..., ())</code> has size <code>2^n|a|</code></p>",
        "id": 277083330,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648602495
    },
    {
        "content": "<p>so I think we do need the more efficient encoding of the length after all</p>",
        "id": 277083342,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648602513
    },
    {
        "content": "<p>Yeah it's not good enough for trees, I was planning on encoding trees as lists of tuples with the tuples holding the data as well as \"pointers\" to the children</p>",
        "id": 277083358,
        "sender_full_name": "Praneeth Kolichala",
        "timestamp": 1648602550
    },
    {
        "content": "<p>that's not compositional enough, you would have to analyze the whole tree at once to do that</p>",
        "id": 277083369,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648602580
    },
    {
        "content": "<p>there is an easy tweak: you can encode <code>log |a|</code> in unary and then <code>|a|</code> in binary, and then <code>a</code> and <code>b</code></p>",
        "id": 277083465,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648602700
    },
    {
        "content": "<p>this gets <code>2 log |a| + |a| + |b|</code> size</p>",
        "id": 277083472,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648602719
    },
    {
        "content": "<p>Yes, this is the natural next step, but the more complicated the pairing function becomes, the harder it is to implement on a TM (currently, my <code>code</code> uses the pairing function as a black box, so it would have to be compiled manually to a TM)</p>",
        "id": 277083544,
        "sender_full_name": "Praneeth Kolichala",
        "timestamp": 1648602798
    },
    {
        "content": "<p>I don't see why this function would get involved in <code>tm_to_partrec</code>?</p>",
        "id": 277083629,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648602900
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/Is.20.60to_partrec.2Ecode.60.20actually.20efficient.3F/near/277083369\">said</a>:</p>\n<blockquote>\n<p>that's not compositional enough, you would have to analyze the whole tree at once to do that</p>\n</blockquote>\n<p>What do you mean by this? It's still a poly-time construction, the space usage is good (constant-factor overhead).</p>",
        "id": 277083640,
        "sender_full_name": "Praneeth Kolichala",
        "timestamp": 1648602910
    },
    {
        "content": "<p>you are referencing pointers so you need to have a context to translate the tree, it can't just be a function <code>tree -&gt; nat</code></p>",
        "id": 277083658,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648602960
    },
    {
        "content": "<p>and it gets even harder to do things like that if inductive types are nested in each other</p>",
        "id": 277083709,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648603003
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/Is.20.60to_partrec.2Ecode.60.20actually.20efficient.3F/near/277083629\">said</a>:</p>\n<blockquote>\n<p>I don't see why this function would get involved in <code>tm_to_partrec</code>?</p>\n</blockquote>\n<p>Eventually, we'd want to show something like \"<code>code</code> is polytime\" --&gt; \"TM computes in polytime,\" right? (e.g. at least for reductions which are easier from TM machines, like Cook-Levin, although this might not be that bad from compositional basis functions either, I'm not sure)</p>",
        "id": 277083714,
        "sender_full_name": "Praneeth Kolichala",
        "timestamp": 1648603024
    },
    {
        "content": "<p>so to the extent possible if we can translate trees to natural numbers without any contextual information it would be preferable</p>",
        "id": 277083719,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648603032
    },
    {
        "content": "<p>a simple <code>pair : nat -&gt; nat -&gt; nat</code> function applied everywhere achieves that</p>",
        "id": 277083725,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648603054
    },
    {
        "content": "<p>what does \"<code>code</code> is polytime\" mean there?</p>",
        "id": 277083781,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648603108
    },
    {
        "content": "<p>do you have a cost model on <code>code</code> to link to?</p>",
        "id": 277083811,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648603176
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/Is.20.60to_partrec.2Ecode.60.20actually.20efficient.3F/near/277083658\">said</a>:</p>\n<blockquote>\n<p>you are referencing pointers so you need to have a context to translate the tree, it can't just be a function <code>tree -&gt; nat</code></p>\n</blockquote>\n<p>What do you mean context? The \"pointers\" were metaphorical, I just mean indices in the list.</p>\n<p>So for example, the tree ((A, B), C) would translate to <code>[(root, 1, 2), (child 1, 3, 4), (C, none, none), (A, none, none), (B, none, none)]</code>. The format is <code>[(data of node, index of left child, index of right child)]</code></p>",
        "id": 277083818,
        "sender_full_name": "Praneeth Kolichala",
        "timestamp": 1648603189
    },
    {
        "content": "<p>That's what I was talking about. You can't interpret <code>(root, 1, 2)</code> without the \"context\" <code>[(root, 1, 2), (child 1, 3, 4), (C, none, none), (A, none, none), (B, none, none)]</code></p>",
        "id": 277083890,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648603232
    },
    {
        "content": "<p>I want an encoding that does not require a context</p>",
        "id": 277083898,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648603253
    },
    {
        "content": "<p>which means that <code>f(((A, B), C))</code> is a function only of <code>f((A, B))</code> and <code>f(C)</code></p>",
        "id": 277083912,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648603291
    },
    {
        "content": "<p>As inspiration, I always consider the case of the representations I have been using here: lists of characters where you put <code>(</code> and <code>)</code> and <code>,</code> between elements</p>",
        "id": 277083982,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648603380
    },
    {
        "content": "<p>this is a great encoding, it does not suffer from any blowup problems and it's fully compositional</p>",
        "id": 277083992,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648603394
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/Is.20.60to_partrec.2Ecode.60.20actually.20efficient.3F/near/277083781\">said</a>:</p>\n<blockquote>\n<p>what does \"<code>code</code> is polytime\" mean there?</p>\n</blockquote>\n<p>It means the function represented by the code as a function from N to N runs in polynomial time. The cost model is still a WIP, but there is some preliminary code here: <a href=\"https://github.com/prakol16/lean_complexity_theory_polytime_defs/blob/main/src/time_bound.lean\">https://github.com/prakol16/lean_complexity_theory_polytime_defs/blob/main/src/time_bound.lean</a>. Note that the cost for <code>pair</code> should add something (e.g. the length of <code>c₁.eval v</code>) which is not currently there to get nice properties, and the cost of an oracle could be changed to the length of the output or possibly a custom cost function for oracles.</p>",
        "id": 277084209,
        "sender_full_name": "Praneeth Kolichala",
        "timestamp": 1648603609
    },
    {
        "content": "<blockquote>\n<p>Note that the cost for pair should add something (e.g. the length of c₁.eval v) which is not currently there to get nice properties</p>\n</blockquote>\n<p>I'm not sure about that. I would hope that it is a lemma that you can't produce a value of size <code>n</code> without taking time <code>n</code></p>",
        "id": 277084358,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648603798
    },
    {
        "content": "<p>the pairing function should be primitive in <code>code</code>, so references to the cost of a nat pairing function seem inappropriate</p>",
        "id": 277084440,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648603844
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/Is.20.60to_partrec.2Ecode.60.20actually.20efficient.3F/near/277084358\">said</a>:</p>\n<blockquote>\n<blockquote>\n<p>Note that the cost for pair should add something (e.g. the length of c₁.eval v) which is not currently there to get nice properties</p>\n</blockquote>\n<p>I'm not sure about that. I would hope that it is a lemma that you can't produce a value of size <code>n</code> without taking time <code>n</code></p>\n</blockquote>\n<p>Exactly, I meant that the function should be modified to get that nice property.</p>",
        "id": 277084444,
        "sender_full_name": "Praneeth Kolichala",
        "timestamp": 1648603846
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/Is.20.60to_partrec.2Ecode.60.20actually.20efficient.3F/near/277084440\">said</a>:</p>\n<blockquote>\n<p>the pairing function should be primitive in <code>code</code>, so references to the cost of a nat pairing function seem inappropriate</p>\n</blockquote>\n<p>The function itself is primitive, but the size of the output compared to the two inputs matters and needs to be accounted for.</p>",
        "id": 277084464,
        "sender_full_name": "Praneeth Kolichala",
        "timestamp": 1648603869
    },
    {
        "content": "<p>the size of the output should be the sum of the two within a log factor</p>",
        "id": 277084544,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648603926
    },
    {
        "content": "<p>so you will get a log overhead which seems fine</p>",
        "id": 277084563,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648603947
    },
    {
        "content": "<p>TMs already have much worse overhead just shuffling around the tape</p>",
        "id": 277084624,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648604026
    },
    {
        "content": "<p>so you shouldn't aim for better than polytime</p>",
        "id": 277084701,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1648604074
    }
]