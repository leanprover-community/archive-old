[
    {
        "content": "<p>Ok, I think I am going to take a pause on \"math in Lean\", and do some infrastructure work.</p>\n<ul>\n<li>I'm going to set up a virtual machine running on a fast machine that watches a shared Dropbox folder, and runs <code>lean --make</code> every time it sees anything change. Others can then <code>cd ~/Dropbox/lean-box/yourname/</code>, <code>ln -s ~/my-lean-project/</code>, and Dropbox will continuously deliver <code>.olean</code> files back to their project directory. I've tried this before, and it works, at least on a single OS.</li>\n<li>I'm going to try to catch up on <span class=\"user-mention\" data-user-id=\"110026\">@Simon Hudon</span>'s investigation of <code>sccache</code>, and see what would need to happen to make this work, as it seems like an excellent solution. If we need to patch Lean, no problem; <code>elan</code> makes it very simple to work with forks these days.</li>\n<li>Keeley has told me that per-<code>begin ... end</code> block caching may be feasible, but probably requiring a small patch to Lean. When he has time, I'll ask him what's involved.</li>\n</ul>\n<p>All of these seem more valuable than writing out explicit proofs of boring facts.</p>",
        "id": 147995454,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1542661765
    },
    {
        "content": "<p>sounds good to me... nothing like a little fear of tedium to get the ball rolling on more advanced automation and caching :)</p>",
        "id": 147995576,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1542661891
    },
    {
        "content": "<p><a href=\"https://github.com/leanprover/lean/issues/1601\" target=\"_blank\" title=\"https://github.com/leanprover/lean/issues/1601\">https://github.com/leanprover/lean/issues/1601</a> makes me slightly pessimistic about the third item</p>",
        "id": 147995589,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1542661915
    },
    {
        "content": "<p>I think Keeley's idea is hackier than what Leo had in mind, and so may have an orthogonal set of issues. :-)</p>",
        "id": 147995766,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1542662096
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110087\">@Scott Morrison</span> That sounds fantastic. I got the impression from Sebastian that Lean 3 might not be completely frozen, so minor tweaks might even be patched back into Lean.</p>",
        "id": 148015546,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1542687125
    },
    {
        "content": "<p>Would it be an idea to develop some git hooks that look at your build server? And then instead of indexing by username, maybe index by git commit hash?</p>",
        "id": 148015564,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1542687201
    },
    {
        "content": "<p>That way new users that install elan will automatically pull up to date oleans for the latest mathlib master.</p>",
        "id": 148015578,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1542687231
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110087\">@Scott Morrison</span> What kind of specs will your build machine have? Can I contribute with my little monster, or is it just a drop in the ocean compared to yours? I've got a 16-threaded beast with 24G RAM, but it is pretty oldish (7 years?). When otherwise idle, it compiles mathlib from scratch in about 6 minutes (using 12 threads on average).</p>",
        "id": 148017230,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1542690186
    },
    {
        "content": "<p>Let's wait and see if we can actually build something that works, first. :-) This machine is slightly bigger (18 Xeon W cores, and 128gb of RAM), with a similar compile time (I actually remember timing 7 minutes?) The hardware is not the hard part, in any case.</p>",
        "id": 148017800,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1542691221
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110087\">@Scott Morrison</span> The poor little Xeon :D On caching: we can really get arbitrarily fancy. My config monad work should be done in a day, so I'll finally get on it. (I had a migraine today :()</p>\n<p>I really think the biggest obstacle is just syntax. If people can figure out a way to override lean's use of <code>tactic.execute</code> and <code>tactic.step</code>, then you'll only need an import to do caching in vanilla lean. From reading the source code <code>src/frontends/lean/tactic_notation.cpp</code> (see <code>parse_tactic_class()</code> in that file), I don't think this is possible and I will have to change one line of code. Otherwise you will have to type extra character(s), like <code>begin [cache] ... end</code> or <code>begin [c] ... end</code> or maybe <code>cbegin ... end</code> (but this would be vanilla supported).</p>\n<p>The other option will be to point <code>elan</code> to to the fork with a <code>lean_version = \"xxx\"</code> in <code>leanpkg.toml</code>, which will get everything working without touching <code>begin ... end</code> blocks at all. This would be vanilla compatible---if you don't run the fork, you just don't get caching of these blocks.</p>\n<p>My current understanding is that the actual caching implementation will not be too difficult. My \"caching program\" (not in the sense of an executable program), would be to first write fast <code>expr</code> serialization. I can think of all sorts of things---like storing proofs hot in mutable state in a user_attribute---which we could tack-on to speed up a naive caching implementation after-the-fact.</p>\n<p>I suspect we could get more speed using a buddy-process and some tricks with writing the proofs directly to bytecode and back again (I have a strategy for getting lean to do this without touching bytecode handling ourselves), but perhaps this should be saved for the future. Since <code>begin...end</code> blocks can be processed in parallel, this step would definitely require a \"buddy process\" (such a thing would be completely invisible to the user, just like the communication processes that start up when you launch <code>rewrite_search</code>'s graph visualiser).</p>",
        "id": 148026785,
        "sender_full_name": "Keeley Hoek",
        "timestamp": 1542705815
    },
    {
        "content": "<p>Awesome! I'm cheering for you!</p>",
        "id": 148026910,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1542706000
    },
    {
        "content": "<p>Also worth noting is that I keep having ideas to try to trick <code>[user_notation]</code>-like features into capturing a <code>begin...end</code>, but all have failed. Maybe someone else will come up with a smart way to do it. That's the problem which has been making me hesitant, though, so I guess I'll press onward for now.</p>",
        "id": 148027124,
        "sender_full_name": "Keeley Hoek",
        "timestamp": 1542706253
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110111\">@Keeley Hoek</span> How are you planning to deal with the nondeterminism issues described in the Github issue? That is, a cached proof term will most likely not be a valid term in the recomputed context, even though the input hasn't changed.</p>",
        "id": 148027203,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1542706330
    },
    {
        "content": "<p>I'm not confident about what you mean Sebastian---which of course is a bit scary.</p>\n<p>The plan was (at least to start---and what everything I mentioned up there was about) just remembering the entire proof term which was generated in a <code>begin...end</code> block. The obvious impact is not having to re-run really expensive tactics which appear in that block, and only recompiling a small piece of a big file---or a huge chunk of mathlib if you changed a core file---if you only changed a proof, or added a new definition, etc. (I'm not claiming that any of this would be guaranteed to be <em>safe</em>, but I think Kenny's work is a testament to how much things could get better if you only have to run a <code>by simp</code> once to figure out it actually did, for example.)</p>\n<p>So even though we don't remember what individual tactics did, or guarantee that the proof we remembered will work at all, I think this could still be really useful. Especially because, even when definitions of theorems are broken or a lemma argument is changed generated proofs using them will not work, this kind of hard caching will still stop the spread of the recompilation like a cancer throughout the entire library---hopefully only 1 level of recompilation will need to be done.</p>",
        "id": 148029332,
        "sender_full_name": "Keeley Hoek",
        "timestamp": 1542708975
    },
    {
        "content": "<p>the problem is that a context contains variables, identified by unique names, and these unique names will be different when you use an old term in a new context</p>",
        "id": 148029388,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1542709069
    },
    {
        "content": "<p>I think this can be fixed by just remembering the variables by their position instead of their name, or using positional information to reconstruct a bad name</p>",
        "id": 148029446,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1542709103
    },
    {
        "content": "<p>But do any such names actually appear in the final proof term? Like if I run <code>#print my_lemma</code>, surely there won't be much state in there?</p>",
        "id": 148029476,
        "sender_full_name": "Keeley Hoek",
        "timestamp": 1542709138
    },
    {
        "content": "<p>For example, if you have <code>\\lam x y z, begin exact f x end</code> then lean sees <code>\\lam x0 y1 z2, begin exact f x0 end</code>, and so if you store <code>f x0</code>, then when lean reparses the exact same theorem it sees <code>\\lam x3 y4 z5, f x0</code> which doesn't typecheck</p>",
        "id": 148029581,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1542709216
    },
    {
        "content": "<p>The pp names and unique names are still associated to the binders in the final proof term</p>",
        "id": 148029677,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1542709339
    },
    {
        "content": "<p>and unique means something like globally unique since you turned on lean, I'm not sure how far you can push nonuniqueness</p>",
        "id": 148029706,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1542709386
    },
    {
        "content": "<p>I'm not sure I understand. Do you mean a program like this:</p>\n<div class=\"codehilite\"><pre><span></span>structure my_struct :=\n(n : ℕ)\n(g : ℕ → ℕ)\n\ndef f (y : ℕ) : ℕ := 2 * y\n\ndef a_constructor (n : ℕ) : my_struct :=\n{\n  n := n,\n  g := λ x, begin exact f x end\n}\n</pre></div>\n\n\n<p>for example?</p>\n<p>If I do</p>\n<div class=\"codehilite\"><pre><span></span>run_cmd (do\n  e ← tactic.get_env,\n  l ← e.get `a_constructor,\n  tactic.trace l.value.to_raw_fmt\n)\n</pre></div>\n\n\n<p>I get</p>\n<div class=\"codehilite\"><pre><span></span>(lam n default (const nat []) (app (app (const my_struct.mk []) (var 0)) (lam x default (const nat []) (app (const f []) (var 0)))))\n</pre></div>\n\n\n<p>In particular, the <code>x</code> is bound under the lambda, so I don't need to worry about matching up the <code>x</code> with anything. Am I missing the point?</p>",
        "id": 148030499,
        "sender_full_name": "Keeley Hoek",
        "timestamp": 1542710208
    },
    {
        "content": "<p>well, two things: first the <code>lam</code> there is actually storing the unique id of the bound variable (so the <code>var</code> doesn't have to)</p>",
        "id": 148030682,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1542710450
    },
    {
        "content": "<p>and second, a tactic doesn't deal with closed terms, it is elaborated in an \"open\" context (with local constants in surrounding binders) corresponding to where <code>begin ... end</code> actually appears</p>",
        "id": 148030725,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1542710517
    },
    {
        "content": "<p><code>to_raw_fmt</code> doesn't print the unique ids to save our sanity, I guess</p>",
        "id": 148030785,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1542710576
    },
    {
        "content": "<p>but you can pattern match it out</p>",
        "id": 148030794,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1542710587
    },
    {
        "content": "<p>I'm looking at the <code>expr</code> definition and it has <code>lam : name → binder_info → expr → expr → expr</code>---In particular, I don't see any room for a secret id <code>name</code> which could be stored in the second argument of the <code>local_const</code> constructor, for example<br>\nBut I see the problem if a <code>local_const</code> (for example?) appears---and I understand your way to fix it, too</p>",
        "id": 148031137,
        "sender_full_name": "Keeley Hoek",
        "timestamp": 1542711005
    },
    {
        "content": "<p>oh, I guess I was mistaken</p>",
        "id": 148031384,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1542711332
    },
    {
        "content": "<p>looks like it's only when in a local context that you have to worry about the uids of local constants</p>",
        "id": 148031433,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1542711371
    },
    {
        "content": "<p>Okay, so I can confirm that for sufficiently simple <code>.lean</code> files, as long as you consistently use the same version of Lean (preferably provided by elan, following a leanpkg.toml file), that the <code>.olean</code> files are completely cross platform.</p>",
        "id": 148084471,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1542768680
    },
    {
        "content": "<p>With a very simple lean file containing <code>#print \"compiling\"</code> and a few definitions, then syncing that file via Dropbox between a mac, windows, and linux computer, I can verify that the olean file produced on any of the 3, works on the other two.</p>",
        "id": 148084527,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1542768814
    },
    {
        "content": "<p>Unfortunately once you scale up to \"all of mathlib\", Dropbox puts too many timestamps in the wrong order, and essentially isn't useful.</p>",
        "id": 148094316,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1542787118
    },
    {
        "content": "<p>Repeatedly running <code>lean --make</code> on two different computers (waiting for each to complete before running again) usually results in a small subset of mathlib being compiled each time you switch computers.</p>",
        "id": 148094334,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1542787186
    },
    {
        "content": "<p>That said, I don't think I ever saw more than a minute of compiling on a single computer, so maybe it could be better than nothing...</p>",
        "id": 148094418,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1542787247
    },
    {
        "content": "<p><code>sccache</code> will hopefully be much more awesome. :-)</p>",
        "id": 148094430,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1542787259
    },
    {
        "content": "<p>That minute on your computers translates to 6 minutes on my laptop, or Chris's...</p>",
        "id": 148094459,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1542787302
    },
    {
        "content": "<p>But sure, it still is helpful.</p>",
        "id": 148094494,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1542787323
    },
    {
        "content": "<p>Ok, I will soon add some scripts that relentlessly run <code>lean --make</code> on appropriate subdirectories, and try it out for real. (e.g. have my desktop machine compile for my laptop, and if anyone else wants to try it to)</p>",
        "id": 148094635,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1542787561
    },
    {
        "content": "<p>Before doing fancy Dropbox things, why not trying to copy-paste what the main Lean repository is doing to produce lean nightlies  and get a lean-community/mathlib-nightlies/ repository? Should I try to do that?</p>",
        "id": 148108370,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1542805463
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110024\">@Sebastian Ullrich</span> do you have comments about the above plan? Is there anything I should know about why the Lean nightlies are setup that way?</p>",
        "id": 148108687,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1542805862
    },
    {
        "content": "<p>You mean why is it a separate repo?</p>",
        "id": 148108897,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1542806148
    },
    {
        "content": "<p>Yes, for instance</p>",
        "id": 148108950,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1542806182
    },
    {
        "content": "<p>or any other comment</p>",
        "id": 148108959,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1542806194
    },
    {
        "content": "<p>maybe no comment is needed</p>",
        "id": 148108963,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1542806198
    },
    {
        "content": "<p>I suppose the Dropbox solution makes it easy to actually deliver the output to people</p>",
        "id": 148109070,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1542806354
    },
    {
        "content": "<p>I really don't like to idea to ask people interested in mathlib to use Dropbox</p>",
        "id": 148109097,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1542806395
    },
    {
        "content": "<p>The nightlies are in a separate repository so that they are not mixed with the official releases on the Github Releases page</p>",
        "id": 148109177,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1542806477
    },
    {
        "content": "<p>I guess what you'd want to have is to point <code>leanpkg</code> to a Github Release including .olean files instead of a git hash, just like with <code>elan</code>. But that... would not be a small task.</p>",
        "id": 148109267,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1542806546
    },
    {
        "content": "<p>Or alternatively have <code>sccache</code> do that</p>",
        "id": 148109317,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1542806613
    },
    {
        "content": "<p>What I mean is much more naive: I want to be able to write a tiny bash script that downloads a compiled version of mathlib inside the <code>_target</code> subdirectory of the current directory, and uses touch to pretend every olean have just been created.</p>",
        "id": 148109511,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1542806820
    },
    {
        "content": "<p>Yeah, that doesn't sound too bad to me</p>",
        "id": 148109913,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1542807205
    },
    {
        "content": "<p>Ok, thanks. I'll try to do that</p>",
        "id": 148110228,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1542807583
    },
    {
        "content": "<p>That can be a viable solution but if someone wanted to figure out how to setup sccache to share storable, I think that would be more effective. That way, we wouldn't have to upload a new version of mathlib every few day. Just compiling would get the mathlib that others have compiled</p>",
        "id": 148148031,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1542850656
    }
]