[
    {
        "content": "<p>This topic was moved here from <a class=\"stream-topic\" data-stream-id=\"113489\" href=\"/#narrow/stream/113489-new-members/topic/Lean.20server.20mode.20-.20tactics\">#new members &gt; Lean server mode - tactics</a> by <span class=\"user-mention silent\" data-user-id=\"252300\">Jalex Stark</span></p>",
        "id": 206145734,
        "sender_full_name": "Notification Bot",
        "timestamp": 1596722958
    },
    {
        "content": "<p>I looked into the 200 milliseconds issue a while back.  It's not easy to resolve, although we could add a command-line flag to reduce it to, say, 100ms or 50ms.  The server doesn't have a \"finished\" event internally that we could hook into.  The problem is that the 200ms is a polling interval, and reducing it will just cause extra json traffic.</p>",
        "id": 206147207,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1596723617
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110043\">@Gabriel Ebner</span> I think a flag would be a good compromise.  Also, by \"extra JSON traffic\", do you mean the we would see more <code>all_messages</code> responses and <code>current_tasks</code> responses?</p>",
        "id": 206152802,
        "sender_full_name": "Jason Rute",
        "timestamp": 1596726043
    },
    {
        "content": "<p>Yes.</p>",
        "id": 206152832,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1596726058
    },
    {
        "content": "<p>I think if we were working with the lean server programmatically, there is no issue having more JSON messages (or at least any cost in processing two extra JSON messages every 50 ms would be negligible to the 50 ms wait).  While I see the point of the the 200 ms when used as a language server, I don't see the issue with reducing the wait even more with a flag.</p>",
        "id": 206153481,
        "sender_full_name": "Jason Rute",
        "timestamp": 1596726310
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"321854\">@Auguste Poiroux</span> I'm glad I asked.  I've sketched some of what I've been working on to <span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span> in <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/Data.20sets.3A.20where.20to.20put.20them.3F/near/204324247\">this conversation</a>.  For Lean 3, I've found some simple hacks to record tactic steps in the library.  Basically, one can modify the base <code>.lean</code> files to record the tactic name, goal, and all the parameters of the interactive tactics.  If you like, we can discuss my ideas further.  I've implemented some of them so far, but I still need to get around to doing it at scale with all or most of the interactive tactics.  As for interactive back and forth with Lean, there is the lean server mode.  Other than that, I'm building a more direct prototype tool, but that is still in an incomplete stage.  I'd be happy to talk about this further, either on Zulip or in a face-to-face chat.</p>",
        "id": 206155108,
        "sender_full_name": "Jason Rute",
        "timestamp": 1596726939
    },
    {
        "content": "<p>As for Lean 4, I am not sure what is being added that would support this.  I get the vague sense that it will be easier since major parts of the Lean compiler and parser will be written in Lean, but I doubt there will be any tactic-based proof recording or programatic interactivity with Lean out of the box.  (I'm not involved in Lean 4, so take my predictions with a grain of salt.)</p>",
        "id": 206155818,
        "sender_full_name": "Jason Rute",
        "timestamp": 1596727264
    },
    {
        "content": "<p>Thank you very much for the answers! I will be happy to discuss this together with <span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span> .</p>",
        "id": 206166348,
        "sender_full_name": "Auguste Poiroux",
        "timestamp": 1596732373
    }
]