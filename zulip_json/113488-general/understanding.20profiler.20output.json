[
    {
        "content": "<p>So I am 2/3 of the way through a pretty big proof which I am currently reluctant to break up into smaller pieces.</p>",
        "id": 126403538,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526024698
    },
    {
        "content": "<p>I might be pushing type class inference quite hard here, because it's a maths proof so everything is a group homomorphism and a ring homomorphism and I want Lean to infer everything.</p>",
        "id": 126403551,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526024730
    },
    {
        "content": "<p>It has got to the point when, whenever I type something, I get the orange \"thinking\" bars for 5 seconds.</p>",
        "id": 126403554,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526024754
    },
    {
        "content": "<p>I can live with this, but I wondered if there was an easy way to speed things up.</p>",
        "id": 126403595,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526024778
    },
    {
        "content": "<p>[I have other alternatives, such as \"plough on\" or \"break the proof up into two pieces\", which will be painful]</p>",
        "id": 126403604,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526024822
    },
    {
        "content": "<p>So I typed <code>set_option profiler true</code></p>",
        "id": 126403613,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526024844
    },
    {
        "content": "<p>and now I can see a bunch of information and I realise I don't really understand it.</p>",
        "id": 126403618,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526024862
    },
    {
        "content": "<p>For example</p>",
        "id": 126403655,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526024885
    },
    {
        "content": "<p>it starts</p>",
        "id": 126403671,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526024993
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span>elaboration: tactic execution took 4.96s\nnum. allocated objects:  5886\nnum. allocated closures: 6029\n 4961ms   100.0%   _interaction._lambda_2\n 4960ms   100.0%   tactic.istep\n 4960ms   100.0%   scope_trace\n 4959ms   100.0%   tactic.istep._lambda_1\n 4959ms   100.0%   tactic.step\n 3460ms    69.7%   tactic.to_expr\n 1388ms    28.0%   tactic.interactive.have._lambda_1\n 1055ms    21.3%   tactic.interactive.propagate_tags\n 1007ms    20.3%   interaction_monad_orelse\n</pre></div>",
        "id": 126403715,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526025004
    },
    {
        "content": "<p>so I would be quite happy to get the wait time down to 1 second</p>",
        "id": 126403719,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526025016
    },
    {
        "content": "<p>but I now see that the problem might be <code>tactic.to_expr</code> and <code>tactic.step</code> and this doesn't really help me at all in locating the problem</p>",
        "id": 126403727,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526025046
    },
    {
        "content": "<p>I am envisaging that the problem might be \"this simp is taking forever\", which I could fix by looking at the proof simp finds and then typing it in directly</p>",
        "id": 126403735,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526025073
    },
    {
        "content": "<p>or \"this type class inference is taking forever\", which again I feel like I might be able to help out with</p>",
        "id": 126403740,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526025089
    },
    {
        "content": "<p>How do I diagnose the issue further?</p>",
        "id": 126403742,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526025097
    },
    {
        "content": "<p>The heavy hitters are the ones when the number of ms decreases significantly from the previous line</p>",
        "id": 126403850,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1526025339
    },
    {
        "content": "<p>so <code>tactic.to_expr</code> and <code>tactic.interactive.have</code> here</p>",
        "id": 126403852,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1526025359
    },
    {
        "content": "<p>Basically that means that elaboration is taking up all the time</p>",
        "id": 126403894,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1526025371
    },
    {
        "content": "<p>so how can I help?</p>",
        "id": 126404455,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526026518
    },
    {
        "content": "<p>Can I see explicitly which lines of code are causing the problem?</p>",
        "id": 126404456,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526026529
    },
    {
        "content": "<p>ooh I just got an achievement</p>",
        "id": 126404498,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526026576
    },
    {
        "content": "<p>\"type of sorry macro is not a sort\"</p>",
        "id": 126404499,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526026576
    },
    {
        "content": "<p>new error message</p>",
        "id": 126404500,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526026576
    },
    {
        "content": "<p>heh</p>",
        "id": 126404510,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526026635
    },
    {
        "content": "<p>it should have said \"you put an extra bracket on that line you dimwit\"</p>",
        "id": 126404511,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526026653
    },
    {
        "content": "<p>OK so it might be the case that I can help the elaborator out. I have 500 lines of code. Where do I start?</p>",
        "id": 126404553,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526026686
    },
    {
        "content": "<p><code>elaboration of zariski.sheaf_of_types_on_standard_basis_for_finite_covers took 20.3s</code></p>",
        "id": 126436589,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526076690
    },
    {
        "content": "<p>finished :-)</p>",
        "id": 126436596,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526076703
    },
    {
        "content": "<p>wonderful</p>",
        "id": 126436650,
        "sender_full_name": "Kenny Lau",
        "timestamp": 1526076746
    },
    {
        "content": "<p><code>set_option class.instance_max_depth 75</code></p>",
        "id": 126436661,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526076785
    },
    {
        "content": "<p>This is just for one lemma.#</p>",
        "id": 126436665,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526076819
    },
    {
        "content": "<p>Obviously my code might be crappy</p>",
        "id": 126436666,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526076819
    },
    {
        "content": "<p>Will this whole system really scale?</p>",
        "id": 126436667,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526076819
    },
    {
        "content": "<p>max depth 72 is the min for which the code compiles</p>",
        "id": 126436716,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526076889
    },
    {
        "content": "<p>It's the proof that an affine scheme satisfies the sheaf axiom for finite covers of basic opens by basic opens</p>",
        "id": 126436733,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526076927
    },
    {
        "content": "<p>I've been putting it off for weeks, I knew it would be horrible, but I didn't know it would be this horrible.</p>",
        "id": 126436738,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526076946
    },
    {
        "content": "<p>Big proofs are quite wobbly... there's no way you can split the lemma up into something shorter and less complicated?</p>",
        "id": 126439771,
        "sender_full_name": "Andrew Ashworth",
        "timestamp": 1526081928
    },
    {
        "content": "<p>Not really. I could break it into some smaller pieces, but the problem is that the pieces other than the \"main\" piece would have really really complicated statements. Even the statement of the result whose hypotheses are so painful to check involves 13 groups / group homomorphisms which are inferred by type class inference, and the actual groups and homomorphisms involved are very elaborate, coming from some technical ring theory which I built up within the proof. Taking this stuff out into another lemma would involve making some very convoluted definitions and very long statements. On the other hand this is a snapshot of what \"deep\" mathematics looks like -- when one moves away from stuff like finite groups it does get complicated. Formalising graduate level real analysis (standard results in Hardy and Sobolev spaces) will I imagine be much worse.</p>",
        "id": 126440349,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526082755
    },
    {
        "content": "<p>If you yearn for the day of explicit <code>is_group_hom</code> assumptions, why don't you make the type <code>group_hom A B</code> of all functions that are group homs between groups A and B? That will make the typeclass problem trivial</p>",
        "id": 126440571,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1526083157
    },
    {
        "content": "<p>It's not clear to me that this is the real issue, but it might help</p>",
        "id": 126440582,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1526083200
    },
    {
        "content": "<p>I am not convinced that the problems you are discovering are unavoidable, but I haven't had much time to look at your formalization in depth</p>",
        "id": 126440640,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1526083250
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span> Wow! Congratulations! That must have been a major road block.</p>",
        "id": 126448591,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1526100927
    },
    {
        "content": "<p>Can someone explain to me what the pros and cons are of having a type <code>group_hom A B</code> like Mario suggested?</p>",
        "id": 126448638,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1526101018
    },
    {
        "content": "<p>I personally don't understand the subtleties between the different possibilities for doing this - you could have a definition, or a structure, or a class. If you have a class then you want type class inference to do the donkeywork for you -- you seem to be making a commitment of the form \"it should be easy to work out when something is a group hom so we'll make a machine do it for you\". Unfortunately as I found out in my scheme work, life is not always so easy: I had a situation with a map f of (finite) types J -&gt; I, groups G i and H j, and group homs c j from G (f j) to H j, and then wanted to define a map from Pi_i G i to Pi_j H j sending (g i) to the element which was c j (g (f j)) at j, and I thought I would be clogging up the type class inference system to write some explicit instance which was supposed to spot this, so I proved it by hand and then had to feed it into the type class inference system manually -- as I'm sure you'll agree Johan, a mathematician would note that this was obviously a group homomorphism -- \"none of the G i or H j know anything about each other so they can't interfere with each other\" -- and move on.</p>",
        "id": 126455761,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526117646
    },
    {
        "content": "<p>I think this scheme theory effort could be important for the future of maths in Lean. I can't wait to see how Mario or Johannes will clean it</p>",
        "id": 126464249,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1526137210
    },
    {
        "content": "<p>I don't believe this monster proof cannot be cut in pieces</p>",
        "id": 126464252,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1526137227
    },
    {
        "content": "<p>The issue is to figure out what is the right infrastructure</p>",
        "id": 126464255,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1526137247
    },
    {
        "content": "<p>It's not about stating a lemma for each quarter of the proof (which would indeed give very technical statements)</p>",
        "id": 126464262,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1526137279
    },
    {
        "content": "<p>It's like my problem with the chain rule, compared to the new Coq proof</p>",
        "id": 126464264,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1526137311
    },
    {
        "content": "<p>In this case part of the infrastructure is a clever way of handling little o notations</p>",
        "id": 126464307,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1526137343
    },
    {
        "content": "<p>I think figuring out the infrastructure is really a core skill for non-trivial math formalization, and it's certainly normal that we don't get it right on our first try (especially for people with no CS background)</p>",
        "id": 126464354,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1526137482
    },
    {
        "content": "<p>I just did this scheme thing for fun. I have no idea whether they're interested in it for mathlib. I know that various bits should go in there, like the universal property of localization etc, but I don't know if they want all this sheaf stuff. My impression is that Mario is not that interested in definitions, he would rather have lemmas. I'm of a very different opinion but I was not going to be pushing for schemes to go into mathlib because of this. Mario was like \"yeah but what the theorem?\" when we talked about it and I was just going \"it's schemes, there is no theorem, there are 1000 theorems but the fundamental thing is the definition\". Well we'll have a theorem soon, but I'm not sure he'll be interested in it. I must say that this experience has made me deeply skeptical about stuff like <a href=\"https://blog.deepsense.ai/machine-learning-application-in-automated-reasoning/\" target=\"_blank\" title=\"https://blog.deepsense.ai/machine-learning-application-in-automated-reasoning/\">https://blog.deepsense.ai/machine-learning-application-in-automated-reasoning/</a></p>",
        "id": 126467149,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526143911
    },
    {
        "content": "<p>Yes... there is something of a gap to bridge (-; You don't get there with just a bit of NLP.</p>",
        "id": 126468000,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1526145852
    },
    {
        "content": "<p>Nevertheless, I sincerely hope that throwing some AI into the mix, the computer can take some of the tedious bits of work out of our hands...</p>",
        "id": 126468003,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1526145888
    },
    {
        "content": "<p>And basically this is what we try to do with some tactics...</p>",
        "id": 126468011,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1526145907
    },
    {
        "content": "<p>But one could imagine a rigged up version.</p>",
        "id": 126468012,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1526145916
    },
    {
        "content": "<p>Having spent several days wrestling with a 500 line proof which was of the form \"this is completely trivial\", it is now a joy to be back writing short proofs of non-trivial statements -- \"continuous image of compact is compact\", \"we already proved a lemma saying what the image of Spec(f) was in this case\", \"compact iff every open cover has a finite subcover\" etc etc -- I feel like I'm making rapid progress in every line now.</p>",
        "id": 126468709,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1526147606
    },
    {
        "content": "<p>I really really think you should try to get schemes in mathlib</p>",
        "id": 126508258,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1526242292
    },
    {
        "content": "<p>Otherwise we'll never know whether Lean can handle it without type class depth 100</p>",
        "id": 126508261,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1526242317
    },
    {
        "content": "<p>And I also think like <a href=\"https://blog.deepsense.ai/machine-learning-application-in-automated-reasoning/\" target=\"_blank\" title=\"https://blog.deepsense.ai/machine-learning-application-in-automated-reasoning/\">https://blog.deepsense.ai/machine-learning-application-in-automated-reasoning/</a> looks like crackpot science</p>",
        "id": 126508301,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1526242358
    },
    {
        "content": "<p>Clearly writing this paper without first trying to translate the scheme definition by hand is either stupid or fraud</p>",
        "id": 126508309,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1526242398
    },
    {
        "content": "<p>In <a href=\"#narrow/stream/116395-maths/topic/topological.20space.20from.20filter/near/189336789\" title=\"#narrow/stream/116395-maths/topic/topological.20space.20from.20filter/near/189336789\">this thread</a>  (at the bottom of a big post containing lots of code) I was bemoaning the fact that the Lean code I enjoy writing best is very different (and in particular much longer) to the kind of Lean code which is mathlib-acceptable; I have no instinct to optimise and part of me actually thinks it's a step in the wrong direction because it makes proofs less readable. </p>\n<p>I thought I would do some experiments trying to shorten my code and seeing if it made any difference to how quickly it compiled. But I've realised that the profiler output I'm seeing is so chaotic that I am not sure I will be able to draw any sensible conclusions from any experiment I do. With <code>set_option profiler true</code> set I restarted Lean 10 times and looked at how long it took to elaborate my proof that if <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi></mrow><annotation encoding=\"application/x-tex\">X</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span></span></span></span> is compact then <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>X</mi><mo>×</mo><mi>Y</mi><mo>→</mo><mi>Y</mi></mrow><annotation encoding=\"application/x-tex\">X\\times Y\\to Y</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">Y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">Y</span></span></span></span> is closed for all <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>Y</mi></mrow><annotation encoding=\"application/x-tex\">Y</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">Y</span></span></span></span>, and I got this:</p>\n<div class=\"codehilite\"><pre><span></span>elaboration of closed_pr2_of_compact took 186ms\nelaboration of closed_pr2_of_compact took 192ms\nelaboration of closed_pr2_of_compact took 169ms\nelaboration of closed_pr2_of_compact took 227ms\nelaboration of closed_pr2_of_compact took 92.1ms\nelaboration of closed_pr2_of_compact took 195ms\nelaboration of closed_pr2_of_compact took 254ms\nelaboration of closed_pr2_of_compact took 287ms\nelaboration of closed_pr2_of_compact took 256ms\nelaboration of closed_pr2_of_compact took 262ms\n</pre></div>\n\n\n<p>The quickest run was about 1/3 the time of the longest. I should say that by \"I restarted Lean\" I mean various things, e.g. sometimes \"I typed some characters into the file and then deleted them, forcing recompilation in VS Code\" and sometimes \"I hit ctrl-shift-P and restarted Lean\".</p>\n<p>Is there any way I can get a more meaningful answer to the question \"exactly how many computer science units of time did it take to completely compile my current proof of this result\"? Preferably one which bears some relation to wall clock time on a machine with nothing else running, but ideally is constant over restarts?</p>",
        "id": 189386986,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1582975593
    },
    {
        "content": "<p>That quickest run is definitely curious (assuming it wasn't a run where the proof was simply broken). You could try running Lean from the cmdline using <code>lean -j0</code> to get hopefully more stable timings. You can also set <code>profiler</code> from there: <code>lean -j0 -Dprofiler=true</code>.</p>",
        "id": 189387121,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1582975921
    },
    {
        "content": "<p>Even with my more unscientific method I can see the difference after just changing a bunch of <code>apply h1, exact h2</code> to <code>exact h1 h2</code> and <code>split, exact h3, exact h4</code> to <code>exact ⟨h3, h4⟩</code>.</p>\n<div class=\"codehilite\"><pre><span></span>/-\nelaboration of closed_pr2_of_compact took 150ms\nelaboration of closed_pr2_of_compact took 80.6ms\nelaboration of closed_pr2_of_compact took 93.1ms\nelaboration of closed_pr2_of_compact took 89.5ms\nelaboration of closed_pr2_of_compact took 111ms\nelaboration of closed_pr2_of_compact took 137ms\nelaboration of closed_pr2_of_compact took 135ms\nelaboration of closed_pr2_of_compact took 168ms\nelaboration of closed_pr2_of_compact took 177ms\nelaboration of closed_pr2_of_compact took 168ms\n-/\n</pre></div>\n\n\n<p>Does each tactic come with some sort of overhead which really means that e.g. <code>rw X, rw Y</code> is appreciably slower than <code>rw [X,Y]</code>?</p>",
        "id": 189388633,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1582978982
    }
]