[
    {
        "content": "<p>I'm playing around with z3. Trying to see how far I can push it. Initially, I am just interested in using lean to drive z3 (similar to, say an F# script), later I'll look into doing more fancy stuff.</p>\n<p>Because lean doesn't have an FFI and also because it makes is very easy replace z3 with <code>[smtlib-compatible smt solver]</code>, I'm not using the z3 api, but rather am communicating with it through pipes in a child process.</p>\n<p>Lean seems to be perfectly capable dealing with parsing, AST, etc. but I'm really struggling with IO for all the wrong reasons.</p>\n<p>The SMTLib protocol is a two-way communication protocol, not something you send a script to and get a response. You send a few commands, at some point, you may send <code>(check-sat)</code>, then <code>z3</code> is meant to send you <code>sat</code>, <code>unsat</code> or <code>unknown</code>. Depending on what you got, you then have other commands you can execute and deal with. And you can issue some other commands to get back to a different state where you can use other commands again, etc. If used from a REPL, It's really fairly intuitive.</p>\n<p>Unfortunately, the interaction really doesn't look at all like any of the IO samples I've seen like reading a file, because it's really interactive. The most natural way for me to represent such a protocol would be a state machine where transitions happen when a message is sent or received.</p>\n<p>So far, I haven't found a good way how to implement this. I can't read after each message sent, because I don't know how much data to read and the read is blocking. In a usual language, I'd either do event-based async io, or have a thread used for writing and one for reading. Also the protocol is not line-based, so I can't use that trick either.</p>\n<p>Any ideas how to go about it, or have any of you done something similar?</p>",
        "id": 205074260,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595810847
    },
    {
        "content": "<p>You might need to adapt the I/O API</p>",
        "id": 205075150,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1595812595
    },
    {
        "content": "<p>as in add API features for async IO?</p>",
        "id": 205075201,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595812692
    },
    {
        "content": "<p>Either that or read one line of output and nothing more</p>",
        "id": 205075436,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1595813222
    },
    {
        "content": "<p>I'm not sure I'm the best person to put an answer here.  I don't know anything about z3 or <code>[smtlib-compatible smt solver]</code>.  (You might also want to look at what <span class=\"user-mention\" data-user-id=\"110043\">@Gabriel Ebner</span> did with hooking up an SMT solver to Lean.)</p>\n<p>However, I can say the following. I've been playing around with using Lean to communicate (in both directions) with python via IO for machine learning..  While your needs are probably different from mine, if you can get a two-way communication going with a Python script, then you can have the script handle the communication with Z3.  I think this is similar to what <span class=\"user-mention\" data-user-id=\"110596\">@Rob Lewis</span> and <span class=\"user-mention\" data-user-id=\"110187\">@Minchao Wu</span> did with communicating between Lean and Python (<a href=\"#narrow/stream/113488-general/topic/Calling.20external.20process.20in.20a.20tactic/near/198857265\">https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/Calling.20external.20process.20in.20a.20tactic/near/198857265</a>).</p>\n<p>As for communicating between Lean and Python, I've found two ways:</p>\n<ol>\n<li>Call Lean as a process from within a python script (and have Lean communicate with stdin, stdout)</li>\n<li>Have Lean call the Python process as a child processes.  (this is probably better for your case).</li>\n</ol>\n<p>Also, in my method, you need a communication protocol.  Lean doesn't have JSON built in, but I implemented it and implemented some serializers for some of my classes.  (I also made a hacky version of JSON, since Lean's string parsing is too slow.</p>",
        "id": 205075440,
        "sender_full_name": "Jason Rute",
        "timestamp": 1595813230
    },
    {
        "content": "<p><a href=\"https://github.com/leanprover-community/mathlib/issues/1083\">#1083</a> (a long-abandoned PR that aimed to set up a connection bewteen Lean and Vampire) might be interesting too.</p>",
        "id": 205075563,
        "sender_full_name": "Bryan Gin-ge Chen",
        "timestamp": 1595813418
    },
    {
        "content": "<p>I'll look at the samples, thanks. As for z3 specifically, I used the old <code>smt2-interface</code> as well as <span class=\"user-mention\" data-user-id=\"110026\">@Simon Hudon</span> 's z3 repo. And they both don't really have a solution just hard-code the interaction. Which, whilst valid, is not very useful for my use-case.</p>",
        "id": 205075616,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595813523
    },
    {
        "content": "<p>And as for the idea of using a separate wrapper for the IO, I thought about that too, personally, I wouldn't use python, but F# out of mere preference. But I get the point and it may well be a valid option.</p>",
        "id": 205075703,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595813719
    },
    {
        "content": "<p>Also, as for the interactivity, the application I'm building is quite interactive.  Lean keeps tract of the search tree (where every node is a tactic state, the tree allows backtracking), and python (possibly using say TensorFlow) guides Lean's exploration of the search tree.  I however don't need async communication.  Each call in either direction blocks.  It's not really ready for showing yet, but if this interests you and you want a sneak peak, I'd be happy to share my private repo.</p>",
        "id": 205075710,
        "sender_full_name": "Jason Rute",
        "timestamp": 1595813751
    },
    {
        "content": "<p>To make it nice, I was thinking of sticking to the protocol, at least more or less, so I don't invent a new protocol.</p>",
        "id": 205075750,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595813764
    },
    {
        "content": "<p>well, there's a fairly trivial F# program I could write... One that always responds. That way, every call could be made blocking, because we'd know that there will be a result, eventually.</p>",
        "id": 205075763,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595813851
    },
    {
        "content": "<p>plus in such a wrapper, I can do something like base64 encode the payload, so it's always one line.</p>",
        "id": 205075805,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595813886
    },
    {
        "content": "<p>Why don't we just add to <code>system.io</code> some kind of <code>io_stream</code> type with operations like <code>open</code>, <code>read</code>, <code>write</code>?</p>",
        "id": 205085515,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595831936
    },
    {
        "content": "<p>it should be pretty easy to support that on the C++ side</p>",
        "id": 205085524,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595831957
    },
    {
        "content": "<p>Actually, never mind this already seems to exist</p>",
        "id": 205085674,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595832212
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><code><span class=\"kn\">import</span> <span class=\"n\">system</span><span class=\"bp\">.</span><span class=\"n\">io</span>\n\n<span class=\"bp\">#</span><span class=\"kn\">eval</span> <span class=\"n\">do</span>\n  <span class=\"n\">child</span> <span class=\"err\">‚Üê</span> <span class=\"n\">io</span><span class=\"bp\">.</span><span class=\"n\">proc</span><span class=\"bp\">.</span><span class=\"n\">spawn</span> <span class=\"o\">{</span>\n    <span class=\"n\">cmd</span> <span class=\"o\">:=</span> <span class=\"s2\">&quot;tee&quot;</span><span class=\"o\">,</span>\n    <span class=\"n\">args</span> <span class=\"o\">:=</span> <span class=\"o\">[</span><span class=\"s2\">&quot;/dev/null&quot;</span><span class=\"o\">],</span>\n    <span class=\"n\">stdin</span> <span class=\"o\">:=</span> <span class=\"n\">io</span><span class=\"bp\">.</span><span class=\"n\">process</span><span class=\"bp\">.</span><span class=\"n\">stdio</span><span class=\"bp\">.</span><span class=\"n\">piped</span><span class=\"o\">,</span>\n    <span class=\"n\">stdout</span> <span class=\"o\">:=</span> <span class=\"n\">io</span><span class=\"bp\">.</span><span class=\"n\">process</span><span class=\"bp\">.</span><span class=\"n\">stdio</span><span class=\"bp\">.</span><span class=\"n\">piped</span><span class=\"o\">,</span>\n    <span class=\"n\">stderr</span> <span class=\"o\">:=</span> <span class=\"n\">io</span><span class=\"bp\">.</span><span class=\"n\">process</span><span class=\"bp\">.</span><span class=\"n\">stdio</span><span class=\"bp\">.</span><span class=\"n\">piped</span><span class=\"o\">},</span>\n  <span class=\"n\">io</span><span class=\"bp\">.</span><span class=\"n\">fs</span><span class=\"bp\">.</span><span class=\"n\">put_str</span> <span class=\"n\">child</span><span class=\"bp\">.</span><span class=\"n\">stdin</span> <span class=\"s2\">&quot;foo</span><span class=\"se\">\\n</span><span class=\"s2\">&quot;</span><span class=\"o\">,</span>\n  <span class=\"n\">io</span><span class=\"bp\">.</span><span class=\"n\">fs</span><span class=\"bp\">.</span><span class=\"n\">flush</span> <span class=\"n\">child</span><span class=\"bp\">.</span><span class=\"n\">stdin</span><span class=\"o\">,</span>\n  <span class=\"n\">s</span> <span class=\"err\">‚Üê</span> <span class=\"n\">io</span><span class=\"bp\">.</span><span class=\"n\">fs</span><span class=\"bp\">.</span><span class=\"n\">read</span> <span class=\"n\">child</span><span class=\"bp\">.</span><span class=\"n\">stdout</span> <span class=\"mi\">4</span><span class=\"o\">,</span>\n  <span class=\"n\">io</span><span class=\"bp\">.</span><span class=\"n\">run_tactic</span> <span class=\"o\">(</span><span class=\"n\">tactic</span><span class=\"bp\">.</span><span class=\"n\">trace</span> <span class=\"n\">s</span><span class=\"bp\">.</span><span class=\"n\">to_string</span><span class=\"o\">),</span> <span class=\"c1\">-- foo</span>\n  <span class=\"n\">io</span><span class=\"bp\">.</span><span class=\"n\">fs</span><span class=\"bp\">.</span><span class=\"n\">put_str</span> <span class=\"n\">child</span><span class=\"bp\">.</span><span class=\"n\">stdin</span> <span class=\"s2\">&quot;bar</span><span class=\"se\">\\n</span><span class=\"s2\">&quot;</span><span class=\"o\">,</span>\n  <span class=\"n\">io</span><span class=\"bp\">.</span><span class=\"n\">fs</span><span class=\"bp\">.</span><span class=\"n\">flush</span> <span class=\"n\">child</span><span class=\"bp\">.</span><span class=\"n\">stdin</span><span class=\"o\">,</span>\n  <span class=\"n\">s</span> <span class=\"err\">‚Üê</span> <span class=\"n\">io</span><span class=\"bp\">.</span><span class=\"n\">fs</span><span class=\"bp\">.</span><span class=\"n\">read</span> <span class=\"n\">child</span><span class=\"bp\">.</span><span class=\"n\">stdout</span> <span class=\"mi\">4</span><span class=\"o\">,</span>\n  <span class=\"n\">io</span><span class=\"bp\">.</span><span class=\"n\">run_tactic</span> <span class=\"o\">(</span><span class=\"n\">tactic</span><span class=\"bp\">.</span><span class=\"n\">trace</span> <span class=\"n\">s</span><span class=\"bp\">.</span><span class=\"n\">to_string</span><span class=\"o\">),</span> <span class=\"c1\">-- bar</span>\n  <span class=\"n\">io</span><span class=\"bp\">.</span><span class=\"n\">fs</span><span class=\"bp\">.</span><span class=\"n\">close</span> <span class=\"n\">child</span><span class=\"bp\">.</span><span class=\"n\">stdin</span><span class=\"o\">,</span>\n  <span class=\"n\">exitv</span> <span class=\"err\">‚Üê</span> <span class=\"n\">io</span><span class=\"bp\">.</span><span class=\"n\">proc</span><span class=\"bp\">.</span><span class=\"n\">wait</span> <span class=\"n\">child</span><span class=\"o\">,</span>\n  <span class=\"n\">guard</span> <span class=\"o\">(</span><span class=\"n\">exitv</span> <span class=\"bp\">=</span> <span class=\"mi\">0</span><span class=\"o\">)</span>\n</code></pre></div>",
        "id": 205086647,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595833499
    },
    {
        "content": "<p>It shouldn't be hard to put an SMTLIB wrapper around this interaction</p>",
        "id": 205086683,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595833557
    },
    {
        "content": "<p>right, so this is what I have right now. The problem with your line <code>s &lt;- io.fs.read child.stdout 4</code>, is that I don't have <code>4</code> and the call is blocking. I can't do a read to end as it's blocking, I can't read a buffer of, say 1024, because it blocks until it either gets that many or reaches EOF, and I can't read-line because some responses are multi-line and I'd have to parse the (partial) response to guess that there should be more data to come. </p>\n<p>Apparently how the F* repo is (or at least was, maybe they changed that in the meantime) doing this is by weaving in an <code>(echo \"Done!\")</code>after every submit they do. Then they know, that the last thing they need to read is a <code>Done!</code> message. </p>\n<p>Of all the solutions I've seen so far, this feels like the simplest and moderately clean. Because I can then use just the <code>get_line</code> function over and over, until I read my marker line, knowing that everything I read before would have been the response to the user's request. </p>\n<p>And it's safe in the sense, that even in case there is a clash with the string (I'd use a much more cryptic marker to reduce the chances of a conflict), <code>get_line</code> will still not be blocked, but at worst will not return the whole output. So at least the process won't just hang.</p>",
        "id": 205093864,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595840328
    },
    {
        "content": "<p>You can tell that SMTLIB output is done with one character lookahead</p>",
        "id": 205094160,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595840545
    },
    {
        "content": "<p>so <code>get_char</code> should do the trick</p>",
        "id": 205094164,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595840552
    },
    {
        "content": "<p>I'm very skeptical that you'll be able to get a robust solutions by fiddling around. Async programming is a topic of its own, and clearly very difficult to get right.</p>",
        "id": 205094205,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1595840599
    },
    {
        "content": "<p>not really, after all writing to a pipe is not atomic.</p>",
        "id": 205094206,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595840600
    },
    {
        "content": "<p>I don't follow</p>",
        "id": 205094227,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595840621
    },
    {
        "content": "<p>I assume the SMT prover flushes after each response</p>",
        "id": 205094271,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595840642
    },
    {
        "content": "<p>the marker is a pretty clear delimiter. But just a look-ahead can totally read half a message.</p>",
        "id": 205094296,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595840653
    },
    {
        "content": "<p>I'd be really, really surprised... a model can be huge.</p>",
        "id": 205094317,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595840672
    },
    {
        "content": "<p>so there's a good chance they will write multiple times before the message is over.</p>",
        "id": 205094333,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595840692
    },
    {
        "content": "<p>If the response is a keyword like <code>sat\\n</code> then the whitespace indicates the end, if it's a composite sexpr like <code>(echo bla bla)</code> then the end paren does the job</p>",
        "id": 205094354,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595840706
    },
    {
        "content": "<p>also if the look-ahead is blocking, that's enough to hang the process and if it's non-blocking, you may read nothing because z3 is still computing.</p>",
        "id": 205094374,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595840726
    },
    {
        "content": "<p>I looked at some SMTLIB parsers and they just use getchar</p>",
        "id": 205094403,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595840755
    },
    {
        "content": "<p>as in call getchar for every single char?</p>",
        "id": 205094512,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595840824
    },
    {
        "content": "<p>yeah</p>",
        "id": 205094517,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595840828
    },
    {
        "content": "<p>ultimately, that's what the parser does</p>",
        "id": 205094524,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595840842
    },
    {
        "content": "<p>that's an awful lot of calls, what's wrong with the marker?</p>",
        "id": 205094532,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595840849
    },
    {
        "content": "<p>I was thinking making a function like this: <code>list command -&gt; response</code></p>",
        "id": 205094603,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595840887
    },
    {
        "content": "<p>and after each batch, I'll just weave in the marker.</p>",
        "id": 205094612,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595840901
    },
    {
        "content": "<p>Sure, you can do that regardless of how parsing works</p>",
        "id": 205094613,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595840905
    },
    {
        "content": "<p>that way we still get good behaviour w.r.t. large batches, because only one message per batch.</p>",
        "id": 205094634,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595840929
    },
    {
        "content": "<p>that's not excessive costs.</p>",
        "id": 205094639,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595840936
    },
    {
        "content": "<p>and it makes for a very clear delimiter, imo.</p>",
        "id": 205094650,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595840945
    },
    {
        "content": "<p>Sure, if the format lets you do that, then that will allow you to use a bigger buffer</p>",
        "id": 205094731,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595841005
    },
    {
        "content": "<p>It does and honestly I was fairly re-assured that a big project was using that approach, it suggests that it holds up in practice. Even if feels a bit hacky, it lets us pretend we are doing RPC.</p>",
        "id": 205094794,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595841092
    },
    {
        "content": "<p>which is nice from an API point of view.</p>",
        "id": 205094804,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595841100
    },
    {
        "content": "<p>At least JSON-RPC uses a <code>Content-Length: n</code> at the start of the response so you don't have to play that game</p>",
        "id": 205094878,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595841131
    },
    {
        "content": "<p>right, that's quite nice.</p>",
        "id": 205094933,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595841187
    },
    {
        "content": "<p>But this seems like an optimization, I wouldn't bother until the rest of the arch is working first</p>",
        "id": 205094934,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595841187
    },
    {
        "content": "<p>Something tells me that repeated getchar calls will be the least of your performance worries</p>",
        "id": 205095040,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595841246
    },
    {
        "content": "<p>I can't really change how z3 returns its responses. And in the first phase, I want to just do a z3 binding.</p>",
        "id": 205095062,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595841275
    },
    {
        "content": "<p>and ideally not make very strong assumptions on the order of commands, etc.</p>",
        "id": 205095075,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595841294
    },
    {
        "content": "<p>and it's pretty easy to code a parser using lots of getchar</p>",
        "id": 205095080,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595841299
    },
    {
        "content": "<p>but what do you do if there is nothing to read at all?</p>",
        "id": 205095101,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595841319
    },
    {
        "content": "<p>block</p>",
        "id": 205095107,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595841326
    },
    {
        "content": "<p>i.e. there just is no response</p>",
        "id": 205095109,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595841327
    },
    {
        "content": "<p>well, SMTlib doesn't produce a response for every operation.</p>",
        "id": 205095131,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595841349
    },
    {
        "content": "<p>you should know if you expect a response, and if z3 hangs then so should you</p>",
        "id": 205095135,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595841353
    },
    {
        "content": "<p>the smtlib protocol determines what you are looking for</p>",
        "id": 205095190,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595841378
    },
    {
        "content": "<p>if I do that, then the IO code and command code are very tightly coupled. Because the decision to read or not read depends on the concrete command.</p>",
        "id": 205095218,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595841413
    },
    {
        "content": "<p>So I can't abstract that away in a natural way.</p>",
        "id": 205095227,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595841427
    },
    {
        "content": "<p>You can have a <code>read_command : io response</code></p>",
        "id": 205095242,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595841443
    },
    {
        "content": "<p>Whereas adding the marker makes every reponse always end in a <code>Done!</code>.</p>",
        "id": 205095247,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595841447
    },
    {
        "content": "<p>I was thinking about that one, too, actually</p>",
        "id": 205095304,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595841484
    },
    {
        "content": "<p>and then <code>run_smt_cmd : request -&gt; io response</code> will do <code>return response.none</code> on some requests</p>",
        "id": 205095322,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595841501
    },
    {
        "content": "<p>and <code>read_command</code> on others</p>",
        "id": 205095330,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595841513
    },
    {
        "content": "<p>So you'd code up the whole spec?</p>",
        "id": 205095354,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595841540
    },
    {
        "content": "<p>the parts that matter to you, at least</p>",
        "id": 205095372,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595841557
    },
    {
        "content": "<p>there's also a config option, though. This lets the user change the behaviour of z3 as to it would write <code>success</code> after every command.</p>",
        "id": 205095507,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595841680
    },
    {
        "content": "<p>and that's totally a command the user can send.</p>",
        "id": 205095513,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595841691
    },
    {
        "content": "<p>so now the reading of responses even depends on the exact order of commands.</p>",
        "id": 205095533,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595841716
    },
    {
        "content": "<p>all of that is possible, but feels like a huge amount of complexity just to avoid a single marker from the sender side.</p>",
        "id": 205095586,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595841741
    },
    {
        "content": "<p>do you have any concrete issues with the approach or are you merely offering other ways to achieve the same outcome?</p>",
        "id": 205095612,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595841776
    },
    {
        "content": "<p>If you don't want that option, then ignore it</p>",
        "id": 205095623,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595841792
    },
    {
        "content": "<p>if you have a grammar of commands to send, you can just skip that one</p>",
        "id": 205095646,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595841821
    },
    {
        "content": "<p>I see, so this may become less of an issue once I have more code, then.</p>",
        "id": 205095728,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595841878
    },
    {
        "content": "<p>If you actually want to talk in smtlib then one would expect a fully detailed (if incomplete) grammar at some point. Trading sexprs only gets you so far</p>",
        "id": 205095736,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595841890
    },
    {
        "content": "<p>At this early stage I'm submitting s-expressions directly</p>",
        "id": 205095739,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595841895
    },
    {
        "content": "<p>yes, I definitely agree with that.</p>",
        "id": 205095763,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595841915
    },
    {
        "content": "<p>and if you are at the trading sexprs stage then you can just pretend that inconvenient options don't exist and trust the user not to send them</p>",
        "id": 205095821,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595841955
    },
    {
        "content": "<p>In the end, though, I think I really prefer the option of adding the marker. Then I can completely hide that inside of the io loop that the user doesn't see and they see much the same thing as they would in a repl.</p>",
        "id": 205095897,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595842004
    },
    {
        "content": "<p>and it's simple which is something I like for maintenance.</p>",
        "id": 205095928,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595842034
    },
    {
        "content": "<p>and the user can't break things by changing options.</p>",
        "id": 205095972,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595842076
    },
    {
        "content": "<p>You should have the parser hooked up to the IO loop anyway (even if the actual mechanism is hidden in some monad transformers), because otherwise you have to buffer more than necessary</p>",
        "id": 205096287,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595842292
    },
    {
        "content": "<p>my current thinking was to use <code>get_line</code> repeatedly until the marker and use the parser on the output, possibly per line possibly at the end. And the output of the monad would be a response, not a string.</p>",
        "id": 205096452,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595842428
    },
    {
        "content": "<p>it's mostly about avoiding to block accidently without restricting the user's API artificially. So I'm weighing options and trying to compare advantages and issues with any.</p>",
        "id": 205096580,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595842502
    },
    {
        "content": "<p>I think that any parse approach can be encompassed in <code>request -&gt; io response</code>, or <code>\\Pi r : request, smt_monad (response r)</code> if you want to get fancy</p>",
        "id": 205096712,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595842579
    },
    {
        "content": "<p>So far my main concern about the read one char at a time are possibly a huge number of api calls (somewhat minor, I guess) and the complexity to make sure we don't accidently read when there's nothing to read, i.e. the chances of a block.</p>\n<p>My main criticism of the \"send a marker\" approach is that it feels a bit hacky</p>",
        "id": 205096741,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595842601
    },
    {
        "content": "<p>I suspect that there are so many buffers between lean and the actual IO that many getchar calls won't actually be a problem</p>",
        "id": 205096795,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595842658
    },
    {
        "content": "<p>good to know!</p>",
        "id": 205096817,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595842673
    },
    {
        "content": "<p>do you have some further criticism for the marker idea that I need to consider, btw?</p>",
        "id": 205096921,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595842716
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/Ideas.20for.20two-way.20communication.20between.20processes/near/205095040\">said</a>:</p>\n<blockquote>\n<p>Something tells me that repeated getchar calls will be the least of your performance worries</p>\n</blockquote>\n<p>In my experience the parsing is the slowest part if you do it in pure Lean.  I used Lean's <a href=\"https://github.com/leanprover-community/lean/blob/549e2fed50b361d0d49a3dd1e7ccb6de9440059b/library/data/buffer/parser.lean\">parsing library</a> (not to be confused with Lean's parser which is not available inside tactics), and I've found it really slow.  I think the slowdown is character-by-character evaluation.</p>",
        "id": 205105363,
        "sender_full_name": "Jason Rute",
        "timestamp": 1595849320
    },
    {
        "content": "<p>Even with batched OS calls, you will usually have a character parser to parse that text, and that will be slow. But I don't really see an alternative unless you somehow do the work outside lean</p>",
        "id": 205105664,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595849561
    },
    {
        "content": "<p>I don't think it's that bad, actually. Because generally the input is much, much bigger.</p>",
        "id": 205105941,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595849798
    },
    {
        "content": "<p>and that's not parsed, but just concatenated.</p>",
        "id": 205105945,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595849809
    },
    {
        "content": "<p>Plus, I'm hoping lean4 would make it better in future.</p>",
        "id": 205105976,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595849856
    },
    {
        "content": "<p>if parsing becomes the bottle neck, I can always do the parsing in F# and spit out some trivially-parsable thing for lean.</p>",
        "id": 205106060,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595849899
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span>  That is sort of my point.  Parsing is the bottle neck (on the Lean side.  Of course, if Lean blocks, Z3 is probably the bottleneck overall).  Although, as I think about it, my parsing woes where related to parsing quoted strings.  When I changed my protocol so that I didn't have quoted strings (using a bastardized version of JSON), then it was much faster.)</p>",
        "id": 205106109,
        "sender_full_name": "Jason Rute",
        "timestamp": 1595849943
    },
    {
        "content": "<p>I mean... technically my parser will deal with quoted strings.</p>",
        "id": 205106608,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595850247
    },
    {
        "content": "<p>But i can always put that rule last</p>",
        "id": 205106616,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595850255
    },
    {
        "content": "<p>and since in practice, we probably get numbers it may be ok.</p>",
        "id": 205106630,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595850270
    },
    {
        "content": "<p>You could structure the parser as a finite (or infinite) state machine</p>",
        "id": 205106821,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595850379
    },
    {
        "content": "<p>I read on the repo of SMTlib in F#, that the guy ran 40k test scripts for his parser from the smtlib homepage. Maybe I can do that, too.</p>",
        "id": 205106927,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595850466
    },
    {
        "content": "<p>It might be okay to use parser combinators if you liberally sprinkle <code>@[inline]</code> but lean doesn't do nearly as much optimization as haskell to make functional programming style efficient</p>",
        "id": 205106929,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595850469
    },
    {
        "content": "<p>that way, it would both be known to work and reasonably efficient.</p>",
        "id": 205106980,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595850484
    },
    {
        "content": "<p>anyway, I don't think that it's wasted effort, because either way, we probably want the inductives for commands available in lean. And I can always use an existing F# lib for parsing.</p>",
        "id": 205107156,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595850610
    },
    {
        "content": "<p>and then do the trivially-parsable format for lean.</p>",
        "id": 205107167,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595850622
    },
    {
        "content": "<p>It would only mean replacing the parser whilst leaving everything else in place.</p>",
        "id": 205107194,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595850644
    },
    {
        "content": "<p>Do you have a smtlib sexpr parser?</p>",
        "id": 205107243,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595850682
    },
    {
        "content": "<p>I am working on one for lean and there's one for F#.</p>",
        "id": 205107410,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595850778
    },
    {
        "content": "<p>the f# one is just an existing lib.</p>",
        "id": 205107423,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595850786
    },
    {
        "content": "<p>so at worst, the lean sexpr parser is wasted.</p>",
        "id": 205107445,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595850807
    },
    {
        "content": "<p>a sexpr parser is obviously independently useful</p>",
        "id": 205107558,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595850877
    },
    {
        "content": "<p>smtlib sexprs are slightly more complicated because they have things like <code>|long atoms|</code> and <code>\"weird \"\"string\"\" quoting\"</code></p>",
        "id": 205107599,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595850922
    },
    {
        "content": "<p>oh I see, then we could make the sexpr parser separately packaged and the SMTlib protocol on top of that.</p>",
        "id": 205107738,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595851030
    },
    {
        "content": "<p>as two different things.</p>",
        "id": 205107743,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595851036
    },
    {
        "content": "<p>hmm, can you even make an sexpr parser that smtlib uses, then? Don't you have to tokenize differently like the long atoms?</p>",
        "id": 205107987,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595851230
    },
    {
        "content": "<p>i mean as n sexpr, <code>(|what does| \"this \"\"tokenize\"\" as?\")</code></p>",
        "id": 205108036,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595851266
    },
    {
        "content": "<p>You probably need a dedicated smtlib style sexpr parser, which can be separated from the smtlib grammar parsing</p>",
        "id": 205108046,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595851272
    },
    {
        "content": "<p>right, that makes sense.</p>",
        "id": 205108060,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595851286
    },
    {
        "content": "<p>my idea was to make the smtlib sexpr parser first.</p>",
        "id": 205108076,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595851311
    },
    {
        "content": "<p>and then just pattern match various s-exprs to build commands.</p>",
        "id": 205108095,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595851321
    },
    {
        "content": "<p>you could try to generalize the pure sexpr part, but I think it would make the parser a lot slower</p>",
        "id": 205108132,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595851324
    },
    {
        "content": "<p>Ok, so the agreed plan of action for now is:</p>\n<ul>\n<li>make an smtlib-style sexpr parser</li>\n<li>run a large test suite</li>\n<li>if it's good enough, continue, else use some other language of the parsing, simplifying Lean's job</li>\n<li>after that pattern-match sexprs to build commands</li>\n</ul>",
        "id": 205108544,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595851661
    },
    {
        "content": "<p>If it helps, in that example I sent you, I did something similar, except with JSON instead of sexprs.  I had a general purpose JSON parser which read in and parsed JSON to an inductive type <code>json</code>. (Besides the parser, I also built a serializer for the <code>json</code> type.) Then for my API, I made custom structures and inductive types.  All serialization and deserialization of the API objects went through the <code>json</code> type.  (I even wrote a python script which took a lean structure or inductive type and automatically wrote all the boilerplate to convert to/from <code>json</code>.  (I've been spoiled by Google's Protobuf format which automatically turns a protobuf API into whatever language you need, so I wanted to reproduce a little of that magic.)</p>",
        "id": 205109713,
        "sender_full_name": "Jason Rute",
        "timestamp": 1595852455
    },
    {
        "content": "<p>right, so I have a \"serializer\" for the s-exprs that I support.</p>",
        "id": 205110663,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595853122
    },
    {
        "content": "<p>but no parser yet.</p>",
        "id": 205110702,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595853125
    },
    {
        "content": "<p>It's not really fully-fletched yet, but it's enough to solve sudoku in z3 :P</p>",
        "id": 205110731,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595853149
    },
    {
        "content": "<p>in particular, I'm not escaping strings yet, etc.</p>",
        "id": 205110777,
        "sender_full_name": "Daniel Fabian",
        "timestamp": 1595853191
    }
]