[
    {
        "content": "<p>my understanding was zulip uses an old version of pygments, and that the lean pygments update was never merged to begin with</p>",
        "id": 123002866,
        "sender_full_name": "Andrew Ashworth",
        "timestamp": 1519662213
    },
    {
        "content": "<p>we can still do </p>\n<div class=\"codehilite\"><pre><span></span><span class=\"n\">meta</span> <span class=\"n\">def</span> <span class=\"n\">f</span> <span class=\"o\">:=</span> <span class=\"k\">by</span> <span class=\"n\">sorry</span>\n</pre></div>",
        "id": 123002921,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1519662251
    },
    {
        "content": "<p>which is a bit disappointing</p>",
        "id": 123002930,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1519662274
    },
    {
        "content": "<p>I had better luck with earlier tests</p>",
        "id": 123002938,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1519662284
    },
    {
        "content": "<p>I don't think there is such an option</p>",
        "id": 123002948,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1519662305
    },
    {
        "content": "<p>let me try again:</p>\n<div class=\"codehilite\"><pre><span></span><span class=\"kn\">example</span> <span class=\"o\">:</span> <span class=\"mi\">1</span> <span class=\"bp\">+</span> <span class=\"mi\">1</span> <span class=\"bp\">=</span> <span class=\"mi\">2</span> <span class=\"o\">:=</span> <span class=\"k\">by</span> <span class=\"n\">norm_num</span>\n</pre></div>",
        "id": 123002966,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1519662354
    },
    {
        "content": "<p>that one is nicer</p>",
        "id": 123003003,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1519662363
    },
    {
        "content": "<p>pygments doesn't like meta...</p>",
        "id": 123003010,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1519662389
    },
    {
        "content": "<p>i think pygments for lean is still on highlighting based on lean 2's syntax, iirc</p>",
        "id": 123003170,
        "sender_full_name": "Andrew Ashworth",
        "timestamp": 1519662613
    },
    {
        "content": "<p>I guess that could explain a lot</p>",
        "id": 123003200,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1519662683
    },
    {
        "content": "<p>yeah, first i think we'll need to submit a support ticket to zulip and see if they will fork pygments for us, and then we can update the pygment's lexer file for lean</p>",
        "id": 123003261,
        "sender_full_name": "Andrew Ashworth",
        "timestamp": 1519662741
    },
    {
        "content": "<p>Yes, I guess <span class=\"user-mention\" data-user-email=\"rwbarton@gmail.com\" data-user-id=\"110032\">@Reid Barton</span> will do that for us</p>",
        "id": 123003279,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1519662789
    },
    {
        "content": "<p>I've already checked with the Zulip devs and they would be happy to fork pygments if there is a request to do so.</p>",
        "id": 123003285,
        "sender_full_name": "Reid Barton",
        "timestamp": 1519662806
    },
    {
        "content": "<p>If someone here can produce a patch then I can take care of getting it upstreamed</p>",
        "id": 123003336,
        "sender_full_name": "Reid Barton",
        "timestamp": 1519662881
    },
    {
        "content": "<p>Great, <span class=\"user-mention\" data-user-email=\"sebasti@nullri.ch\" data-user-id=\"110024\">@Sebastian Ullrich</span> already has everything we need</p>",
        "id": 123003356,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1519662957
    },
    {
        "content": "<p>I'm requested elsewhere. See you</p>",
        "id": 123003400,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1519662970
    },
    {
        "content": "<p>Our pygments fork is at <a href=\"https://bitbucket.org/gebner/pygments-main\" target=\"_blank\" title=\"https://bitbucket.org/gebner/pygments-main\">https://bitbucket.org/gebner/pygments-main</a></p>",
        "id": 123003826,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1519663713
    },
    {
        "content": "<p>I ran all of mathlib and a couple of my projects through Gabriel's pygments fork, using the following command:</p>\n<div class=\"codehilite\"><pre><span></span>find . -name &#39;*.lean&#39; \\( -exec ~/.local/bin/pygmentize -l lean -F raiseonerror &#39;{}&#39; &#39;;&#39; -o -exec echo $&#39;\\npygmentize failed:&#39; &#39;{}&#39; &#39;;&#39; -quit \\)\n</pre></div>\n\n\n<p>There was just one lexer error, it doesn't know about the escape sequence <code>\"\\t\"</code>. <span class=\"user-mention\" data-user-id=\"110043\">@Gabriel Ebner</span> should I submit a PR, or would it be easier for you to just fix it yourself?</p>",
        "id": 155163511,
        "sender_full_name": "Reid Barton",
        "timestamp": 1547553294
    },
    {
        "content": "<p>(Minimum failing example: <code>example : string := \"\\t\"</code>)</p>",
        "id": 155163531,
        "sender_full_name": "Reid Barton",
        "timestamp": 1547553347
    },
    {
        "content": "<p>It also doesn't know about <code>\"\\x12\"</code>, <code>\"\\u1234\"</code>, or <code>\"\\'\"</code> (I checked the Lean source to see what escape sequences exist)</p>",
        "id": 155163672,
        "sender_full_name": "Reid Barton",
        "timestamp": 1547553516
    },
    {
        "content": "<p>Please file a PR.</p>",
        "id": 155163795,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1547553677
    },
    {
        "content": "<p>OK</p>",
        "id": 155163875,
        "sender_full_name": "Reid Barton",
        "timestamp": 1547553759
    },
    {
        "content": "<p>I think you can get pwned with <code>-exec</code> if someone writes a malicious mathlib PR, although I've never understood the details (I read this in the find man page)</p>",
        "id": 155164033,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1547553931
    },
    {
        "content": "<blockquote>\n<p>Please file a PR.</p>\n</blockquote>\n<p>I think I managed to do this.</p>",
        "id": 155167115,
        "sender_full_name": "Reid Barton",
        "timestamp": 1547557369
    },
    {
        "content": "<p>Merged.  I've also given you write access if you want.</p>",
        "id": 155167460,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1547557735
    },
    {
        "content": "<p>I know <span class=\"user-mention\" data-user-id=\"110031\">@Patrick Massot</span> was also having LaTeX problems with some specific characters but I don't know whether that's something that would be fixed within pygments or outside it</p>",
        "id": 155168459,
        "sender_full_name": "Reid Barton",
        "timestamp": 1547558625
    },
    {
        "content": "<p>Reid, you only need to try using pygment with LaTeX to see it's all broken, and needs fixing from pygment</p>",
        "id": 155168553,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1547558713
    },
    {
        "content": "<p>Now I'm confused: I can't reproduce the problem</p>",
        "id": 155169307,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1547559496
    },
    {
        "content": "<p>The following works:</p>\n<div class=\"codehilite\"><pre><span></span>\\documentclass{article}\n\n\\usepackage{newunicodechar}\n\n\\newunicodechar{Œ±}{\\ensuremath{\\alpha}}\n\\newunicodechar{Œ≤}{\\ensuremath{\\beta}}\n\\newunicodechar{Œπ}{\\ensuremath{\\iota}}\n\\newunicodechar{ùì§}{\\ensuremath{\\mathcal{U}}}\n\\newunicodechar{‚Åª}{\\ensuremath{^-}}\n\\newunicodechar{¬π}{\\ensuremath{^1}}\n\\newunicodechar{‚àà}{\\ensuremath{\\in}}\n\\newunicodechar{‚àò}{\\ensuremath{\\circ}}\n\\newunicodechar{‚àÄ}{\\ensuremath{\\forall}}\n\\newunicodechar{‚àÉ}{\\ensuremath{\\exists}}\n\\newunicodechar{ùìù}{\\ensuremath{\\mathcal{N}}}\n\\newunicodechar{‚®Ø}{\\ensuremath{\\mathcal{\\times}}}\n\\newunicodechar{‚ü®}{\\ensuremath{\\langle}}\n\\newunicodechar{‚ü©}{\\ensuremath{\\rangle}}\n\n\\usepackage{minted}\n\\begin{document}\n\\begin{minted}{lean}\nexample  {f : Œ± ‚Üí Œ≤} (hf : uniform_continuous&#39; f) : continuous f :=\nsuffices ‚àÄ a, ‚àÄ V ‚àà ùìù (f a), f ‚Åª¬π&#39; V ‚àà ùìù a,\n  from continuous_iff_nhds_sets.2 this,\nassume a V Vin,\nsuffices ‚àÉ U ‚àà ùì§ Œ±, f ‚Åª¬π&#39; V = Œπ a ‚Åª¬π&#39; U,  by rwa mem_nhds_uniformity&#39;,\nhave exW : ‚àÉ W ‚àà ùì§ Œ≤, V = Œπ (f a) ‚Åª¬π&#39; W, by rwa mem_nhds_uniformity&#39; at Vin,\nlet ‚ü®W, W_in, hWV‚ü© := exW in\n‚ü®(f ‚®Ø f) ‚Åª¬π&#39; W, hf W W_in,  -- let&#39;s use U = (f ‚®Ø f) ‚Åª¬π&#39; W\n  calc\n    f ‚Åª¬π&#39; V = f ‚Åª¬π&#39; (Œπ (f a) ‚Åª¬π&#39; W) : by rw hWV\n        ... = (Œπ (f a) ‚àò f) ‚Åª¬π&#39; W   : rfl\n        ... = (f‚®Øf ‚àò Œπ a) ‚Åª¬π&#39; W     : by rw show Œπ (f a) ‚àò f = (f ‚®Ø f) ‚àò Œπ a,\n                                            by ext ; refl\n        ... = Œπ a ‚Åª¬π&#39; (f‚®Øf ‚Åª¬π&#39; W)   : rfl‚ü©\n\\end{minted}\n\\end{document}\n</pre></div>\n\n\n<p>compiled using <code> xelatex -shell-escape test.tex</code> after installing Gabriel's pygment fork</p>",
        "id": 155169837,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1547559964
    },
    {
        "content": "<p>of course the <code>newunicodechar</code> lines are ugly, and you can't even do it once and for all because of TeX super small memory capacity. But this is not related to pygment</p>",
        "id": 155169965,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1547560071
    },
    {
        "content": "<p>AFAIR, we at some point declared a \"fallback\" token class in the Lean pygments tokenizer so that it should never fail on an unknown notation now</p>",
        "id": 155170760,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1547560705
    },
    {
        "content": "<p>If you use a font with enough symbols (such as the Isabelle fonts I sent you the other day), everything works out of the box without any need for <code>\\newunicodechar</code>.<br>\nUnrelated (and out of topic): should I PR <a href=\"https://github.com/sgouezel/mathlib/tree/essai6\" target=\"_blank\" title=\"https://github.com/sgouezel/mathlib/tree/essai6\">https://github.com/sgouezel/mathlib/tree/essai6</a> at once, or split it in smaller bits (and maybe wait for the refactoring)? :)</p>",
        "id": 155171886,
        "sender_full_name": "Sebastien Gouezel",
        "timestamp": 1547561703
    },
    {
        "content": "<p>Oh, I forgot this email! I'll try to find it back</p>",
        "id": 155172615,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1547562417
    },
    {
        "content": "<p>About the PR, here is a rule of thumb: each time GitHub says \"Large diffs are not rendered by default\" you may consider splitting in smaller bits</p>",
        "id": 155172655,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1547562448
    },
    {
        "content": "<p>I think if you want reasonably fast merging you should aim for &lt;200 lines per PR. If you are adding a new file, I guess you can make them a bit larger. But everything &gt;500 lines seems to just rot away in the queue.</p>",
        "id": 155172807,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1547562601
    },
    {
        "content": "<p>We are talking about \" 3,734 additions and 264 deletions. \" in one commit here</p>",
        "id": 155172875,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1547562626
    },
    {
        "content": "<p>I do understand that this means you will have to create 10-20 PRs...</p>",
        "id": 155172881,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1547562632
    },
    {
        "content": "<p>Let's wait for the reorganization maybe</p>",
        "id": 155172895,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1547562649
    },
    {
        "content": "<p>My question was mainly a joke, of course I won't PR it in one go. And yes, I will wait for the refactoring before I submit anything. By the way, I am really happy to have done something in Lean (define the space of all nonempty compact metric spaces, with the Gromov-Hausdorff distance) that does not even make sense in Isabelle.</p>",
        "id": 155173389,
        "sender_full_name": "Sebastien Gouezel",
        "timestamp": 1547563047
    },
    {
        "content": "<p>Does it directly make sense in DTT, or did you still have to cheat a bit?</p>",
        "id": 155173468,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1547563104
    },
    {
        "content": "<p>It makes sense to consider all compact subsets of <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi mathvariant=\"normal\">‚Ñì</mi><mi mathvariant=\"normal\">‚àû</mi></msup><mo>(</mo><mrow><mi mathvariant=\"double-struck\">N</mi></mrow><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\ell^\\infty(\\mathbb{N})</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathrm\">‚Ñì</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.664392em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">‚àû</span></span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathbb\">N</span></span><span class=\"mclose\">)</span></span></span></span> modulo isometry (and it also makes sense in Isabelle). Call the quotient <code>GH_space</code>. It is easy to check that any compact metric space can be isometrically embedded in <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi mathvariant=\"normal\">‚Ñì</mi><mi mathvariant=\"normal\">‚àû</mi></msup><mo>(</mo><mrow><mi mathvariant=\"double-struck\">N</mi></mrow><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\ell^\\infty(\\mathbb{N})</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathrm\">‚Ñì</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.664392em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">‚àû</span></span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathbb\">N</span></span><span class=\"mclose\">)</span></span></span></span>, which gives a canonical map associating to any compact metric type a <code>GH_space</code> element. This is the part that does not make sense in Isabelle: you can not define a map that will take a type (with some additional typeclass properties) and yield an element of another type.</p>",
        "id": 155184044,
        "sender_full_name": "Sebastien Gouezel",
        "timestamp": 1547570322
    },
    {
        "content": "<p>I understand that. But my distant memory of GH distance between X and Y  involve sending X and Y into any other metric space. Is such a definition already problematic (and only heuristic) in set theory?</p>",
        "id": 155184670,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1547570915
    },
    {
        "content": "<blockquote>\n<p>But my distant memory of GH distance between X and Y  involve sending X and Y into any other metric space. Is such a definition already problematic (and only heuristic) in set theory?</p>\n</blockquote>\n<p>Textbooks do not really go to such details, but they should: if you say \"all compact metric spaces up to isometry\", this is not well defined (but if you notice that the cardinal of such a space is bounded, then everything is easy to solve). In the same way, if you say \"send X and Y to all metric spaces\", this is not well defined, but in fact all that matters is the union of the images of X and Y, which is compact and therefore has bounded cardinal. This is essentially what I do, saying that it is enough to consider embeddings in <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi mathvariant=\"normal\">‚Ñì</mi><mi mathvariant=\"normal\">‚àû</mi></msup><mo>(</mo><mrow><mi mathvariant=\"double-struck\">N</mi></mrow><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\ell^\\infty(\\mathbb{N})</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathrm\">‚Ñì</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.664392em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">‚àû</span></span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathbb\">N</span></span><span class=\"mclose\">)</span></span></span></span> to say something about all metric spaces.</p>",
        "id": 155187105,
        "sender_full_name": "Sebastien Gouezel",
        "timestamp": 1547572867
    },
    {
        "content": "<p>Still, do you think everybody working with GH distance will be happy with your definition?</p>",
        "id": 155187371,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1547573115
    },
    {
        "content": "<p>Should we ask Gromov? <span class=\"emoji emoji-1f609\" title=\"wink\">:wink:</span></p>",
        "id": 155187414,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1547573150
    },
    {
        "content": "<p>Yes, because I prove that it gives what you expect: for any embeddings of X and Y in metric spaces, the Gromov-Hausdorff distance between X and Y is bounded above by the Hausdorff distance of the images. And there is one such embedding that realizes the Gromov-Hausdorff distance.</p>",
        "id": 155187510,
        "sender_full_name": "Sebastien Gouezel",
        "timestamp": 1547573212
    },
    {
        "content": "<p>In fact, the API is designed so that, in the end, you should completely forget that it was defined using <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi mathvariant=\"normal\">‚Ñì</mi><mi mathvariant=\"normal\">‚àû</mi></msup><mo>(</mo><mrow><mi mathvariant=\"double-struck\">N</mi></mrow><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\ell^\\infty(\\mathbb{N})</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord\"><span class=\"mord mathrm\">‚Ñì</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.664392em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathrm mtight\">‚àû</span></span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathbb\">N</span></span><span class=\"mclose\">)</span></span></span></span>: this is just a handy technical tool in the construction.</p>",
        "id": 155187605,
        "sender_full_name": "Sebastien Gouezel",
        "timestamp": 1547573288
    },
    {
        "content": "<p>What is the current status of pygments?</p>",
        "id": 165337936,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1557496633
    },
    {
        "content": "<p>Where is the most up to date version hosted? I couldn't find a repo on <span class=\"user-mention\" data-user-id=\"110043\">@Gabriel Ebner</span>'s github account with <code>pygm</code> in the name...</p>",
        "id": 165337962,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1557496667
    },
    {
        "content": "<p>Aah, I now found <a href=\"https://bitbucket.org/leanprover/pygments-main\" target=\"_blank\" title=\"https://bitbucket.org/leanprover/pygments-main\">https://bitbucket.org/leanprover/pygments-main</a>. Is that the version I should use?</p>",
        "id": 165338141,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1557496789
    },
    {
        "content": "<p><a href=\"https://bitbucket.org/gebner/pygments-main\" target=\"_blank\" title=\"https://bitbucket.org/gebner/pygments-main\">https://bitbucket.org/gebner/pygments-main</a></p>",
        "id": 165338176,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1557496802
    },
    {
        "content": "<p>We had to come back to this pygment issue for the <a href=\"https://leanprover-community.github.io/lean-perfectoid-spaces/\" target=\"_blank\" title=\"https://leanprover-community.github.io/lean-perfectoid-spaces/\">perfectoid website</a>. Of course we use Gabriel's pygments. But I think we should really try to PR it upstream. Very unfortunately, I see on <a href=\"https://pypi.org/project/Pygments/#history\" target=\"_blank\" title=\"https://pypi.org/project/Pygments/#history\">https://pypi.org/project/Pygments/#history</a> that we have missed a release. <span class=\"user-mention\" data-user-id=\"110043\">@Gabriel Ebner</span>  don't you want to open a PR? Clearly they are currently very active. It would be very nice to get rid of these red rectangles we get everywhere on Zulip. Maybe we should also introduce a more specific language code like \"lean3\" to prepare for future mess in the Lean4 transition</p>",
        "id": 165458660,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1557656531
    },
    {
        "content": "<p>Ok, I'll look into making a PR.  My experience with bitbucket and mercurial is very lacking though, so it might take a bit.  I'm not sure if we should have different syntaxes for <code>lean3</code> and <code>lean4</code>.  Right now the differences (for syntax highlighting) are very minimal (just a few new keywords).</p>",
        "id": 165466634,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1557670838
    },
    {
        "content": "<p>Their use of bitbucket and mercurial is indeed very painful...</p>",
        "id": 165466691,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1557670924
    },
    {
        "content": "<p>I happened to look at pygments again today because of the mathlib doc-gen stuff and it looks like <a href=\"https://github.com/pygments/pygments\" target=\"_blank\" title=\"https://github.com/pygments/pygments\">pygments development now occurs on github</a> (and there's even been <a href=\"https://github.com/pygments/pygments/commit/411a7b47413e5a1658ff1f5d1aa2f55ff3443f22#diff-e110d5d6ccdb22d858afceedb5787045\" target=\"_blank\" title=\"https://github.com/pygments/pygments/commit/411a7b47413e5a1658ff1f5d1aa2f55ff3443f22#diff-e110d5d6ccdb22d858afceedb5787045\">a commit</a> that updated the Lean syntax highlighting). </p>\n<p><span class=\"user-mention\" data-user-id=\"110043\">@Gabriel Ebner</span> it might be easier now to make a PR. If you'll be busy for a while with other stuff I can also try to tackle it sometime next week.</p>",
        "id": 190322715,
        "sender_full_name": "Bryan Gin-ge Chen",
        "timestamp": 1583955618
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"123965\">@Bryan Gin-ge Chen</span> Please do it!</p>",
        "id": 190322753,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1583955658
    },
    {
        "content": "<p>Wow... would that mean that the dear red boxes on Zulip might disappear in the near future?</p>",
        "id": 190323009,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1583955835
    },
    {
        "content": "<p>I hope so. It looks like Zulip is a few versions behind on pygments but presumably we can ping them to bump their dependency after we get pygments fixed.</p>",
        "id": 190323703,
        "sender_full_name": "Bryan Gin-ge Chen",
        "timestamp": 1583956242
    },
    {
        "content": "<p>Getting rid of the red boxes would be so awesome!</p>",
        "id": 190332601,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1583961446
    },
    {
        "content": "<p>PR here: <a href=\"https://github.com/pygments/pygments/pull/1415\" target=\"_blank\" title=\"https://github.com/pygments/pygments/pull/1415\">https://github.com/pygments/pygments/pull/1415</a></p>",
        "id": 190611156,
        "sender_full_name": "Bryan Gin-ge Chen",
        "timestamp": 1584215024
    },
    {
        "content": "<p>Looks like Pygments just got a new release <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span> - <a href=\"https://github.com/pygments/pygments/releases/tag/2.7.0\">https://github.com/pygments/pygments/releases/tag/2.7.0</a></p>",
        "id": 209888549,
        "sender_full_name": "Alex Peattie",
        "timestamp": 1599927657
    },
    {
        "content": "<p>I've just pinged Zulip about it: <a href=\"https://github.com/zulip/zulip/issues/16335\">https://github.com/zulip/zulip/issues/16335</a> <span aria-label=\"pray\" class=\"emoji emoji-1f64f\" role=\"img\" title=\"pray\">:pray:</span></p>",
        "id": 209888610,
        "sender_full_name": "Bryan Gin-ge Chen",
        "timestamp": 1599927739
    },
    {
        "content": "<p>Syntax highlighting is now fixed! Compare <a href=\"#narrow/stream/113488-general/topic/app_builder_exception.20in.20.60nlinarith.60/near/204138256\">this old message</a> and this one:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"c1\">-- works</span>\n<span class=\"kd\">example</span> <span class=\"o\">(</span><span class=\"n\">t</span> <span class=\"o\">:</span> <span class=\"n\">R</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"n\">b</span> <span class=\"o\">:</span> <span class=\"n\">‚Ñù</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">a</span> <span class=\"bp\">‚â§</span> <span class=\"n\">b</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"bp\">‚à•</span><span class=\"n\">t</span><span class=\"bp\">‚à•</span> <span class=\"bp\">*</span> <span class=\"n\">a</span> <span class=\"bp\">‚â§</span> <span class=\"bp\">‚à•</span><span class=\"n\">t</span><span class=\"bp\">‚à•</span> <span class=\"bp\">*</span> <span class=\"n\">b</span> <span class=\"o\">:=</span>\n<span class=\"kd\">by</span> <span class=\"n\">nlinarith</span> <span class=\"o\">[</span><span class=\"n\">norm_nonneg</span> <span class=\"n\">t</span><span class=\"o\">]</span>\n</code></pre></div>\n\n<p>(<strong>Edit</strong>: scrolling back, it looks like it was changed sometime around 24 hours ago.)</p>",
        "id": 210964048,
        "sender_full_name": "Bryan Gin-ge Chen",
        "timestamp": 1600843372
    },
    {
        "content": "<p>I am using sphinx with pygments for syntax highlighting. Lean code gets highlighted, but \"def\" is not recognized as a keyword. Before I do some digging on my own, does anyone know offhand whether there is a better version of pygments that I should be using somehow?</p>",
        "id": 242452621,
        "sender_full_name": "Jeremy Avigad",
        "timestamp": 1623507026
    },
    {
        "content": "<p>What I usually do is to copy pygment's theorem.py and then include the modified file using</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">\\</span><span class=\"n\">newmintinline</span><span class=\"o\">[</span><span class=\"n\">lean</span><span class=\"o\">]{</span><span class=\"kd\">theorem</span><span class=\"bp\">.</span><span class=\"n\">py</span><span class=\"o\">:</span><span class=\"n\">LeanLexer</span> <span class=\"bp\">-</span><span class=\"n\">x</span><span class=\"o\">}{</span><span class=\"n\">bgcolor</span><span class=\"bp\">=</span><span class=\"n\">white</span><span class=\"o\">}</span>\n<span class=\"bp\">\\</span><span class=\"n\">newminted</span><span class=\"o\">[</span><span class=\"n\">leancode</span><span class=\"o\">]{</span><span class=\"kd\">theorem</span><span class=\"bp\">.</span><span class=\"n\">py</span><span class=\"o\">:</span><span class=\"n\">LeanLexer</span> <span class=\"bp\">-</span><span class=\"n\">x</span><span class=\"o\">}{</span><span class=\"n\">fontsize</span><span class=\"bp\">=\\</span><span class=\"n\">footnotesize</span><span class=\"o\">}</span>\n</code></pre></div>\n<p>Current theorem.py from our course: <a href=\"https://gist.github.com/Kha/ba248a9cd2d245d741c85bd8efb5442d\">https://gist.github.com/Kha/ba248a9cd2d245d741c85bd8efb5442d</a></p>",
        "id": 242455237,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1623510211
    },
    {
        "content": "<p>This should of course be upstreamed... eventually</p>",
        "id": 242455246,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1623510230
    },
    {
        "content": "<p>What I haven't figured out yet is how to highlight <code>#check</code> but not <code>check</code></p>",
        "id": 242455289,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1623510245
    },
    {
        "content": "<p>Thanks! Sphinx also uses Pygments to generate the html docs, but I should be able to specify the new lexer in the <code>conf.py</code> configuration file. I'll try it later and report back.</p>",
        "id": 242457326,
        "sender_full_name": "Jeremy Avigad",
        "timestamp": 1623512756
    },
    {
        "content": "<p>Which version of pygments are you using?</p>",
        "id": 242457560,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1623513063
    },
    {
        "content": "<p>The latest version has much better support than the one from about a year ago thanks to Bryan</p>",
        "id": 242457583,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1623513111
    },
    {
        "content": "<p>Xref <a href=\"https://github.com/zulip/zulip/issues/16335#issue-700291108\">https://github.com/zulip/zulip/issues/16335#issue-700291108</a></p>",
        "id": 242457659,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1623513197
    },
    {
        "content": "<p>I installed the current version of Sphinx, which has Pygments built in. So I used whatever came with it. I am guessing that it is just an older version.</p>",
        "id": 242458454,
        "sender_full_name": "Jeremy Avigad",
        "timestamp": 1623514140
    },
    {
        "content": "<p>Does sphinx have an all in one installer? I assumed you install it through pip, in which case it will use any pygments version already on your system, and only install the latest version if it can't find one</p>",
        "id": 242458763,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1623514549
    },
    {
        "content": "<p>Your python version is likely also relevant, as the python bundled with many distros is far older than pygments still releases for.</p>",
        "id": 242458820,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1623514591
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/stream/113488-general/topic/pygments/near/242457583\">said</a>:</p>\n<blockquote>\n<p>The latest version has much better support than the one from about a year ago thanks to Bryan</p>\n</blockquote>\n<p>(I can't take too much credit! All the actual grammar changes were actually due to other folks (I think Floris, Gabriel and Reid?))</p>",
        "id": 242458941,
        "sender_full_name": "Bryan Gin-ge Chen",
        "timestamp": 1623514786
    },
    {
        "content": "<p>Brilliant! I did <code>pip install --upgrade pygments</code>, and now <code>def</code> is highlighted correctly. <span class=\"user-mention\" data-user-id=\"310045\">@Eric Wieser</span>, many thanks. That was exactly the advice I needed.</p>",
        "id": 242462183,
        "sender_full_name": "Jeremy Avigad",
        "timestamp": 1623519216
    },
    {
        "content": "<p>I'm writing a Sphinx document with some Lean code and am curious about whether there's a better <a href=\"https://pygments.org/styles/\">Pygments style</a> for Lean than the default one.</p>\n<ul>\n<li>Does anyone know which Pygments style Zulip uses?</li>\n<li>I <a href=\"https://github.com/leanprover/alectryon/blob/master/alectryon/pygments_style.py\">think I found</a> the Pygments style which is the Alectryon default?</li>\n</ul>\n<p>I'm also a bit confused about the wide world of syntax highlighting.  What is the <a href=\"https://leanprover.github.io/lean4/doc/tour.html\">Lean 4 manual</a> using, is that also Pygments? Is it possible to take a VS Code theme that you're happy with and turn it into a Pygments style?</p>",
        "id": 317018614,
        "sender_full_name": "Heather Macbeth",
        "timestamp": 1671562915
    },
    {
        "content": "<p>The lean4 manual is using highlightjs; I found out by using \"inspect element\" in the browser and spotting the <code>hljs</code> class names.</p>",
        "id": 317018934,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1671563007
    },
    {
        "content": "<p>Arguably using Pygments is \"cleaner\" because it does the highlighting up-front when you generate the pages with sphinx, rather than on the fly on the user's device on each page load</p>",
        "id": 317019193,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1671563092
    },
    {
        "content": "<p>I think the pygments grammar is better than the hljs one for Lean 3 too; although I likely have some patches I could contribute back for hljs as it's what I use in presentations</p>",
        "id": 317019321,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1671563136
    },
    {
        "content": "<p><a href=\"https://leanprover.github.io/theorem_proving_in_lean/\">#tpil</a> uses pygments; do you not like the style there?</p>",
        "id": 317019487,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1671563181
    },
    {
        "content": "<p>Indeed, it looks like <a href=\"https://leanprover.github.io/theorem_proving_in_lean/\">#tpil</a> is using the default <a href=\"https://pygments.org/styles/\">Pygments style</a>.  I think this is a nice style, but for teaching might prefer to use a style which closely mimics the VS Code theme in my setup.</p>",
        "id": 317019923,
        "sender_full_name": "Heather Macbeth",
        "timestamp": 1671563340
    },
    {
        "content": "<p>And I was also curious about what styles Zulip and Alectryon are using because I assume somebody already put a lot of thought into that?</p>",
        "id": 317020040,
        "sender_full_name": "Heather Macbeth",
        "timestamp": 1671563382
    },
    {
        "content": "<p><a href=\"https://github.com/zulip/zulip/blob/753deab0872c3113ad81f1e7577f390feab782da/static/styles/pygments.css\">This</a> looks to be the Zulip style</p>",
        "id": 317021178,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1671563751
    },
    {
        "content": "<p>The dark zulip style <a href=\"https://github.com/zulip/zulip/blob/753deab0872c3113ad81f1e7577f390feab782da/static/styles/dark_theme.css#L879-L1053\">is here</a></p>",
        "id": 317021507,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1671563846
    },
    {
        "content": "<p>(They were in the same file until <a href=\"https://github.com/zulip/zulip/commit/148f74d3a7c2d2d21727587f6163ccd8087ebad8#diff-a44a13b91a0631e2208006d4c97b43ed6ea0fa3873455dedf05940193e480b32\">this commit</a>)</p>",
        "id": 317021823,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1671563931
    },
    {
        "content": "<p>It looks like <span class=\"user-mention\" data-user-id=\"451040\">@Niklas B√ºlow</span> has written a custom Lean 4 Pygments lexer for Alectryon:<br>\n<a href=\"https://github.com/leanprover/alectryon/blob/master/alectryon/pygments_lexer.py\">https://github.com/leanprover/alectryon/blob/master/alectryon/pygments_lexer.py</a><br>\nwhich differs from the default Pygments lexer<br>\n<a href=\"https://github.com/pygments/pygments/blob/master/pygments/lexers/theorem.py\">https://github.com/pygments/pygments/blob/master/pygments/lexers/theorem.py</a><br>\nwritten, <a href=\"https://github.com/pygments/pygments/pull/1415\">apparently</a>, by <span class=\"user-mention\" data-user-id=\"110043\">@Gabriel Ebner</span> , <span class=\"user-mention\" data-user-id=\"110024\">@Sebastian Ullrich</span> and <span class=\"user-mention\" data-user-id=\"110032\">@Reid Barton</span>.</p>\n<p>Would it be possible to adopt any improvements Niklas has made into the default lexer and then eliminate the duplication?  I think the discrepancy will get annoying in a document which mixes Alectryon blocks with plain code blocks; their output is noticeably different.</p>",
        "id": 317162054,
        "sender_full_name": "Heather Macbeth",
        "timestamp": 1671630525
    },
    {
        "content": "<p>I had a quick look and here are some differences I noticed:</p>\n<ul>\n<li>Niklas' lexer categorizes as <code>Keyword.Namespace</code> some tokens which in the standard one are marked as <code>Keyword.Declaration</code>, including <code>theorem</code>, <code>noncomputable</code>, ...</li>\n<li>Niklas' lexer categorizes as <code>Keyword.Namespace</code> some tokens which in the standard one are marked as <code>Keyword</code>, including <code>#eval</code>, <code>#check</code>,...</li>\n<li>I <em>think</em> Niklas' lexer has a shorter keyword list overall but because of formatting differences I'm not sure.</li>\n<li>Niklas' lexer doesn't treat docstrings differently from comments</li>\n<li>Niklas' lexer has a list of symbols including <code>‚àÄ</code>, <code>‚â§</code>, <code>‚Ñ§</code>, ... which are categorized as <code>Name.Builtin.Pseudo</code>; these have no special handling in the standard lexer</li>\n</ul>",
        "id": 317162082,
        "sender_full_name": "Heather Macbeth",
        "timestamp": 1671630533
    },
    {
        "content": "<p>Note: there is the question of whether we need separate Lean 3 and Lean 4 lexers; Niklas' is specifically intended for Lean 4.  The languages may be close enough that we don't.</p>",
        "id": 317162165,
        "sender_full_name": "Heather Macbeth",
        "timestamp": 1671630574
    },
    {
        "content": "<p>I think Niklas' lexer is just a copy of <a href=\"https://github.com/leanprover/lean4/blob/master/doc/latex/lean4.py\">https://github.com/leanprover/lean4/blob/master/doc/latex/lean4.py</a>. We did not contribute changes back because for the longest time upstream Pygments was unmaintained.</p>",
        "id": 317164003,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1671631063
    },
    {
        "content": "<p>Thanks!  Does that mean that (now that upstream Pygments is maintained again) the default Pygments lexer is strictly better?</p>",
        "id": 317171210,
        "sender_full_name": "Heather Macbeth",
        "timestamp": 1671632839
    },
    {
        "content": "<p>The default pygments lexer is for Lean3 AFAIK</p>",
        "id": 317192881,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1671638645
    },
    {
        "content": "<p>Looking at the <a href=\"https://github.com/pygments/pygments/commits/master/pygments/lexers/theorem.py\">file history</a> the last update was by me two years ago, and I was definitely thinking of only Lean 3.</p>",
        "id": 317193104,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1671638714
    },
    {
        "content": "<blockquote>\n<p>Note: there is the question of whether we need separate Lean 3 and Lean 4 lexers;</p>\n</blockquote>\n<p>I think this is a good idea, if we don't then we have to  worry about breaking Lean3 highlighting each time we add support for new Lean4 syntaxes. The languages have different grammars so they should expose different Lexers.</p>\n<p>We can of course still share implementations between them</p>",
        "id": 317193562,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1671638828
    },
    {
        "content": "<p>One tricky point is that we'll have to choose which one is our Zulip default (probably Lean 4, to look forward).  And then make a mass change backwards to edit most earlier messages with unlabelled code blocks to have a Lean 3 label.</p>",
        "id": 317213081,
        "sender_full_name": "Heather Macbeth",
        "timestamp": 1671644651
    },
    {
        "content": "<p>I think that even admins can't do a mass message edit.</p>",
        "id": 317214099,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1671644963
    },
    {
        "content": "<p>If I remember correctly I already asked that question.</p>",
        "id": 317214135,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1671644976
    },
    {
        "content": "<p>Old messages contain the output of the syntax highlighting</p>",
        "id": 317214516,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1671645086
    },
    {
        "content": "<p>You can see that in really old messages where the highlighting is broken because the highlighter used at the time had bugs</p>",
        "id": 317214542,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1671645096
    },
    {
        "content": "<p>So there is no issue here with changing the default</p>",
        "id": 317214574,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1671645107
    },
    {
        "content": "<p>Maybe we can ask for having different per-stream defaults while the port is still happening?</p>",
        "id": 317214782,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1671645157
    },
    {
        "content": "<p>If people edit an old message then they might want to change <code> ``` </code> into <code> ```lean3 </code>. But that's not really a problem.</p>",
        "id": 317214848,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1671645173
    },
    {
        "content": "<p>Another day, another reason to love <img alt=\":zulip:\" class=\"emoji\" src=\"/static/generated/emoji/images/emoji/unicode/zulip.png\" title=\"zulip\"></p>",
        "id": 317245155,
        "sender_full_name": "Ya√´l Dillies",
        "timestamp": 1671655249
    },
    {
        "content": "<p>zulip's team always listens too, even to crazy bugs like not being able to search the word \"unit\"</p>",
        "id": 317246414,
        "sender_full_name": "Eric Rodriguez",
        "timestamp": 1671655738
    }
]