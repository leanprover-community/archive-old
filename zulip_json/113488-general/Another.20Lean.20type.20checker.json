[
    {
        "content": "<p>I'd like to share something I've been working on for a while in an attempt to learn more about Lean's internals and how the gears of dependent types turn (I think I remember seeing a few Rust fans here too). <a href=\"https://github.com/ammkrn/nanoda.git\" target=\"_blank\" title=\"https://github.com/ammkrn/nanoda.git\">https://github.com/ammkrn/nanoda.git</a>  <br>\nGoing forward I'll be trying to add features aimed at exposing the internals in an informative way and expanding the documentation until (hopefully) the whole thing is annotated.</p>",
        "id": 173766483,
        "sender_full_name": "Chris B",
        "timestamp": 1566366187
    },
    {
        "content": "<p>awesome</p>",
        "id": 173767741,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1566368211
    },
    {
        "content": "<p>I wonder if we can hook this up with olean-rs to get typechecking straight from olean files</p>",
        "id": 173767818,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1566368305
    },
    {
        "content": "<p>Is there any chance of modifying it to be proof-producing? Specifically, I would like a record of how definitional equalities are proven so that it can be consumed by a much less intelligent verifier</p>",
        "id": 173767936,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1566368514
    },
    {
        "content": "<p>Sure, I can put in an option to output the intermediate states of two terms as they go through reduction/inference during the definitional equality checking if that's what you mean.</p>",
        "id": 173768209,
        "sender_full_name": "Chris B",
        "timestamp": 1566368880
    },
    {
        "content": "<p>Yes, that's the idea. I've been wanting to translate lean proofs into other languages for a while now, and the main blocker is that lean proofs leave a lot of work unfinished to be cleaned up by the typechecker.</p>",
        "id": 173768541,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1566369245
    },
    {
        "content": "<p>The other big thing I guess is inductive types, although I'm not sure how useful you can make the trace. Ideally I would want a record of why the typechecker thinks an inductive definition is permitted, and how it built the intro and recursion rules and the computation rule</p>",
        "id": 173768748,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1566369524
    },
    {
        "content": "<p>Construction of the intro/elim/reduction rules for inductive types is fairly procedural and they're built from components that exist separately earlier in the module so that shouldn't be hard. wrt to why the typechecker gives any particular definition the thumbs up you might have to narrow down what parts of the 'history' you need since some of the steps produce really large amounts of intermediate info.</p>",
        "id": 173769171,
        "sender_full_name": "Chris B",
        "timestamp": 1566370092
    },
    {
        "content": "<p>the short answer is \"all of it\"</p>",
        "id": 173771667,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1566373496
    },
    {
        "content": "<p>but it's possible I can reconstruct the rest from a reasonable amount of tracing data</p>",
        "id": 173771688,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1566373522
    },
    {
        "content": "<p>One way to describe the problem is that I want a trace that does not require knowledge of the rules of dependent type theory to verify</p>",
        "id": 173771773,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1566373611
    },
    {
        "content": "<blockquote>\n<p>really large amounts of intermediate info</p>\n</blockquote>\n<p>Could you be more specific about this? If you are talking about repeated information that's not a problem, as it can be backreferenced, but if you are generating huge terms during reduction from small inputs that's actually what I care to capture. I assume that doesn't happen very often in lean proofs though</p>",
        "id": 173771887,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1566373763
    },
    {
        "content": "<p>I guess it depends on whether you plan on using an export file type deal or if you want to connect the tools directly. The terms aren't large in terms of memory consumption since the trees are mostly pointers, but the expressions themselves are frequently large in terms of the number of nodes/leaves and they go through a lot of steps in the checker, so if you try to put all that information somewhere persistent like text, then the history can get really big. When I was first trying to figure out why some things worked the way they do I was just doing naive logging and would get these runaway 300 MB log files.</p>",
        "id": 173773110,
        "sender_full_name": "Chris B",
        "timestamp": 1566374850
    },
    {
        "content": "<p>Right, the problem with pp.all style printing is it ignores subterm duplication, which can cause exponential blowup at the printing stage</p>",
        "id": 173774410,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1566376214
    },
    {
        "content": "<p>Any method that explicitly represents subterm duplication should be able to address this problem. The export file format uses numbered backreferences, or in human readable printing you can insert <code>let</code>s, or you can just do a memory dump (although this is tricky to set up reliably)</p>",
        "id": 173774536,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1566376360
    },
    {
        "content": "<p>I usually find the easiest thing to implement is numbered backreferences. You just keep a hashmap of exprs you've printed so far, and every time you see one you have printed before you print a reference to it rather than printing the whole term again</p>",
        "id": 173774689,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1566376547
    },
    {
        "content": "<p>That's basically what the export format printer does too</p>",
        "id": 173774738,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1566376563
    },
    {
        "content": "<p>I have a program I want to pipe this into but it would probably be easiest to communicate using some intermediate file format rather than via RPC (plus the intermediate file format has independent interest as a more-explicit lean export format)</p>",
        "id": 173774884,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1566376738
    },
    {
        "content": "<p>Some back of the envelope numbers, in checking mathlib, <code>infer</code> gets called 44.3 million times, <code>def_eq</code> 4.7 million.</p>",
        "id": 173775168,
        "sender_full_name": "Chris B",
        "timestamp": 1566377029
    },
    {
        "content": "<p>Are you targeting single definitions or like all of mathlib at once deal?</p>",
        "id": 173775224,
        "sender_full_name": "Chris B",
        "timestamp": 1566377063
    },
    {
        "content": "<p>I'll check later how much that goes down by if the caches for inference/definitional equality checks are reused globally.</p>",
        "id": 173775927,
        "sender_full_name": "Chris B",
        "timestamp": 1566377825
    },
    {
        "content": "<p>I don't think all of mathlib at once is out of the question; those numbers are big but not unreasonable</p>",
        "id": 173781879,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1566383937
    },
    {
        "content": "<p>I would anticipate that if I can get an importer into metamath working it will check in &lt; 1 minute, possibly a lot less</p>",
        "id": 173781952,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1566384004
    },
    {
        "content": "<p>the biggest worry is if you hand me a 5 terabyte file</p>",
        "id": 173781975,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1566384036
    },
    {
        "content": "<p>Rad. In that case, let me know what I can do concretely to either get the ball rolling or how I can help you to do so.</p>",
        "id": 173782529,
        "sender_full_name": "Chris B",
        "timestamp": 1566384654
    },
    {
        "content": "<p>I guess if you can get tracing output from the program in any simple machine readable format (similar to the lean export format but feel free to pick your favorite concrete syntax) I can try to process the output and give more specific feedback on where I need more detailed info.</p>",
        "id": 173785938,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1566388137
    },
    {
        "content": "<p>I probably won't be able to work on this immediately though</p>",
        "id": 173786001,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1566388187
    },
    {
        "content": "<p>Word.</p>",
        "id": 173810514,
        "sender_full_name": "Chris B",
        "timestamp": 1566405060
    }
]