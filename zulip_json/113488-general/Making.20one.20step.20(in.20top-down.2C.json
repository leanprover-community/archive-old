[
    {
        "content": "<p>Natural deduction formalism allows to apply inference rules in any direction - both in top-down and bottom-up direction. That is in opposite to the sequent calculus whose inference rules are mean for bottom-up application only. That is why forward and backward inference is possible in natural deduction, i.e. it is possible to gate statements, to choose inference rule, to choose the direction for the inference rule and make one step of inference. Such logic (as opposite to the restricted versions of first order logic like datalog or prolog) have no clear notion of consequence set, but such single step is some kind of computing of consequence set, part of it.</p>\n<p>I am now playing with the Microsoft Lean theorem prover which has documentation for the natural deduction. My question is - can I do the mentioned actions in this prover - i.e. specify statement, inference rule and application direction and get the result? Lean is theorem prover and that is why it may compute only large chunks of those single steps, but maybe it is possible to use Lean to compute such single steps as well? And maybe it is possible to use Lean in API manner as API calculator - to submit statements and flag for the inference rule and get back the statements of such single step in other software? Is it possible and how?Making one step (in top-down,</p>",
        "id": 184269221,
        "sender_full_name": "Alex Skara",
        "timestamp": 1577377128
    },
    {
        "content": "<p>If you use tactics to prove a theorem <code>s</code>, you can then use <code>#print s</code> to see the individual steps of the proof, for example:</p>\n<div class=\"codehilite\"><pre><span></span>lemma eg (A B C : Prop) : (A → (B → C)) → (A ∧ B → C) := by cc\n#print eg\n</pre></div>\n\n\n<div class=\"codehilite\"><pre><span></span>theorem eg : ∀ (A B C : Prop), (A → B → C) → A ∧ B → C :=\nλ (A B C : Prop) (a : A → B → C) (a_1 : A ∧ B),\n  of_eq_true\n    (eq.trans\n       (eq.trans (eq.symm (imp_eq_of_eq_true_left (eq_true_of_and_eq_true_right (eq_true_intro a_1))))\n          (eq.symm\n             (imp_eq_of_eq_true_left\n                (eq.trans (eq.symm (and_eq_of_eq_true_right (eq_true_of_and_eq_true_right (eq_true_intro a_1))))\n                   (eq_true_intro a_1)))))\n       (eq_true_intro a))\n</pre></div>",
        "id": 184275265,
        "sender_full_name": "Etienne Laurin",
        "timestamp": 1577384375
    },
    {
        "content": "<p>To do this from other software you could use the <code>--export</code> or <code>--server</code> modes</p>",
        "id": 184275318,
        "sender_full_name": "Etienne Laurin",
        "timestamp": 1577384403
    },
    {
        "content": "<p>Thanks for suggestion but I am have a bit different use case. Reasoning and not the theorem proving is my use case. And it is important for reasoning to make one step in a manner that it is the external decision what premises to choose and which inference rule to apply (and not the built-in search process). There are some works that point to this direction e.g. <a href=\"https://ieeexplore.ieee.org/document/6359662\" target=\"_blank\" title=\"https://ieeexplore.ieee.org/document/6359662\">https://ieeexplore.ieee.org/document/6359662</a> and <a href=\"http://www.isle.org/~langley/papers/icarus.rrl.ilp05.pdf\" target=\"_blank\" title=\"http://www.isle.org/~langley/papers/icarus.rrl.ilp05.pdf\">http://www.isle.org/~langley/papers/icarus.rrl.ilp05.pdf</a> and whole emerging culture of relational reinforcement learning and automatic theory proving that uses guidance from the (deep) reinforcement learning (there is strong Czech group working on that). Just wanted to know is it worth to dig deeper in to Lean documentation or the code with the aim to enable such one-step inference rule applications. Currently I am developing my own software for that using teaching software for sequent calculus and for natural deduction, but it would be more nice to have some solid tools. I also asked the same question in Coq and Isabelle groups and they too have no mechanisms for explicit control over one step inferences.</p>",
        "id": 184276585,
        "sender_full_name": "Alex Skara",
        "timestamp": 1577385736
    },
    {
        "content": "<p>Lean's tactic mode allows you to specify a proof as a list of steps. The <code>have</code> tactic can perform a single forward step, and the <code>refine</code> tactic a single backwards step. For example:</p>\n<div class=\"codehilite\"><pre><span></span>example {p q r : Prop} : p → q → r → p ∧ q ∧ r :=\nbegin\n  intros,\n  have : q ∧ r := and.intro ‹q› ‹r›,\n  have : p ∧ q ∧ r :=  and.intro ‹p› ‹q ∧ r›,\n  exact ‹p ∧ q ∧ r›\nend\n\nexample {p q r : Prop} : p → q → r → p ∧ q ∧ r :=\nbegin\n  intros,\n  refine and.intro _ _,\n  exact ‹p›,\n  refine and.intro _ _,\n  exact ‹q›,\n  exact ‹r›\nend\n</pre></div>",
        "id": 184279642,
        "sender_full_name": "Etienne Laurin",
        "timestamp": 1577389861
    },
    {
        "content": "<p>Thanks once more. But for the 'have' tactic - as I understand - Lean requires me to know and write down the result (q ∧ r) of and.intro application to the q and r. What I am seeking is - to use Lean as the calculator - input p, q and rule name (and.intro) and get the result (q ∧ r). Of course, I expect that in the future I will be able in such manner not only to apply the inference rules, but the whole theorems and this can lead me to the realm of symbolic computing. At present as I understand - Lean (and Coq, Isabelle, etc.) are good (best) at checking of the already known proofs (and some proof assistants are also using heuristics and algorityms to find the proofs) but they are not usable as calculators. But I wonder - why is that? Under the hood proof assistants certainly act as calculators, so, one just to bring those capabilities out? Well - I will continue to work on my own software but if anyone is wishing in Lean community to adapt Lean to be usable as the calculator, then I would be glad to hear some guidance or advise. I wonder that AI community is so stick with the theorem proving paradigm. But human reasoning rarely happens in such a way. We can take any article on philosophy, physics, history, science and we can see that deduction happens and the temporary goal is discovered only at the end (and it is so even in the cases when the article is presented as the theorem proving endeavour). Noone expects that scientific paper answers all the question, but one expects that each paper make advancements, some new results of inference and each paper - new advancement. To make AI more commonsense, more applicable, more closer to the actual situation it is necessary to move from the backward theorem proving to the controller forward-chaining-type deductive inference and Lean (Coq, Isabelle) could be reliable calculator in this way. Just different look on the A(General)I and just the symbolic alternative to the <a href=\"https://openai.com/blog/microsoft/\" target=\"_blank\" title=\"https://openai.com/blog/microsoft/\">https://openai.com/blog/microsoft/</a> .</p>",
        "id": 184282866,
        "sender_full_name": "Alex Skara",
        "timestamp": 1577394215
    },
    {
        "content": "<p>You could use them as calculators, but it is not an application very many people are interested in. If you are willing to learn how to extend Lean with tactics (similarly, Coq with Ltac) such a thing is possible.</p>",
        "id": 184282964,
        "sender_full_name": "Andrew Ashworth",
        "timestamp": 1577394325
    },
    {
        "content": "<p>Étienne wrote the expected type for pedagogical purposes only, Lean doesn't need them.</p>",
        "id": 184283020,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1577394380
    },
    {
        "content": "<p>If I am understanding you correctly - we have an example of something similar somewhere in the history of this chat. It was developing an environment to play the wolf-goat-cabbage game with specialized commands.</p>",
        "id": 184283265,
        "sender_full_name": "Andrew Ashworth",
        "timestamp": 1577394587
    },
    {
        "content": "<p>I also dimly remember an \"explode\" tactic written by Mario where you can print out natural deduction trees</p>",
        "id": 184283387,
        "sender_full_name": "Andrew Ashworth",
        "timestamp": 1577394727
    },
    {
        "content": "<p>So if you were interested in using Lean, you could write custom tactic(s) and a tactic environment to do logical deduction. Then going forward, perhaps write your own graphical tree interface. I have seen such things for Coq but I do not remember the names or websites</p>",
        "id": 184283490,
        "sender_full_name": "Andrew Ashworth",
        "timestamp": 1577394895
    },
    {
        "content": "<p>OK, I will have a look on tactics. Thanks.</p>",
        "id": 184284049,
        "sender_full_name": "Alex Skara",
        "timestamp": 1577395736
    },
    {
        "content": "<p><a href=\"#narrow/stream/116395-maths/topic/wolf.20goat.20cabbage\" title=\"#narrow/stream/116395-maths/topic/wolf.20goat.20cabbage\">Here's a link to the wolf goat cabbage thread.</a></p>",
        "id": 184284193,
        "sender_full_name": "Bryan Gin-ge Chen",
        "timestamp": 1577395956
    }
]