[
    {
        "content": "<p>Dear convex analysts, could we try not to touch <code>analysis.convex.basic</code> for a little while? I'm scrambling it all in <a href=\"https://github.com/leanprover-community/mathlib/issues/9058\">#9058</a> which means I have to reproduce changes by hand from a mangled diff.</p>",
        "id": 252468949,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1631111156
    },
    {
        "content": "<p>Do you have an estimate for how long you want to freeze it?</p>",
        "id": 252472241,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1631112188
    },
    {
        "content": "<p>I'm in favour of the generalisation of <a href=\"https://github.com/leanprover-community/mathlib/issues/9058\">#9058</a> but I'm a bit wary of a freeze (though I'm sure I could be persuaded). I wonder an alternative approach would be to split <code>analysis.convex.basic</code> into several files so that even if we still opt to freeze, the impact will be smaller.</p>",
        "id": 252477450,
        "sender_full_name": "Oliver Nash",
        "timestamp": 1631113708
    },
    {
        "content": "<p>For clarity, I mean to precede <a href=\"https://github.com/leanprover-community/mathlib/issues/9058\">#9058</a>  by a simple PR that changes nothing except for splitting the file. <span class=\"user-mention\" data-user-id=\"387244\">@Yaël Dillies</span>  Do you think this would help?</p>",
        "id": 252477649,
        "sender_full_name": "Oliver Nash",
        "timestamp": 1631113787
    },
    {
        "content": "<p>It seems to me a lot of the scrambling is reordering lemmas around. If you're worried about conflicts, it might make sense to first make a PR to reorder the lemmas in a somewhat sensible order, and a second one to generalize them</p>",
        "id": 252485093,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1631116381
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"112680\">Johan Commelin</span> <a href=\"#narrow/stream/113488-general/topic/Freezing.20analysis.2Econvex.2Ebasic/near/252472241\">said</a>:</p>\n<blockquote>\n<p>Do you have an estimate for how long you want to freeze it?</p>\n</blockquote>\n<p>A week maybe? I'm working hard on it and in 3 days I went through half of <code>analysis.convex.basic</code>. So 3 more days it is, then probably 2 or 3 more for the other files using convex stuff.</p>",
        "id": 252485500,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1631116519
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"240862\">Oliver Nash</span> <a href=\"#narrow/stream/113488-general/topic/Freezing.20analysis.2Econvex.2Ebasic/near/252477450\">said</a>:</p>\n<blockquote>\n<p>I'm in favour of the generalisation of <a href=\"https://github.com/leanprover-community/mathlib/issues/9058\">#9058</a> but I'm a bit wary of a freeze (though I'm sure I could be persuaded). I wonder an alternative approach would be to split <code>analysis.convex.basic</code> into several files so that even if we still opt to freeze, the impact will be smaller.</p>\n</blockquote>\n<p>I'm already planning on splitting <code>analysis.convex.basic</code> into <code>analysis.convex.function</code> (Yury already wanted that in <a href=\"https://github.com/leanprover-community/mathlib/issues/4787\">#4787</a>) and <code>analysis.convex.combination</code>. But this won't help much as the bulk of the work is to find the correct generality of each lemma, and I'm not scrambling the 3 future files together.</p>\n<p><span class=\"user-mention silent\" data-user-id=\"310045\">Eric Wieser</span> <a href=\"#narrow/stream/113488-general/topic/Freezing.20analysis.2Econvex.2Ebasic/near/252485093\">said</a>:</p>\n<blockquote>\n<p>It seems to me a lot of the scrambling is reordering lemmas around. If you're worried about conflicts, it might make sense to first make a PR to reorder the lemmas in a somewhat sensible order, and a second one to generalize them</p>\n</blockquote>\n<p>This won't help much either because the scrambling is motivated by the necessary assumptions, and as said above this is the hard part of what I'm doing.</p>",
        "id": 252486451,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1631116836
    },
    {
        "content": "<p>It's not my call but I'm even more wary after hearing more. I encourage you to find ways to break down this work into more PRs.</p>",
        "id": 252486544,
        "sender_full_name": "Oliver Nash",
        "timestamp": 1631116870
    },
    {
        "content": "<p>Well I can always just leave ℝ in some places. This is the easy way to split the work.</p>",
        "id": 252486747,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1631116940
    },
    {
        "content": "<p>Right: a general definition is much more important than a general lemma etc.</p>",
        "id": 252486816,
        "sender_full_name": "Oliver Nash",
        "timestamp": 1631116965
    },
    {
        "content": "<p>Okay well if you agree with this approach then a first PR can be ready this evening, if I get out of the orange bar hell.</p>",
        "id": 252486959,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1631117024
    },
    {
        "content": "<p>Bear in mind, it's not my call. Others may see things differently. But delivering a stream of smaller PRs that generalise things incrementally (definitions first, then lemmas) will probably make everyone's life better.</p>",
        "id": 252487328,
        "sender_full_name": "Oliver Nash",
        "timestamp": 1631117150
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"387244\">Yaël Dillies</span> <a href=\"#narrow/stream/113488-general/topic/Freezing.20analysis.2Econvex.2Ebasic/near/252486747\">said</a>:</p>\n<blockquote>\n<p>Well I can always just leave ℝ in some places. This is the easy way to split the work.</p>\n</blockquote>\n<p>I think this is a sensible approach; generalize the definition and the really basic APIs, and replace <code>convex</code> with <code>convex ℝ</code> everywhere else. Then you can do the rest piecewise in later PRs.</p>",
        "id": 252494288,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1631119775
    },
    {
        "content": "<p>Here's the first one! <a href=\"https://github.com/leanprover-community/mathlib/issues/9094\">#9094</a><br>\nit generalizes <code>segment</code> and <code>open_segment</code></p>",
        "id": 252499079,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1631121569
    },
    {
        "content": "<p>I left a few comments, hopefully easy.</p>",
        "id": 252578808,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1631170142
    },
    {
        "content": "<p>Thanks!</p>",
        "id": 252578972,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1631170274
    },
    {
        "content": "<p><a href=\"https://github.com/leanprover-community/mathlib/issues/9115\">#9115</a> puts <code>finset.center_mass</code>in its own file. It commutes with <a href=\"https://github.com/leanprover-community/mathlib/issues/9094\">#9094</a>, but I'm now stuck. One of them must go through for me to continue the refactor.</p>",
        "id": 252642089,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1631200034
    },
    {
        "content": "<p>Yael, <a href=\"https://github.com/leanprover-community/mathlib/issues/9094\">#9094</a> doesn't compile</p>",
        "id": 252643023,
        "sender_full_name": "Eric Rodriguez",
        "timestamp": 1631200391
    },
    {
        "content": "<p>Fixing it <span aria-label=\"tools\" class=\"emoji emoji-1f6e0\" role=\"img\" title=\"tools\">:tools:</span></p>",
        "id": 252643274,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1631200488
    },
    {
        "content": "<p>It was the new notation, that already existed anyway. <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span></p>",
        "id": 252643844,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1631200706
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110031\">@Patrick Massot</span>, localized <code>[x, y]</code> notation causes parsing problems. I'll just remove it and you can keep declaring it locally, as it was done before.</p>",
        "id": 252704898,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1631226046
    },
    {
        "content": "<p>By the way, <code>[x, y]</code> notation is one of the few remaining unresolved mathport issues. There are some things that can still be done but I would rather the overload didn't exist</p>",
        "id": 252705006,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1631226111
    },
    {
        "content": "<p>Ah, further reason!</p>",
        "id": 252705413,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1631226361
    },
    {
        "content": "<p>This is simple to fix -- give us our notation back and the CS people can use some random unicode thing for their lists</p>",
        "id": 252707299,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1631227512
    },
    {
        "content": "<p>Who needs lists anyway</p>",
        "id": 252707333,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1631227536
    },
    {
        "content": "<p>something... something... finset  something... something...</p>",
        "id": 252707407,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1631227568
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/113488-general/topic/Freezing.20analysis.2Econvex.2Ebasic/near/252705006\">said</a>:</p>\n<blockquote>\n<p>By the way, <code>[x, y]</code> notation is one of the few remaining unresolved mathport issues. There are some things that can still be done but I would rather the overload didn't exist</p>\n</blockquote>\n<p>This is really sad for Lean 4. Can't we get that weird super specialized list thing localized (or scoped or whatever)?</p>",
        "id": 252710963,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1631229846
    },
    {
        "content": "<p>It's not a problem with lean 4 so much as with mathport</p>",
        "id": 252712885,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1631231265
    },
    {
        "content": "<p>The problem is that we have a notation name conflict, so we don't know whether we want the list notation or the ... whatever this is</p>",
        "id": 252713014,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1631231374
    },
    {
        "content": "<p>Also, there is a lot more reliance on macros in lean 4 that might unfold to something containing list brackets. I really don't think it's a good idea to overload them</p>",
        "id": 252713359,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1631231613
    }
]