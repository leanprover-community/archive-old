[
    {
        "content": "<p>Is there any chance of simplifying the kernel to only support a fixed set of inductive types, and have everything else compile into them? We already do such reduction for nested inductives and mutual inductives. I envision such a move happening when we write a new equation compiler and inductive compiler in lean (which will probably be late in development of lean 4 if not later). The argument about concern for changing the kernel is now greatly reduced because of the theory work I've been doing to make sure that this is consistent</p>",
        "id": 124010706,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521640501
    },
    {
        "content": "<p>I assume you mean that the kernel would have one type:</p>\n<div class=\"codehilite\"><pre><span></span>inductive W (α : Sort*) (β : α -&gt; Sort*)\n| intro (x : α) (f : β x -&gt; W) : W\n</pre></div>\n\n\n<p>How do you define <code>α</code>?</p>",
        "id": 124014525,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1521645582
    },
    {
        "content": "<p>See my paper <a href=\"https://github.com/digama0/lean-type-theory/releases/\" target=\"_blank\" title=\"https://github.com/digama0/lean-type-theory/releases/\">https://github.com/digama0/lean-type-theory/releases/</a> for details. Actually you need 8 specific inductive types: <code>false</code>, <code>sigma</code>, <code>sum</code>, <code>ulift</code>, <code>nonempty</code>, <code>W</code>, <code>eq</code> and <code>acc</code>, from these you can get all the inductive types. (I say \"reduction to W\" because W does most of the heavy lifting, but you need the others to put it all together.)</p>",
        "id": 124016835,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521646401
    },
    {
        "content": "<p>Is it common in computer science to have public git repository of papers under progress?</p>",
        "id": 124016903,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521646501
    },
    {
        "content": "<p>I don't know, I did that because it started getting near book length while people kept asking questions to which I could refer to the parts of the paper that are done</p>",
        "id": 124016921,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521646548
    },
    {
        "content": "<p>I was originally planning to keep it under wraps until it was ready for publication, but I don't know if it will ever be published as it currently exists, it's more useful as a lean reference</p>",
        "id": 124016978,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521646610
    },
    {
        "content": "<p>\"near book length\"?! <span class=\"emoji emoji-1f923\" title=\"rolling on the floor laughing\">:rolling_on_the_floor_laughing:</span>  You should see papers in my field...</p>",
        "id": 124017571,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521647347
    },
    {
        "content": "<p>Long paper for us mean over 100 pages</p>",
        "id": 124017586,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521647371
    },
    {
        "content": "<p>Very long means more than 500</p>",
        "id": 124017590,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521647386
    },
    {
        "content": "<p>Above 1000 pages people complain</p>",
        "id": 124017649,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521647410
    },
    {
        "content": "<p>Then papers are split</p>",
        "id": 124017668,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521647438
    },
    {
        "content": "<p>How dare you call such things \"papers\"? How do you sleep at night?</p>",
        "id": 124017701,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1521647515
    },
    {
        "content": "<p>as in <a href=\"https://arxiv.org/find/grp_math/1/ti:+AND+HF+HM/0/1/0/all/0/1\" target=\"_blank\" title=\"https://arxiv.org/find/grp_math/1/ti:+AND+HF+HM/0/1/0/all/0/1\">https://arxiv.org/find/grp_math/1/ti:+AND+HF+HM/0/1/0/all/0/1</a></p>",
        "id": 124017703,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521647519
    },
    {
        "content": "<p>Those are novels!</p>",
        "id": 124017748,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1521647528
    },
    {
        "content": "<p>\"Once upon a time, there was a little epsilon that was barely greater than 0 ...\"</p>",
        "id": 124017790,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1521647628
    },
    {
        "content": "<p>The total for this series HF=HM is 25+133+195+240+276 = 869</p>",
        "id": 124017864,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521647707
    },
    {
        "content": "<p>So people don't complain</p>",
        "id": 124017866,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521647712
    },
    {
        "content": "<p>But some people still feel the need to learn about proof assistants (that's me)</p>",
        "id": 124017882,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521647743
    },
    {
        "content": "<p>Are any of those papers peer reviewed? How long do you wait for your reviews?</p>",
        "id": 124017936,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1521647785
    },
    {
        "content": "<p>That particular series is not yet published</p>",
        "id": 124018303,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521648288
    },
    {
        "content": "<p>But it is a rather extreme case</p>",
        "id": 124018305,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521648296
    },
    {
        "content": "<p>And actually my longest paper is only 70 pages long</p>",
        "id": 124018330,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521648360
    },
    {
        "content": "<p>My paper isn't close to finished yet... I mean it is projected book length</p>",
        "id": 124018382,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521648407
    },
    {
        "content": "<p>I see. Anyway, it's very nice to have this early release</p>",
        "id": 124018485,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521648595
    },
    {
        "content": "<p>Yes, people peer review 100 page papers certainly. Perhaps the process is rather different to what goes on in CS though. I basically never get sent conference proceedings to review, but I get sent papers in my area from journals and am sometimes asked to make general comments and sometimes asked to specifically look at the paper, or a part of the paper, and make detailed comments.</p>",
        "id": 124025092,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1521658299
    },
    {
        "content": "<p>Back to W types, <span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span> do you know what kind of impact your suggestion might have on the performances of type checking?</p>",
        "id": 124025682,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1521659137
    },
    {
        "content": "<p>Oh -- answer to \"how long do you wait\" is \"any time between a few weeks and a year\"</p>",
        "id": 124025987,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1521659571
    },
    {
        "content": "<p>(sometimes more)</p>",
        "id": 124025989,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1521659577
    },
    {
        "content": "<p>For a journal? That's faster than what I've seen.</p>",
        "id": 124026001,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1521659616
    },
    {
        "content": "<p>That's one great thing about a theorem prover: you don't have to wait weeks to realize that you messed up</p>",
        "id": 124026047,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1521659650
    },
    {
        "content": "<p>More exactly, I had a conference paper invited for publication in a journal. I submitted in November, got criticism in June of the year after, resubmitted in July and didn't hear about it until March of the following year where I was asked to prepare the camera ready version</p>",
        "id": 124026140,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1521659833
    },
    {
        "content": "<p>As an aside, despite being invited for a special issue on formal methods, some of my reviewers complained that my paper was too formal, that it had too many formulas ...</p>",
        "id": 124026199,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1521659897
    },
    {
        "content": "<p>A lot of computer scientists don't like math. Especially in software engineering</p>",
        "id": 124026203,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1521659920
    },
    {
        "content": "<p>\"software engineering\" is too hand-wavey :-\\</p>",
        "id": 124026221,
        "sender_full_name": "Moses Schönfinkel",
        "timestamp": 1521659962
    },
    {
        "content": "<p>It depends on how you group the syllables: too often it is taken as soft ware-engineering (and you should put quotes around engineering, if you're being exact)</p>",
        "id": 124026292,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1521660051
    },
    {
        "content": "<p>Because of that I have refused to call my research software engineering for a long time until I realized that engineering ethics is lacking to software. Software engineering is the right phrase but it hasn't been seen often. One good way of figuring out if someone is doing actual software engineering is to ask \"what do you think of getting sued if your user loses all their data?\"</p>",
        "id": 124026399,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1521660235
    },
    {
        "content": "<p>Can I sue Lean if it loses all my proofs?</p>",
        "id": 124026552,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1521660451
    },
    {
        "content": "<p>I'm not sure but at the moment no. I think if you're a paying customer of Coq and that Coq that some proof is valid and that it isn't you can sue them. Or maybe it's in the process of happening</p>",
        "id": 124026710,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1521660634
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110026\">@Simon Hudon</span> It shouldn't affect typechecking speed of stuff that doesn't depend on internal implementation of inductives. The recursor and intros become defs which are almost never unfolded, except that the computation rule may require unfolding stuff; but I think that rfl-lemmas are used here to simplify the process even now, so as long as the computational rule can be registered as a rfl-lemma it should not need to unfold the definitions. The only place where the speed could be affected is in the time it takes to compile an inductive definition, but it shouldn't be much more than is already being done to reduce nested inductives, as well as all the auxiliary functions that get defined in any case (<code>sizeof</code> and <code>inj_arrow</code> and <code>no_confusion</code> etc)</p>",
        "id": 124032584,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521669447
    },
    {
        "content": "<p>Cool <span class=\"emoji emoji-1f604\" title=\"smile\">:smile:</span> And does that mean that we no longer add axioms for each new inductive type? I like that idea a lot</p>",
        "id": 124032781,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1521669652
    },
    {
        "content": "<p>Hey can I register my own lemmas as rfl-lemmas, or is that above my pay grade?</p>",
        "id": 124033448,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1521670678
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span> Please don't underestimate kernel reduction time.  Any and all computation in the kernel is performed using basic ɩ-reduction, rfl-lemmas are completely irrelevant for the kernel.  That is, one unfolding of <code>nat.rec</code> now would probably correspond to two or more ɩ-reduction steps when using the reduction to <code>W</code>.  There is also the associated increase in term size which does not exactly help performance either.</p>",
        "id": 124052279,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521709401
    },
    {
        "content": "<p>Has this been a problem with working with nested inductives?</p>",
        "id": 124052336,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521709556
    },
    {
        "content": "<p>or wf recursion</p>",
        "id": 124052385,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521709588
    },
    {
        "content": "<p>Well we typically don't use definitional reduction for functions defined by well-founded recursion.  And yes, the nested inductives are really slow in the kernel.  It's not such a big deal because neither well-founded recursion nor generalized inductives are widely used, and then typically not for kernel reduction.</p>",
        "id": 124052460,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521709754
    },
    {
        "content": "<p>Hm, I wonder if the kernel could make use of rfl-lemmas. That would probably solve this problem and then some, since equation compiler definitions would be usable</p>",
        "id": 124052535,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521709888
    },
    {
        "content": "<p>Theoretically, yes.  (Although you potentially get non-termination, non-confluence, and loss of subject reduction <span class=\"emoji emoji-1f604\" title=\"smile\">:smile:</span> )  If I get bored, I might even try to implement inductives in trepplein using <code>W</code> with rfl-lemmas.  However, I'm doubtful that Leo will ever pursue that approach.  He didn't even use rfl-lemmas generated by the equation compiler in the type context.</p>",
        "id": 124052644,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521710047
    },
    {
        "content": "<p>Really? I thought they were used by the elaborator (\"smart unfolding\")</p>",
        "id": 124052651,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521710080
    },
    {
        "content": "<p>I believe that feature is implemented slightly differently.  IIRC we store an auxiliary definition that looks e.g. like <code>nat.add = λ x, λ y, nat.cases_on y ... nat.add ...</code> and use that for unfolding.</p>",
        "id": 124052710,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521710177
    },
    {
        "content": "<p>The <code>cases_on</code> still uses ɩ-reduction.</p>",
        "id": 124052716,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521710214
    },
    {
        "content": "<p>Of course we don't have to worry about non-confluence and subject reduction since lean never had those to begin with <span class=\"emoji emoji-1f604\" title=\"smile\">:smile:</span> but I agree that for it to behave properly you want to only use rfl-lemmas coming from structural recursive definitions, and so you would probably need an algebra of such</p>",
        "id": 124052720,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521710224
    },
    {
        "content": "<p>It might even be possible to have equation lemmas for wf definitions, but only for the underlying acc.rec term, where the hypothesis is exposed, to ensure termination</p>",
        "id": 124052774,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521710349
    },
    {
        "content": "<p>(yes I'm talking about features that probably will never be in leo lean, but maybe in other typecheckers)</p>",
        "id": 124052775,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521710384
    }
]