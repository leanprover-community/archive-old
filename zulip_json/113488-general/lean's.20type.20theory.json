[
    {
        "content": "<p>Okay, I'm a bit embarrassed to release this in this very early form, but there's enough meat in it that it can be useful to others even before it's done. This will probably become a major part of my master's thesis. What you will find:</p>\n<ul>\n<li>A definition of the axioms of lean<ul>\n<li>The basic DTT stuff</li>\n<li>let binders and definitions</li>\n<li>inductive types (in full gory detail)</li>\n<li>the computation rules (beta, eta, zeta, delta, iota)</li>\n<li>Quotient types</li>\n<li>propext and choice</li>\n</ul>\n</li>\n<li>Algorithmic equality (aka lean's defeq)<ul>\n<li>proof that algorithmic equality is not transitive and defeq is not decidable</li>\n</ul>\n</li>\n<li>Unique typing<ul>\n<li>A long and complicated proof, involving a hierarchy of church-rosser theorems. I'm really glad it worked out, but the complexity shows, and I need to trim it down and make it more accessible</li>\n</ul>\n</li>\n<li>Soundness (unfinished)<ul>\n<li>It is exactly as simple as it sounds like, but the language is huge and there are a lot of cases.</li>\n</ul>\n</li>\n</ul>\n<p><a href=\"https://github.com/digama0/lean-type-theory/releases/download/v0.1/main.pdf\" target=\"_blank\" title=\"https://github.com/digama0/lean-type-theory/releases/download/v0.1/main.pdf\">https://github.com/digama0/lean-type-theory/releases/download/v0.1/main.pdf</a></p>",
        "id": 123826805,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521257970
    },
    {
        "content": "<p>Oh many thanks for this -- as you saw, I made some sort of effort to engage with this kind of material without reading the source code (i.e. restricting to the docs) and it was tough. I am relieved to see that iota reduction applies to things defined by recursion rather than just cases!</p>",
        "id": 123835473,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1521278251
    },
    {
        "content": "<p>I spent some time yesterday trying to get to the bottom of this <code>accrec</code> example and it would have been a darn sight easier if I'd had access to this paper then.</p>",
        "id": 123836058,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1521279635
    },
    {
        "content": "<p>I think it's great that we finally have a written description of the type theory implemented in Lean.  Ideally it should also be included in the reference manual, and/or published somewhere.</p>",
        "id": 123837211,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521282416
    },
    {
        "content": "<p>section 2.3: I don't think it is a good idea to require full whnf in the algorithmic equivalence since we don't do it any of the implementations.  We do lazy delta-reduction, that is, do full beta/iota/quotient/zeta and only unfold the constant with the larger definitional height, once.  I think you should just replace ↓ by ⇝* here.</p>",
        "id": 123837329,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521282643
    },
    {
        "content": "<p>section 2.4: \"Lean takes a simpler approach and simply zeta expands these binders when necessary for checking.\":  I don't think you've defined \"Lean\" anywhere.  Not all of the implementations follow this approach.  The C++ <code>type_checker</code>, the Haskell <code>tc</code>, and <code>trepplein</code> all eagerly unfold lets.  However, the <code>type_context</code> doesn't.  I believe the term ζ-reduction typically refers to x ⇝ e'.</p>",
        "id": 123837381,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521282825
    },
    {
        "content": "<p>There are a few white lies in algorithmic equivalence, and I'd be happy to give a more honest account but I'm not quite sure how. (One thing I have noticed is that sometimes pure congruence proofs don't check, because one side is eagerly iota reduced to something that is not recognizably equivalent anymore.)</p>",
        "id": 123837575,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521283232
    },
    {
        "content": "<p>section 2.6.2: \"Here we have K-like elimination\": do you mean large elimination?  K-like reduction for acc would not be strongly normalizing, right?</p>",
        "id": 123837576,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521283240
    },
    {
        "content": "<p>I don't use the term \"subsingleton elimination\" anywhere in the paper, I may have mixed up my terms. I use K-like elimination to refer to large eliminating props</p>",
        "id": 123837581,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521283293
    },
    {
        "content": "<p>When I talk about \"lean does X\", I am usually referring to lean.exe's kernel. I didn't want to get into checking expressions with lets in the context, like <code>type_context</code> does, which is why I omitted that approach.</p>",
        "id": 123837625,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521283409
    },
    {
        "content": "<blockquote>\n<p>but there is a second reduction rule used for K-like eliminators. It can be thought of as a combination of proof irrelevance to change the major<br>\npremise into a constructor followed by the iota rule.</p>\n</blockquote>\n<p>Yes, you might want to clean up the definitions (and actually define them). ^^</p>",
        "id": 123837626,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521283410
    },
    {
        "content": "<p>which part?</p>",
        "id": 123837628,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521283433
    },
    {
        "content": "<p>Also: I just finished the proof of soundness. Celebrate! Lean can't prove false</p>",
        "id": 123837668,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521283471
    },
    {
        "content": "<p>K-like elimination refers to K-like reduction here, and subsingleton elimination on the page before, afaict.</p>",
        "id": 123837669,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521283474
    },
    {
        "content": "<p>That's not using algorithmic defeq, right?</p>",
        "id": 123837670,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521283496
    },
    {
        "content": "<p>Soundness for both algorithmic and ideal typechecking</p>",
        "id": 123837680,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521283557
    },
    {
        "content": "<p>I proved it for the ideal version, and the algorithmic check implies ideal check</p>",
        "id": 123837721,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521283592
    },
    {
        "content": "<blockquote>\n<p>algorithmic check implies ideal check</p>\n</blockquote>\n<p>That's not proven yet, right?</p>",
        "id": 123837765,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521283702
    },
    {
        "content": "<p>It's pretty trivial</p>",
        "id": 123837766,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521283712
    },
    {
        "content": "<p>the algorithmic rules are a subset of the ideal ones</p>",
        "id": 123837767,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521283724
    },
    {
        "content": "<p>the ideal check is basically what lean would do if it was nondeterministic and tried all the tricks at once</p>",
        "id": 123837772,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521283761
    },
    {
        "content": "<p>Except that the ideal ones have extra side conditions that require the well-typedness of all terms that occur.  The implication requires at the very least subject reduction for ⇝, which is not completely obvious to me.</p>",
        "id": 123837816,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521283848
    },
    {
        "content": "<p>Ok, I see subjection reduction is Lemma 3.10.</p>",
        "id": 123837861,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521283925
    },
    {
        "content": "<p>Note that -&gt;_kappa is a bit different from -&gt;, it has slightly different rules for iota stuff</p>",
        "id": 123837866,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521283986
    },
    {
        "content": "<p>I never explicitly stated subject reduction for -&gt; (using the ideal check), but maybe I should be more precise about it</p>",
        "id": 123837869,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521284038
    },
    {
        "content": "<p>I think the general approach for the algorithmic defeq is good.  It's better to have an over-approximation than to precisely model the actual (current implementation of the) type-checker.  If you can show this defeq proof system to be sound, then all \"reasonable\" type-checkers should be correct.</p>",
        "id": 123838082,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521284352
    },
    {
        "content": "<p>section 2.3:  you're also missing η-expansion, see <a href=\"https://github.com/leanprover/lean/blob/07bb7d809b6be49f38ce4e427c54a82708ae281f/src/kernel/type_checker.cpp#L517-L529\" target=\"_blank\" title=\"https://github.com/leanprover/lean/blob/07bb7d809b6be49f38ce4e427c54a82708ae281f/src/kernel/type_checker.cpp#L517-L529\">https://github.com/leanprover/lean/blob/07bb7d809b6be49f38ce4e427c54a82708ae281f/src/kernel/type_checker.cpp#L517-L529</a></p>",
        "id": 123838128,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521284413
    },
    {
        "content": "<p>Would it suffice to replace the eta rule with extensionality \"e x &lt;-&gt; e' x =&gt; e &lt;-&gt; e'\"?</p>",
        "id": 123838372,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521285120
    },
    {
        "content": "<p>or is this only used when solving lam x:a. e &lt;-&gt; e'</p>",
        "id": 123838415,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521285190
    },
    {
        "content": "<p>Yes, you can then recover η via the conversion rule.</p>",
        "id": 123838416,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521285199
    },
    {
        "content": "<p>Yes, in practice it is only used when one side is a lambda.</p>",
        "id": 123838417,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521285207
    },
    {
        "content": "<p>I know some typecheckers prefer extensionality over eta, since it's pretty easy to figure out when to use it</p>",
        "id": 123838454,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521285243
    },
    {
        "content": "<blockquote>\n<blockquote>\n<p>but there is a second reduction rule used for K-like eliminators. It can be thought of as a combination of proof irrelevance to change the major<br>\npremise into a constructor followed by the iota rule.</p>\n</blockquote>\n<p>Yes, you might want to clean up the definitions (and actually define them). ^^</p>\n</blockquote>\n<p>I don't follow. That passage looks alright, is something missing?</p>",
        "id": 123838801,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521286165
    },
    {
        "content": "<p>K-like elimination refers to multiple concepts in the paper: 1) subsingleton elimination, and 2) K-like reduction.  For example, <code>and</code> has 1) but not 2).</p>",
        "id": 123838901,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521286398
    },
    {
        "content": "<p>I use it essentially only for (1), (2) is more of a remark that comes up once as a sort of historical note \"why K?\"</p>",
        "id": 123838941,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521286488
    },
    {
        "content": "<p>You use it for 2) in section 2.6.4.  Although it is not clear how you obtain the <code>b</code> there.</p>",
        "id": 123838949,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521286537
    },
    {
        "content": "<p>I need a name for inductive types that eliminate to Type but live in Prop. \"Large elimination\" seems to also suggest when the type itself is large, so it's not a great name. Will subsingleton elimination cover exactly this usage?</p>",
        "id": 123838988,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521286582
    },
    {
        "content": "<p>the b is obtained from the LHS as described in the paragraph after</p>",
        "id": 123838989,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521286602
    },
    {
        "content": "<p>and it only applies if you can obtain all of b that way</p>",
        "id": 123838990,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521286616
    },
    {
        "content": "<p>I've only seen \"subsingleton elimination\" in this usage.</p>",
        "id": 123838991,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521286618
    },
    {
        "content": "<p>cool, I'll stop saying K-like then</p>",
        "id": 123838996,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521286642
    },
    {
        "content": "<p>Ah, next page, ok.</p>",
        "id": 123838997,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521286649
    },
    {
        "content": "<p>Huh, I've been telling myself that defeq is only undecidable in inconsistent contexts, but this is not true, almost trivially: if <code>x : 0 |- A = B</code> is some undecidable defeq problem, then <code>|- \\lam x : 0. A = \\lam x : 0. B</code> is also an undecidable defeq problem</p>",
        "id": 123840473,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521290324
    },
    {
        "content": "<p>I swear one day I'll have time to actually read this paper (or maybe a version with a bit higher word/symbol ratio). In the mean time I'm surprised by the source code. It' funny to see Lean consistently use unicode to be more readable than Coq but you still write <code>\\Gamma\\vdash \\alpha:\\U_\\ell\\quad \\Gamma\\vdash e:\\beta</code> in your LaTeX source like it's still 1990.</p>",
        "id": 123843167,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521296881
    },
    {
        "content": "<p>You even use <code>$$</code>!</p>",
        "id": 123843211,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521296933
    },
    {
        "content": "<p>And a non-semantic use of <code>\\frac</code></p>",
        "id": 123843221,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521296958
    },
    {
        "content": "<p>Ok, I go back to work</p>",
        "id": 123843223,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521296970
    },
    {
        "content": "<p>Yeah LaTeX is pretty horrible. Nothing seems to measure up though. And people have tried a lot</p>",
        "id": 123843262,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1521297003
    },
    {
        "content": "<p>Mario's LaTeX is horrible</p>",
        "id": 123843270,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521297022
    },
    {
        "content": "<p>Nothing keeps him in 1990</p>",
        "id": 123843272,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521297029
    },
    {
        "content": "<p>He could use <code>xeLaTeX</code> (or <code>LuaLaTeX</code>) and <code>unicode-math</code></p>",
        "id": 123843279,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521297094
    },
    {
        "content": "<p>Maybe that and underwater basket weaving are the things he doesn't rock at. But seriously, what does 2018 LaTeX look like?</p>",
        "id": 123843280,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1521297107
    },
    {
        "content": "<p>At least <a href=\"https://gitlab.com/PatrickMassot/h-principle/blob/master/src/hol_approx.tex\" target=\"_blank\" title=\"https://gitlab.com/PatrickMassot/h-principle/blob/master/src/hol_approx.tex\">https://gitlab.com/PatrickMassot/h-principle/blob/master/src/hol_approx.tex</a></p>",
        "id": 123843324,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521297163
    },
    {
        "content": "<p>(some unicode is not used in this example because this source code is also meant for MathJax consumption)</p>",
        "id": 123843336,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521297204
    },
    {
        "content": "<p>I have not actually tried those. You actually enter your formulas with unicode and don't need spacing commands?</p>",
        "id": 123843337,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1521297209
    },
    {
        "content": "<p>You still need spacing commands</p>",
        "id": 123843341,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521297231
    },
    {
        "content": "<p>but no <code>\\Gamma</code></p>",
        "id": 123843343,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521297240
    },
    {
        "content": "<p>That is pretty nice</p>",
        "id": 123843383,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1521297266
    },
    {
        "content": "<p>I'm never sure if unicode is going to get mangled somewhere</p>",
        "id": 123843396,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521297307
    },
    {
        "content": "<p>I've been trying org-mode for my dissertation. Maybe I should add one of those too</p>",
        "id": 123843397,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1521297308
    },
    {
        "content": "<p>I remember Floris sent in a tex file with lean snippets, and the journal typesetter complained about the unicode</p>",
        "id": 123843441,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521297366
    },
    {
        "content": "<p>Oh yes, you could have trouble with the journal</p>",
        "id": 123843444,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521297386
    },
    {
        "content": "<p>Today you still need to fight arXiv if you want to use 21th century LaTeX</p>",
        "id": 123843450,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521297409
    },
    {
        "content": "<p>can you use those tools as preprocessors?</p>",
        "id": 123843452,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1521297420
    },
    {
        "content": "<p>That's the reason why you see more and more papers on arxiv where only the pdf is available and not the TeX source</p>",
        "id": 123843459,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521297441
    },
    {
        "content": "<p>No one has ever convincingly explained to me why <code>$$</code> is worse than <code>\\[</code> (or something else?)</p>",
        "id": 123843504,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521297495
    },
    {
        "content": "<p>section 3.4: why do you consider η-reduction?  I don't think any Lean typechecker has that.</p>",
        "id": 123843560,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521297641
    },
    {
        "content": "<p>$$ has spacing issues (beyond being harder to parsers)</p>",
        "id": 123843567,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521297668
    },
    {
        "content": "<p><a href=\"https://tex.stackexchange.com/questions/503/why-is-preferable-to/69854\" target=\"_blank\" title=\"https://tex.stackexchange.com/questions/503/why-is-preferable-to/69854\">https://tex.stackexchange.com/questions/503/why-is-preferable-to/69854</a> probably contains useful links</p>",
        "id": 123843569,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1521297699
    },
    {
        "content": "<p>How else are you going to get eta reduction unless you put it in? Also: the constraints on the kappa reduction relation are very tight. I went through no less than 10 variations on it before I was able to get the church rosser theorem to go through</p>",
        "id": 123843622,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521297802
    },
    {
        "content": "<blockquote>\n<p>That's the reason why you see more and more papers on arxiv where only the pdf is available and not the TeX source</p>\n</blockquote>\n<p>Do you mean that it is not used as a preprocessor and therefore people only submit pdfs?</p>",
        "id": 123843662,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1521297843
    },
    {
        "content": "<p>Not at all?  None of the typecheckers uses it, AFAIK.  Trepplein definitely doesn't.  We only do η for defeq.</p>",
        "id": 123843665,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521297851
    },
    {
        "content": "<p>I just got the feeling that η is a serious complication here, and the main reason you need a new and different reduction relation and defeq relation.</p>",
        "id": 123843671,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521297890
    },
    {
        "content": "<p>the whole point of the kappa reduction is so that the statement of Theorem 3.15 holds</p>",
        "id": 123843679,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521297912
    },
    {
        "content": "<p>The alternative would be to try to put eta or extensionality in the =p relation</p>",
        "id": 123843724,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521298022
    },
    {
        "content": "<p>I thought it is included in the ... in the definition of =p.</p>",
        "id": 123843729,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521298033
    },
    {
        "content": "<p>the ... only includes compatibility rules</p>",
        "id": 123843730,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521298048
    },
    {
        "content": "<p>I don't think it says that anywhere. (at least not above and below the definition)</p>",
        "id": 123843772,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521298099
    },
    {
        "content": "<p>It's a very spartan relation, it's just replacing proofs and nothing else (except for that lambda thing)</p>",
        "id": 123843778,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521298178
    },
    {
        "content": "<p>I will investigate whether it suffices to have one-sided extensionality e =p e' x =&gt; lam x:a. e =p e' and remove eta from the kappa reduction. If so that would allow me to remove the context from -&gt;k, which would be nice</p>",
        "id": 123843925,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521298475
    },
    {
        "content": "<p>I think the biggest departure from the usual reduction relation is the K reduction (which I have renamed K+), because it is super aggressive unfolding of a proof, which guarantees nontermination when it sees an acc.rec</p>",
        "id": 123844178,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521299071
    },
    {
        "content": "<p>so is this paper about what Lean does, or what it should do in your opinion :-)</p>",
        "id": 123844779,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1521300585
    },
    {
        "content": "<p>And do the devs have any comments about whether Lean 4 will do the same thing when it comes to definitional equality?</p>",
        "id": 123844830,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1521300613
    },
    {
        "content": "<p>Not sure if I count as a dev anymore, but I seriously doubt there will be any foundational changes in Lean 4.</p>",
        "id": 123844835,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521300645
    },
    {
        "content": "<p>That's good to know -- I guess there were foundational changes from Lean 2 to Lean 3 so I suppose it wasn't something one could definitely assume...</p>",
        "id": 123844845,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1521300698
    },
    {
        "content": "<p>There were exactly two foundational changes from Lean 2 to Lean 3: 1) let-expressions in the kernel (completely harmless), 2) mutually inductive types are no longer supported by the kernel (these are now simulated).  Also the axioms for choice and quotients got some mostly cosmetic changes.</p>",
        "id": 123844931,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521300846
    },
    {
        "content": "<p>Oh I thought there was some change to the underlying type theory -- HoTT in Lean 2?</p>",
        "id": 123844940,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1521300906
    },
    {
        "content": "<p>Oh yes, HoTT got removed from the kernel (you had to pass an extra command-line flag to use it, and there was a separate library).  Completely forgot about that.  But we now have a reasonably way to do it without kernel changes: <a href=\"https://github.com/gebner/hott3\" target=\"_blank\" title=\"https://github.com/gebner/hott3\">https://github.com/gebner/hott3</a></p>",
        "id": 123845033,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521301109
    },
    {
        "content": "<blockquote>\n<p>so is this paper about what Lean does, or what it should do in your opinion :-)</p>\n</blockquote>\n<p>The motivation is of course what lean does, but this is badly behaved in a number of ways which make it completely unsuitable for theoretical treatment, so I replace it with a better version, show soundness of the original version with respect to that, and then forget about the original thing</p>",
        "id": 123845396,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521302001
    },
    {
        "content": "<p>As Gabriel mentions, there are multiple \"leans\", and they don't all agree on the foundational stuff. This is in part what I wanted to address with this paper, to get down a single system that we can talk about as the ideal lean, and look at how close we can get to that. One thing which should be true, however, is that all existing lean kernels are underestimates of the typing judgment in this paper. That means that anything you can't prove with the ideal judgment can't be verified in these kernels either, which is the soundness result I want</p>",
        "id": 123845485,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521302214
    },
    {
        "content": "<p>AFAICT all existing kernels even fit within the <em>algorithmic</em> definitional equality check.</p>",
        "id": 123845593,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521302448
    },
    {
        "content": "<p>NB: I think the algorithmic definitional equality is not just an ugly approximation of the ideal one, but also important as a practical <em>optimization</em>: using the algorithmic definitional equality, we can elide almost all type-inference calls during type-checking.</p>",
        "id": 123845655,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521302553
    },
    {
        "content": "<p>Compare also the various variants of the typing rules proved equivalent in [1].<br>\n[1] A.Bauer, P. Haselwarter, T. Wintertaler, A modular formalization of type theory in Coq, TYPES (2017). <a href=\"http://math.andrej.com/2017/05/29/a-modular-formalization-of-type-theory-in-coq/\" target=\"_blank\" title=\"http://math.andrej.com/2017/05/29/a-modular-formalization-of-type-theory-in-coq/\">http://math.andrej.com/2017/05/29/a-modular-formalization-of-type-theory-in-coq/</a></p>",
        "id": 123845731,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521302710
    },
    {
        "content": "<p>I'm also having difficulty with stating strong normalization because of my struggles here, I think. What is the reduction relation of interest here? Is it just head reduction? I think it is supposed to include reduction under binders, but then once we decide \"arbitrarily\" not to reduce some things that should be reducible, in what sense are we talking about the \"right\" relation? I.e. what does strong normalization have to do with consistency?</p>",
        "id": 123845987,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521303320
    },
    {
        "content": "<p>Weak head reduction is enough for consistency.  But strong normalization for the full reduction relation is definitely interesting as well.</p>",
        "id": 123846304,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521304024
    },
    {
        "content": "<p>Since we've talked about η today, I think I've found a novel way to break transitivity with just K-like reduction for <code>eq</code>:</p>\n<div class=\"codehilite\"><pre><span></span><span class=\"n\">def</span> <span class=\"n\">foo</span> <span class=\"o\">:</span> <span class=\"mi\">0</span> <span class=\"bp\">=</span> <span class=\"mi\">0</span> <span class=\"bp\">→</span> <span class=\"bp\">ℕ</span> <span class=\"o\">:=</span>\n<span class=\"bp\">@</span><span class=\"n\">eq</span><span class=\"bp\">.</span><span class=\"n\">rec</span> <span class=\"bp\">ℕ</span> <span class=\"mi\">0</span> <span class=\"o\">(</span><span class=\"bp\">λ</span> <span class=\"bp\">_</span><span class=\"o\">,</span> <span class=\"bp\">ℕ</span><span class=\"o\">)</span> <span class=\"mi\">42</span> <span class=\"mi\">0</span>\n<span class=\"n\">def</span> <span class=\"n\">bar</span> <span class=\"o\">:</span> <span class=\"mi\">0</span> <span class=\"bp\">=</span> <span class=\"mi\">0</span> <span class=\"bp\">→</span> <span class=\"bp\">ℕ</span> <span class=\"o\">:=</span>\n<span class=\"bp\">@</span><span class=\"n\">eq</span><span class=\"bp\">.</span><span class=\"n\">rec</span> <span class=\"bp\">ℕ</span> <span class=\"mi\">0</span> <span class=\"o\">(</span><span class=\"bp\">λ</span> <span class=\"n\">n</span><span class=\"o\">,</span> <span class=\"k\">if</span> <span class=\"n\">n</span> <span class=\"bp\">=</span> <span class=\"mi\">0</span> <span class=\"k\">then</span> <span class=\"bp\">ℕ</span> <span class=\"k\">else</span> <span class=\"n\">empty</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"mi\">42</span> <span class=\"o\">:</span> <span class=\"bp\">ℕ</span><span class=\"o\">)</span> <span class=\"mi\">0</span>\n\n<span class=\"kn\">example</span> <span class=\"o\">:</span> <span class=\"n\">foo</span> <span class=\"bp\">=</span> <span class=\"o\">(</span><span class=\"bp\">λ</span> <span class=\"bp\">_</span><span class=\"o\">,</span> <span class=\"mi\">42</span><span class=\"o\">)</span> <span class=\"o\">:=</span> <span class=\"n\">rfl</span>\n<span class=\"kn\">example</span> <span class=\"o\">:</span> <span class=\"n\">bar</span> <span class=\"bp\">=</span> <span class=\"o\">(</span><span class=\"bp\">λ</span> <span class=\"bp\">_</span><span class=\"o\">,</span> <span class=\"mi\">42</span><span class=\"o\">)</span> <span class=\"o\">:=</span> <span class=\"n\">rfl</span>\n<span class=\"kn\">example</span> <span class=\"o\">:</span> <span class=\"n\">foo</span> <span class=\"bp\">=</span> <span class=\"n\">bar</span> <span class=\"o\">:=</span> <span class=\"n\">rfl</span> <span class=\"c1\">-- fails</span>\n</pre></div>",
        "id": 123846367,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1521304202
    },
    {
        "content": "<p>I found an interesting potential computational rule for <code>quot.sound</code>:</p>\n<div class=\"codehilite\"><pre><span></span>variables (α : Sort*) (r : α → α → Prop) (a : α)\n  (f : α → Sort*) (H : ∀ (a b : α), r a b → f a = f b)\n  (e : f a) (b : α) (h : r a b)\n\nexample : @eq.rec (quot r) (quot.mk r a) (quot.lift f H) e\n            (quot.mk r b) (quot.sound h) = cast (H a b h) e :=\nby change H a b h with (congr_arg (quot.lift f H) (quot.sound h):_);\n   induction quot.sound h; refl\n</pre></div>",
        "id": 123846714,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521304939
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110043\">@Gabriel Ebner</span> That was a big pain during the proof of church rosser. It's actually not a theoretical problem, but rather a side effect of K reductions without accounting for eta reduction</p>",
        "id": 123846769,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521305121
    },
    {
        "content": "<p>I fixed it by making sure that all recursors have the right number of arguments at all times</p>",
        "id": 123846775,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521305150
    },
    {
        "content": "<p>Alternatively, any K-like inductive should be eta expanded before normalization</p>",
        "id": 123846824,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521305186
    },
    {
        "content": "<p>The problem is that unapplied K recursors are stuck terms when they shouldn't be</p>\n<div class=\"codehilite\"><pre><span></span>variables (α : Sort*) (a : α) (C : α → Sort*) (e : C a)\n#reduce λ h, @eq.rec α a C e a h -- λ (h : a = a), e   &lt;- good\n#reduce @eq.rec α a C e a -- eq.rec e                  &lt;- bad\n</pre></div>",
        "id": 123847134,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521305896
    },
    {
        "content": "<p>I originally had the recursors evaluating to lambdas like this, but it was a notational nightmare since the number of unapplications depends on how many variables there are (the only one you have \"control\" over is the major premise, once that one is allowed to be a variable you have to deal with the parameters and such, and any of those could be variables or things equivalent to variables...), so I opted instead for an up-front eta expansion, since during reduction a recursor never loses its major premise</p>",
        "id": 123847259,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1521306217
    }
]