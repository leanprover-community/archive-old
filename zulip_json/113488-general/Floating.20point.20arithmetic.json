[
    {
        "content": "<p>A student here has a lovely suggestion for a simple application of machine learning to automation. I’d love to try implementing it with her, but quickly realised that we’d need to do floating point arithmetic (just some gradient descent problems, so essentially inverting numerical matrices).</p>",
        "id": 125010724,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1523577428
    },
    {
        "content": "<p>It seems the options would be:<br>\n1. Do this directly in Lean<br>\n2. Do it in C++, and have to compile our own branch of Lean to run it<br>\n3. Call external processes via the io monad</p>",
        "id": 125010780,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1523577515
    },
    {
        "content": "<p>If anyone has advice or suggestions choosing between these, I’d love to hear.</p>",
        "id": 125010794,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1523577583
    },
    {
        "content": "<p>Any chance that representing your numbers as fractions like Q does would be good enough?</p>",
        "id": 125010851,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1523577654
    },
    {
        "content": "<p>The other idea I can think of is to use the C api to call a lean function that takes the float type and its operations as parameters.</p>",
        "id": 125011141,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1523578206
    },
    {
        "content": "<p>In the second case, that means that you don't need your own branch of Lean which might make it easier to evolve along the successive versions of Lean</p>",
        "id": 125011155,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1523578271
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 125011157,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1523578273
    },
    {
        "content": "<p>i would try and write it in C++ for now; when lean 4 rolls around there should be a ffi we can interface with</p>",
        "id": 125012392,
        "sender_full_name": "Andrew Ashworth",
        "timestamp": 1523580750
    },
    {
        "content": "<p>ironically it might be less work, since there's no notion of matrix computations in lean</p>",
        "id": 125012563,
        "sender_full_name": "Andrew Ashworth",
        "timestamp": 1523581105
    },
    {
        "content": "<p>There is an experimental implementation of floating point arithmetic in <code>data.fp.basic</code> in mathlib. I'm not certain about all the modeling choices yet, especially considering how inconsistent hardware support is for floats, even when IEEE-conforming. I know Leo is also tackling this problem; the last version of the lean IR I saw supported floats at the low level, so I expect that Lean 4 will have a float datatype, and I'm not sure what he intends to do about the inconsistencies (probably just ignore them, but that means going meta which I'd like to avoid).</p>",
        "id": 125014205,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1523584621
    },
    {
        "content": "<blockquote>\n<p>The other idea I can think of is to use the C api to call a lean function that takes the float type and its operations as parameters.</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"110026\">@Simon Hudon</span>, where can I read about / see an example of the C api?</p>",
        "id": 125017055,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1523590951
    },
    {
        "content": "<p>I don't know of any good documentation. Beside the source code, you could look at Joe Hendrix' Haskell binding for Lean: <a href=\"https://github.com/GaloisInc/lean-haskell-bindings/tree/master/src/Language/Lean/Internal\" target=\"_blank\" title=\"https://github.com/GaloisInc/lean-haskell-bindings/tree/master/src/Language/Lean/Internal\">https://github.com/GaloisInc/lean-haskell-bindings/tree/master/src/Language/Lean/Internal</a></p>",
        "id": 125017243,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1523591385
    },
    {
        "content": "<p>Maybe before I get started: I'm looking to write most of my tactic in Lean, and just farm out the numerics to C. Is this API suitable for doing that kind of thing? Or just for calling Lean from C?</p>",
        "id": 125017302,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1523591467
    },
    {
        "content": "<p>I think just calling Lean from C should be sufficient. You can do a bit like the old IO interface and make a type class:</p>\n<div class=\"codehilite\"><pre><span></span>class float.interface :=\n  (float : Type)\n  (add : float -&gt; float -&gt; float)\n  (mul : floal -&gt; float -&gt; float)\n  -- ...\n</pre></div>\n\n\n<p>Then, on the lean side, all you need is <code>variable [float.interface]</code> at the beginning of the files that need access to float. On the C side, you create an instance and you call <code>main</code> with that instance as a parameter.</p>",
        "id": 125017469,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1523591785
    },
    {
        "content": "<p>Okay, but I want to initiate all this running from inside the tactic monad. How do I even tell Lean about the existence of that C code?</p>",
        "id": 125017523,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1523591904
    },
    {
        "content": "<p>I see, yeah, that's tricky. Maybe forking Lean would be easier for that</p>",
        "id": 125017544,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1523591982
    },
    {
        "content": "<p>Would the Lean Mathematica interface be useful here?</p>",
        "id": 125022727,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1523603528
    },
    {
        "content": "<p>[I don't really know what I'm talking about]</p>",
        "id": 125022729,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1523603544
    },
    {
        "content": "<p>That sounds like a good idea to me. It might simplify things even more because matrix multiplication / inversion is already implemented in Mathematical</p>",
        "id": 125032505,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1523623370
    }
]