[
    {
        "content": "<p>Has anyone used this already? <a href=\"https://copilot.github.com/\">https://copilot.github.com/</a></p>",
        "id": 244318856,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1624988305
    },
    {
        "content": "<p>Signed up for the waitlist.</p>",
        "id": 244321413,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1624989461
    },
    {
        "content": "<p>Let us know how it goes when you get access... Just saw the link on HN.</p>",
        "id": 244321686,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1624989572
    },
    {
        "content": "<p>On this note, <a href=\"https://www.tabnine.com/\">TabNine</a> could also be interesting to play with in the context of Lean</p>",
        "id": 244324359,
        "sender_full_name": "Bhavik Mehta",
        "timestamp": 1624990599
    },
    {
        "content": "<p>Oh and it looks like tabnine also works with the correct editor.</p>",
        "id": 244324757,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1624990791
    },
    {
        "content": "<p>Just FYI, from the copilot waitlist signup:<br>\n<a href=\"/user_uploads/3121/quiZ8VPNA7VYds7QrYXxHaCK/Screenshot-2021-06-29-at-13-12-46-Build-software-better-together.png\">Screenshot-2021-06-29-at-13-12-46-Build-software-better-together.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/quiZ8VPNA7VYds7QrYXxHaCK/Screenshot-2021-06-29-at-13-12-46-Build-software-better-together.png\" title=\"Screenshot-2021-06-29-at-13-12-46-Build-software-better-together.png\"><img src=\"/user_uploads/3121/quiZ8VPNA7VYds7QrYXxHaCK/Screenshot-2021-06-29-at-13-12-46-Build-software-better-together.png\"></a></div>",
        "id": 244332578,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1624994130
    },
    {
        "content": "<p>I poked at TabNine in Python and wasn’t impressed.</p>",
        "id": 244335067,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1624995228
    },
    {
        "content": "<p>this looks kinda like lean-gptf</p>",
        "id": 244347362,
        "sender_full_name": "Eric Rodriguez",
        "timestamp": 1625000598
    },
    {
        "content": "<p>Is there any reason to think that copilot or TabNine would support Lean, which has a very small user base?</p>",
        "id": 244364801,
        "sender_full_name": "Jason Rute",
        "timestamp": 1625012229
    },
    {
        "content": "<p>Also, for tactic proofs, I imagine lean-gptf would do better than any other solution which can't see the tactic state.</p>",
        "id": 244364867,
        "sender_full_name": "Jason Rute",
        "timestamp": 1625012285
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/113488-general/topic/github.20copilot/near/244364801\">said</a>:</p>\n<blockquote>\n<p>Is there any reason to think that copilot or TabNine would support Lean, which has a very small user base?</p>\n</blockquote>\n<p>TabNine certainly does support Lean - I've only been using it this evening but it's already been pretty convenient and helpful so far</p>",
        "id": 244369989,
        "sender_full_name": "Bhavik Mehta",
        "timestamp": 1625018635
    },
    {
        "content": "<p>I stand corrected.  I’d love to hear your thoughts!</p>",
        "id": 244372557,
        "sender_full_name": "Jason Rute",
        "timestamp": 1625022021
    },
    {
        "content": "<p>It's like a smarter version of VSCode autocomplete - since it's easy to setup and fast it's mostly been convenient in practice; the suggestions are sometimes really weird but also sometimes pretty smart, it filled in a couple of proofs of me earlier today and I just had this example</p>",
        "id": 244512561,
        "sender_full_name": "Bhavik Mehta",
        "timestamp": 1625107340
    },
    {
        "content": "<p><a href=\"/user_uploads/3121/vGbmBf87gMfO0gTroPCLHegp/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/vGbmBf87gMfO0gTroPCLHegp/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/vGbmBf87gMfO0gTroPCLHegp/image.png\"></a></div>",
        "id": 244512571,
        "sender_full_name": "Bhavik Mehta",
        "timestamp": 1625107352
    },
    {
        "content": "<p>What's cool to me here is that there was no instance of <code>f.inv</code> anywhere in this file, and no instances of <code>to_nat_trans := f.inv</code> in mathlib, so presumably it made an analogy with the <code>hom := { to_nat_trans := f.hom</code> earlier to make this suggestion (and it was what I wanted!)</p>",
        "id": 244512620,
        "sender_full_name": "Bhavik Mehta",
        "timestamp": 1625107419
    },
    {
        "content": "<p>Meanwhile it seems less smart for me:<br>\n<a href=\"/user_uploads/3121/QxBuhgFKnKUJJrgiOPEfVN9v/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/QxBuhgFKnKUJJrgiOPEfVN9v/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/QxBuhgFKnKUJJrgiOPEfVN9v/image.png\"></a></div>",
        "id": 244574315,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1625149452
    },
    {
        "content": "<p>is that copilot or tabnine</p>",
        "id": 244582138,
        "sender_full_name": "Huỳnh Trần Khanh",
        "timestamp": 1625152239
    },
    {
        "content": "<p>So <span class=\"user-mention\" data-user-id=\"246273\">@Bhavik Mehta</span> is using tabnine and <span class=\"user-mention\" data-user-id=\"310045\">@Eric Wieser</span> is using copilot, right?</p>",
        "id": 244597360,
        "sender_full_name": "Jason Rute",
        "timestamp": 1625158948
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span> You should convince open ai to use gptf in copilot for lean. <span aria-label=\"rolling on the floor laughing\" class=\"emoji emoji-1f923\" role=\"img\" title=\"rolling on the floor laughing\">:rolling_on_the_floor_laughing:</span>   (More seriously, I could imagine a future when all of these coding helper tools use internal language-server-like information to make suggestions, either using the actual language server, or by training a world model to predict what the language server would say.)</p>",
        "id": 244597474,
        "sender_full_name": "Jason Rute",
        "timestamp": 1625159008
    },
    {
        "content": "<p>Actually, it looks like TabNine already <a href=\"https://www.tabnine.com/semantic\">makes use of LSP information</a>.  Since Lean 3's server is nonstandard, I assume it doesn't use it, but I can't be sure.</p>",
        "id": 244600560,
        "sender_full_name": "Jason Rute",
        "timestamp": 1625160418
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/113488-general/topic/github.20copilot/near/244600560\">said</a>:</p>\n<blockquote>\n<p>Actually, it looks like TabNine already <a href=\"https://www.tabnine.com/semantic\">makes use of LSP information</a>.  Since Lean 3's server is nonstandard, I assume it doesn't use it, but I can't be sure.  If it does, maybe TabNine and lean-gptf aren't so different (but I honestly have no idea how tabnine (or copilot) work, only speculation)????</p>\n</blockquote>\n<p>I think a direct comparison isn't the most helpful thing here - in my mind the value of TabNine is to speed up filling in boilerplate and repetitive-looking code (eg I found it helpful when writing docstrings and my example above) whereas the value of lean-gptf is to suggest tactics in the middle of a non-trivial argument. I think their use-cases right now are somewhat orthogonal. That said, tabnine is easier to set up and integrate into my workflow than lean-gptf is - in my experience at least</p>",
        "id": 244600820,
        "sender_full_name": "Bhavik Mehta",
        "timestamp": 1625160569
    },
    {
        "content": "<p>Totally.  (I actually removed that comparison as I thought about it more.)   Part of my speculation though is that tools like gptf which aim to provide proof completion, and tools like tabnine which aim to provide code completion, are starting to converge.  We showed in gptf that combining the internal state of a theorem prover with lots of semantically aware training data and a powerful language model gave good prediction results (and even better if combined with a tree search).  This is really possible with any programming language to some extent and language servers make it easier to access such internal information (and generate training data).  Obviously we understand lean much better than TabNine likely does and our gptf training data is very well curated for the task at hand, but maybe one day the lean 4 language server will make its own language model autocomplete predictions based on semantic data, or maybe it will integrate seamlessly with external autocomplete tools like TabNice or CoPilot through LSP.</p>",
        "id": 244601818,
        "sender_full_name": "Jason Rute",
        "timestamp": 1625161053
    },
    {
        "content": "<p>In copilot's defense, it did correctly fill in all the data fields for a structure I'd defined based on a similar definition within the same file</p>",
        "id": 244604512,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1625162347
    },
    {
        "content": "<p>That is, it was able to fill out <a href=\"https://github.com/pygae/lean-ga/commit/9f2f36dd9236faa4403f933e8800c395cd9b2516#diff-ea46f0747e8966ee3d0d9038acf03712d4167146505ba9a539e4ef8cd4b0b360R75-R81\">these lines</a> based presumably on what it learned from the removed lines further down the patch</p>",
        "id": 244604661,
        "sender_full_name": "Eric Wieser",
        "timestamp": 1625162410
    },
    {
        "content": "<p>Note that OpenAI Codex, the model behind Copilot, was never trained on Lean code and Copilot does not leverage the LSP either. Its current Lean capabilities are zero-shot capabilities of Codex, based on what it sees from the content of your file before the place of completion. Don't expect it to be good, but it's already quite exciting to see that it picks up the syntax generally correctly. We're looking to include Lean code in future version of Codex which would make copilot potentially useful when working with Lean.</p>\n<p>Alternatively, it is clear from this thread that the UX of Copilot is the right one as it requires no effort from the user compared with lean-gptf. We have new models of GPT-f that are much more powerful than what is currently available to the current <code>gptf</code> tactic. We're looking to make them available and are thinking about leveraging the Lean VSCode extension. Obviously we can't use the same UX as copilot as GPT-f only works in tactic mode and you generally want to see &gt;1 suggestions, but we could query the model in the background when working on a tactic state such that suggestions are displayed in the info view without user intervention.</p>\n<p>Do you think it's the right direction? Any other idea? Happy to chat about these!</p>",
        "id": 244667806,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1625210750
    },
    {
        "content": "<p>Also, on top of picking the syntax, Copilot is not completely dumb (though these examples are probably memorized) <br>\n<a href=\"/user_uploads/3121/1jjOa6_Ybm_zltDfVstDlThU/Screen-Shot-2021-06-18-at-14.47.52.png\">Screen-Shot-2021-06-18-at-14.47.52.png</a> <br>\n<a href=\"/user_uploads/3121/8VRdJdpeh-eGU3yh2qRvKLRv/Screen-Shot-2021-06-18-at-14.54.47.png\">Screen-Shot-2021-06-18-at-14.54.47.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/1jjOa6_Ybm_zltDfVstDlThU/Screen-Shot-2021-06-18-at-14.47.52.png\" title=\"Screen-Shot-2021-06-18-at-14.47.52.png\"><img src=\"/user_uploads/3121/1jjOa6_Ybm_zltDfVstDlThU/Screen-Shot-2021-06-18-at-14.47.52.png\"></a></div><div class=\"message_inline_image\"><a href=\"/user_uploads/3121/8VRdJdpeh-eGU3yh2qRvKLRv/Screen-Shot-2021-06-18-at-14.54.47.png\" title=\"Screen-Shot-2021-06-18-at-14.54.47.png\"><img src=\"/user_uploads/3121/8VRdJdpeh-eGU3yh2qRvKLRv/Screen-Shot-2021-06-18-at-14.54.47.png\"></a></div>",
        "id": 244668023,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1625210884
    },
    {
        "content": "<p>I think queries in the background are a very good move. The less the user needs to do, the better.</p>",
        "id": 244669954,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1625212234
    },
    {
        "content": "<p>Whether this is computationally feasible, I don't know.</p>",
        "id": 244669965,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1625212245
    },
    {
        "content": "<p>I can imagine that \"fire a query when the user explicitly asks for it\" vs \"fire a query every time the user hits a key\" is a difference of maybe almost two orders of magnitude.</p>",
        "id": 244670005,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1625212291
    },
    {
        "content": "<p>Definitely but I'm confident we'll make it work <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span>  (by make it work I mean finding the compute to support the Lean community more than technically which is OK as demonstrated by Copilot)</p>",
        "id": 244670104,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1625212355
    }
]