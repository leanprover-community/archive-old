[
    {
        "content": "<p>I actually would be super interested in getting lean faster than C on such codes and have thought about this quite a bit. A lot of the vectorization/performance tricks that we apply in <a href=\"https://dl.acm.org/doi/10.1145/3428263\">https://dl.acm.org/doi/10.1145/3428263</a> and <a href=\"https://dl.acm.org/doi/10.1145/3485539\">https://dl.acm.org/doi/10.1145/3485539</a> could potentially work better in lean.</p>",
        "id": 319368231,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672831313
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"122318\">Tobias Grosser</span> <a href=\"#narrow/stream/348111-std4/topic/SAT.20core.20defs.20in.20Std.3F/near/319368231\">said</a>:</p>\n<blockquote>\n<p>I actually would be super interested in getting lean faster than C on such codes and have thought about this quite a bit. A lot of the vectorization/performance tricks that we apply in <a href=\"https://dl.acm.org/doi/10.1145/3428263\">https://dl.acm.org/doi/10.1145/3428263</a> and <a href=\"https://dl.acm.org/doi/10.1145/3485539\">https://dl.acm.org/doi/10.1145/3485539</a> could potentially work better in lean.</p>\n</blockquote>\n<p>Why do you believe they could work better in Lean?</p>",
        "id": 319379448,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1672835598
    },
    {
        "content": "<p>In C++ we face issues with (a) pointer aliasing, (b) partial evaluating the type-specific variants - the templates become crazy, (c) it is hard to supply proofs that certain low-precision types are sufficient, (d) and we cannot synthesis vector code effectively from C++. Lean's pure nature makes pointer aliasing simple to work with and lean is more modular and flexible such that b&amp;d can be addressed, and (c) is what lean is anyway good at.</p>",
        "id": 319408965,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672844989
    },
    {
        "content": "<p>I feel we could build e..g something like <a href=\"https://terralang.org/\">https://terralang.org/</a> in lean with an LLVM/MLIR backend.</p>",
        "id": 319409127,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672845021
    },
    {
        "content": "<p>Also, the macro system in lean will make many of these things a lot easier, and the interactive proof mode could probably be used to make this process more approachable from a human perspective.</p>",
        "id": 319409277,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672845066
    },
    {
        "content": "<p>Also, if you look at how the simplex algorithm is implemented, it is really rewriting matrices in-place. Hence, the initial algorithm can be nicely written in a purely functional style yet the generated code could be fully in place. If we then find a good way to (a) specialize the code according to types and (b) switch between those variants with little overhead we are good.</p>",
        "id": 319409758,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672845194
    },
    {
        "content": "<p>Given that we now have an LLVM backend we could implement sth like the clang/gcc vector extensions: <a href=\"https://clang.llvm.org/docs/LanguageExtensions.html#vectors-and-extended-vectors\">https://clang.llvm.org/docs/LanguageExtensions.html#vectors-and-extended-vectors</a></p>",
        "id": 319410055,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672845280
    },
    {
        "content": "<p>Which expose fast SIMD code to the programmers.</p>",
        "id": 319410088,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672845288
    },
    {
        "content": "<p>Compilers such as GHC do not have a good SIMD backend, so they have a hard time implementing these.</p>",
        "id": 319410148,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672845311
    },
    {
        "content": "<p>LLVM also has excellent support for <a href=\"https://clang.llvm.org/docs/LanguageExtensions.html#checked-arithmetic-builtins\">Checked arithmetic builtins</a> and even SIMD versions of those, which again is sth that we could use.</p>",
        "id": 319410365,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672845369
    },
    {
        "content": "<p>Finally, and now we go crazy (but I like that) we could even encode rationals as floats/doubles. <a href=\"/user_uploads/3121/CNYyNfzsrFZMvvbVs25OYYLA/ideas_fast-ap-integers.md-at-main-opencompl_ideas.pdf\">ideas_fast-ap-integers.md-at-main-opencompl_ideas.pdf</a></p>",
        "id": 319410844,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672845521
    },
    {
        "content": "<p>And again, to decide when a float is precise and when we need to fall-back to arbitrary precision rationals we certainly would benefit from lean as a language.</p>",
        "id": 319411064,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672845589
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"122318\">Tobias Grosser</span> <a href=\"#narrow/stream/348111-std4/topic/SAT.20core.20defs.20in.20Std.3F/near/319409127\">said</a>:</p>\n<blockquote>\n<p>I feel we could build e..g something like <a href=\"https://terralang.org/\">https://terralang.org/</a> in lean with an LLVM/MLIR backend.</p>\n</blockquote>\n<p>that's pretty interesting <span aria-label=\"thinking\" class=\"emoji emoji-1f914\" role=\"img\" title=\"thinking\">:thinking:</span> <span class=\"user-mention\" data-user-id=\"122318\">@Tobias Grosser</span> do you know this well? I'm curious how this differs from <a href=\"https://fstarlang.github.io/lowstar/html/Introduction.html#the-essence-of-low\">Low*</a>, or is it very similar?</p>",
        "id": 319429849,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1672851341
    },
    {
        "content": "<p>I guess it's similar. What's nice about Terra is that it integrates with llvm which means you get well optimized code that is JIT compiled without going through C and you can also have access of llvms vector abstractions.</p>",
        "id": 319430477,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672851527
    },
    {
        "content": "<p>What makes Terra special is that you can use  Lua variables from terras low level code and Lua can access Terra variables. It's very dynamic yet fast.</p>",
        "id": 319430613,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672851577
    },
    {
        "content": "<p>I feel in lean we could do the same, but maybe even nicer with dynamic syntax extensions, eventually exposing mlir abstractions,...</p>",
        "id": 319430804,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672851619
    },
    {
        "content": "<p>If this goes well we could give the lean users access to very low level abstractions, yet allowing for fast code to be generated. This will also help scilean and such.</p>",
        "id": 319431070,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672851691
    },
    {
        "content": "<p>It probably would require some kind of compiler support to treat these low-level abstractions specially in code generation, right?</p>",
        "id": 319431237,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1672851732
    },
    {
        "content": "<p>Lean already allows for annotations for using c.</p>",
        "id": 319431368,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672851771
    },
    {
        "content": "<p>We could add annotations for using custom llvm and MLIR as implementation of a lean function.</p>",
        "id": 319431447,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672851792
    },
    {
        "content": "<p>And then some macro magic to provide a lean api to end-users.</p>",
        "id": 319431564,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672851827
    },
    {
        "content": "<p>Coincidentally we already have an llvm backend, so what's missing is mostly macro magic.</p>",
        "id": 319431641,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672851844
    },
    {
        "content": "<p>I guess also the <a href=\"https://arxiv.org/abs/1703.00053\">right abstractions</a> if we'd want to reason about that code</p>",
        "id": 319432047,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1672851969
    },
    {
        "content": "<p>Do you know anybody who could be interested in collaborating on the macro aspects of this?</p>",
        "id": 319432074,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672851977
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"122318\">Tobias Grosser</span> <a href=\"#narrow/stream/348111-std4/topic/SAT.20core.20defs.20in.20Std.3F/near/319431447\">said</a>:</p>\n<blockquote>\n<p>We could add annotations for using custom llvm and MLIR as implementation of a lean function.</p>\n</blockquote>\n<p>I mean this would just be an attribute with special support in the LLVMEmitter in the Lean code generator no?<br>\n<span class=\"user-mention silent\" data-user-id=\"122318\">Tobias Grosser</span> <a href=\"#narrow/stream/348111-std4/topic/SAT.20core.20defs.20in.20Std.3F/near/319431564\">said</a>:</p>\n<blockquote>\n<p>And then some macro magic to provide a lean api to end-users.</p>\n</blockquote>\n<p>If we have Lean functions tagged as implement by LLVM/MLIR what additional macro magic do we need?</p>",
        "id": 319432433,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1672852089
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"315434\">Andrés Goens</span> <a href=\"#narrow/stream/348111-std4/topic/SAT.20core.20defs.20in.20Std.3F/near/319432047\">said</a>:</p>\n<blockquote>\n<p>I guess also the <a href=\"https://arxiv.org/abs/1703.00053\">right abstractions</a> if we'd want to reason about that code</p>\n</blockquote>\n<p>Maybe. I feel that this could be orthogonal. It would be nice if this is verified, but I am unsure finding canonical semantics for everything will be easy. The current c annotations also do not come with semantics and are already very useful. Offering a way to add verification seems to be beneficial as an opt in.</p>",
        "id": 319432687,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672852197
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"395550\">Henrik Böving</span> <a href=\"#narrow/stream/348111-std4/topic/SAT.20core.20defs.20in.20Std.3F/near/319432433\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"122318\">Tobias Grosser</span> <a href=\"#narrow/stream/348111-std4/topic/SAT.20core.20defs.20in.20Std.3F/near/319431447\">said</a>:</p>\n<blockquote>\n<p>We could add annotations for using custom llvm and MLIR as implementation of a lean function.</p>\n</blockquote>\n<p>I mean this would just be an attribute with special support in the LLVMEmitter in the Lean code generator no?<br>\n<span class=\"user-mention silent\" data-user-id=\"122318\">Tobias Grosser</span> <a href=\"#narrow/stream/348111-std4/topic/SAT.20core.20defs.20in.20Std.3F/near/319431564\">said</a>:</p>\n<blockquote>\n<p>And then some macro magic to provide a lean api to end-users.</p>\n</blockquote>\n<p>If we have Lean functions tagged as implement by LLVM/MLIR what additional macro magic do we need?</p>\n</blockquote>\n<p>In theory we could supply a string of llvm-it that the llvm emitter than translates. This is easy and maybe just a minor change. I feel it would be nice if we would actually parse the LLVM-IR into lean data structure to be able to check certain properties early on and also to be able to eventually attach semantics. But maybe that is indeed step two?</p>",
        "id": 319433186,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672852377
    },
    {
        "content": "<p>I mean the C stuff is just parsed as strings right now as well :D there was a time where we even had full C expressions instead of just function support.</p>\n<p>What kind of semantics are you thinking about here?</p>",
        "id": 319434043,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1672852673
    },
    {
        "content": "<p>I guess in the end it boils down to how superficial the Lean data structure is that it represents it. A data structure that represents the LLVM/MLIR syntax is surely an improvement over a string, but I'd argue not a terribly big one. If we'd want some sort of semantic representation of the LLVM/MLIR code to be able to e.g. typecheck some of the code, which I think we'd need for your points (a) and (b) perhaps above, although I don't fully understand those. For your point (c) a semantic embedding sounds indispensable, whereas for (d) this probably would already be very useful just to be able to code generate something opaque.</p>",
        "id": 319434324,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1672852795
    },
    {
        "content": "<p><a href=\"https://github.com/opencompl/lean-mlir\">https://github.com/opencompl/lean-mlir</a> shows our experiments on a lean-based parser for MLIR as well as ideas to build modular semantics. It's very much work-in-progress, so many of these questions are unanswered. However, I am sure <span class=\"user-mention\" data-user-id=\"130575\">@Siddharth Bhat</span> and <span class=\"user-mention\" data-user-id=\"484617\">@Sébastien Michelland</span> and others have ideas to share. I am happy to just start with a string-to-llvm annotation and feel there could be some very low-hanging fruits, e.g. a (type-generic) SIMD implementation for lean?</p>",
        "id": 319434905,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672852998
    },
    {
        "content": "<p>That allow for manual SIMDization.</p>",
        "id": 319434942,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672853009
    },
    {
        "content": "<p>I feel adding a string-only LLVM annotation as a first step could be a nice start and we could improve on this incrementally. I would guess such a patch is &lt; 100 LOC.</p>",
        "id": 319435114,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672853055
    },
    {
        "content": "<p>(maybe this conversation could be split off into a new topic?)</p>",
        "id": 319435461,
        "sender_full_name": "Reid Barton",
        "timestamp": 1672853171
    },
    {
        "content": "<p>(yes, I don't know how to. This belongs into lean4 dev or at the least into a separate thread. I don't want to experiment to not break this long thread. Anybody knows how to split threads?)</p>",
        "id": 319435746,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672853279
    },
    {
        "content": "<p>I think you need admin permissions... <span class=\"user-mention\" data-user-id=\"110024\">@Sebastian Ullrich</span> <span class=\"user-mention\" data-user-id=\"110043\">@Gabriel Ebner</span> ? (saw you online; this discussion might also be of interest to the dev team)</p>",
        "id": 319447190,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1672857083
    },
    {
        "content": "<p>35 messages were moved here from <a class=\"stream-topic\" data-stream-id=\"348111\" href=\"/#narrow/stream/348111-std4/topic/SAT.20core.20defs.20in.20Std.3F\">#std4 &gt; SAT core defs in Std?</a> by <span class=\"user-mention silent\" data-user-id=\"110024\">Sebastian Ullrich</span>.</p>",
        "id": 319468412,
        "sender_full_name": "Notification Bot",
        "timestamp": 1672864451
    },
    {
        "content": "<p>Thank you!</p>",
        "id": 319473373,
        "sender_full_name": "Tobias Grosser",
        "timestamp": 1672866477
    }
]