[
    {
        "content": "<p>Hi, I was wondering: are there any plans to have a reading list or sample AI for the competition?  I ask as somebody interested in following this and understand what approaches work well, but without the capacity to build a team/compete in it.</p>",
        "id": 177300159,
        "sender_full_name": "Joe Hendrix",
        "timestamp": 1570147870
    },
    {
        "content": "<p>Wait, I always interpreted \"competion\" as 1 AI team against all the human competitors. I'd rather bundle forces than have multiple AI teams competing against each other and not sharing ideas etc etc</p>",
        "id": 177308952,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1570162183
    },
    {
        "content": "<blockquote>\n<p>Hi, I was wondering: are there any plans to have a reading list or sample AI for the competition?  </p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"110994\">@Joe Hendrix</span> A reading list would be difficult now, since there is no consensus on what existing paradigms might even help. Hopefully there will be enough experiments and incremental progress over time that we can build a useful reading list out of future papers.</p>",
        "id": 177518697,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1570454918
    },
    {
        "content": "<blockquote>\n<p>Wait, I always interpreted \"competion\" as 1 AI team against all the human competitors. I'd rather bundle forces than have multiple AI teams competing against each other and not sharing ideas etc etc</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"112680\">@Johan Commelin</span> The first stage of the project---to establish that the problems and solutions can indeed be formalized, to build a dataset of problems for training and validation, and to establish the rules for what constitute winning---is 100% a community effort. It might even be nice for us all to work towards a community paper introducing the grand challenge and the dataset of historical problems.  On the other hand, it is too early to foresee how the AI research itself will play out. There may be many pairwise-unrelated approaches of differing scale taken by different groups of people at different times.</p>",
        "id": 177519807,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1570455608
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"230999\">@Daniel Selsam</span> I think I was mostly looking at reading list for motivation, i.e., what has motivated you or other organizers that this is achievable?    After looking at a few of the IMO problems, competing in the IMO seems much harder to me than the Aristo/Project Halo goals, and they weren't expecting formal proofs in the answers to questions.</p>",
        "id": 177544404,
        "sender_full_name": "Joe Hendrix",
        "timestamp": 1570471483
    },
    {
        "content": "<p>How does one get involved with the community paper?</p>",
        "id": 178876033,
        "sender_full_name": "Brando Miranda",
        "timestamp": 1571851433
    },
    {
        "content": "<blockquote>\n<p>How does one get involved with the community paper?</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"246156\">@Brando Miranda</span> I will share a preliminary project proposal in the relatively near future. Note that we want to wait until Lean4 is more mature (e.g. has a tactic framework) before beginning the formalization in earnest.</p>",
        "id": 178876669,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1571851892
    },
    {
        "content": "<blockquote>\n<blockquote>\n<p>How does one get involved with the community paper?</p>\n</blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"246156\">Brando Miranda</span> I will share a preliminary project proposal in the relatively near future. Note that we want to wait until Lean4 is more mature (e.g. has a tactic framework) before beginning the formalization in earnest.</p>\n</blockquote>\n<p>How do I make sure I get informed when such a decision/proposal is out. :)</p>",
        "id": 178883230,
        "sender_full_name": "Brando Miranda",
        "timestamp": 1571856049
    },
    {
        "content": "<blockquote>\n<blockquote>\n<p>How does one get involved with the community paper?</p>\n</blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"246156\">Brando Miranda</span> I will share a preliminary project proposal in the relatively near future. Note that we want to wait until Lean4 is more mature (e.g. has a tactic framework) before beginning the formalization in earnest.</p>\n</blockquote>\n<p>Is the IMO challenge focus only on making a environment + data set using lean for ML using IMO problems or does also provide a lean environment for ML research/applications etc?</p>\n<p>I am curious to learn to what extent lean can be used for ML. Is such a thing possible and how easy is it to do it in Lean?</p>",
        "id": 178883694,
        "sender_full_name": "Brando Miranda",
        "timestamp": 1571856412
    },
    {
        "content": "<p>(sorry if my msgs are on the wrong thread, learning to use ZULIP, won't happen again! :) )</p>",
        "id": 178885297,
        "sender_full_name": "Brando Miranda",
        "timestamp": 1571857521
    },
    {
        "content": "<blockquote>\n<p>Is the IMO challenge focus only on making a environment + data set using lean for ML using IMO problems or does also provide a lean environment for ML research/applications etc?</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"246156\">@Brando Miranda</span> The goal is to spur fundamental progress in computer science, and to eventually build an AI that can win gold. Different people involved have different thoughts about the role that ML will play in this endeavor. I believe that ML may be able to help a lot. I plan to wrap existing frameworks in Lean and to deeply integrate ML into the Lean tactic language, but the exact interfaces and abstractions are yet to be determined.</p>",
        "id": 178904155,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1571870921
    },
    {
        "content": "<blockquote>\n<p>I plan to wrap existing frameworks in Lean and to deeply integrate ML into the Lean tactic language, </p>\n</blockquote>\n<p>Can you clarify what that means? Even if its vaguely? Does that mean one can access and use Pytorch Tensorflow using Lean itself or accessing Lean from within Python (the universal ML language)?</p>",
        "id": 178904343,
        "sender_full_name": "Brando Miranda",
        "timestamp": 1571871076
    },
    {
        "content": "<blockquote>\n<p>Does that mean one can access and use Pytorch Tensorflow using Lean itself or accessing Lean from within Python (the universal ML language)?</p>\n</blockquote>\n<p>To clarify: I have no current plans to write a TF/PyTorch frontend in Lean. There are many options for how to connect Lean to a trained network at runtime. In prior work I used gRPC (e.g. in <a href=\"https://github.com/dselsam/neurocore-public\" target=\"_blank\" title=\"https://github.com/dselsam/neurocore-public\">https://github.com/dselsam/neurocore-public</a>), but it is also possible to wrap relevant parts of Lean in Python (<a href=\"https://github.com/dselsam/lean-python-bindings\" target=\"_blank\" title=\"https://github.com/dselsam/lean-python-bindings\">https://github.com/dselsam/lean-python-bindings</a> bit-rot but something like it could be resurrected), or to wrap C++/Python in Lean (e.g. in <a href=\"https://github.com/dselsam/certigrad\" target=\"_blank\" title=\"https://github.com/dselsam/certigrad\">https://github.com/dselsam/certigrad</a>). For me the pressing conceptual challenge is how to let users write high-level tactics that induce intractable search spaces, and how to have the system train models to guide those tactics as conveniently and generically as possible.</p>",
        "id": 178905903,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1571872443
    },
    {
        "content": "<blockquote>\n<p>For me the pressing conceptual challenge is how to let users write high-level tactics that induce intractable search spaces, and how to have the system train models to guide those tactics as conveniently and generically as possible.</p>\n</blockquote>\n<p>why is that the goal? Perhaps my intuition is different. Why would we want intractable tactic spaces? Why do we want the system to train conventionally or generically? Should the goal be tractable spaces that achieve the goal we want (i.e. solve the maths problems)? Or perhaps I misunderstood something.</p>",
        "id": 178906844,
        "sender_full_name": "Brando Miranda",
        "timestamp": 1571873318
    },
    {
        "content": "<blockquote>\n<blockquote>\n<p>For me the pressing conceptual challenge is how to let users write high-level tactics that induce intractable search spaces, and how to have the system train models to guide those tactics as conveniently and generically as possible.</p>\n</blockquote>\n<p>why is that the goal? Perhaps my intuition is different. Why would we want intractable tactic spaces? Why do we want the system to train conventionally or generically? Should the goal be tractable spaces that achieve the goal we want (i.e. solve the maths problems)? Or perhaps I misunderstood something.</p>\n</blockquote>\n<p>We want to be able to conveniently write the parts of the strategies/tactics/tricks/tools that we can figure out how to write, but I hypothesize that it will prove very difficult to write these things down in sufficiently precise detail to produce brute-force-able search spaces. So we want learning to carry the rest of the burden, by learning how to search these spaces efficiently.</p>",
        "id": 178916047,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1571884702
    },
    {
        "content": "<blockquote>\n<blockquote>\n<blockquote>\n<p>For me the pressing conceptual challenge is how to let users write high-level tactics that induce intractable search spaces, and how to have the system train models to guide those tactics as conveniently and generically as possible.</p>\n</blockquote>\n<p>why is that the goal? Perhaps my intuition is different. Why would we want intractable tactic spaces? Why do we want the system to train conventionally or generically? Should the goal be tractable spaces that achieve the goal we want (i.e. solve the maths problems)? Or perhaps I misunderstood something.</p>\n</blockquote>\n<p>We want to be able to conveniently write the parts of the strategies/tactics/tricks/tools that we can figure out how to write, but I hypothesize that it will prove very difficult to write these things down in sufficiently precise detail to produce brute-force-able search spaces. So we want learning to carry the rest of the burden, by learning how to search these spaces efficiently.</p>\n</blockquote>\n<p>Ok I think I get it now. What you are saying is just to specify tactic spaces such that they are \"interesting\" spaces to search (not artificially restricted) and instead have the learning decide how to use/search these spaces.</p>\n<p>My misunderstanding came from the word \"intractable\". If we can learn to search it, by definition its not intractable in my mind. I think its better to say \"interesting\" or \"large\" or something. But thanks for the clarification!</p>",
        "id": 178996630,
        "sender_full_name": "Brando Miranda",
        "timestamp": 1571950580
    },
    {
        "content": "<p>I could be wrong, but is the goal of the IMO challenge to produce a human readable list of tactics used to solve IMO problems? I thought that to complete a proof you merely need to construct a value of the required type</p>",
        "id": 183721434,
        "sender_full_name": "Caleb Helbling",
        "timestamp": 1576646357
    },
    {
        "content": "<p>It would be easier to generate training data by randomly generating values, then get the type of the value and ask the AI to run in reverse</p>",
        "id": 183721486,
        "sender_full_name": "Caleb Helbling",
        "timestamp": 1576646441
    },
    {
        "content": "<p>Essentially you'd be randomly generating proofs and then asking what the proposition being proved is</p>",
        "id": 183721509,
        "sender_full_name": "Caleb Helbling",
        "timestamp": 1576646513
    },
    {
        "content": "<p>I saw this paper today on Hacker News: deep learning for symbolic mathematics <a href=\"https://openreview.net/pdf?id=S1eZYeHFDS\" target=\"_blank\" title=\"https://openreview.net/pdf?id=S1eZYeHFDS\">https://openreview.net/pdf?id=S1eZYeHFDS</a></p>",
        "id": 183721622,
        "sender_full_name": "Caleb Helbling",
        "timestamp": 1576646715
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"254644\">@Caleb Helbling</span> A randomly generated proof will be a proof of a very weird and uninteresting proposition. That's the big problem with maths</p>",
        "id": 183722493,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1576648211
    },
    {
        "content": "<p>You have a crazy-crazy big search space. And almost everything is uninteresting.</p>",
        "id": 183722500,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1576648233
    },
    {
        "content": "<p>Yes, but maybe the AI would learn from the uninteresting cases to generalize to the more interesting cases?</p>",
        "id": 183724107,
        "sender_full_name": "Caleb Helbling",
        "timestamp": 1576650863
    },
    {
        "content": "<p>I also realized that type checking is undecidable without type annotations in dependently typed languages, which sort of defeats the idea of randomly generating values and getting their types</p>",
        "id": 183724128,
        "sender_full_name": "Caleb Helbling",
        "timestamp": 1576650920
    },
    {
        "content": "<p>you would learn uninteresting heuristics if you look only at uninteresting problems</p>",
        "id": 183724130,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1576650921
    },
    {
        "content": "<p>Type checking in dependently typed languages is often decidable</p>",
        "id": 183724139,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1576650953
    },
    {
        "content": "<p>in lean's case it's not but the issues almost never come up in practice</p>",
        "id": 183724190,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1576650983
    },
    {
        "content": "<p>well interesting is a human defined label. Maybe there are proofs that are uninteresting to humans because they have no meaning but are actually rather complicated</p>",
        "id": 183724200,
        "sender_full_name": "Caleb Helbling",
        "timestamp": 1576651020
    },
    {
        "content": "<p>sure, there is an infinite family of such</p>",
        "id": 183724210,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1576651041
    },
    {
        "content": "<p>Also some interesting propositions might have simple proofs</p>",
        "id": 183724296,
        "sender_full_name": "Caleb Helbling",
        "timestamp": 1576651152
    },
    {
        "content": "<p>Would having a small core calculus help with keeping synthetically generated proofs interesting? It would help prune the branching factor at each step</p>",
        "id": 183724359,
        "sender_full_name": "Caleb Helbling",
        "timestamp": 1576651251
    },
    {
        "content": "<p>It helps, but not very much. The search space is still exponential</p>",
        "id": 183724569,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1576651622
    },
    {
        "content": "<p>And most proofs of interesting theorems are going to be at least 20 steps long, at which point you are already overwhelmed even with a very small branching factor</p>",
        "id": 183724631,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1576651698
    },
    {
        "content": "<p>If you want to get past that you have to use higher level \"steps\", like tactics that already have a lot of interestingness heuristics built in</p>",
        "id": 183724703,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1576651810
    },
    {
        "content": "<blockquote>\n<p>Would having a small core calculus help with keeping synthetically generated proofs interesting?</p>\n</blockquote>\n<p>consider resolution for propositional logic---if anything, the proofs become more boring and most of the steps are uninteresting</p>",
        "id": 183725616,
        "sender_full_name": "Jesse Michael Han",
        "timestamp": 1576653271
    }
]