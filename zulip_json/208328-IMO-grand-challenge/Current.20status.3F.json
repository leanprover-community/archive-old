[
    {
        "content": "<p>Hey, I saw today's Quanta article about the IMO grand challenge. It sounds cool. I was wondering what the current status is - are there any teams working on an IMO problem solver with some work in progress? I'd be interested in helping out if there was some group open to outside contributors</p>",
        "id": 210802841,
        "sender_full_name": "Kevin Lacker",
        "timestamp": 1600723900
    },
    {
        "content": "<p>We are currently very interested in getting a nice collection of IMO problems formalised, both statements and proofs</p>",
        "id": 210805259,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600725279
    },
    {
        "content": "<p>is there a repo of this stuff somewhere</p>",
        "id": 210805291,
        "sender_full_name": "Kevin Lacker",
        "timestamp": 1600725304
    },
    {
        "content": "<p>There are a couple of Olympiad problems formalised in mathlib</p>",
        "id": 210805376,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600725359
    },
    {
        "content": "<p>is there a big list or is it like, the combinatorics ones are in the combinatorics directory, etc</p>",
        "id": 210805481,
        "sender_full_name": "Kevin Lacker",
        "timestamp": 1600725426
    },
    {
        "content": "<p><a href=\"https://github.com/leanprover-community/mathlib/blob/master/archive/imo1988_q6.lean\">https://github.com/leanprover-community/mathlib/blob/master/archive/imo1988_q6.lean</a></p>",
        "id": 210805508,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600725450
    },
    {
        "content": "<p>There are very few</p>",
        "id": 210805514,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600725454
    },
    {
        "content": "<p>It would be nice to start organising them like that</p>",
        "id": 210805538,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600725468
    },
    {
        "content": "<p>They will all live in the archive directory</p>",
        "id": 210805551,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600725479
    },
    {
        "content": "<p>src is for the standard maths library, this is entertainment</p>",
        "id": 210805614,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600725504
    },
    {
        "content": "<p>i wonder what the very easiest IMO problem to formalize is...</p>",
        "id": 210805894,
        "sender_full_name": "Kevin Lacker",
        "timestamp": 1600725707
    },
    {
        "content": "<p>IMO 1972 b2 is quite easy and we chatted about its formalization in general a few weeks ago. I'll make a PR to add to to archive/</p>",
        "id": 210832546,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600756858
    },
    {
        "content": "<p>Done here: <a href=\"https://github.com/leanprover-community/mathlib/pull/4209\">https://github.com/leanprover-community/mathlib/pull/4209</a></p>",
        "id": 210834330,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600758522
    },
    {
        "content": "<p>For some problems that ask you to find a certain object (say IMO 2019 P1 &amp; P4), how would you write the statement in Lean?</p>",
        "id": 210854349,
        "sender_full_name": "Quang Dao",
        "timestamp": 1600772198
    },
    {
        "content": "<p>There has been quite some discussion about that (on this stream) without a satisfactory answer so far</p>",
        "id": 210854386,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1600772228
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"246591\">@Quang Dao</span> see <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/How.20to.20help.3F/near/175254384\">https://leanprover.zulipchat.com/#narrow/stream/208328-IMO-grand-challenge/topic/How.20to.20help.3F/near/175254384</a></p>",
        "id": 210854579,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1600772379
    },
    {
        "content": "<p>(took some time to find that discussion)</p>",
        "id": 210854590,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1600772389
    },
    {
        "content": "<p>thanks! this link from the discussion is now unusable: <a href=\"https://github.com/IMO-grand-challenge/formal-encoding/blob/master/design/determine.lean\">https://github.com/IMO-grand-challenge/formal-encoding/blob/master/design/determine.lean</a></p>",
        "id": 210855205,
        "sender_full_name": "Quang Dao",
        "timestamp": 1600772803
    },
    {
        "content": "<p>do you know where it has moved to?</p>",
        "id": 210855223,
        "sender_full_name": "Quang Dao",
        "timestamp": 1600772817
    },
    {
        "content": "<p>anyway, I'm trying to find simpler instances in Lean where the problem is \"find something\". Could you solve a polynomial equation (say a quadratic) in Lean?</p>",
        "id": 210855687,
        "sender_full_name": "Quang Dao",
        "timestamp": 1600773216
    },
    {
        "content": "<p>Reposting my list of \"find something\" answers of shortlisted problems 2006 -- 2018: <a href=\"http://www.olsak.net/mirek/determine-answers.txt\">http://www.olsak.net/mirek/determine-answers.txt</a></p>",
        "id": 210856199,
        "sender_full_name": "Miroslav Olšák",
        "timestamp": 1600773616
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"246591\">Quang Dao</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/210855205\">said</a>:</p>\n<blockquote>\n<p>thanks! this link from the discussion is now unusable: <a href=\"https://github.com/IMO-grand-challenge/formal-encoding/blob/master/design/determine.lean\">https://github.com/IMO-grand-challenge/formal-encoding/blob/master/design/determine.lean</a></p>\n</blockquote>\n<p><a href=\"https://gist.github.com/dselsam/da69f929de2d623b4a8b5d8ef8a278f9\">https://gist.github.com/dselsam/da69f929de2d623b4a8b5d8ef8a278f9</a></p>",
        "id": 210867561,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1600780433
    },
    {
        "content": "<p>What's the status of the IMO challenge??? What are some of the noteworthy attempts at solving it and what benchmarks have they set??</p>",
        "id": 320459370,
        "sender_full_name": "Lucas Teixeira",
        "timestamp": 1673359886
    },
    {
        "content": "<p>Nvm, I think this topic is more appropriate for <a class=\"stream\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving\">#Machine Learning for Theorem Proving</a></p>",
        "id": 320459925,
        "sender_full_name": "Lucas Teixeira",
        "timestamp": 1673360021
    },
    {
        "content": "<p>The IMO grand challenge has always seemed to me to be more of an idea than a concrete plan.  I suspect it won't start happening until a group has an AI which they think can do well on it.  Although there is a <a href=\"https://imo-grand-challenge.github.io/\">committee</a> so maybe it is active and I'm just not in the loop.  Nonetheless, there has been a lot of progress on the <a href=\"https://paperswithcode.com/sota/automated-theorem-proving-on-minif2f-test\">MiniF2F benchmark</a> which can be thought of as an easier version of the IMO grand challenge.</p>",
        "id": 320524853,
        "sender_full_name": "Jason Rute",
        "timestamp": 1673377751
    },
    {
        "content": "<p>In <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Meta.20IMO.20result/near/312748505\">another thread</a> <span class=\"user-mention\" data-user-id=\"266253\">@Joseph Myers</span> (who is not on the IMO Grand Challenge committee but seems very interested in it) was trying to get it going.</p>",
        "id": 320528195,
        "sender_full_name": "Jason Rute",
        "timestamp": 1673378820
    },
    {
        "content": "<p>Just a thought: is it possible to set up something like the <a href=\"https://super.gluebenchmark.com/faq\">SuperGLUE</a> benchmark/leaderboard ...</p>",
        "id": 320528326,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1673378862
    },
    {
        "content": "<p>I should also point out that a major premise of the IMO grand challenge is that for a computer to do well on the IMO (and for a human to trust the computer's solution) it has to give a formal proof.  Models like Minerva (and even ChatGPT) are starting to cast doubt on that assumption.  (Although models like Draft Sketch Prove  (<a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/More.20papers.20on.20autoformalization\">#Machine Learning for Theorem Proving &gt; More papers on autoformalization</a>)  also show the two approaches are quite compatible and systems which generate informal proofs and convert them to formal theorem proofs are a nice symbiosis.)</p>",
        "id": 320531844,
        "sender_full_name": "Jason Rute",
        "timestamp": 1673380031
    },
    {
        "content": "<p>Why do you say that even ChatGPT starts to cast doubt on that assumption?<br>\nIf anything, it has strengthened my belief that I'll only believe a computer-generated proof if it is formally verified. ChatGPT is way too good at bullshitting.</p>",
        "id": 320532510,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1673380243
    },
    {
        "content": "<p>Before Minerva, I was 99% sure the first computer solutions to the IMO grand challenge would be formal.  After, I'm 80% sure.  As for BS, the question is if that is a fundamental property of large language model applications, or if it can be fixed (without having to formalize everything in a formal system).</p>",
        "id": 320534064,
        "sender_full_name": "Jason Rute",
        "timestamp": 1673380757
    },
    {
        "content": "<p>(To be clear, I don't think ChatGPT itself, especially the current version, would do well.)</p>",
        "id": 320534494,
        "sender_full_name": "Jason Rute",
        "timestamp": 1673380882
    },
    {
        "content": "<p>(I thought I was posting in <a class=\"stream-topic\" data-stream-id=\"208328\" href=\"/#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F\">#IMO-grand-challenge &gt; Current status?</a> in response to a question asked there.  Sorry to resurrect this old thread.)</p>",
        "id": 320536711,
        "sender_full_name": "Jason Rute",
        "timestamp": 1673381737
    },
    {
        "content": "<p>5 messages were moved here from <a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Meta.20IMO.20result\">#Machine Learning for Theorem Proving &gt; Meta IMO result</a> by <span class=\"user-mention silent\" data-user-id=\"112680\">Johan Commelin</span>.</p>",
        "id": 320539538,
        "sender_full_name": "Notification Bot",
        "timestamp": 1673382774
    },
    {
        "content": "<p>Pretty soon we should be able to translate most of minif2f to Lean 4.</p>",
        "id": 320546659,
        "sender_full_name": "David Renshaw",
        "timestamp": 1673385545
    },
    {
        "content": "<p>A key feature of the IMO Grand Challenge should be that it keeps entrants honest: (a) the problems are new, and entrants required to have finished their coding and training before the IMO, so they can't have learned from reading an informal solution to the same problem; (b) the marking criteria are as far as possible objective, public and such that marks for a solution can be independently verified without inside knowledge (they don't depend on the (non-public, not collected anywhere) mark schemes used for human solutions at the IMO, nor on having a common understanding of what somewhat vague natural language attempts do or do not count as sufficient for a complete solution worth full marks); (c) entrants make a public declaration in advance that they are entering, to avoid publication bias from only announcing results that sound good; (d) the formal statements are independently agreed before the competition to be an accurate translation of the informal statements.</p>\n<p>I don't think existing public claims of AI to have solved olympiad-like problems satisfy any of (a), (c) or (d), while it's not clear how informal-to-informal AI would manage (b) (at least it would need independent assessment of any claimed solutions by someone who was a coordinator on the relevant problem at the IMO).</p>",
        "id": 320566208,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1673394270
    },
    {
        "content": "<p>I think something in the spirit of (b) is possible for informal-to-informal.  By the way, one reason that Daniel Selsam, the creator of the IMO grand challenge, didn't address the informal-to-informal part is that he thought this would so hard that he said he would resign if it happens (see section ML-topia in <a href=\"https://dselsam.github.io/IMO-GC-battle-of-ideas/\">his blog post</a>).  I don't know if he still thinks that, but I'd hate to think that a natural language solution is rejected just because it is in natural language.  (If like 2019 Daniel Selsam, one thinks that it is so impossible it is not worth planning for, I can respect that opinion.)</p>",
        "id": 320578641,
        "sender_full_name": "Jason Rute",
        "timestamp": 1673402010
    },
    {
        "content": "<p>I'm on the committee and as far as I know it's not active. I've been taking a great interest in Joseph's posts on how the technical details should work</p>",
        "id": 320648019,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1673427301
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> time will tell but fwiw I think formal is now the underdog -- and I <em>did</em> resign! I just got a new job :)</p>",
        "id": 320834276,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1673492180
    },
    {
        "content": "<blockquote>\n<p>I think formal is now the underdog </p>\n</blockquote>\n<p><span aria-label=\"open mouth\" class=\"emoji emoji-1f62e\" role=\"img\" title=\"open mouth\">:open_mouth:</span></p>",
        "id": 320840502,
        "sender_full_name": "David Renshaw",
        "timestamp": 1673494422
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"230999\">@Daniel Selsam</span> Congrats on the new job! (Mind telling us where/what?)</p>\n<p>What made you switch positions so that you now think formal is the underdog? Is there a big breakthrough that I missed?</p>",
        "id": 320869162,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1673508537
    },
    {
        "content": "<p>+1 pretty curious why formal is not a good approach?</p>",
        "id": 320917390,
        "sender_full_name": "fzyzcjy",
        "timestamp": 1673524018
    },
    {
        "content": "<p>You could do an autoformalization challenge on IMO problems: give the AI formal statements (easy-mode, i.e. answers for any \"determine\" problem included) for the problems of an IMO from after that AI was coded and trained <em>and</em> informal statements and solutions, and ask it to produce formal proofs of the provided formal statements based on the given informal proofs. My impression of the current state of AI is that this is a lot closer to working than producing full proofs of recent IMO problems from scratch (and that as discussed above, if an AI could produce a valid informal solution then it could be connected to an AI that produces a formal version from that).</p>",
        "id": 320925484,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1673526520
    },
    {
        "content": "<p>The IMO Grand Challenge as originally stated, i.e. formal to formal, still strongly resonates with me. If that approach is now the underdog (or perhaps more charitably: is receiving less hype these days) well, then, all the more glory there will be when it arrives at the destination first. :P</p>",
        "id": 320928860,
        "sender_full_name": "David Renshaw",
        "timestamp": 1673527600
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"112680\">Johan Commelin</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/320869162\">said</a>:</p>\n<blockquote>\n<p>Is there a big breakthrough that I missed?</p>\n</blockquote>\n<p>No recent breakthroughs, but that is the whole point: the current models are the same models as a few years ago (which couldn't even produce coherent sentences) just bigger. </p>\n<ul>\n<li>scaling reliably lowers perplexity</li>\n<li>lowering perplexity reliably improves capabilities</li>\n<li>tons of runway left in compute &amp; data, + low-hanging algorithmic fruit everywhere</li>\n</ul>\n<p>I think formal is the underdog now for IMO because there is a lot of hard work humans would need to do and they are not strongly incentivized to do it, whereas informal gets to ride the scaling wave and will (I think) eventually fall as a side-effect. I agree with you that current models are nowhere near and think that if one did not know their history one would be right to dismiss them entirely -- however, I think this annoying extrapolation argument is actually very strong. We'll see.</p>",
        "id": 320970134,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1673538335
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"230999\">@Daniel Selsam</span> What do you think is the median year in which the challenge will be completed, if you don't mind my asking?</p>",
        "id": 320972864,
        "sender_full_name": "Bolton Bailey",
        "timestamp": 1673539016
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"230999\">@Daniel Selsam</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/320970134\">said</a>:</p>\n<blockquote>\n<p>I agree with you that current models are nowhere near and think that if one did not know their history one would be right to dismiss them entirely -- however, I think this annoying extrapolation argument is actually very strong. We'll see.</p>\n</blockquote>\n<p>There is a limit to the extrapolation argument. Right now the models are so big that only large companies can run the models and everyone else has to buy time on them. If they keep growing they will become national level artifacts. At some point it won't be worth their time to run some silly problem some researchers thought up about a math problem. This doesn't seem to be <em>scaling</em> to me in the sense that we aren't empowering everyone to do formal methods, we are centralizing and gatekeeping the tools because of the spectacular costs involved. It's not really a question of whether it is <em>possible</em> (well it is to some extent, but once we prove it is possible that won't be enough to keep the funding coming) - it is whether it is <em>economical</em>, and while you can handwave to some extent and say tech gets better and cheaper over time, the growth of ML models is <em>far</em> outpacing that growth.</p>",
        "id": 320982506,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1673541587
    },
    {
        "content": "<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"230999\">Daniel Selsam</span> I think formal is the underdog now for IMO because there is a lot of hard work humans would need to do and they are not strongly incentivized to do it</p>\n</blockquote>\n<p>I would appreciate it if I could know what are those hard work -  Do you mean deep learning algorithms and ideas, or the time-consuming work to formalize the whole math world?</p>",
        "id": 321056690,
        "sender_full_name": "fzyzcjy",
        "timestamp": 1673567459
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/320982506\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"230999\">Daniel Selsam</span> <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/Current.20status.3F/near/320970134\">said</a>:</p>\n<blockquote>\n<p>I agree with you that current models are nowhere near and think that if one did not know their history one would be right to dismiss them entirely -- however, I think this annoying extrapolation argument is actually very strong. We'll see.</p>\n</blockquote>\n<p>There is a limit to the extrapolation argument. Right now the models are so big that only large companies can run the models and everyone else has to buy time on them. If they keep growing they will become national level artifacts. At some point it won't be worth their time to run some silly problem some researchers thought up about a math problem. This doesn't seem to be <em>scaling</em> to me in the sense that we aren't empowering everyone to do formal methods, we are centralizing and gatekeeping the tools because of the spectacular costs involved. It's not really a question of whether it is <em>possible</em> (well it is to some extent, but once we prove it is possible that won't be enough to keep the funding coming) - it is whether it is <em>economical</em>, and while you can handwave to some extent and say tech gets better and cheaper over time, the growth of ML models is <em>far</em> outpacing that growth.</p>\n</blockquote>\n<p>The way I think of this issue is that large models are becoming utilities, like power plants. Very few companies/people will generate electricity, but many will make electrical appliances and most people will use them.</p>\n<p>The above holds provided \"prompt engineering\" and \"post processing\" will be enough to get good results from the huge models.</p>",
        "id": 321070435,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1673575613
    }
]