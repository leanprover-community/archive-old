[
    {
        "content": "<p>Congratulations and thanks to <span class=\"user-mention\" data-user-id=\"110865\">@Jeremy Avigad</span> for the beginning of o-analysis and proving the chain rule, and most importantly introducing mathlib to <strong>derivatives</strong> for the first time.</p>",
        "id": 159119844,
        "sender_full_name": "Kenny Lau",
        "timestamp": 1550797611
    },
    {
        "content": "<p>Thanks for noticing. I am inordinately proud of the proof of the chain rule: <a href=\"https://github.com/avigad/mathlib/blob/fderiv/src/analysis/normed_space/deriv.lean#L154-L178\" target=\"_blank\" title=\"https://github.com/avigad/mathlib/blob/fderiv/src/analysis/normed_space/deriv.lean#L154-L178\">https://github.com/avigad/mathlib/blob/fderiv/src/analysis/normed_space/deriv.lean#L154-L178</a>. It is at least as readable as the proof I found on Stack exchange: <a href=\"https://math.stackexchange.com/questions/2216797/frechet-derivative-chain-rule\" target=\"_blank\" title=\"https://math.stackexchange.com/questions/2216797/frechet-derivative-chain-rule\">https://math.stackexchange.com/questions/2216797/frechet-derivative-chain-rule</a>. (And the result is stronger, because it allows restriction to a subset of the ambient space.)</p>",
        "id": 159120628,
        "sender_full_name": "Jeremy Avigad",
        "timestamp": 1550798531
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span> <span class=\"user-mention\" data-user-id=\"110064\">@Kenny Lau</span> Thanks for the careful review. I'll make all the changes you suggested over the weekend. I only responded now to the ones I don't understand or disagreed with.</p>",
        "id": 159123655,
        "sender_full_name": "Jeremy Avigad",
        "timestamp": 1550802359
    },
    {
        "content": "<p>Oops, I am having github issues. I tried a few responses yesterday as a \"report\", but realized this morning that I didn't click the right button to \"submit\" it yesterday. Anyhow, I woke up this morning thinking of all the things I should do differently. So maybe wait until the next round of revisions.</p>\n<p>Mario, the only comment I disagreed with substantially  is changing the definition of <code>has_fderiv_at</code>. The whole point is that it should be definitionally a special case of the more general theorems, so that we can apply exactly the same theorems whether we are using <code>has_fderiv_at</code> or <code>has_fderiv_at_within</code>. In fact, I dropped by <code>at</code> and <code>at_within</code> from the theorem names for that reason.</p>",
        "id": 159162488,
        "sender_full_name": "Jeremy Avigad",
        "timestamp": 1550847866
    },
    {
        "content": "<p>you can't have the same theorems in any case, the restatement part is important</p>",
        "id": 159162742,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1550848084
    },
    {
        "content": "<p>if there are two definitions then you need to state all the theorems that you care about twice</p>",
        "id": 159162752,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1550848105
    },
    {
        "content": "<p>Even with your definition, where <code>has_deriv_at</code> is a special case of <code>has_deriv_at_within</code>, there should be a theorem that says <code>has_deriv_at id (const 1)</code>, not something starting <code>has_deriv_at_within</code></p>",
        "id": 159162811,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1550848198
    },
    {
        "content": "<p>The Coq development actually uses a common generalization of <code>has_deriv_at</code> and <code>has_deriv_at_within</code>, where you have an argument for the filter <code>F</code> (presumably <code>F &lt;= nhds 0</code> but you will not need that for many theorems)</p>",
        "id": 159162911,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1550848273
    },
    {
        "content": "<p>I am not convinced. The theorem <code>has_fderiv_id</code> as it is currently stated can be applied to both the <code>at</code> and <code>at_within</code> versions in tactic mode. The only shortcoming is that in proof term mode you have to add <code>univ</code> or <code>_</code> as a parameter if you want the unrelativized version. An alternative is to make the set parameter implicit. In practice, I think it can usually be inferred from context.</p>\n<p>Do you really think it pays to have two versions of every theorem, the only difference being that one has a parameter instantiated to <code>univ</code>? I'll do it if you want, but it feels like have two versions of every theorem about multiplication, one where a multiplicand is instantiated to <code>2</code>. I'd like to think of <code>at</code> as light notation for a global <code>at_within</code>, not a totally different concept. </p>\n<p>Isabelle's library uses the a general filter in the definition, but most of the theorems are specific to <code>at</code> and <code>at_within</code>.  But that doesn't help, since it leads to the same dilemma: either you give the filter explicitly every time, or make it implicit.</p>",
        "id": 159163591,
        "sender_full_name": "Jeremy Avigad",
        "timestamp": 1550848906
    },
    {
        "content": "<p>syntactic matching is important. If you don't want two versions of the theorems, you shouldn't define <code>has_deriv_at</code> at all</p>",
        "id": 159163803,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1550849052
    },
    {
        "content": "<p>If you think people will use it, though, then you have to put in the legwork for it</p>",
        "id": 159163819,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1550849069
    },
    {
        "content": "<p>For the most part, the restatements are very easy to prove, it's just an instantiation so it's a one liner</p>",
        "id": 159163882,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1550849126
    },
    {
        "content": "<p>But they form the API for the library. I'm worried that defining <code>has_deriv_at</code> in terms of <code>has_deriv_at_within</code> will make <code>within univ</code> stuff appear when manipulating derivative goals for things that have nothing to do with partial functions or restrictions</p>",
        "id": 159164016,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1550849211
    },
    {
        "content": "<p>The way the filter helps in this case is that you can define <code>has_deriv_at</code> in terms of <code>has_deriv_at_filter</code> and it will be definitionally what you want it to be. Whereas defining <code>has_deriv_at</code> in terms of <code>has_deriv_at_within</code> defines it in terms of the <code>nhds_within 0 set.univ</code> filter, which is not <code>nhds 0</code></p>",
        "id": 159164160,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1550849333
    },
    {
        "content": "<p>In fact, you could probably generalize all the theorems you have proven thus far for <code>has_deriv_at_within</code> to <code>has_deriv_at_filter</code> and nothing would change. I don't think you've done anything \"interesting\" with the set restrictions yet, except in the chain rule where you take an image; but you can comap the filter and get the same effect, I think</p>",
        "id": 159164393,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1550849482
    },
    {
        "content": "<p>I am going to follow your suggestion of making the <code>littleo</code> definition the official definition of <code>has_deriv</code>. Since you insist, I'll make two versions of every theorem, one an instantiation of the other. I don't think there is any danger of the <code>univ</code> appearing unexpectedly: if you unfold to <code>littleo</code>, most <code>littleo</code> calculations work uniformly across settings. If you are really planning to get your hands dirty, you'll probably need to do all kinds of manipulations and rewriting anyhow, and rewriting with <code>at_within_univ</code> won't make a difference. I'll provide all the glue to unpack <code>has_deriv_at</code> directly to the <code>nhds</code> filter versions if that is needed.</p>",
        "id": 159164669,
        "sender_full_name": "Jeremy Avigad",
        "timestamp": 1550849668
    },
    {
        "content": "<p>You should push this to a mathlib branch, I will see if I can make a case for some of this stuff</p>",
        "id": 159164757,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1550849748
    },
    {
        "content": "<p>The main reason I think the littleo definition will be better is to avoid the division. We don't know that <code>x != x0</code> so manipulating that part requires some case splitting</p>",
        "id": 159164860,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1550849832
    },
    {
        "content": "<p>I'm assuming that the littleo library has all the theorems we need. If it doesn't then obviously that should be addressed anyway</p>",
        "id": 159164901,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1550849872
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span>  I just updated the PR, with all the changes you and Kenny asked for.<br>\n<span class=\"user-mention\" data-user-id=\"110064\">@Kenny Lau</span> A nicer proof of the continuity property using asymptotics is here:<br>\n<a href=\"https://github.com/leanprover-community/mathlib/blob/817d195e371bdd87d24882b4f05f55de25ff91ce/src/analysis/normed_space/deriv.lean#L153-L167\" target=\"_blank\" title=\"https://github.com/leanprover-community/mathlib/blob/817d195e371bdd87d24882b4f05f55de25ff91ce/src/analysis/normed_space/deriv.lean#L153-L167\">https://github.com/leanprover-community/mathlib/blob/817d195e371bdd87d24882b4f05f55de25ff91ce/src/analysis/normed_space/deriv.lean#L153-L167</a></p>",
        "id": 159234623,
        "sender_full_name": "Jeremy Avigad",
        "timestamp": 1550937788
    },
    {
        "content": "<p>nice!</p>",
        "id": 159234638,
        "sender_full_name": "Kenny Lau",
        "timestamp": 1550937834
    },
    {
        "content": "<p>I'm really happy to see derivatives coming to mathlib, but I'm a bit sad to see that we don't use Cyril's nice setup to compute with little-o and big-O. For instance the chain rule proof is really ugly compared to what we saw in Amsterdam.</p>",
        "id": 159246033,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1550956630
    },
    {
        "content": "<p>With Cyrille's setup and Lean's calc blocks we could have a proof that reads the same as a paper proof (at least after getting Lean 4's parser).</p>",
        "id": 159246081,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1550956719
    },
    {
        "content": "<p>Are you sure? When you say it's ugly do you mean the proof is more cumbersome than it needs to be, or it doesn't use enough notations?</p>\n<p>I know that Jeremy and I both have some serious reservations about using Cyril's trick for turning predicates like big-O into equations. (I like the definition of the predicate, but not the thing with the hidden witness.) I'm worried that it will cause more magic breakage issues for people who don't see that the witnesses are changing behind their back, and also I don't even know if lean can support notations like this in the first place. It definitely goes against lean's convention of implicit and explicit arguments based on what is inferrable.</p>\n<p>In short, I don't think using trickery to get a nice looking statement is worth the damage it does when people inevitably have to peek behind the curtain and find the system fighting them.</p>\n<p>If on the other hand you mean that the proof is unnecessarily complicated, then I would like to fix that. I think Cyril's proof is good not because of the notations but because all the pieces fit together nicely. It's possible that some of the <code>=/</code> steps or something caused some additional rewrites that would be explicit in lean land, but I think it can be brought down to a similar size as Cyril's proof regardless. I think Jeremy wrote the proof in a deliberately verbose style so that you can see how the proof goes, and I don't see anything untoward.</p>",
        "id": 159258486,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1550980360
    },
    {
        "content": "<p>There is a small notation part. But as I wrote, it seems we need the Lean 4 parser to have the same notation that have in Coq (actually I hope we could have even better). But this is not the core issue. Cyril's trick allows to compute with little-o, as we do in the real world. He can write <code>[o_F e of f] + [o_F e of g] =o_F e</code> and this is a true addition. I can't see how you could do that with predicates.</p>",
        "id": 159269611,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1551001696
    },
    {
        "content": "<p>The proof we want is really a computation, it should be on nice <code>calc</code></p>",
        "id": 159269685,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1551001809
    },
    {
        "content": "<blockquote>\n<p><code>[o_F e of f] + [o_F e of g] =o_F e</code></p>\n</blockquote>\n<p>It's not obvious to me what this means, so if this is the notation that is so much better I'm less than enthused</p>",
        "id": 159270199,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1551002813
    },
    {
        "content": "<p>Predicates are easy to understand if you use them consistently and don't have too many variations</p>",
        "id": 159270211,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1551002864
    },
    {
        "content": "<p>Rewriting with functions is not nice, so I'm not sold on <code>calc</code>ing this proof</p>",
        "id": 159270255,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1551002902
    },
    {
        "content": "<p>The notation is not so great, but it clearly says <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>o</mi><mo>(</mo><mi>e</mi><mo>)</mo><mo>+</mo><mi>o</mi><mo>(</mo><mi>e</mi><mo>)</mo><mo>=</mo><mi>o</mi><mo>(</mo><mi>e</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">o(e) + o(e) = o(e)</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base\"><span class=\"mord mathit\">o</span><span class=\"mopen\">(</span><span class=\"mord mathit\">e</span><span class=\"mclose\">)</span><span class=\"mbin\">+</span><span class=\"mord mathit\">o</span><span class=\"mopen\">(</span><span class=\"mord mathit\">e</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord mathit\">o</span><span class=\"mopen\">(</span><span class=\"mord mathit\">e</span><span class=\"mclose\">)</span></span></span></span></p>",
        "id": 159286886,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1551034381
    },
    {
        "content": "<p>The fact that rewriting with function is not nice is part of the problem, not part of the solution. We need better tools, not changing a nice math proof because the tools are not good enough</p>",
        "id": 159286903,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1551034424
    },
    {
        "content": "<p>The math proof is a computation, not a collection of predicates</p>",
        "id": 159286907,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1551034441
    },
    {
        "content": "<p>I'm surprised you are so hardline on this but are okay with <code>tendsto</code></p>",
        "id": 159287906,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1551035996
    },
    {
        "content": "<p>What tendsto?</p>",
        "id": 159287960,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1551036026
    },
    {
        "content": "<p>Who talked about tendsto?</p>",
        "id": 159287962,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1551036034
    },
    {
        "content": "<p>mathematicians pretend <code>lim f = x</code> is an equality all the time</p>",
        "id": 159287963,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1551036054
    },
    {
        "content": "<p>but I think trying to mimic the notation here does more harm than good</p>",
        "id": 159287976,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1551036103
    },
    {
        "content": "<p>a big O statement is not an equality</p>",
        "id": 159288025,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1551036129
    },
    {
        "content": "<p>Algebraic manipulations of big O and little o are very powerful ways of computing limits</p>",
        "id": 159288122,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1551036353
    },
    {
        "content": "<p>Sure, but they have analogues in relations too, and with the right setup it won't even be a longer proof</p>",
        "id": 159288171,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1551036412
    },
    {
        "content": "<p>the relations are more general and more honest to what is literally meant</p>",
        "id": 159288182,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1551036441
    },
    {
        "content": "<p>I'm pretty sure the proofs will get exponentially longer</p>",
        "id": 159288230,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1551036516
    },
    {
        "content": "<p>That sounds like a concrete claim... let's find out</p>",
        "id": 159288355,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1551036751
    },
    {
        "content": "<p>The chain rule now:</p>\n<div class=\"codehilite\"><pre><span></span><span class=\"bp\">⟨</span><span class=\"n\">hg</span><span class=\"bp\">.</span><span class=\"mi\">1</span><span class=\"bp\">.</span><span class=\"n\">comp</span> <span class=\"n\">hf</span><span class=\"bp\">.</span><span class=\"mi\">1</span><span class=\"o\">,</span> <span class=\"k\">begin</span>\n  <span class=\"k\">have</span> <span class=\"n\">eq₁</span> <span class=\"o\">:=</span> <span class=\"o\">(</span><span class=\"n\">hg</span><span class=\"bp\">.</span><span class=\"mi\">1</span><span class=\"bp\">.</span><span class=\"n\">is_bigo_comp</span> <span class=\"bp\">_</span><span class=\"o\">)</span><span class=\"bp\">.</span><span class=\"n\">trans_is_littleo</span> <span class=\"n\">hf</span><span class=\"bp\">.</span><span class=\"mi\">2</span><span class=\"o\">,</span>\n  <span class=\"k\">have</span> <span class=\"n\">eq₂</span> <span class=\"o\">:=</span> <span class=\"o\">((</span><span class=\"n\">hg</span><span class=\"bp\">.</span><span class=\"mi\">2</span><span class=\"bp\">.</span><span class=\"n\">comp</span> <span class=\"n\">f</span><span class=\"o\">)</span><span class=\"bp\">.</span><span class=\"n\">mono</span> <span class=\"n\">le_comap_map</span><span class=\"o\">)</span><span class=\"bp\">.</span><span class=\"n\">trans_is_bigo</span> <span class=\"n\">hf</span><span class=\"bp\">.</span><span class=\"n\">is_bigo_sub</span><span class=\"o\">,</span>\n  <span class=\"n\">refine</span> <span class=\"n\">eq₂</span><span class=\"bp\">.</span><span class=\"n\">tri</span> <span class=\"o\">(</span><span class=\"n\">eq₁</span><span class=\"bp\">.</span><span class=\"n\">congr_left</span> <span class=\"o\">(</span><span class=\"bp\">λ</span> <span class=\"n\">x&#39;</span><span class=\"o\">,</span> <span class=\"bp\">_</span><span class=\"o\">)),</span>\n  <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"k\">show</span> <span class=\"n\">g&#39;</span> <span class=\"o\">(</span><span class=\"bp\">_-_</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">g&#39;</span> <span class=\"bp\">_</span> <span class=\"bp\">-</span> <span class=\"n\">g&#39;</span> <span class=\"bp\">_</span><span class=\"o\">,</span> <span class=\"k\">from</span> <span class=\"o\">(</span><span class=\"n\">hg</span><span class=\"bp\">.</span><span class=\"mi\">1</span><span class=\"bp\">.</span><span class=\"n\">to_linear_map</span> <span class=\"bp\">_</span><span class=\"o\">)</span><span class=\"bp\">.</span><span class=\"n\">map_sub</span> <span class=\"bp\">_</span> <span class=\"bp\">_</span><span class=\"o\">]</span>\n<span class=\"kn\">end</span><span class=\"bp\">⟩</span>\n</pre></div>\n\n\n<p>Coq:</p>\n<div class=\"codehilite\"><pre><span></span><span class=\"kn\">Proof</span><span class=\"o\">.</span>\n<span class=\"k\">move</span><span class=\"o\">=&gt;</span> <span class=\"n\">df</span> <span class=\"n\">dg</span><span class=\"o\">;</span> <span class=\"k\">split</span><span class=\"o\">;</span> <span class=\"kr\">first</span> <span class=\"kp\">by</span> <span class=\"k\">move</span><span class=\"o\">=&gt;</span> <span class=\"o\">?;</span> <span class=\"k\">apply</span><span class=\"o\">:</span> <span class=\"n\">continuous_comp</span><span class=\"o\">.</span>\n<span class=\"k\">apply</span><span class=\"o\">:</span> <span class=\"n\">eqaddoEx</span> <span class=\"o\">=&gt;</span> <span class=\"n\">y</span><span class=\"o\">;</span> <span class=\"k\">rewrite</span> <span class=\"n\">diff_locallyx</span><span class=\"o\">//</span> <span class=\"o\">-</span><span class=\"n\">addrA</span> <span class=\"n\">diff_locallyxC</span><span class=\"o\">//</span> <span class=\"n\">linearD</span><span class=\"o\">.</span>\n<span class=\"k\">rewrite</span> <span class=\"n\">addrA</span> <span class=\"o\">-</span><span class=\"n\">addrA</span><span class=\"o\">;</span> <span class=\"k\">congr</span> <span class=\"o\">(_</span> <span class=\"o\">+</span> <span class=\"o\">_</span> <span class=\"o\">+</span> <span class=\"o\">_).</span>\n<span class=\"k\">rewrite</span> <span class=\"n\">diff_eqO</span> <span class=\"o\">//</span> <span class=\"o\">[</span><span class=\"k\">&#39;</span><span class=\"n\">d</span> <span class=\"n\">f</span> <span class=\"n\">x</span> <span class=\"o\">:</span> <span class=\"o\">_</span> <span class=\"o\">-&gt;</span> <span class=\"o\">_]</span><span class=\"n\">diff_eqO</span> <span class=\"o\">//.</span>\n<span class=\"kp\">by</span> <span class=\"k\">rewrite</span> <span class=\"o\">{</span><span class=\"mi\">2</span><span class=\"o\">}</span><span class=\"n\">eqoO</span> <span class=\"n\">addOx</span> <span class=\"n\">compOo_eqox</span> <span class=\"n\">compoO_eqox</span> <span class=\"n\">addox</span><span class=\"o\">.</span>\n<span class=\"kn\">Qed</span><span class=\"o\">.</span>\n</pre></div>\n\n\n<p>Just about the same size!</p>",
        "id": 159308499,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1551062969
    },
    {
        "content": "<p>also just as unreadable, but I guess that's fair game for comparing to coq</p>",
        "id": 159308555,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1551063065
    },
    {
        "content": "<p>I have mixed feelings about Cyril et al.'s approach. On the one hand, it is nice that the calculations look like calculations. On the other hand, the inner workings are somewhat baroque and unintuitive, and require a parser hack. I personally find it easier to work with straightforward notation and concepts. And it is not clear to me that being able to do arbitrary calculational substitutions is a big win with asymptotic calculations, or that it will make the calculations that much shorter or any easier.<br>\nAnyhow, the current asymptotics file is just a start. When we start doing more serious calculations, we will have a better sense of what we want, and it would be great if someone wants to implement and try out the calculational trick.</p>",
        "id": 159308565,
        "sender_full_name": "Jeremy Avigad",
        "timestamp": 1551063119
    },
    {
        "content": "<p>One thing that I needed for the above version of the chain rule was rules like </p>\n<div class=\"codehilite\"><pre><span></span>is_littleo (\\lam x, f1 x - f2 x) g l -&gt;\nis_littleo (\\lam x, f2 x - f3 x) g l -&gt;\nis_littleo (\\lam x, f1 x - f3 x) g l\n</pre></div>\n\n\n<p>which are substituting for transitivity of equality. We could have a four-argument version of little o to say <code>f1 = f2 + o(g)</code> but it seems like it works just as well with an explicit subtraction... as long as it doesn't get unfolded by simp or something</p>",
        "id": 159308679,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1551063259
    },
    {
        "content": "<p>P.S. Please don't golf the proof of the chain rule in the actual file! As they say, size isn't everything. I think there is a lot of merit in having readable proofs, especially if it makes them easier to maintain. For example, I went out of my way to restate the main hypotheses instead of in-lining <code>hf.right</code> and <code>hg.right</code>, because that it what an ordinary textbook would do, and because they proof is inscrutable without that.</p>",
        "id": 159308698,
        "sender_full_name": "Jeremy Avigad",
        "timestamp": 1551063323
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span> Yes, I thought of that. I agree, it is not a big win over using the explicit subtraction.</p>",
        "id": 159308771,
        "sender_full_name": "Jeremy Avigad",
        "timestamp": 1551063443
    },
    {
        "content": "<p>Obviously this proof is not as verbose as your version. I'm not sure how to reconcile the two styles, tbh. I think it is helpful to stay in tactic mode for verbose proofs, because then you can follow along with the tactic state. Even a straight have/show proof is harder for me than a compacted tactic mode proof, although I'm not an average reader.</p>",
        "id": 159308920,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1551063711
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110064\">@Kenny Lau</span> Thanks for the tip about normed spaces. So, here is my to-do list: merge Mario's changes and additions, make a readable version of the proof of the chain rule, change <code>is_littleo</code> and <code>is_bigo</code> to <code>is_o</code> and <code>is_O</code> respectively (Mario suggested this, and I they look good in the file), and generalize to normed spaces over an arbitrary normed field. I probably won't be able to work on this for a couple of days, but I will do it soon.</p>",
        "id": 159429314,
        "sender_full_name": "Jeremy Avigad",
        "timestamp": 1551192580
    },
    {
        "content": "<p>nice</p>",
        "id": 159431884,
        "sender_full_name": "Kenny Lau",
        "timestamp": 1551194507
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 159463816,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1551219431
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110865\">@Jeremy Avigad</span> could you tell us a bit about your calculus roadmap now that we have derivatives? I have time for Lean (I'm on ski vacation without enough working ankles to ski) and I'm waiting for merge on the uniform space front. So I'd like to try a bit of calculus, but I don't want to work on something you are already working on</p>",
        "id": 159914523,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1551707351
    },
    {
        "content": "<p>I don't have a much of a grand road plan. With teaching, travel, and a paper deadline, I don't think I will be able to do much in March. I think the next thing to do with derivatives is to specialize the Fréchet derivative to the univariate case, and link in the kinds of results in <a href=\"https://github.com/leanprover/mathlib/issues/711\" target=\"_blank\" title=\"https://github.com/leanprover/mathlib/issues/711\">#711</a>. If you do anything along those lines now, I will check with you before picking it up again.</p>\n<p>I have two students interested in formalizing analysis. They are just starting out with Lean. One may work on extending the Lebesgue integral for nonneg functions to the Bochner integral, and then do bounded variation and absolute continuity and the FTC. The other may work on differential equations.</p>\n<p>Short answer: do whatever you want, and let us know, and we'll work around it.</p>",
        "id": 159971269,
        "sender_full_name": "Jeremy Avigad",
        "timestamp": 1551753330
    }
]