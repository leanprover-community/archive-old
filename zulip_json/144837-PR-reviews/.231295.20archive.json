[
    {
        "content": "<p>In <a href=\"https://github.com/leanprover-community/mathlib/issues/1295\" target=\"_blank\" title=\"https://github.com/leanprover-community/mathlib/issues/1295\">#1295</a> I added a folder where we can put one-off formalization projects. I called it <code>archive/</code>, following the archive of formal proofs. If this gets accepted, it would be nice to get <span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span> and/or <span class=\"user-mention\" data-user-id=\"110032\">@Reid Barton</span>'s formalization of IMO 2019-1, and <span class=\"user-mention\" data-user-id=\"110865\">@Jeremy Avigad</span>'s formalization of the mutilated checkerboard. And of course for all other projects which I don't know on the top of my head.</p>",
        "id": 172386562,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1564797969
    },
    {
        "content": "<p>We can probably add more information to the README, but we should first make some organizational decisions:</p>\n<ul>\n<li>Do we want to have a size limit? I would say we shouldn't put the perfectoid space project in here. I'm also don't think we want to have things like Flypitch in here (but maybe some of the basic logic files are fine?). Something with the size of the cap set problem (2k-3k LOC) should be fine though (although presumably <span class=\"user-mention\" data-user-id=\"110596\">@Rob Lewis</span> wants that in its own repository)</li>\n<li>We might want to specifically say that we don't want anything that is under active development?</li>\n</ul>\n<p>What else should be added to the README?</p>",
        "id": 172386794,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1564798479
    },
    {
        "content": "<p>Can we also have a requirement that all general use lemmas have already been factored into <code>src/</code>? We really don't want this to be a \"shortcut\", that results in people not putting in the effort to polish up generally useful material for wide consumption.</p>",
        "id": 172387180,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1564799224
    },
    {
        "content": "<p>Yes, I added that to the README:</p>\n<blockquote>\n<p>When you make a pull request, do make sure that you put all lemmas which should be in mathlib in the right place (in mathlib).</p>\n</blockquote>",
        "id": 172387197,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1564799282
    },
    {
        "content": "<p>Now reformulated to</p>\n<blockquote>\n<p>When you make a pull request, do make sure that you put all lemmas which are generally useful in right place in mathlib (in the <code>src/</code> directory).</p>\n</blockquote>",
        "id": 172387416,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1564799710
    },
    {
        "content": "<p>I think it is fine to put the perfectoid project there. It just means that its folder will be empty because 100% of it is generally useful and belongs in mathlib...</p>",
        "id": 172390291,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1564805600
    },
    {
        "content": "<p>When we run <code>leanpkg build</code> locally, will that only compile <code>src/</code> or also <code>archive/</code>?</p>",
        "id": 172391006,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1564807113
    },
    {
        "content": "<p>Because I fear that we will get lots of confusion if the local build passes, but it turns out it didn't test <code>archive/</code></p>",
        "id": 172391012,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1564807139
    },
    {
        "content": "<p><code>leanpkg build</code> will only compile <code>src/</code>.</p>\n<blockquote>\n<p>Because I fear that we will get lots of confusion if the local build passes, but it turns out it didn't test archive/</p>\n</blockquote>\n<p>If you run <code>leanpkg build</code> you are currently already building less than Travis, since Travis runs <code>leanpkg test</code>, which also builds the test folder.</p>",
        "id": 172392357,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1564810026
    },
    {
        "content": "<p>Sure, but I guess that will cause less confusion</p>",
        "id": 172392807,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1564811004
    },
    {
        "content": "<p>The test are less likely to break</p>",
        "id": 172392809,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1564811010
    },
    {
        "content": "<p>Any chance we could put <code>archive</code> under <code>test</code>?</p>",
        "id": 172414742,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1564853944
    },
    {
        "content": "<blockquote>\n<p>Any chance we could put <code>archive</code> under <code>test</code>?</p>\n</blockquote>\n<p>It feels a bit out of place to me, but if people feel strongly about <code>leanpkg test</code> also compiling the archive, I can move <code>archive</code> there.</p>",
        "id": 172623314,
        "sender_full_name": "Floris van Doorn",
        "timestamp": 1565121496
    },
    {
        "content": "<p>I agree. I think <code>archive</code> and <code>test</code> serve very different purposes.</p>",
        "id": 172623345,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1565121528
    },
    {
        "content": "<p>Alternatively, we can add a bash script <code>build_all</code> to build the library, the tests and the archive</p>",
        "id": 172626359,
        "sender_full_name": "Simon Hudon",
        "timestamp": 1565123960
    },
    {
        "content": "<p>As an extra data point about this archive idea, as well as automation vs maintainability: I'm back to my office, trying to catch up with things, and I just tried to open <span class=\"user-mention\" data-user-id=\"110865\">@Jeremy Avigad</span> <a href=\"https://gist.github.com/avigad/1080e327ad6806884c9c5091f5c449bd\" target=\"_blank\" title=\"https://gist.github.com/avigad/1080e327ad6806884c9c5091f5c449bd\">https://gist.github.com/avigad/1080e327ad6806884c9c5091f5c449bd</a>. And it doesn't compile with current mathlib (lean-3.4.2 branch). Of course the issue is <code>simp</code> invocations.</p>",
        "id": 173784224,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1566386461
    },
    {
        "content": "<p>I also noticed <a href=\"http://www.andrew.cmu.edu/user/avigad/Papers/mutilated.pdf\" target=\"_blank\" title=\"http://www.andrew.cmu.edu/user/avigad/Papers/mutilated.pdf\">www.andrew.cmu.edu/user/avigad/Papers/mutilated.pdf</a> suffers from the usual Lean + LaTeX glitches (see the place of the reverse rewrite arrow on line 144 in the pdf).</p>",
        "id": 173784335,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1566386562
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span> Do you remember how we solved that arrow issue in your LMS paper?</p>",
        "id": 173784358,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1566386591
    },
    {
        "content": "<p>Jeremy: in <a href=\"https://gist.github.com/avigad/1080e327ad6806884c9c5091f5c449bd#file-mutilated-lean-L134\" target=\"_blank\" title=\"https://gist.github.com/avigad/1080e327ad6806884c9c5091f5c449bd#file-mutilated-lean-L134\">https://gist.github.com/avigad/1080e327ad6806884c9c5091f5c449bd#file-mutilated-lean-L134</a> you should learn about <code>conv_lhs</code> which is a convenient little shortcut</p>",
        "id": 173784437,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1566386658
    },
    {
        "content": "<p>We solved it by <span class=\"user-mention\" data-user-id=\"110596\">@Rob Lewis</span> saying \"which version of the Lean LaTeX thing we you using? The publicly available one in the GitHub repo? Don't use that, use this one which is much newer and circulates informally\"</p>",
        "id": 173784796,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1566387084
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110031\">@Patrick Massot</span> Thanks for this information and for the tip. I am traveling now but I'll update the notes and the proof soon and add it to the archive folder.<br>\nRegarding maintainability of proofs that use automation: Isabelle's library provides strong empirical evidence that it can be done. The library is hundreds of thousands of lines long, and automation is used everywhere. Moreover, the archive of formal proofs has over 2.2 million lines. <br>\nThis is not to say that automation doesn't raise maintainability issues or introduce tradeoffs, but we should take the Isabelle experience into account.</p>",
        "id": 173804560,
        "sender_full_name": "Jeremy Avigad",
        "timestamp": 1566401244
    },
    {
        "content": "<p>Isabelle favors a very <code>have</code>-heavy proof style, right?</p>",
        "id": 173805436,
        "sender_full_name": "Reid Barton",
        "timestamp": 1566401732
    },
    {
        "content": "<p>P.S. I just found this very nice talk by Larry Paulson: <br>\n<a href=\"http://cpp2017.mpi-sws.org/Paulson.pdf\" target=\"_blank\" title=\"http://cpp2017.mpi-sws.org/Paulson.pdf\">http://cpp2017.mpi-sws.org/Paulson.pdf</a><br>\nIt makes a good case that structured proofs with automation are more useful (and maybe even maintainable?) than unreadable tactic proofs.</p>",
        "id": 173805554,
        "sender_full_name": "Jeremy Avigad",
        "timestamp": 1566401815
    },
    {
        "content": "<p>I think the issue here is that the proofs in the mutilated chessboard proof aren't structured for automation. I see a bunch of nonterminal simp calls, which are very hard to maintain.</p>",
        "id": 173805863,
        "sender_full_name": "Rob Lewis",
        "timestamp": 1566402049
    },
    {
        "content": "<p>(At least, they look nonterminal at a glance. I didn't open the file in VSCode.)</p>",
        "id": 173805947,
        "sender_full_name": "Rob Lewis",
        "timestamp": 1566402116
    },
    {
        "content": "<p>Rob, I guess that's exactly what broke but, in order to check, I would need to find the version of mathlib that used to make this code to work. Indeed in a proof like <code>by { simp, rw [...], simp }</code> that no longer succeeds, I have to way to tell whether the first of second (or both) simp do something different than what they used to do.</p>",
        "id": 173807530,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1566403116
    },
    {
        "content": "<p>And I also love the structured proof style. The reason we can't have quite it in Lean is poor automation.</p>",
        "id": 173807603,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1566403167
    },
    {
        "content": "<p>O.k., you have shamed me into fixing the problem. The gist should now work with today's <code>mathlib</code>. In fact, deleting a single character fixed the problem: I had stated an auxiliary simplification lemma in terms of a value cast from <code>pnat</code>, but with a recent change,  the simplifier reduced it to a <code>nat</code>.</p>\n<p>In my defense, most of the nonterminal <code>simp</code>s are things that automation should have gotten. <code>finish</code> gets one of them but freezes on some others. The instance of <code>simp; rw [foo]; simp</code> should have been <code>simp [foo]</code> but for some reason, <code>simp</code> couldn't match <code>foo</code> and <code>rw</code> could. </p>\n<p>Oh, and I used one instance of <code>simp, show ...</code>. It could easily be rewritten to a <code>suffices</code> followed by a terminal <code>simp</code>, but rewriting the proof this way makes it less natural. (I guess I am arguing that <code>simp, show ...</code> should count as a terminal <code>simp</code>).</p>",
        "id": 173815422,
        "sender_full_name": "Jeremy Avigad",
        "timestamp": 1566408819
    },
    {
        "content": "<blockquote>\n<p>O.k., you have shamed me into fixing the problem. The gist should now work with today's <code>mathlib</code>. In fact, deleting a single character fixed the problem: I had stated an auxiliary simplification lemma in terms of a value cast from <code>pnat</code>, but with a recent change,  the simplifier reduced it to a <code>nat</code>.</p>\n</blockquote>\n<p>I hope it's clear the goal was not to shame anyone. I understand very well that all this only proves how far we have from the level of automation we'd like to have. I just spent a bit of time looking for obvious optimization of the proofs. First I think you could argue that mathlib misses the following general lemma:</p>\n<div class=\"codehilite\"><pre><span></span><span class=\"kn\">lemma</span> <span class=\"n\">add_ne</span> <span class=\"o\">{</span><span class=\"n\">α</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span><span class=\"bp\">*</span><span class=\"o\">}</span> <span class=\"o\">[</span><span class=\"n\">add_group</span> <span class=\"n\">α</span><span class=\"o\">]</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"o\">{</span><span class=\"n\">b</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">(</span><span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">b</span> <span class=\"bp\">≠</span> <span class=\"mi\">0</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">a</span> <span class=\"bp\">+</span> <span class=\"n\">b</span> <span class=\"bp\">≠</span> <span class=\"n\">a</span><span class=\"o\">:=</span>\n<span class=\"bp\">λ</span> <span class=\"n\">h&#39;</span><span class=\"o\">,</span> <span class=\"n\">h</span> <span class=\"err\">$</span> <span class=\"n\">add_left_cancel</span> <span class=\"o\">(</span><span class=\"k\">show</span> <span class=\"n\">a</span> <span class=\"bp\">+</span> <span class=\"n\">b</span> <span class=\"bp\">=</span> <span class=\"n\">a</span> <span class=\"bp\">+</span> <span class=\"mi\">0</span><span class=\"o\">,</span> <span class=\"k\">by</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">add_zero</span><span class=\"o\">,</span> <span class=\"n\">h&#39;</span><span class=\"o\">])</span>\n</pre></div>\n\n\n<p>Something funny with this lemma is that you also need (in the very last proof):</p>\n<div class=\"codehilite\"><pre><span></span><span class=\"kn\">lemma</span> <span class=\"n\">nat</span><span class=\"bp\">.</span><span class=\"n\">add_ne</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"bp\">ℕ</span><span class=\"o\">)</span> <span class=\"o\">{</span><span class=\"n\">b</span> <span class=\"o\">:</span> <span class=\"bp\">ℕ</span><span class=\"o\">}</span> <span class=\"o\">(</span><span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">b</span> <span class=\"bp\">≠</span> <span class=\"mi\">0</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">a</span> <span class=\"bp\">+</span> <span class=\"n\">b</span> <span class=\"bp\">≠</span> <span class=\"n\">a</span><span class=\"o\">:=</span>\n<span class=\"bp\">λ</span> <span class=\"n\">h&#39;</span><span class=\"o\">,</span> <span class=\"n\">h</span> <span class=\"err\">$</span> <span class=\"n\">add_left_cancel</span> <span class=\"o\">(</span><span class=\"k\">show</span> <span class=\"n\">a</span> <span class=\"bp\">+</span> <span class=\"n\">b</span> <span class=\"bp\">=</span> <span class=\"n\">a</span> <span class=\"bp\">+</span> <span class=\"mi\">0</span><span class=\"o\">,</span> <span class=\"k\">by</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">add_zero</span><span class=\"o\">,</span> <span class=\"n\">h&#39;</span><span class=\"o\">])</span>\n</pre></div>\n\n\n<p>Note how the proof is exactly the same sequence of letters. Yet I can't find a combination of type classes that covers both. It's probably my lack of proper understanding of semi-cancellative almost distributive mononoids with zero. Of course with a powerful programming language with duck typing we could just write the proof and get it checked at runtime...</p>\n<p>Then I don't understand why some people make such a fuss about decidability instances and computability and still there are so many steps that should be <code>dec_trivial</code> but aren't. Some of them still are. For instance, in the main part of <code>card_mutilated_inter_black_squares</code>, when proving <code>¬7 = 0</code> you can replace <code>intro h, have := congr_arg fin.val h, contradiction</code> by <code>exact dec_trivial</code>. </p>\n<p>In <code>card_bind_squares_inter_white_squares</code> I don't know the point of this <code>swap</code> dance. Why not writing:</p>\n<div class=\"codehilite\"><pre><span></span><span class=\"n\">repeat</span> <span class=\"o\">{</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">bind_inter</span><span class=\"o\">,</span> <span class=\"n\">card_bind</span><span class=\"o\">]</span> <span class=\"o\">},</span>\n  <span class=\"n\">simp</span> <span class=\"n\">only</span> <span class=\"o\">[</span><span class=\"n\">card_squares_inter_white_squares</span><span class=\"o\">,</span> <span class=\"n\">card_squares_inter_black_squares</span><span class=\"o\">],</span>\n  <span class=\"n\">all_goals</span> <span class=\"o\">{</span> <span class=\"n\">intros</span><span class=\"o\">,</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">inter_right_comm</span><span class=\"o\">,</span> <span class=\"err\">←</span><span class=\"n\">inter_assoc</span><span class=\"o\">,</span> <span class=\"n\">h</span><span class=\"o\">]</span> <span class=\"bp\">;</span> <span class=\"n\">tauto</span> <span class=\"o\">},</span>\n</pre></div>\n\n\n<p>since the proof is unreadable anyway? By the way, is this last goal (solved by the last <code>{...}</code> something Isabelle automation would do?</p>",
        "id": 173866725,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1566466590
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><span class=\"kn\">lemma</span> <span class=\"n\">nat</span><span class=\"bp\">.</span><span class=\"n\">add_ne</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"bp\">ℕ</span><span class=\"o\">)</span> <span class=\"o\">{</span><span class=\"n\">b</span> <span class=\"o\">:</span> <span class=\"bp\">ℕ</span><span class=\"o\">}</span> <span class=\"o\">(</span><span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">b</span> <span class=\"bp\">≠</span> <span class=\"mi\">0</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">a</span> <span class=\"bp\">+</span> <span class=\"n\">b</span> <span class=\"bp\">≠</span> <span class=\"n\">a</span><span class=\"o\">:=</span>\n<span class=\"bp\">λ</span> <span class=\"n\">h&#39;</span><span class=\"o\">,</span> <span class=\"n\">h</span> <span class=\"err\">$</span> <span class=\"n\">add_left_cancel</span> <span class=\"o\">(</span><span class=\"k\">show</span> <span class=\"n\">a</span> <span class=\"bp\">+</span> <span class=\"n\">b</span> <span class=\"bp\">=</span> <span class=\"n\">a</span> <span class=\"bp\">+</span> <span class=\"mi\">0</span><span class=\"o\">,</span> <span class=\"k\">by</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">add_zero</span><span class=\"o\">,</span> <span class=\"n\">h&#39;</span><span class=\"o\">])</span>\n</pre></div>\n\n\n<p>this is the contrapositive of something which is <code>by linarith</code> (probably overkill)</p>",
        "id": 173884808,
        "sender_full_name": "Jesse Michael Han",
        "timestamp": 1566482286
    },
    {
        "content": "<p>Thanks for the suggestions -- I'll incorporate them. I am meeting with Seul now, but for the record, here is a nice Isabelle formalization:<br>\n<a href=\"https://github.com/avigad/arwm/blob/master/isabelle_experiments/mutilated.thy\" target=\"_blank\" title=\"https://github.com/avigad/arwm/blob/master/isabelle_experiments/mutilated.thy\">https://github.com/avigad/arwm/blob/master/isabelle_experiments/mutilated.thy</a><br>\n<a href=\"https://github.com/avigad/arwm/blob/master/isabelle_experiments/mutilated.pdf\" target=\"_blank\" title=\"https://github.com/avigad/arwm/blob/master/isabelle_experiments/mutilated.pdf\">https://github.com/avigad/arwm/blob/master/isabelle_experiments/mutilated.pdf</a><br>\nAfter the definitions, the proof is about 50 lines, as compared to about 110 in the Lean file.</p>",
        "id": 173902974,
        "sender_full_name": "Jeremy Avigad",
        "timestamp": 1566494894
    },
    {
        "content": "<p>Since I have been obsessed with automation that last few weeks, yesterday I formalized an elementary proof of the IVT in Isabelle as well. <br>\n<a href=\"https://github.com/avigad/arwm/blob/master/isabelle_experiments/ivt.pdf\" target=\"_blank\" title=\"https://github.com/avigad/arwm/blob/master/isabelle_experiments/ivt.pdf\">https://github.com/avigad/arwm/blob/master/isabelle_experiments/ivt.pdf</a><br>\nAll the experiments, with notes, are here:<br>\n<a href=\"https://github.com/avigad/arwm/tree/master/isabelle_experiments\" target=\"_blank\" title=\"https://github.com/avigad/arwm/tree/master/isabelle_experiments\">https://github.com/avigad/arwm/tree/master/isabelle_experiments</a></p>",
        "id": 174037353,
        "sender_full_name": "Jeremy Avigad",
        "timestamp": 1566649875
    },
    {
        "content": "<blockquote>\n<p>P.S. I just found this very nice talk by Larry Paulson: <br>\n<a href=\"http://cpp2017.mpi-sws.org/Paulson.pdf\" target=\"_blank\" title=\"http://cpp2017.mpi-sws.org/Paulson.pdf\">http://cpp2017.mpi-sws.org/Paulson.pdf</a><br>\nIt makes a good case that structured proofs with automation are more useful (and maybe even maintainable?) than unreadable tactic proofs.</p>\n</blockquote>\n<p>In these slides I learned that HOL Light grows with some 3000 lines per month. Github just told me that in the last month mathlib grew with &gt;6000 lines. Is HOL terser, or are we growing faster?</p>",
        "id": 174048694,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1566669844
    },
    {
        "content": "<p>Keep in mind that HOL light is almost completely one man's work</p>",
        "id": 174050031,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1566672168
    },
    {
        "content": "<p>This is not a line number competition anyway...</p>",
        "id": 174050454,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1566672945
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110865\">@Jeremy Avigad</span> Somewhere you wrote that you are interested in a \"log of the proof discovery\" (my words) and not so much the polished end-result. I've no idea how hard it is to tweak VScode, but I guess it could record Lean sessions for us. Of course you don't want to watch hours and hours of us struggling with natural number subtraction. But the logs of those sessions could potentially be analyzed by a machine. And it might give even more insight than non-polished end-results. (After all, a non-polished end-result still doesn't capture my backspaces, etc...)</p>",
        "id": 174051595,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1566675029
    },
    {
        "content": "<p>My concern was that people developing automated tools should have a realistic picture of how the tools are used and where they succeed and where they fail. The most common method of evaluation is to take an existing library, delete the proofs, and try to fill them in again automatically. There are various ways that might skew the data. For example, the existing libraries already reflect all the things we did to make the proofs work, like rewrite definitions and add supporting lemmas. It is not an indication of what we wanted to do in the first place. And it is likely that automation is succeeding on the easy tasks, not the ones where we really want the help.</p>\n<p>Automatically harvesting data is a nice idea. I don't have a good sense what machine learning techniques can or cannot do, and what might work there.</p>\n<p>But I think even anecdotal examples can be helpful. Experiment with an existing tool, figure out what it can and cannot do, and document the successes and failures. The reason Isabelle's automation is so good is that formalizers and tool developers worked together, and often were even the same person. So the tool developers had a clear picture what the were trying to achieve. From the few examples I have done, I am at least getting a better sense of where Sledgehammer has trouble. I'll do my best to summarize what I have learned in the talk I am preparing.</p>\n<p>There is the added complication that computer scientists don't get a lot of credit for helping mathematicians. They are generally expected to support their students, and it is easier to get funded if they are verifying compilers or network security protocols or airplane control systems. But we can be grateful for the fact that there are people in CS interested in mathematical reasoning, and the least we can do is help supply them with data and examples.</p>",
        "id": 174055736,
        "sender_full_name": "Jeremy Avigad",
        "timestamp": 1566683154
    }
]