[
    {
        "content": "<p>Does anyone have opinions about the tactic casing convention? Lean 4 seems to be indecisive about whether tactics should be snake case (<code>simp_all</code>) or camel case (<code>inferInstance</code>, <code>refineLift'</code>), while I went for all camel case in mathport and I think <span class=\"user-mention\" data-user-id=\"399706\">@Aur√©lien Saue</span> is following my syntax descriptions in <a href=\"https://github.com/leanprover-community/mathlib4/issues/27\">mathlib4#27</a>. There are also things like <code>erewrite</code> that are just uncased, should they be <code>eRewrite</code>? <code>eRw</code> seems weird.</p>",
        "id": 247599539,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627572447
    },
    {
        "content": "<p><code>casesM</code>? <code>introV</code>? <code>exFalso</code>? <code>existsI</code>?</p>",
        "id": 247599678,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627572515
    },
    {
        "content": "<p>cc: <span class=\"user-mention\" data-user-id=\"230999\">@Daniel Selsam</span> <span class=\"user-mention\" data-user-id=\"110043\">@Gabriel Ebner</span> <span class=\"user-mention\" data-user-id=\"110024\">@Sebastian Ullrich</span></p>",
        "id": 247599805,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627572598
    },
    {
        "content": "<p>I vote camelCase everywhere (possibly with special cases for weird ones like <code>eRw</code>)</p>",
        "id": 247599996,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1627572693
    },
    {
        "content": "<p>There is some precedence for snake case: most commands like <code>set_option</code>, <code>elab_rules</code>, etc. are snake case</p>",
        "id": 247600075,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1627572730
    },
    {
        "content": "<p>the <code>TacticM</code> counterparts of the tactic syntax are regular Lean programs, definitely camelCased, and the tactic syntax feels to me at least like sugar for calling them</p>",
        "id": 247600356,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1627572897
    },
    {
        "content": "<p>But I haven't done much interactive proving yet so my intuitions may be out of line</p>",
        "id": 247600446,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1627572949
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110043\">Gabriel Ebner</span> <a href=\"#narrow/stream/287929-mathlib4/topic/Tactic.20casing.20convention/near/247600075\">said</a>:</p>\n<blockquote>\n<p>There is some precedence for snake case: most commands like <code>set_option</code>, <code>elab_rules</code>, etc. are snake case</p>\n</blockquote>\n<p>Also <code>set_option</code> is in the term grammar; not sure there are many other multi-word keywords in the term grammar</p>",
        "id": 247600903,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627573161
    },
    {
        "content": "<p>With snake case?</p>",
        "id": 247600967,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1627573189
    },
    {
        "content": "<p>yes</p>",
        "id": 247600978,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627573193
    },
    {
        "content": "<p><code>def bla := set_option foo 37 in 2 + 2</code></p>",
        "id": 247601041,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627573210
    },
    {
        "content": "<p>I think there is a strong argument for maintaining the parallel between term constructions and tactics for things like <code>have</code> / <code>let</code> / <code>show</code> that maybe generalizes to <code>set_option</code>?</p>",
        "id": 247601348,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627573351
    },
    {
        "content": "<p>Yes, <code>set_option</code> should obviously be the same in command, term, and tactic mode.</p>",
        "id": 247601406,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1627573382
    },
    {
        "content": "<p>If <code>set_option</code> becomes a tactic (and why wouldn't it), it would be confusing if it was spelled differently</p>",
        "id": 247601423,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627573391
    },
    {
        "content": "<p>that said, you could just as easily turn it around and argue that commands should be camel cased</p>",
        "id": 247601518,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627573438
    },
    {
        "content": "<p>For reference, in rust keywords are mostly one-word but there are <code>typeof</code> and <code>macro_rules</code> which weakly suggest a snake casing convention; haskell somehow manages to get away with keywords being actual english words (or symbols), with space separated compound keywords like <code>deriving instance</code> or <code>type family</code>; and C++ keywords are snake cased like <code>co_await</code> or mashed lowercase like <code>alignas</code> or <code>sizeof</code></p>",
        "id": 247602255,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627573752
    },
    {
        "content": "<p>Mmh, <code>by infer instance</code>?</p>",
        "id": 247602717,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1627573971
    },
    {
        "content": "<p>Why are we mixing conventions now? <a href=\"https://github.com/leanprover-community/mathlib4/blob/master/Mathlib/Data/Nat/Basic.lean\">Nat/Basic.lean</a> hints that defs/lemmas are going to be snake_case in future; is it trying to be a way to easily tell apart tactics vs defs?</p>",
        "id": 247602814,
        "sender_full_name": "Eric Rodriguez",
        "timestamp": 1627574026
    },
    {
        "content": "<p>tactics vs defs are already syntactically distinguishable, so they can overlap or not as we prefer</p>",
        "id": 247602918,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627574059
    },
    {
        "content": "<p>unless we want to introduce a shorthand where <code>e</code> means <code>exact e</code>, which seems like a bad idea since it will probably cause lots of clashes</p>",
        "id": 247602987,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627574104
    },
    {
        "content": "<p><a href=\"https://github.com/leanprover-community/lean-liquid/blob/master/src/hacks_and_tricks/by_exactI_hack.lean\">it isn't unheard of tbf</a></p>",
        "id": 247603159,
        "sender_full_name": "Eric Rodriguez",
        "timestamp": 1627574188
    },
    {
        "content": "<p>but I can't imagine it being a good idea</p>",
        "id": 247603177,
        "sender_full_name": "Eric Rodriguez",
        "timestamp": 1627574199
    },
    {
        "content": "<p>lol it's using a zero width keyword</p>",
        "id": 247603254,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627574237
    },
    {
        "content": "<p>strictly speaking that's a user notation, not a tactic, so it lets you skip the <code>by</code> as well as <code>exact</code></p>",
        "id": 247603428,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627574321
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/287929-mathlib4/topic/Tactic.20casing.20convention/near/247602255\">said</a>:</p>\n<blockquote>\n<p>For reference, in rust keywords are mostly one-word but there are <code>typeof</code> and <code>macro_rules</code> which weakly suggest a snake casing convention;</p>\n</blockquote>\n<p>From what I understood from the discussion of when <code>natLit!</code> became <code>nat_lit</code>, I believe that snake case is now the standard in the Lean 4 core for any and all multi-word syntax keywords. This is why <code>set_option</code>, <code>macro_rules</code> and the like are snake case. Things like <code>typeof</code>, <code>erw</code>,  are special exceptions because mish-mashes of short words are often though of as a single (new) word in CS (ex. segfault or <code>exfalso</code>).</p>\n<p>The question, I think, is whether tactics are to be thought of as keywords (and thus snake case) or function-like identifiers (and thus camel case). Given that that tactics don't create new keywords, I would go for the latter.</p>",
        "id": 247636274,
        "sender_full_name": "Mac",
        "timestamp": 1627590225
    },
    {
        "content": "<p>they are basically contextual keywords though. If you use a misspelled tactic it doesn't even parse</p>",
        "id": 247636443,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627590308
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span>  true, to the parser, they are symbols and thus functionally keywords, but I would consider that an implementation detail.</p>",
        "id": 247636631,
        "sender_full_name": "Mac",
        "timestamp": 1627590413
    },
    {
        "content": "<p>I mean, unlike a regular function where you can still understand what comes next without the name making reference to anything, a tactic is a new piece of syntax with its own parsing rules, so if you don't recognize the tactic nothing after it makes sense</p>",
        "id": 247636991,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627590577
    },
    {
        "content": "<p>Also, the Lean 4 core seems to lean in this direction as every multi-word tactic is in camel case outside <code>simp_all</code> (which I suspect may be an oversight).</p>",
        "id": 247637009,
        "sender_full_name": "Mac",
        "timestamp": 1627590586
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span>  Well, yeah, I certainly don't consider tactics to be regular functions. However, I do consider them to be <em>like</em> functions in that they are are pieces of notation identified by a single name with a singular function. Keywords, however, I view as common parser tokens that may appear in many different pieces of syntax (ex.  <code>where</code>, <code>do</code>, <code>by</code>, <code>let</code>, etc.).</p>",
        "id": 247637907,
        "sender_full_name": "Mac",
        "timestamp": 1627591022
    },
    {
        "content": "<p>Currently, the fact that most tactics start with a keyword seems to be a mere convention inherited from lean 3, where this practice is required. I don't know if we're going to see more infix and mixfix tactics in lean 4 going forward</p>",
        "id": 247638102,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627591108
    },
    {
        "content": "<p>I wonder whether ssreflect has any good ideas for tactic operators</p>",
        "id": 247638304,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627591223
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span> well the fact that tactics start with a symbol (identifier) is rather key to its parsing, as the tactic parser only makes the lead symbol not a keyword (and the whole 'leading behavior' of parser categories seems to have been specifically designed for this purpose). A symbol in any other location would create real keywords.</p>",
        "id": 247638384,
        "sender_full_name": "Mac",
        "timestamp": 1627591278
    },
    {
        "content": "<p>You can have non-keyword symbols anywhere using <code>&amp;\"foo\"</code></p>",
        "id": 247638440,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627591313
    },
    {
        "content": "<p>I believe that the auto-non-keyword thing is a mere convenience</p>",
        "id": 247638512,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627591344
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span> that is entirely separate concept from the kind of pseudo-keyword a tactic is.</p>",
        "id": 247638531,
        "sender_full_name": "Mac",
        "timestamp": 1627591362
    },
    {
        "content": "<p>I don't see how</p>",
        "id": 247638565,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627591385
    },
    {
        "content": "<p>for example, <code>simp</code> uses an optional <code>(config = ...)</code> argument, and the word <code>config</code> is written as <code>&amp;\"config\"</code> so that you can use config as a variable or function name elsewhere</p>",
        "id": 247638699,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627591459
    },
    {
        "content": "<p>they are parsed very differently? the leading behavior parser uses the leading identifier to disambiguate between parsers to run. Without the special leading behavior and just using a non-reserved symbol (i.e., <code>&amp;\"foo\"</code>), every tactic would look like it begin with <code>ident</code> to the parser. Thus, no disambiguation would occur and <em>every</em> parser would be run (it wouldn't even stop on the first success due to the longest-match behavior of the parser). Thus the former is O(log n) in parsers (as <code>TokenMap</code> us an <code>RBMap</code>) whereas the later is O(n).</p>",
        "id": 247638972,
        "sender_full_name": "Mac",
        "timestamp": 1627591638
    },
    {
        "content": "<p>that sounds like an implementation issue; non-reserved symbols shouldn't make it any slower in principle</p>",
        "id": 247639453,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627591900
    },
    {
        "content": "<p>I disagree. In my view, there is a major conceptual difference between non-reserved symbols and parser leading behavior.</p>",
        "id": 247640321,
        "sender_full_name": "Mac",
        "timestamp": 1627592321
    },
    {
        "content": "<p>But maybe one of Lean 4 developers (e.g., <span class=\"user-mention\" data-user-id=\"110024\">@Sebastian Ullrich</span>) would have better insight than me. Especially since he, as I understand it, was largely responsible for the Lean 4 parser.</p>",
        "id": 247640337,
        "sender_full_name": "Mac",
        "timestamp": 1627592334
    },
    {
        "content": "<p>However, I should note, as I am not an expert in this matter, I may be understanding this all wrong.</p>",
        "id": 247640621,
        "sender_full_name": "Mac",
        "timestamp": 1627592445
    },
    {
        "content": "<p>That is, if you have n different parsers that differ only in a single place where they each have different non-reserved symbols, it should be possible to distinguish them in O(log n) using a discrimination tree</p>",
        "id": 247642022,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627593157
    },
    {
        "content": "<p>It's possible that this has been special-cased in the case of the initial symbol in a tactic, but it works generally</p>",
        "id": 247642093,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627593193
    },
    {
        "content": "<p>I would think that to get that to work generally would require knowing/storing much more information about the parsers than is usually feasible (especially in Lean where parsers can be arbitrary functions without any clear grammar).</p>",
        "id": 247652970,
        "sender_full_name": "Mac",
        "timestamp": 1627600274
    },
    {
        "content": "<p>Why? <code>&amp;\"foo\"</code> is a very declarative way to say \"match an ident that is equal to <code> `foo</code>\"</p>",
        "id": 247654908,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627601730
    },
    {
        "content": "<p>it's not essentially different from <code>\"foo\"</code> which says \"match a token that is equal to <code>\"foo\"</code>\"</p>",
        "id": 247654996,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627601779
    },
    {
        "content": "<p>At the <code>syntax</code> level, yes, you could probably do such inferences. However, at the <code>Parser</code>/<code>ParserFn</code> level it is no longer so declarative. Furthermore, <code>syntax</code> can  actually reference arbitrary parsers so any <code>syntax</code> doing so would also be unable to be analyzed in such a manner.</p>",
        "id": 247660606,
        "sender_full_name": "Mac",
        "timestamp": 1627607356
    },
    {
        "content": "<p>I am also a little confused, <span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span> . I know that you have fiddled with parsers in-depth before and realized that they keep very little information about their grammar (i.e., when you wanted to print all the grammars of in a parser category and discovered that wasn't really feasible). So, as I feel like you probably already know some of the points I am making, I suspect I may be misunderstanding whatever you are trying to convey.</p>",
        "id": 247660852,
        "sender_full_name": "Mac",
        "timestamp": 1627607668
    },
    {
        "content": "<p>I'm talking about the parsers as they are expressed at the <code>syntax</code> level. In order to preserve the distinction to the compiled level, one would need to retain that <code>TokenMap</code> like structure in the parser tables</p>",
        "id": 247660981,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627607815
    },
    {
        "content": "<p>I'm still confused as to what you are proposing. Maybe a concrete example will help. <br>\nFor something like <code>syntax foo &amp;\"and\" bar : term</code> where <code>foo</code> and <code>bar</code> are parser aliases (ex., almost any built-in Lean syntax kind), how are you proposing this discriminates from other parsers with a different token at \"and\"?</p>",
        "id": 247661355,
        "sender_full_name": "Mac",
        "timestamp": 1627608316
    },
    {
        "content": "<p>That syntax gets compiled down to a bunch of transitions in a state machine (a token trie), and so there will be an initial state corresponding to <code>term</code> , followed by an edge along <code>foo</code> (if <code>foo</code> is a terminal or nonterminal; if it is an abbreviation for something then it might be multiple edges) to a state <code>s1</code>, which has a <code>&amp;\"and\"</code> edge to <code>s2</code> which has a <code>bar</code> edge to <code>s3</code> which is an accepting state (marked with the reduction rule \"apply <code>term_and_</code>\").</p>\n<p>The important part in this case is what an <code>&amp;\"and\"</code> edge is. This is a terminal, so it directs the tokenizer to parse a token, and then assert that the parsed token is <code>\"and\"</code>. This is exactly the same as what would happen with <code>\"and\"</code>; the only difference is that one considers <code>Syntax.atom</code> tokens and the other considers <code>Syntax.ident</code></p>",
        "id": 247661896,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627609065
    },
    {
        "content": "<p>When multiple parsers are added that all pass through state <code>s1</code>, it will acquire many out-edges like <code>&amp;\"and\"</code>, <code>&amp;\"or\"</code> and so on. These can be stored in a <code>TokenMap</code> in order to get O(log n) lookup</p>",
        "id": 247661967,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627609127
    },
    {
        "content": "<p>AFAIK this is exactly what is already happening for regular (reserved) tokens, but it's possible that it is not being done for non-reserved tokens</p>",
        "id": 247662051,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627609245
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/287929-mathlib4/topic/Tactic.20casing.20convention/near/247661967\">said</a>:</p>\n<blockquote>\n<p>When multiple parsers are added that all pass through state <code>s1</code>, it will acquire many out-edges like <code>&amp;\"and\"</code>, <code>&amp;\"or\"</code> and so on. These can be stored in a <code>TokenMap</code> in order to get O(log n) lookup</p>\n</blockquote>\n<p>Note that, afaik, in the current Lean 4 parser implementation <code>TokenMap</code> lookups only occur for the leading token of a category parser. A normal parser does not do any such lookups. That is, if I have the syntax <code>\"foo\" \"bar\"</code> <code>\"foo\" \"baz\"</code> and <code>\"foo\" \"bam\"</code> there is no lookup on the second token. Furthermore, parsers are not guaranteed to even have first token information much less 2nd/3rd/4th information. Parsers are not guaranteed to parse tokens either, they can just parse the raw input stream (nor are they guaranteed to be deterministic or terminate).</p>",
        "id": 247662678,
        "sender_full_name": "Mac",
        "timestamp": 1627610076
    },
    {
        "content": "<p>Looking at the code some more, I think the lean 4 parser setup is a bit flatter than this. What I described is how lean 3 notations are compiled, but in lean 4 it appears that it only looks one token deep, and special cases the leading parser and trailing parser cases (corresponding to the initial state and the state after a <code>term</code> edge) to have proper token trees, and all other states are simply stuck in one big list. This means that while it can efficiently handle things like:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">syntax</span> <span class=\"s2\">\"lead1\"</span> <span class=\"n\">term</span> <span class=\"o\">:</span> <span class=\"n\">term</span>\n<span class=\"bp\">...</span>\n<span class=\"n\">syntax</span> <span class=\"s2\">\"leadn\"</span> <span class=\"n\">term</span> <span class=\"o\">:</span> <span class=\"n\">term</span>\n\n<span class=\"n\">syntax</span> <span class=\"n\">term</span> <span class=\"s2\">\"trail1\"</span> <span class=\"n\">term</span> <span class=\"o\">:</span> <span class=\"n\">term</span>\n<span class=\"bp\">...</span>\n<span class=\"n\">syntax</span> <span class=\"n\">term</span> <span class=\"s2\">\"trailn\"</span> <span class=\"n\">term</span> <span class=\"o\">:</span> <span class=\"n\">term</span>\n</code></pre></div>\n<p>it will have linear time performance on</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">syntax</span> <span class=\"s2\">\"a\"</span> <span class=\"s2\">\"lead1\"</span> <span class=\"n\">term</span> <span class=\"o\">:</span> <span class=\"n\">term</span>\n<span class=\"bp\">...</span>\n<span class=\"n\">syntax</span> <span class=\"s2\">\"a\"</span> <span class=\"s2\">\"leadn\"</span> <span class=\"n\">term</span> <span class=\"o\">:</span> <span class=\"n\">term</span>\n\n<span class=\"n\">syntax</span> <span class=\"s2\">\"a\"</span> <span class=\"n\">term</span> <span class=\"s2\">\"trail1\"</span> <span class=\"n\">term</span> <span class=\"o\">:</span> <span class=\"n\">term</span>\n<span class=\"bp\">...</span>\n<span class=\"n\">syntax</span> <span class=\"s2\">\"a\"</span> <span class=\"n\">term</span> <span class=\"s2\">\"trailn\"</span> <span class=\"n\">term</span> <span class=\"o\">:</span> <span class=\"n\">term</span>\n</code></pre></div>",
        "id": 247662690,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627610098
    },
    {
        "content": "<p>It would still be possible to implement this even in the presence of arbitrary parsers; you would just have a token tree for the ones generated by syntax and an \"other\" list for all the manually implemented parsers</p>",
        "id": 247662778,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627610214
    },
    {
        "content": "<p>Yep, you more-or-less got to what I was saying before I finished saying it. :P</p>",
        "id": 247662856,
        "sender_full_name": "Mac",
        "timestamp": 1627610291
    },
    {
        "content": "<p>That would handle things like this:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">syntax</span> <span class=\"s2\">\"properly\"</span> <span class=\"s2\">\"organized\"</span> <span class=\"s2\">\"tokens\"</span> <span class=\"n\">thenCallMyArbitraryParser</span> <span class=\"o\">:</span> <span class=\"n\">term</span>\n</code></pre></div>",
        "id": 247662863,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627610317
    },
    {
        "content": "<p>Note that what you are suggesting is essentially turning every parser into a (closed?) parser category.  You could thus already simulate this in that manner.</p>",
        "id": 247663123,
        "sender_full_name": "Mac",
        "timestamp": 1627610556
    },
    {
        "content": "<p>Not closed, it would be added to whenever you add to the parent category</p>",
        "id": 247663144,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627610587
    },
    {
        "content": "<p>although maybe you can't directly add to it through <code>syntax</code></p>",
        "id": 247663153,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627610611
    },
    {
        "content": "<p>For your example, this would look like:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">declare_syntax_cat</span> <span class=\"n\">properly</span>\n<span class=\"n\">syntax</span> <span class=\"s2\">\"properly\"</span> <span class=\"n\">properly</span> <span class=\"o\">:</span> <span class=\"n\">term</span>\n<span class=\"n\">declare_syntax_cat</span> <span class=\"n\">organized</span>\n<span class=\"n\">syntax</span> <span class=\"s2\">\"organized\"</span> <span class=\"n\">organized</span> <span class=\"o\">:</span> <span class=\"n\">properly</span>\n<span class=\"n\">declare_syntax_cat</span> <span class=\"n\">tokens</span>\n<span class=\"n\">syntax</span> <span class=\"s2\">\"tokens\"</span> <span class=\"n\">tokens</span> <span class=\"o\">:</span> <span class=\"n\">organized</span>\n<span class=\"n\">syntax</span> <span class=\"n\">thenCallMyArbitraryParser</span> <span class=\"o\">:</span> <span class=\"n\">tokens</span>\n</code></pre></div>",
        "id": 247663182,
        "sender_full_name": "Mac",
        "timestamp": 1627610643
    },
    {
        "content": "<p>Similarly:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">declare_syntax_cat</span> <span class=\"n\">termA</span>\n<span class=\"n\">syntax</span> <span class=\"s2\">\"a\"</span> <span class=\"n\">termA</span> <span class=\"o\">:</span> <span class=\"n\">term</span>\n<span class=\"n\">syntax</span> <span class=\"s2\">\"lead1\"</span> <span class=\"n\">term</span> <span class=\"o\">:</span> <span class=\"n\">termA</span>\n<span class=\"bp\">...</span>\n<span class=\"n\">syntax</span> <span class=\"s2\">\"leadn\"</span> <span class=\"n\">term</span> <span class=\"o\">:</span> <span class=\"n\">termA</span>\n\n<span class=\"n\">syntax</span> <span class=\"n\">term</span> <span class=\"s2\">\"trail1\"</span> <span class=\"n\">term</span> <span class=\"o\">:</span> <span class=\"n\">termA</span>\n<span class=\"bp\">...</span>\n<span class=\"n\">syntax</span> <span class=\"n\">term</span> <span class=\"s2\">\"trailn\"</span> <span class=\"n\">term</span> <span class=\"o\">:</span> <span class=\"n\">termA</span>\n</code></pre></div>",
        "id": 247663231,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627610708
    },
    {
        "content": "<p>Although I guess you have to declare in advance whether you expect many <code>\"foo\"</code> parsers or many <code>&amp;\"foo\"</code> parsers by setting the <code>LeadingIdentBehavior</code> appropriately</p>",
        "id": 247663317,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1627610790
    },
    {
        "content": "<p>I suspect that this approach may result in some less-than-ideal performance overhead (either in memory or runtime) if used universally.</p>",
        "id": 247663537,
        "sender_full_name": "Mac",
        "timestamp": 1627611050
    }
]