[
    {
        "content": "<p>Here's another <code>simp</code> example behaving differently between Lean 3 and Lean 4.  My guess is that it's a different choice of priorities, with Lean 3 prioritizing the lemmas given by the user in <code>simp [...]</code> over generic <code>@[simp]</code> lemmas, and Lean 4 not doing this.  Can anyone confirm this?</p>\n<p>If that diagnosis is correct, it seems like it's something we will hit over and over again in the port.</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">class</span> <span class=\"n\">Bot</span> <span class=\"o\">(</span><span class=\"n\">α</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span><span class=\"o\">)</span> <span class=\"n\">where</span> <span class=\"n\">bot</span> <span class=\"o\">:</span> <span class=\"n\">α</span>\n<span class=\"kd\">class</span> <span class=\"n\">Inv</span> <span class=\"o\">(</span><span class=\"n\">α</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span><span class=\"o\">)</span> <span class=\"n\">where</span> <span class=\"n\">inv</span> <span class=\"o\">:</span> <span class=\"n\">α</span> <span class=\"bp\">→</span> <span class=\"n\">α</span>\n\n<span class=\"kd\">notation</span> <span class=\"s2\">\"⊥\"</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">Bot.bot</span>\n<span class=\"kd\">postfix</span><span class=\"o\">:</span><span class=\"n\">max</span> <span class=\"s2\">\"⁻¹\"</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">Inv.inv</span>\n\n<span class=\"kd\">variable</span> <span class=\"o\">{</span><span class=\"n\">α</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span><span class=\"o\">}</span> <span class=\"o\">[</span><span class=\"n\">Bot</span> <span class=\"n\">α</span><span class=\"o\">]</span> <span class=\"o\">[</span><span class=\"n\">Inv</span> <span class=\"n\">α</span><span class=\"o\">]</span>\n\n<span class=\"kd\">@[simp]</span> <span class=\"kd\">theorem</span> <span class=\"n\">inv_eq_bot</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">:</span> <span class=\"n\">a</span><span class=\"bp\">⁻¹</span> <span class=\"bp\">=</span> <span class=\"bp\">⊥</span> <span class=\"bp\">↔</span> <span class=\"n\">a</span> <span class=\"bp\">=</span> <span class=\"bp\">⊥</span> <span class=\"o\">:=</span> <span class=\"gr\">sorry</span>\n\n<span class=\"kd\">theorem</span> <span class=\"n\">inv_ne_bot</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">}</span> <span class=\"o\">(</span><span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">a</span> <span class=\"bp\">≠</span> <span class=\"bp\">⊥</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">a</span><span class=\"bp\">⁻¹</span> <span class=\"bp\">≠</span> <span class=\"bp\">⊥</span> <span class=\"o\">:=</span> <span class=\"gr\">sorry</span>\n\n<span class=\"kd\">example</span> <span class=\"o\">(</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">ha</span> <span class=\"o\">:</span> <span class=\"n\">a</span> <span class=\"bp\">≠</span> <span class=\"bp\">⊥</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">a</span><span class=\"bp\">⁻¹</span> <span class=\"bp\">=</span> <span class=\"bp\">⊥</span> <span class=\"bp\">↔</span> <span class=\"n\">false</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span> <span class=\"n\">simp</span> <span class=\"o\">[</span><span class=\"n\">inv_ne_bot</span> <span class=\"n\">ha</span><span class=\"o\">]</span>\n<span class=\"c1\">-- fails in Lean 4, works in Lean 3</span>\n</code></pre></div>",
        "id": 314689186,
        "sender_full_name": "Heather Macbeth",
        "timestamp": 1670510030
    },
    {
        "content": "<p>Hmm. In both Lean 3 and Lean 4 this code (appropriately decapitalised in Lean 3)</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"c1\">-- Lean 4</span>\n<span class=\"kd\">@[simp]</span> <span class=\"kd\">theorem</span> <span class=\"n\">foo</span> <span class=\"o\">:</span> <span class=\"n\">Nat</span> <span class=\"bp\">=</span> <span class=\"n\">Bool</span> <span class=\"o\">:=</span> <span class=\"gr\">sorry</span>\n\n<span class=\"kd\">example</span> <span class=\"o\">(</span><span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">Nat</span> <span class=\"bp\">=</span> <span class=\"n\">Int</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">Nat</span> <span class=\"bp\">=</span> <span class=\"n\">Fin</span> <span class=\"mi\">37</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span> <span class=\"n\">simp</span>\n  <span class=\"c1\">-- unsolved goals</span>\n  <span class=\"c1\">-- ⊢ Bool = Fin 37</span>\n</code></pre></div>\n<p>take you to <code>Bool = Fin 37</code>, so in both cases the generic simp lemma wins.</p>",
        "id": 314772527,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1670533891
    },
    {
        "content": "<p>The order in which simp applies lemmas with the same priority has always been \"random\", and it has indeed changed between lean 3 and lean 4 as a side effect of the discrimination tree indexing. This will unfortunately break some proofs, because while we try to keep the simp set confluent it isn't always the case, especially if you add your own lemmas to the global simp set. In theory it is possible to have a linter detect when a proof would not have gone through if the lemmas were applied in a different order, but I don't know how hard we should be on such proofs if they happen to work</p>",
        "id": 314776426,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1670535276
    },
    {
        "content": "<p>the workaround, when you want to use a non-confluent <code>simp</code>, is to use multiple <code>simp</code> calls with a subset of the lemmas, or use <code>simp_rw</code></p>",
        "id": 314776568,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1670535337
    },
    {
        "content": "<p>A variant workaround: I identified the <code>bad_lemma</code> which was taking priority in Lean 4 and removed it from the simp set with <code>simp [...., -bad_lemma]</code>.</p>",
        "id": 314777019,
        "sender_full_name": "Heather Macbeth",
        "timestamp": 1670535528
    },
    {
        "content": "<p>But was the bad lemma making <code>simp</code> non-confluent? Is there a way of instead adding a new lemma to make <code>simp</code> confluent again?</p>",
        "id": 314777746,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1670535850
    },
    {
        "content": "<p>that depends</p>",
        "id": 314777833,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1670535903
    },
    {
        "content": "<p>in your example (did you mean to use <code>simp [h]</code> there?) it's clearly non-confluent</p>",
        "id": 314777914,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1670535942
    },
    {
        "content": "<p>In heather's example, you can add <code>ha</code> to the simp set to make it to the end</p>",
        "id": 314778411,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1670536118
    },
    {
        "content": "<p>And yes, Heather's example is non-confluent. This is basically always the case if removing a lemma causes simp to succeed where it didn't before</p>",
        "id": 314778783,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1670536276
    },
    {
        "content": "<p>Since the upshot of this discussion is \"expected behaviour, wontfix\" I have added a mention of non-confluent simps to the porting wiki.</p>",
        "id": 314899777,
        "sender_full_name": "Heather Macbeth",
        "timestamp": 1670594189
    }
]