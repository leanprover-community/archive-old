[
    {
        "content": "<p>Hey, been experimenting with a new toy: lists you construct from the top down :)</p>\n<p>It's a relatively simple FFI external object, just stores the <code>lean_object*</code> representing the head of an expression, and a pointer to a \"hole\" that needs to be filled to complete the expression. So we can write stuff like</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"k\">#eval</span> <span class=\"n\">Hole.hole</span> <span class=\"o\">()</span>\n      <span class=\"bp\">|&gt;.</span><span class=\"n\">cons</span> <span class=\"mi\">5</span>\n      <span class=\"bp\">|&gt;.</span><span class=\"n\">cons</span> <span class=\"mi\">7</span>\n      <span class=\"bp\">|&gt;.</span><span class=\"n\">cons</span> <span class=\"mi\">10</span>\n      <span class=\"bp\">|&gt;.</span><span class=\"n\">fill</span> <span class=\"o\">[]</span>\n</code></pre></div>\n<p>This snippet generates 0 closures, and the last <code>fill []</code> call is O(1) rather than O(n) :D</p>\n<p>Should be useful for writing tail-rec functions that return lists, to avoid the extra <code>reverse</code> at the end where possible. I'll try to write something like <code>append</code> and see if there's a measurable difference compared to the standard implementation.</p>\n<p>Lean: <a href=\"https://github.com/JamesGallicchio/LeanColls/blob/main/LeanColls/Hole.lean\">https://github.com/JamesGallicchio/LeanColls/blob/main/LeanColls/Hole.lean</a><br>\nC: <a href=\"https://github.com/JamesGallicchio/LeanColls/blob/main/bindings/leancolls_hole.c\">https://github.com/JamesGallicchio/LeanColls/blob/main/bindings/leancolls_hole.c</a></p>",
        "id": 302588048,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1665036726
    },
    {
        "content": "<p>(Sharing this here because we were discussing a couple days ago whether List function impls might be faster if they use arrays instead of constructing a reversed list and reversing it at the end -- this avoids any extra cost and I think should just be faster than either solution)</p>",
        "id": 302588118,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1665036799
    },
    {
        "content": "<p>The performance is much worse than doing two traversals -- I'm thinking something is wrong with how my FFI code is building cons nodes. It seems to be spending a ton of time on calls to lean_* functions that I presume I am using incorrectly:<br>\n<a href=\"/user_uploads/3121/Jf4HcHmhJxCHAfWr0By1jzxq/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/Jf4HcHmhJxCHAfWr0By1jzxq/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/Jf4HcHmhJxCHAfWr0By1jzxq/image.png\"></a></div><p>Does anyone know better than I do how these functions are intended to be used?</p>",
        "id": 302708511,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1665078698
    },
    {
        "content": "<p>In particular I'm very unsure what all the <code>lean_align</code> stuff is doing</p>",
        "id": 302708634,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1665078730
    },
    {
        "content": "<p>(alternatively, the overhead of external functions and more cache misses might just be very high here, but I want to think that's not the case)</p>",
        "id": 302709415,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1665078988
    },
    {
        "content": "<p>These stack frames shouldn't even exist I think unless you compiled your code without optimizations</p>",
        "id": 302711891,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1665079726
    },
    {
        "content": "<p>You know, I'm not sure why I assumed lake would add the <code>-O3</code> flag automatically... The stackframes are all gone, and now the hole version is measurably faster than the revappend version :D</p>",
        "id": 302712914,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1665080041
    },
    {
        "content": "<p>Looks like spends ~36% less cycles if you do not include the reference counting, ~29% less cycles if you do include reference counting. If the input list is unshared, the revappend version might be faster because of the savings on reference counting; let me test that</p>",
        "id": 302713719,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1665080291
    },
    {
        "content": "<p>How do you get this nice profiling plot?</p>",
        "id": 302726365,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1665084840
    },
    {
        "content": "<p>Hotspot! It's a basic frontend for perf, Leo recommended it and it's been a lifesaver</p>",
        "id": 302735487,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1665088391
    },
    {
        "content": "<p><a href=\"/user_uploads/3121/AELDTA9TjGv2JQTfIpD8TtSu/Screenshot_20221006_222726.png\">Screenshot_20221006_222726.png</a> more pretty plots :) I'm not entirely sure how to interpret this one, in particular why the leancolls version is hitting so many more <code>lean_alloc_small_cold</code> calls than the lean version</p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/AELDTA9TjGv2JQTfIpD8TtSu/Screenshot_20221006_222726.png\" title=\"Screenshot_20221006_222726.png\"><img src=\"/user_uploads/3121/AELDTA9TjGv2JQTfIpD8TtSu/Screenshot_20221006_222726.png\"></a></div>",
        "id": 302772632,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1665110082
    },
    {
        "content": "<p>but that is the subject of further investigation!</p>",
        "id": 302772647,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1665110097
    }
]