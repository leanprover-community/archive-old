[
    {
        "content": "<p>I'm wondering how the search algorithm of GPTF actually works.  See this #general post for more info: <a href=\"#narrow/stream/113488-general/topic/How.20does.20Lean's.20search.20of.20its.20library.20work.3F/near/254319211\">https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/How.20does.20Lean's.20search.20of.20its.20library.20work.3F/near/254319211</a></p>",
        "id": 254322623,
        "sender_full_name": "Daniel Donnelly",
        "timestamp": 1632293430
    },
    {
        "content": "<p>Gptf for lean (it’s a bit different in metamath gptf) doesn’t have an explicit search.  Instead everything is done via sentence completion (aka next token prediction, aka autoregressive language modeling).  If you haven’t already, I encourage you to watch this talk (<a href=\"https://m.youtube.com/watch?v=EXpmbAfBNnw\">https://m.youtube.com/watch?v=EXpmbAfBNnw</a>).  Specifically, I explain how this works in the next few slides after the demo.  (I made a small mistake.  I said we do breadth first search.  We actually do best first search.). If that makes sense and the you want to learn how a transformer works, see the neural conjecturing topic in <a class=\"stream\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving\">#Machine Learning for Theorem Proving</a> for some good videos and tutorials.</p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"EXpmbAfBNnw\" href=\"https://m.youtube.com/watch?v=EXpmbAfBNnw\"><img src=\"https://uploads.zulipusercontent.net/bd2a9c6a819c867efb19ea439f4a113b891f5dae/68747470733a2f2f692e7974696d672e636f6d2f76692f4558706d624166424e6e772f64656661756c742e6a7067\"></a></div>",
        "id": 254348130,
        "sender_full_name": "Jason Rute",
        "timestamp": 1632307984
    },
    {
        "content": "<p>Also, if you want to know “exactly” there is always the paper: <a href=\"https://arxiv.org/pdf/2102.06203.pdf\">https://arxiv.org/pdf/2102.06203.pdf</a></p>",
        "id": 254348186,
        "sender_full_name": "Jason Rute",
        "timestamp": 1632308040
    },
    {
        "content": "<p>When I said we don’t have an explicit search, I mean we don’t have an explicit search that searches through the lean library.  (To anthropomorphize, lean gptf memorizes all of mathlib.)  So the lean-gptf tool doesn’t use any form of search it just “dreams” up a dozen or so next steps and filters out those that don’t immediately fail.  Now, in the paper we also test whether lean gptf can find whole proofs.  Finding a proof is a type of tree (or graph) search where the nodes are the tactic states and the edges are the tactics.  As I said above, for that we use best first search.</p>",
        "id": 254349954,
        "sender_full_name": "Jason Rute",
        "timestamp": 1632309141
    }
]