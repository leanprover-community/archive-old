[
    {
        "content": "<p>Hi -- naive question perhaps, but how does/did gpt-f learn what constitutes a simpler proof than another? Or more specifically, what made it produce this: <a href=\"https://github.com/leanprover-community/mathlib/pull/5903/files\">https://github.com/leanprover-community/mathlib/pull/5903/files</a> -- is it explicitly trained that <code>rw</code> is a simpler tactic than <code>simp</code> even though in terms of number of characters that's longer?</p>",
        "id": 224620750,
        "sender_full_name": "Julian Berman",
        "timestamp": 1612065682
    },
    {
        "content": "<p>The comments on the last few gpt-f PR's suggest that it's using the length of <code>pp.all</code> output</p>",
        "id": 224620819,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1612065814
    },
    {
        "content": "<p>A ha.</p>",
        "id": 224620866,
        "sender_full_name": "Julian Berman",
        "timestamp": 1612065844
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/274007-lean-gptf/topic/simplicity/near/224620819\">said</a>:</p>\n<blockquote>\n<p>The comments on the last few gpt-f PR's suggest that it's using the length of <code>pp.all</code> output</p>\n</blockquote>\n<p>it is just the length of <code>format.to_string &lt;$&gt; format.flatten &lt;$&gt; tactic.pp $PROOF_TERM</code> with default pretty-printing settings --- they get an order of magnitude larger with <code>pp.all</code> enabled</p>",
        "id": 224621833,
        "sender_full_name": "Jesse Michael Han",
        "timestamp": 1612067656
    },
    {
        "content": "<p>But it's not trained to output short proofs , is that right? It just happens to find shorter ones sometimes?</p>",
        "id": 224621912,
        "sender_full_name": "Alex J. Best",
        "timestamp": 1612067779
    },
    {
        "content": "<p>correct, it's not explicitly trained to produce short proofs, nor do we optimize the data collection process in any way for this --- it just tries to predict what it thinks is the most likely tactic for a given tactic state, based on the training data (tactic steps in mathlib)</p>",
        "id": 224622014,
        "sender_full_name": "Jesse Michael Han",
        "timestamp": 1612067930
    },
    {
        "content": "<p>we determined which proofs were shorter with another script which replays the proofs found by <code>gptf</code> and compares the proof term to the one already in the environment.</p>",
        "id": 224622117,
        "sender_full_name": "Jesse Michael Han",
        "timestamp": 1612068082
    },
    {
        "content": "<p>Makes sense, thanks! Nonetheless I suppose, during training did it get to see multiple proofs of the same thing at all?</p>",
        "id": 224646759,
        "sender_full_name": "Julian Berman",
        "timestamp": 1612102459
    },
    {
        "content": "<p>probably --- remember, its training data is precisely what you see when you step through a tactic proof in <code>mathlib</code>, so for example, it's probably seen <code>false</code> proven from <code>Q</code> and <code>not Q</code> (and other extraneous hypotheses in the context) using <code>contradiction</code>, <code>exact absurd h1 h2</code>, <code>tauto</code>, <code>finish</code>...</p>\n<p>we can check this rigorously, but later---our attention is occupied with some other experiments at the moment.</p>",
        "id": 224649310,
        "sender_full_name": "Jesse Michael Han",
        "timestamp": 1612106244
    }
]