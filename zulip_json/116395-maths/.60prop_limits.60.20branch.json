[
    {
        "content": "<p>I'm trying to get my head around the <code>has_limits</code> issue. I'm sorry if I'm just repeating what people have said already.</p>\n<hr>\n<p>A few weeks ago I was trolling constructivists on Twitter and I met someone who claimed that the definition of being Hausdorff was not a predicate on topological spaces, it was in fact an extra structure on a topological space, that of a function which takes as input two distinct points of the space and outputs two disjoint open subsets. In the presence of AC, these two definitions are the same, but constructively the extra structure (the function) is more powerful than the predicate. It also screws up your definition of equality -- if I choose two different functions, then are the corresponding Hausdorff spaces equal? This is not a question I am interested in because I believe in AC, but it could be used as an argument against the extra structure being part of the definition. In mathlib we have the predicate.</p>\n<p>An example in mathlib where we go the other way is fields. We could define a field to be a non-zero commutative ring where every non-zero element has an inverse, but in this case we actually demand the extra <code>inv</code> structure as part of the data. Different <code>inv</code>s will be equal, but perhaps not defeq, and this causes a bit of tension if you want to prove things like \"R/I is a field iff I is maximal\" -- here it's natural to use the predicate <code>is_field</code>, but we don't, and the moment I start making fields using <code>is_field</code> and then using AC to construct <code>inv</code> for me I might be looking at diamond issues down the line. If I understand correctly, the standard 2nd year UG result \"R/I is a field iff I is maximal\" is not actually stated in mathlib, perhaps because nobody knows how to state it? I wrote <code>is_field</code> <a href=\"#narrow/stream/113489-new-members/topic/integral.20domain/near/208136781\">here</a> but as you can see from Johan's comments above, he thinks this is a bad idea. One solution to this would be a complete refactor of fields. But it's not clear to me that this is worth it. One could argue similarly that groups shouldn't have an identity or inverse, they should just have a multiplication and some axioms, because the axioms can just be rewritten to say \"there exists an identity such that ...\" and \"there exists an inverse map such that...\" and then one can prove that these things are unique. </p>\n<p>Clearly these questions are complicated. The <code>prop_limits</code> mathlib branch is wrestling with ideas like this but one level up. Lemma 1.2.1 in Johnstone's book \"Sketches of an elephant\" gives several equivalent formulations of what it means for a category to have all finite limits, but then immediately afterwards he points out that actually there is another issue -- do we mean that all finite limits exist, or are we given an actual function which takes as input any finite diagram and spits out an actual explicit limit (or more precisely, a limit cone)? It's just like the Hausdorff space question -- is \"all finite limits exist\" a predicate on a category, or extra structure which one can put on a category? And in this case, two different choices of extra structure might not be equal -- they would just be isomorphic in the sense that they would be two functions F and G such that F(D) was isomorphic to G(D) in some \"canonical\" way for each diagram D. \"Isomorphic but not equal\" is really \"one kind of equality, but not another kind\", like potential <code>inv</code> issues that will arise with <code>is_field</code> -- one might get <code>inv</code>s which are equal because of functional extensionality, but not definitionally equal (and we care because field is a class so defeq is important). </p>\n<p>After the lemma, Johnstone goes on to <em>explicitly state</em> that in his book, when he says that C has finite limits, he means that C is equipped with a choice of limit cone for every finite diagram. </p>\n<p>Talking to Reid about this idea a bit, I can see that actually in practice this is kind of super-strong (much too strong?), in the sense that it might not even be happening naturally for concrete categories we know about. Those that can guess the kinds of statements we see in 1.2.1 will be unsurprised to see that one of the conditions is \"C has a terminal object and pullbacks of pairs\". But choosing a terminal object and pullbacks of all pairs is a long way from choosing all finite limits! You still have to choose whether A x B x C means (A x B) x C or A x (B x C) for example. Actually making such choices once and for all seems very mathematically unnatural to me, like actually making the choice of the open set generator function which will be a witness to the proof that a space is Hausdorff kind of sounds like overkill -- it is extra structure which is not relevant to the idea at hand. In fact Johnstone almost immediately gets into trouble with his definition. Say C and D have all finite limits in this constructive sense. Johnstone calls a functor from C to D <em>cartesian</em> if it \"preserves this structure (but only in the 'up-to-isomorphism' sense; it is clearly unreasonable to expect that we can make a canonical choice of limits in C and D...\" etc etc. Johnstone then goes on to claim that the category of all sets has all finite products and his justification is that he'll use {empty set} to be the terminal object, cartesian product gives binary products, subsets give us equalizers, and now invoke 1.2.1. That ain't enough! What is A x B x C? He doesn't say.</p>\n<p>However, if one now goes on to read more of Johnstone's book, one discovers that his definition of an elementary topos (i.e. what he calls a topos) really does require this extra structure. Johnstone regards the choice of a limit cone for all finite diagrams as part of the data of a topos. Now I will be the first to admit that I know <em>absolutely nothing</em> about elementary toposes, and I am slightly unclear about whether they will ever be of any use to me as a number theorist, but having ploughed through some parts of Johnstone's book I do think that this is the definition. <span class=\"user-mention\" data-user-id=\"246273\">@Bhavik Mehta</span> pointed this out to me. Bhavik also points out that the <code>prop_limits</code> branch is coming, and this branch changes the definition of <code>has_limit</code> to a Prop. This does seem to be the mathematically reasonable definition, but an argument against this change is that it now makes it much harder to actually write down Johnstone's definition of a topos. Is this what we want? One can write down a definition which is equivalent to Johnstone's definition using AC. But Bhavik has been explaining to me that with Johnstone's \"constructive\" definition, one can now go on and give AC-free proofs of things like the monadicity theorem and the adjoint functor theorem (I don't know what at least one of these theorems says, by the way). The question is whether we care. It seems that the changes distort Johnstone's vision of the theory in some way.</p>",
        "id": 208454113,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1598735392
    },
    {
        "content": "<blockquote>\n<p>One could argue similarly that groups shouldn't have an identity or inverse, they should just have a multiplication and some axioms, because the axioms can just be rewritten to say \"there exists an identity such that ...\" and \"there exists an inverse map such that...\" and then one can prove that these things are unique. </p>\n</blockquote>\n<p>By the way, this is exactly how things are done in metamath, which takes the \"maximum classical\" approach in most respects because we have unrestricted unique choice. A semigroup/monoid/group is a binary operation with some properties, a ring/division ring/field is two binary operations with some properties. There are function extractors that you use to get the identity of a group and because all groups use this function there is no possibility of coherence problems. Then again, defeq isn't a thing in MM.</p>",
        "id": 208454312,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1598735680
    },
    {
        "content": "<p>I very much dislike the idea of a Hausdorff space being equipped with a \"disjointifier\" function, because it is wildly non-unique. It could be an option if you <code>trunc</code> the relevant \"data\" bits so that you end up with a subsingleton, but then the only difference with the current formulation is Prop vs Type.</p>",
        "id": 208454416,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1598735864
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/116395-maths/topic/.60prop_limits.60.20branch/near/208454113\">said</a>:</p>\n<blockquote>\n<p>In fact Johnstone almost immediately gets into trouble with his definition. Say C and D have all finite limits in this constructive sense. Johnstone calls a functor from C to D <em>cartesian</em> if it \"preserves this structure (but only in the 'up-to-isomorphism' sense; it is clearly unreasonable to expect that we can make a canonical choice of limits in C and D...\" etc etc. </p>\n</blockquote>\n<p>I don't think it's fair to say this is \"trouble\", this is exactly what the current definition of <code>preserves_limits</code> says in mathlib, and any definition of <code>has_limits</code> (ie in Prop or Type) would need to have this property</p>",
        "id": 208454499,
        "sender_full_name": "Bhavik Mehta",
        "timestamp": 1598735999
    },
    {
        "content": "<p>Would it be an option to have <code>has_finite_limits</code> be defined to mean <code>has_initial</code> and <code>has_binary_products</code>?</p>",
        "id": 208454645,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1598736165
    },
    {
        "content": "<p>With this Hausdorff space example, I'd imagine constructivists would still want definitions that are independent of the specific function... if the function is part of the data of a Hausdorff space, you'd need an additional notion of equivalence of such spaces, and it seems the only sensible definition is that it's the underlying spaces are homeomorphic, disregarding the Hausdorff disjointness function.  At that point, you may as well take a the maximal-atlas-like approach and say a Hausdorff space is a topological space along with the nonempty set of all Hausdorff disjointness functions. <br>\n This is essentially the <code>trunc</code> option Mario mentions, I think.</p>",
        "id": 208454655,
        "sender_full_name": "Kyle Miller",
        "timestamp": 1598736183
    },
    {
        "content": "<p>that would be enough to define cartesian functors, by saying that any representation of a list of objects by a tree of products is mapped to any other representation of the mapped list up to isomorphism</p>",
        "id": 208454770,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1598736385
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/116395-maths/topic/.60prop_limits.60.20branch/near/208454645\">said</a>:</p>\n<blockquote>\n<p>Would it be an option to have <code>has_finite_limits</code> be defined to mean <code>has_initial</code> and <code>has_binary_products</code>?</p>\n</blockquote>\n<p>The plan is to make all of these Props, and if this goes through then we don't care what the definition of <code>has_finite_limits</code> is as long as we can prove that it's equivalent to having all finite limits. With the concrete definition this becomes an interesting question though -- <span class=\"user-mention\" data-user-id=\"246273\">@Bhavik Mehta</span> what do you need to make your monadicity/adjoint functor proofs go through?</p>",
        "id": 208455780,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1598737948
    },
    {
        "content": "<p>In what sense? If you mean in terms of axioms, I only used <code>quot.sound</code> and <code>propext</code></p>",
        "id": 208456099,
        "sender_full_name": "Bhavik Mehta",
        "timestamp": 1598738579
    },
    {
        "content": "<p>I mean -- did you really need a choice of limit for all finite diagrams? Or just e.g. binary products?</p>",
        "id": 208456110,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1598738622
    },
    {
        "content": "<p>A choice of colimit for all reflexive pairs</p>",
        "id": 208456115,
        "sender_full_name": "Bhavik Mehta",
        "timestamp": 1598738635
    },
    {
        "content": "<p>For reflexive monadicity, at least</p>",
        "id": 208456153,
        "sender_full_name": "Bhavik Mehta",
        "timestamp": 1598738647
    },
    {
        "content": "<p>I haven't done adjoint functor theorems simply because I didn't need them</p>",
        "id": 208456158,
        "sender_full_name": "Bhavik Mehta",
        "timestamp": 1598738658
    },
    {
        "content": "<p>I think the finiteness part here is misleading though, the discussion is ultimately about whether <code>has_limit</code> is Type-valued or Prop-valued, regardless of the finiteness of the indexing category</p>",
        "id": 208456179,
        "sender_full_name": "Bhavik Mehta",
        "timestamp": 1598738730
    },
    {
        "content": "<p>and the issue seems to be that the definition of a topos in the elephant does actually use the Type-valued variant, despite the fact that there's something quite eccentric about this choice. It reminds me a bit of Lang's approach to Galois theory where he only allows field extensions L/K if K is actually a subset of L, so on occasions when he has a field map K -&gt; L he defines L' to be the disjoint union of K and L \\ (image of K) and puts a field structure on it and uses L'/K instead.</p>",
        "id": 208456428,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1598739127
    },
    {
        "content": "<p>I don't think there are any real issues with the Prop-valued <code>has_finite_limits</code>, but there are some uses that want chosen limits</p>",
        "id": 208458190,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1598741937
    },
    {
        "content": "<p>I don't think that the \"cartesian functor\" example is one of them though</p>",
        "id": 208458200,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1598741967
    },
    {
        "content": "<p>I think the concept of a cartesian functor maximally anti-wants chosen limits.</p>",
        "id": 208458270,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1598742080
    },
    {
        "content": "<p>I disagree, statements about preserving or reflecting or creating limits are usually stated in terms of \"a limit\" rather than \"the limit\"</p>",
        "id": 208458620,
        "sender_full_name": "Bhavik Mehta",
        "timestamp": 1598742623
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span> Thanks for writing that essay! I think it clearly lays out the pros and cons. We somehow find ourselves at crossroads... And I don't know for sure which way to choose.</p>",
        "id": 208583630,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1598891865
    },
    {
        "content": "<p>Mathlib has usually chosen the classical path. But now it's not just intuitionism that is taking \"the other route\".</p>",
        "id": 208583852,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1598891925
    },
    {
        "content": "<p>And I respect Bhavik a lot. He's done a great amount of work with the topos library.</p>",
        "id": 208583915,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1598891947
    },
    {
        "content": "<p>But somehow, it seems that we can't really support both paths.</p>",
        "id": 208583961,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1598891963
    },
    {
        "content": "<p>I personally think that we should go down the Prop approach when developing category theory, because one thing which makes mathlib stand out from the other theorem provers is that we are resolutely classical and this is both encouraging to non-foundational mathematicians (this set includes essentially all the important mathematicians who are making decisions about funding and prizes) and discouraging to the constructivists (who have plenty of other systems to play with, none of which look to me like they'll have an undergraduate degree any time soon). In short my decision is based partly on marketing</p>",
        "id": 208590465,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1598895306
    },
    {
        "content": "<p>As you know from my questions, I am very incompetent on the Lean/programming side of the story, so feel free to disregard this comment.</p>\n<p>I am not sure that I understand the issue with limits, but with the Hausdorff example, I do have a strong view.  For me, the \"correct\" definition is that a topological space is Hausdorff if the diagonal is closed in the self-product.  As a general rule, in maths, I like to think that most issues with AC or weird constructors disappear when making the right definitions.  Isn't there some similar definition for limits that would allow to maintain both approaches?</p>\n<p>I do support the marketing decision, though.  How hard would it be to change the definitions at a later stage?</p>",
        "id": 208593920,
        "sender_full_name": "Damiano Testa",
        "timestamp": 1598897111
    },
    {
        "content": "<p><code>prop_limits</code> is \"changing the definitions at a later stage\" <span aria-label=\"rofl\" class=\"emoji emoji-1f923\" role=\"img\" title=\"rofl\">:rofl:</span></p>",
        "id": 208594482,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1598897368
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"321459\">@Damiano Testa</span> Changing definitions can certainly be done. We do such refactors all the time. But they do require a lot of time and energy</p>",
        "id": 208594632,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1598897436
    },
    {
        "content": "<p>Also, usually they have unanimous support. And in this case, I'm somewhat worried about Bhavik very much disliking the <code>prop_limits</code> side of things</p>",
        "id": 208594715,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1598897481
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"112680\">@Johan Commelin</span> thank you for the reply!</p>\n<p>If I understand correctly Bhavik Mehta's comment, it feels like the issue I have been having recently with <code>is_principal</code> as opposed to being able to make a specific choice of generator.  The result in my case is that I have been unable to use the available <code>is_principal</code> command: I would definitely favour usability over mathematical purity.  But then I do not know what is more usable...  Sorry for creating noise!</p>",
        "id": 208595402,
        "sender_full_name": "Damiano Testa",
        "timestamp": 1598897827
    },
    {
        "content": "<p>It's not noise! You bring a lot of mathematical experience with you. That's certainly valuable.</p>",
        "id": 208595665,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1598897986
    },
    {
        "content": "<p>And I recognise what you say about <code>is_principal</code> and <code>generator</code>. It's currently not as easy to use as we would maybe like.</p>",
        "id": 208595752,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1598898022
    },
    {
        "content": "<p>Thank you for your kind words, but I do feel like I have no idea what I am talking about when it comes to Lean!  Ahaha</p>",
        "id": 208596289,
        "sender_full_name": "Damiano Testa",
        "timestamp": 1598898306
    },
    {
        "content": "<p>You don't understand Lean, you just get used to it. --- von Neumann</p>",
        "id": 208596352,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1598898337
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"321459\">@Damiano Testa</span> the whole concept of a definition is interesting, because it's an area where mathematicians and computer scientists can have quite different opinions. Sometimes we say \"the following ten things are equivalent (blah); we say an object satisfying one or all of them is called a <a href=\"https://en.wikipedia.org/wiki/Discrete_valuation_ring\">discrete valuation ring</a>. The advantage of this approach is that now ten times as many things are \"true by definition\", a proof which we love to give because it saves us from having to do any work.</p>\n<p>In Lean a discrete valuation ring can have precisely one definition, and so then you get 10 theorems of the form \"DVR iff X\". The problem is that it might be a really bad idea letting mathematicians choose which definition to use, because they often gravitate to the most beautiful definition. The computer scientists on the other hand might gravitate towards a definition which has other kinds of good properties, e.g. being easy to compute with or being easy to develop an interface for. Do you know what Lean's definitions of the integers and the rationals are? You might be shocked (write <code>#check int</code> or <code>#check rat</code> and right click to find out). The reason the definition of a continuous map in Lean doesn't mention open sets is precisely because formalisers found that working with filters turned out to be far more convenient -- furthermore, they even found a problem with the Bourbaki definition of a filter, and they changed it to be something more functorial (Lean filters can be pushed forward and pulled back; Bourbaki filters cannot). </p>\n<p>One key thing to remember is that in most cases, it doesn't matter if the definition is something you don't like, because there will be a theorem which says that the definition is equivalent to the thing you do like. For example it's a theorem in Lean that a topological space is compact iff every open cover has a finite subcover. The proof isn't <code>refl</code> but who cares. Similarly, your definition of Hausdorff will be known to be equivalent to Lean's definition, whatever Lean's definition is, so feel free to rewrite. </p>\n<p>What's going on here is more delicate though, because the proposal is to change the definition of e.g. \"I am a category with binary products\" from \"given X and Y, here is X x Y plus a proof that it satisfies the universal property for products\" to \"given X and Y, there exists something satisfying the universal property of products\". Now I believe in the axiom of choice so for me these things are the same -- the proof isn't <code>refl</code> but who cares. But Bhavik seems to be far more concerned about applying the axiom of choice, because one of the standard textbooks on elementary topoi is careful to avoid the axiom of choice at certain stages, and for all I know this is important. A consequence of the change will be that some proofs will become nonconstructive, and then Bhavik will have to work harder to make them constructive again in places where he cares. The reason I've realised I don't care is that if I look at Johnstone 1.2.1 I see a statement of the form \"TFAE: C has all finite limits, C has terminal objects, binary products and equalizers, C has some other stuff, ...\" and as far as I can see the proof is nonconstructive (or perhaps it can be made constructive if one jumps through some hoops and is careful to say what finite means constructively etc etc -- finiteness has several definitions in constructive maths, so in some sense it's not even meaningful to ask whether 1.2.1 can be proved constructively -- it has to be stated constructively first). Johnstone then announces that by \"has finite limits\" he will mean \"comes equipped with a choice of limits\" but then e.g. announces that the category of sets has all finite limits because it comes equipped with a natural terminal object, binary products and equalizers. I would go so far as to say that this was deception. However I do not understand the applications of elementary topoi in logic so I am not able to represent the alternative point of view here -- the one that we are about to make it much harder to work with in Lean.</p>",
        "id": 208655993,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1598947432
    }
]