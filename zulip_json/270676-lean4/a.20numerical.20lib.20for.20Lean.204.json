[
    {
        "content": "<p>Hi everyone! I'm building a lib for Lean 4 called <code>NumLean</code> which allows low level matricial operations. Right now, it's doing this:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kn\">import</span> <span class=\"n\">NumLean</span>\n\n<span class=\"kd\">def</span> <span class=\"n\">main</span> <span class=\"o\">:</span> <span class=\"n\">IO</span> <span class=\"n\">Unit</span> <span class=\"o\">:=</span> <span class=\"k\">do</span>\n  <span class=\"k\">let</span> <span class=\"n\">id</span> <span class=\"bp\">←</span> <span class=\"n\">NLMatrix.id</span> <span class=\"mi\">5</span>\n  <span class=\"c1\">-- let ones ← NLMatrix.new 5 5 1</span>\n  <span class=\"k\">let</span> <span class=\"n\">t</span> <span class=\"o\">:</span> <span class=\"n\">Tensor</span> <span class=\"bp\">←</span> <span class=\"n\">Tensor.new</span> <span class=\"n\">id</span> <span class=\"bp\">↠</span> <span class=\"n\">plusF</span> <span class=\"mi\">4</span> <span class=\"bp\">↠</span> <span class=\"n\">plusF</span> <span class=\"mi\">6</span><span class=\"bp\">.</span><span class=\"mi\">0</span>\n  <span class=\"k\">let</span> <span class=\"n\">m'</span> <span class=\"o\">:</span> <span class=\"n\">NLMatrix</span> <span class=\"bp\">←</span> <span class=\"n\">t.compute</span>\n  <span class=\"n\">IO.println</span> <span class=\"bp\">$</span> <span class=\"bp\">←</span> <span class=\"n\">m'.toString</span>\n<span class=\"c1\">-- 11.0 10.0 10.0 10.0 10.0</span>\n<span class=\"c1\">-- 10.0 10.0  6.0  6.0  6.0 ← these 6's are bugs</span>\n<span class=\"c1\">-- 10.0 10.0 11.0 10.0 10.0</span>\n<span class=\"c1\">-- 10.0 10.0 10.0 11.0 10.0</span>\n<span class=\"c1\">-- 10.0 10.0 10.0 10.0 11.0</span>\n</code></pre></div>\n<p>The problem is that some memory issue is happening and I can't spot it. The commented output shows some unintended 6's. Would appreciate some help on this one. This is the repo link for those who are interested: <a href=\"https://github.com/arthurpaulino/NumLean\">https://github.com/arthurpaulino/NumLean</a></p>",
        "id": 264233343,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639004331
    },
    {
        "content": "<p>Are you aware of the other efforts around tensor and matrix operations at the moment? <span class=\"user-mention\" data-user-id=\"451983\">@Arthur Paulino</span></p>",
        "id": 264235913,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1639005887
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"395550\">Henrik Böving</span> <a href=\"#narrow/stream/270676-lean4/topic/a.20numerical.20lib.20for.20Lean.204/near/264235913\">said</a>:</p>\n<blockquote>\n<p>Are you aware of the other efforts around tensor and matrix operations at the moment? <span class=\"user-mention silent\" data-user-id=\"451983\">Arthur Paulino</span></p>\n</blockquote>\n<p>Not quite. I'm facing this more like a practice exercise/experiment, as I'm really stretching my brain while thinking in terms of usage design in Lean. I'm also getting to know Lean's FFI better in this process, and this knowledge can be useful to integrate more powerful stuff like CUDA someday.</p>\n<p>I know <span class=\"user-mention\" data-user-id=\"346070\">@Tomas Skrivan</span> has been working on something more high level, but he said that he's not worrying about performance/backend at the moment.</p>\n<p>Do you know other projects around this subject?</p>",
        "id": 264239364,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639008317
    },
    {
        "content": "<p>If I search on GitHub for \"Lean\" and \"matrix\" then filter results related to the Lean language, it shows two results:<br>\n<a href=\"https://github.com/search?l=Lean&amp;q=matrix+lean&amp;type=Repositories\">https://github.com/search?l=Lean&amp;q=matrix+lean&amp;type=Repositories</a></p>",
        "id": 264240168,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639008944
    },
    {
        "content": "<p>Ah, the container thing from <span class=\"user-mention\" data-user-id=\"346070\">@Tomas Skrivan</span> was indeed what I had in mind yes, would be very cool if the more performant API would end up supporting their abstraction though</p>",
        "id": 264240323,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1639009073
    },
    {
        "content": "<p>It can definitely be done, but for now I'm struggling with this (supposedly) simple task because I don't seem to be able to sum floats (doubles actually) to a matrix properly <span aria-label=\"smiley\" class=\"emoji emoji-1f603\" role=\"img\" title=\"smiley\">:smiley:</span></p>",
        "id": 264240562,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639009249
    },
    {
        "content": "<p>Okay this is really strange. Probably a bug.</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">def</span> <span class=\"n\">main</span> <span class=\"o\">:</span> <span class=\"n\">IO</span> <span class=\"n\">Unit</span> <span class=\"o\">:=</span> <span class=\"k\">do</span>\n  <span class=\"k\">let</span> <span class=\"n\">id</span> <span class=\"bp\">←</span> <span class=\"n\">NLMatrix.id</span> <span class=\"mi\">5</span>\n  <span class=\"n\">IO.println</span> <span class=\"bp\">$</span> <span class=\"bp\">←</span> <span class=\"n\">id.toString</span>\n  <span class=\"n\">IO.println</span> <span class=\"s2\">\"-------------------------------\"</span>\n  <span class=\"c1\">-- let ones ← NLMatrix.new 5 5 1</span>\n  <span class=\"k\">let</span> <span class=\"n\">t</span> <span class=\"o\">:</span> <span class=\"n\">Tensor</span> <span class=\"bp\">←</span> <span class=\"n\">Tensor.new</span> <span class=\"n\">id</span> <span class=\"bp\">↠</span> <span class=\"n\">plusF</span> <span class=\"mi\">4</span> <span class=\"bp\">↠</span> <span class=\"n\">plusF</span> <span class=\"mi\">6</span><span class=\"bp\">.</span><span class=\"mi\">0</span>\n  <span class=\"k\">let</span> <span class=\"n\">m'</span> <span class=\"o\">:</span> <span class=\"n\">NLMatrix</span> <span class=\"bp\">←</span> <span class=\"n\">t.compute</span>\n  <span class=\"n\">IO.println</span> <span class=\"bp\">$</span> <span class=\"bp\">←</span> <span class=\"n\">m'.toString</span>\n</code></pre></div>\n<p>Produces:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"mi\">1</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">0</span>\n<span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">1</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">0</span>\n<span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">1</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">0</span>\n<span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">1</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">0</span>\n<span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">1</span><span class=\"bp\">.</span><span class=\"mi\">0</span>\n<span class=\"c1\">-------------------------------</span>\n<span class=\"mi\">11</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span>\n<span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">11</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span>\n<span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">11</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span>\n<span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">11</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span>\n<span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">11</span><span class=\"bp\">.</span><span class=\"mi\">0</span>\n</code></pre></div>\n<p>Which is correct. But the following code:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">def</span> <span class=\"n\">main</span> <span class=\"o\">:</span> <span class=\"n\">IO</span> <span class=\"n\">Unit</span> <span class=\"o\">:=</span> <span class=\"k\">do</span>\n  <span class=\"k\">let</span> <span class=\"n\">id</span> <span class=\"bp\">←</span> <span class=\"n\">NLMatrix.id</span> <span class=\"mi\">5</span>\n  <span class=\"c1\">-- IO.println $ ← id.toString -- this commented line is the only difference</span>\n  <span class=\"n\">IO.println</span> <span class=\"s2\">\"-------------------------------\"</span>\n  <span class=\"c1\">-- let ones ← NLMatrix.new 5 5 1</span>\n  <span class=\"k\">let</span> <span class=\"n\">t</span> <span class=\"o\">:</span> <span class=\"n\">Tensor</span> <span class=\"bp\">←</span> <span class=\"n\">Tensor.new</span> <span class=\"n\">id</span> <span class=\"bp\">↠</span> <span class=\"n\">plusF</span> <span class=\"mi\">4</span> <span class=\"bp\">↠</span> <span class=\"n\">plusF</span> <span class=\"mi\">6</span><span class=\"bp\">.</span><span class=\"mi\">0</span>\n  <span class=\"k\">let</span> <span class=\"n\">m'</span> <span class=\"o\">:</span> <span class=\"n\">NLMatrix</span> <span class=\"bp\">←</span> <span class=\"n\">t.compute</span>\n  <span class=\"n\">IO.println</span> <span class=\"bp\">$</span> <span class=\"bp\">←</span> <span class=\"n\">m'.toString</span>\n</code></pre></div>\n<p>Produces:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"c1\">-------------------------------</span>\n<span class=\"mi\">11</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span>\n<span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">11</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span>\n<span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">11</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span>\n<span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">11</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span>\n<span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"mi\">10</span><span class=\"bp\">.</span><span class=\"mi\">0</span>  <span class=\"mi\">6</span><span class=\"bp\">.</span><span class=\"mi\">0</span>  <span class=\"mi\">6</span><span class=\"bp\">.</span><span class=\"mi\">0</span>\n</code></pre></div>\n<p>Which is incorrect. Any clue what might be happening here?</p>",
        "id": 264249274,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639017201
    },
    {
        "content": "<p>Your pointer arithmetic is wrong here:</p>\n<div class=\"codehilite\" data-code-language=\"C\"><pre><span></span><code><span class=\"n\">internal</span><span class=\"w\"> </span><span class=\"kt\">void</span><span class=\"w\"> </span><span class=\"n\">set_val_</span><span class=\"p\">(</span><span class=\"n\">nl_matrix</span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"n\">m</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"kt\">uint32_t</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"kt\">double</span><span class=\"w\"> </span><span class=\"n\">v</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"o\">*</span><span class=\"p\">(</span><span class=\"n\">m</span><span class=\"o\">-&gt;</span><span class=\"n\">data</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"w\"> </span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"k\">sizeof</span><span class=\"p\">(</span><span class=\"kt\">double</span><span class=\"p\">))</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">v</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"c1\">// this product may overflow</span>\n<span class=\"p\">}</span><span class=\"w\"></span>\n</code></pre></div>\n<p><code>m-&gt;data</code> is already a <code>double*</code> pointer, so advancing by <code>i</code> already skips <code>i</code> doubles. So advancing <code>i * sizeof(double)</code> is double counting</p>",
        "id": 264252677,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1639020848
    },
    {
        "content": "<p>protip: bounds check your pointer accesses</p>",
        "id": 264252729,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1639020921
    },
    {
        "content": "<p>Thank you so much! I'm gonna take a look at it tomorrow <span aria-label=\"pray\" class=\"emoji emoji-1f64f\" role=\"img\" title=\"pray\">:pray:</span></p>",
        "id": 264252763,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639020962
    },
    {
        "content": "<p>is there a reason you aren't just writing <code>m-&gt;data[i] = v</code>?</p>",
        "id": 264252834,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1639021062
    },
    {
        "content": "<p>Not at all. Just rusty pointer arithmetic skills :D</p>",
        "id": 264252973,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639021208
    },
    {
        "content": "<p>No idea why I thought that regular indexing wouldn't work</p>",
        "id": 264252992,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639021233
    },
    {
        "content": "<p>Great! I would be really happy if someone else gets low level API for matrices working, so I don't have to do it :)</p>\n<p>I have also started thinking about this a little bit. And my current plan on how to approach this:</p>\n<ol>\n<li>on CPU just use ByteArray, on GPU write a custom GPUByteArray (that is just a chunk of memory sitting in GPU memory)</li>\n<li>Define class <code>CReflected (X : Type)</code> and <code>GPUReflected (X : Type)</code> that provides functions how to read/write X from/to ByteArray. These functions will be mainly used for consistency and not for performance.</li>\n<li>Define <code>CArray (X : Type)</code> and <code>GPUArray (X : Type)</code> just a warper around ByteArrays making sure the buffer size is multiple of <code>sizeof X</code></li>\n<li>Implement something like <code>CArray.mapIdx (kernel : CExpr (UInt64 -&gt; X -&gt; Y)) (arr : CArray X) : CArray Y</code>. Where <code>CExpr T</code> is a subtype of <code>Lean.Expr</code> that is compilable to the specific target, CPU or GPU. Still not sure how to do this, maybe you have to define a new <code>mapIdx</code> for every <code>kernel</code>, write a custom elaborator that takes a syntax, gets expression, checks if it can be compiled to the specific target, generate code, compile and the define appropriate version of mapIdx with specific 'extern' attribute.</li>\n</ol>",
        "id": 264264989,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639034841
    },
    {
        "content": "<p>For reference, in this <a href=\"#narrow/stream/270676-lean4/topic/Extern.20code.20depending.20on.20function.20argument\">thread</a> I asked if the extern code can depend on function arguments. In this case the code would depend on <code>kernel</code>. It can't and the conclusion is to write custom elaborator that would generate a new <code>mapIdx</code> for every <code>kernel</code>.</p>",
        "id": 264298569,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639055694
    },
    {
        "content": "<p>Also I have some half baked code that defines strucuture <code>Kernel</code> specifying basic elements for a target you want to compile down to, C, cuda, OpenCL ...  These core elements of <code>Kernel</code> are:</p>\n<ol>\n<li>ByteArray type</li>\n<li>internal types like <code>float</code> <code>double</code> <code>int</code> ... and pointers to const data <code>float const*</code></li>\n<li>internal n-ary functions  like <code>float fadd(float a, float b)</code>, or 0-ary function like <code>nulltpr</code></li>\n</ol>",
        "id": 264299969,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639056324
    },
    {
        "content": "<p>The definition of <code>Kernel</code>:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">structure</span> <span class=\"n\">Kernel</span> <span class=\"n\">where</span>\n  <span class=\"n\">KByteArray</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span>\n  <span class=\"n\">byteArraySize</span> <span class=\"o\">:</span> <span class=\"n\">KByteArray</span> <span class=\"bp\">→</span> <span class=\"n\">Nat</span>\n  <span class=\"n\">byteArrayRead</span> <span class=\"o\">:</span> <span class=\"o\">(</span><span class=\"n\">arr</span> <span class=\"o\">:</span> <span class=\"n\">KByteArray</span><span class=\"o\">)</span> <span class=\"bp\">→</span> <span class=\"o\">(</span><span class=\"n\">i</span> <span class=\"o\">:</span> <span class=\"n\">Fin</span> <span class=\"o\">(</span><span class=\"n\">byteArraySize</span> <span class=\"n\">arr</span><span class=\"o\">))</span> <span class=\"bp\">→</span> <span class=\"n\">UInt8</span>\n  <span class=\"n\">malloc</span> <span class=\"o\">:</span> <span class=\"o\">(</span><span class=\"n\">size</span> <span class=\"o\">:</span> <span class=\"n\">Nat</span><span class=\"o\">)</span> <span class=\"bp\">→</span> <span class=\"n\">KByteArray</span>\n  <span class=\"n\">malloc_size</span> <span class=\"o\">:</span> <span class=\"bp\">∀</span> <span class=\"n\">n</span><span class=\"o\">,</span> <span class=\"n\">byteArraySize</span> <span class=\"o\">(</span><span class=\"n\">malloc</span> <span class=\"n\">n</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">n</span>\n\n  <span class=\"n\">KType</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span>\n  <span class=\"n\">void</span> <span class=\"o\">:</span> <span class=\"n\">KType</span>\n  <span class=\"n\">ptr</span> <span class=\"o\">:</span> <span class=\"n\">KType</span> <span class=\"bp\">→</span> <span class=\"n\">KType</span>       <span class=\"c1\">-- internal way to talk about buffers</span>\n  <span class=\"n\">typeDec</span> <span class=\"o\">:</span> <span class=\"n\">DecidableEq</span> <span class=\"n\">KType</span>\n  <span class=\"n\">typeName</span> <span class=\"o\">:</span> <span class=\"n\">KType</span> <span class=\"bp\">→</span> <span class=\"n\">String</span>\n  <span class=\"n\">typeSize</span> <span class=\"o\">:</span> <span class=\"n\">KType</span> <span class=\"bp\">→</span> <span class=\"n\">Nat</span>    <span class=\"c1\">-- size in bytes</span>\n\n  <span class=\"n\">KFun</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span>\n  <span class=\"n\">funDec</span> <span class=\"o\">:</span> <span class=\"n\">DecidableEq</span> <span class=\"n\">KFun</span>\n  <span class=\"n\">funName</span> <span class=\"o\">:</span> <span class=\"n\">KFun</span> <span class=\"bp\">→</span> <span class=\"n\">String</span>\n  <span class=\"n\">funArgTypes</span> <span class=\"o\">:</span> <span class=\"n\">KFun</span> <span class=\"bp\">→</span> <span class=\"n\">Array</span> <span class=\"n\">KType</span>\n  <span class=\"n\">funOutType</span>  <span class=\"o\">:</span> <span class=\"n\">KFun</span> <span class=\"bp\">→</span> <span class=\"n\">KType</span>\n\n  <span class=\"n\">null</span> <span class=\"o\">:</span> <span class=\"n\">KFun</span>\n  <span class=\"n\">null_is_ptr</span>   <span class=\"o\">:</span> <span class=\"n\">funOutType</span> <span class=\"n\">null</span> <span class=\"bp\">=</span> <span class=\"n\">ptr</span> <span class=\"n\">void</span>\n  <span class=\"n\">null_is_const</span> <span class=\"o\">:</span> <span class=\"o\">(</span><span class=\"n\">funArgTypes</span> <span class=\"n\">null</span><span class=\"o\">)</span><span class=\"bp\">.</span><span class=\"n\">size</span> <span class=\"bp\">=</span> <span class=\"mi\">0</span>\n\n  <span class=\"c1\">-- Execute a function</span>\n  <span class=\"c1\">-- Stack all inputs in the order into a byte array and produce output</span>\n  <span class=\"c1\">-- This form is mainly used to prove stuff and provide basic runtime</span>\n  <span class=\"c1\">-- However it is not designed for speed!</span>\n  <span class=\"n\">execute</span> <span class=\"o\">:</span> <span class=\"n\">KFun</span> <span class=\"bp\">→</span> <span class=\"n\">KByteArray</span> <span class=\"bp\">→</span> <span class=\"n\">KByteArray</span>\n  <span class=\"c1\">-- Just to make sure the output has the right size</span>\n  <span class=\"n\">execute_otput</span> <span class=\"o\">:</span> <span class=\"bp\">∀</span> <span class=\"n\">f</span> <span class=\"n\">input</span><span class=\"o\">,</span> <span class=\"n\">byteArraySize</span> <span class=\"o\">(</span><span class=\"n\">execute</span> <span class=\"n\">f</span> <span class=\"n\">input</span><span class=\"o\">)</span> <span class=\"bp\">=</span> <span class=\"n\">typeSize</span> <span class=\"o\">(</span><span class=\"n\">funOutType</span> <span class=\"n\">f</span><span class=\"o\">)</span>\n</code></pre></div>",
        "id": 264300038,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639056353
    },
    {
        "content": "<p>Then expression for a specific kernel <code>KExpr</code> is just a subset of <code>Lean.Expr</code>. It is assume that the target is not functional programming language so there is no lambda abstraction. However each expression can have bound variables such that as a whole it can be treated as a function.</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code>  <span class=\"kd\">inductive</span> <span class=\"n\">KExpr</span> <span class=\"o\">(</span><span class=\"n\">k</span> <span class=\"o\">:</span> <span class=\"n\">Kernel</span><span class=\"o\">)</span> <span class=\"n\">where</span>\n    <span class=\"bp\">|</span> <span class=\"n\">bvar</span>  <span class=\"o\">:</span> <span class=\"o\">(</span><span class=\"n\">i</span> <span class=\"o\">:</span> <span class=\"n\">Nat</span><span class=\"o\">)</span> <span class=\"bp\">→</span> <span class=\"n\">KExpr</span> <span class=\"n\">k</span>\n    <span class=\"bp\">|</span> <span class=\"n\">const</span> <span class=\"o\">:</span> <span class=\"o\">(</span><span class=\"n\">f</span> <span class=\"o\">:</span> <span class=\"n\">KFun</span> <span class=\"n\">k</span><span class=\"o\">)</span> <span class=\"bp\">→</span> <span class=\"n\">KExpr</span> <span class=\"n\">k</span>\n    <span class=\"bp\">|</span> <span class=\"n\">app</span>   <span class=\"o\">:</span> <span class=\"o\">(</span><span class=\"n\">f</span> <span class=\"o\">:</span> <span class=\"n\">KExpr</span> <span class=\"n\">k</span><span class=\"o\">)</span> <span class=\"bp\">→</span> <span class=\"o\">(</span><span class=\"n\">arg</span> <span class=\"o\">:</span> <span class=\"n\">KExpr</span> <span class=\"n\">k</span><span class=\"o\">)</span> <span class=\"bp\">→</span> <span class=\"n\">KExpr</span> <span class=\"n\">k</span>\n</code></pre></div>",
        "id": 264300476,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639056543
    },
    {
        "content": "<p>To communicate between Lean types and <code>KType</code> there is  a class <code>ReflectedType</code></p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code>  <span class=\"kd\">class</span> <span class=\"n\">ReflectedType</span> <span class=\"o\">(</span><span class=\"n\">k</span> <span class=\"o\">:</span> <span class=\"n\">Kernel</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">α</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span><span class=\"o\">)</span> <span class=\"kd\">extends</span> <span class=\"n\">Inhabited</span> <span class=\"n\">α</span> <span class=\"n\">where</span>\n    <span class=\"n\">t</span> <span class=\"o\">:</span> <span class=\"n\">KType</span> <span class=\"n\">k</span>\n    <span class=\"n\">readBytes</span>  <span class=\"o\">:</span> <span class=\"o\">(</span><span class=\"n\">KBuffer</span> <span class=\"n\">k</span> <span class=\"n\">t.sizeof</span><span class=\"o\">)</span> <span class=\"bp\">→</span> <span class=\"n\">α</span>\n    <span class=\"n\">writeBytes</span> <span class=\"o\">:</span> <span class=\"o\">(</span><span class=\"n\">KBuffer</span> <span class=\"n\">k</span> <span class=\"n\">t.sizeof</span><span class=\"o\">)</span> <span class=\"bp\">→</span> <span class=\"n\">α</span> <span class=\"bp\">→</span> <span class=\"n\">KByteArray</span> <span class=\"n\">k</span>\n    <span class=\"c1\">--- and some compatibility statements between read and write</span>\n</code></pre></div>\n<p>that allows you to read and write Lean types from/to <code>KByteArray</code> and <code>(KBuffer k t.sizeof)</code> is just a <code>KByteArray</code> that has at least <code>t.sizeof</code> bytes.</p>",
        "id": 264300976,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639056765
    },
    {
        "content": "<p>Now I would be interested how to write a custom elaborator that for example transforms <code>fun x : Float =&gt; 3*x + sin(x)</code> to the appropriate <code>kernel : KExpr</code> and generates code for <code>CArray.map kernel</code></p>",
        "id": 264301512,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639056995
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span> You really spotted the root cause of the issues. It works nicely now! <span aria-label=\"tada\" class=\"emoji emoji-1f389\" role=\"img\" title=\"tada\">:tada:</span></p>",
        "id": 264308596,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639060053
    },
    {
        "content": "<p>Also <a href=\"https://github.com/dselsam/certigrad\">certigrad</a> did some bindings to Eigen. It is in Lean 3, but maybe some inspiration can be taken from there. I have never studied the source code though.</p>",
        "id": 264309354,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639060351
    },
    {
        "content": "<p>Hm, let me explain what I'm trying to do and then you can tell me the flaws and holes in my approach. I think this will help me better understand what you're aiming for.</p>\n<p>I've created a package that can perform matrix operations in C from Lean 4. Matrix instantiation, transposing, addition/multiplication with scalars and other matrices. In this package, I also coded a <code>Tensor</code>, which is an abstraction for concatenating matrix operations. A tensor also has a matrix in the head and a list of operations. Then when you call <code>Tensor.compute</code> it checks dimensions consistency across operations and if everything is fine then it performs the operations, returning a <code>NLMatrix</code></p>",
        "id": 264311073,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639061088
    },
    {
        "content": "<p>It happens <a href=\"https://github.com/arthurpaulino/NumLean/blob/f8eef11fb8ef60660edaef4eb45e00975ea45c44/lib/NumLean.lean#L155\">here</a></p>",
        "id": 264311268,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639061172
    },
    {
        "content": "<p>I think you approach is fine, it is just involves too much custom C code for my liking. I want to as little work in C as possible. Also, I want to take the \"expression template\" approach to get as much speed as possible. This requires compiling a new C function for each expression, which is infeasible to do by hand and some automation is required.</p>",
        "id": 264312415,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639061734
    },
    {
        "content": "<p>Can you show me some exemplary use cases for the API you want to provide?</p>",
        "id": 264312628,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639061842
    },
    {
        "content": "<p>Maybe something like this:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">def</span> <span class=\"n\">saxpy</span> <span class=\"o\">(</span><span class=\"n\">s</span> <span class=\"o\">:</span> <span class=\"n\">Float</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">x</span> <span class=\"n\">y</span> <span class=\"o\">:</span> <span class=\"n\">Vector</span><span class=\"o\">)</span> <span class=\"o\">:=</span> <span class=\"n\">Vector.map2Idx</span> <span class=\"o\">(</span><span class=\"n\">compile</span> <span class=\"o\">(</span><span class=\"k\">fun</span> <span class=\"n\">xi</span> <span class=\"n\">i</span> <span class=\"n\">y'</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">s</span><span class=\"bp\">*</span><span class=\"n\">xi</span> <span class=\"bp\">+</span> <span class=\"n\">y'</span><span class=\"o\">[</span><span class=\"n\">i</span><span class=\"o\">]))</span> <span class=\"n\">x</span> <span class=\"n\">y</span>\n</code></pre></div>\n<p>where <code>Vector</code> is just a wrapper around <code>ByteArray</code>on a specific target(e.g. CPU or GPU). The <code>(compile  expr)</code> has to be a macro/custom elaborator that compiles and expression to some kernel function that holds pointer to linked shared library. The function <code>Vector.map2Idx</code> has signature  <code>Vector.map2Idx (k : CompiledKernel) (vectorToMutate : Vector) (vectorToRefer : Vector) : Vector</code></p>\n<p>Then I would also write a custom macro <code>optimize</code> that would turn <code>optimize (s*x+y)</code> to <code>Vector.map2Idx (compile (fun xi i y' =&gt; s*xi + y'[i])) x y</code></p>",
        "id": 264314184,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639062513
    },
    {
        "content": "<p>My high level tensor interface aready turns <code>saxpy s x y</code> to  <code>intro (λ i =&gt; s*x[i] + y[i])</code> (<a href=\"https://github.com/lecopivo/mathlib4/blob/87ac4014b04b955f37392c0ce65b3344042e0a36/Mathlib/Data/Table/Basic.lean#L439\">code</a>). It is half way there, I just do not know how to decide whether <code>x</code> or <code>y</code> should be mutated in place and turn <code>intro (λ i =&gt; s*x[i] + y[i])</code> to <code>x.mapIdx  (λ xi i =&gt; s*xi + y[i])</code> or  <code>y.mapIdx  (λ yi i =&gt; s*x[i] + yi)</code>. You don't really have access to reference counts of <code>x</code> or <code>y</code> to make this decision automatically, so I'm not sure what to do.</p>",
        "id": 264315143,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639062946
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"451983\">@Arthur Paulino</span> Why are your operations on matrices inside of <code>IO</code> monad?</p>",
        "id": 264315460,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639063072
    },
    {
        "content": "<p>I've just updated the code, let's use <a href=\"https://github.com/arthurpaulino/NumLean/tree/5269b16547df31b95ea08d0b9623e9fececcfd57\">this version</a> for reference</p>",
        "id": 264316016,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639063313
    },
    {
        "content": "<p>Ohh I think your <code>Tensor</code> is something what I call \"expression template\". It is just some representation of  operations on matrices. I find the name <code>Tensor</code> super confusing.</p>",
        "id": 264316309,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639063438
    },
    {
        "content": "<p>I put everything inside <code>IO</code> monad because code could break in C in previous versions. But now that I'm checking for consistency before running the computations I guess I don't need to do that anymore</p>",
        "id": 264316503,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639063513
    },
    {
        "content": "<p>Because now I can assume that, for instance, matrix A and B are of same dimensions when I sum them in C</p>",
        "id": 264316612,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639063553
    },
    {
        "content": "<p>The whole beauty of Lean and dependent types is exactly that you can have dimensions of matrices in types, so you can't accidentally add or multiply matrices with incorrect dimensions.</p>",
        "id": 264316814,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639063627
    },
    {
        "content": "<p>Also the type <code>NLMatrix</code> just cant form a vector space. You need dimensions in the type. And if <code>NLMatrix</code> can't be a vector space then I don't see the point in using Lean.</p>",
        "id": 264317030,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639063706
    },
    {
        "content": "<p>But of course, you can just create a subtype of <code>NLMatrix</code> that has a proof about dimensions :)</p>",
        "id": 264317150,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639063764
    },
    {
        "content": "<p>Right, my code is currently limited to <code>R²</code>. First, I wanted to make sure I would be able to make the data pipeline work back and forth (Lean -&gt; C -&gt; Lean)</p>",
        "id": 264317598,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639063978
    },
    {
        "content": "<p>And maaan, did I learn in the process <span aria-label=\"smiley\" class=\"emoji emoji-1f603\" role=\"img\" title=\"smiley\">:smiley:</span></p>",
        "id": 264317651,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639064002
    },
    {
        "content": "<p>And huge thanks for figuring it out! I was scared of that and didn't attempt doing so yet <span aria-label=\"grinning face with smiling eyes\" class=\"emoji emoji-1f601\" role=\"img\" title=\"grinning face with smiling eyes\">:grinning_face_with_smiling_eyes:</span></p>",
        "id": 264317740,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639064040
    },
    {
        "content": "<p>I will be stealing some parts of that setup for sure :)</p>",
        "id": 264317823,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639064059
    },
    {
        "content": "<p>The way that I setup my design is such that Lean has no idea about the dimensions of matrices and always has to ask C for such (although always in <code>R²</code>)</p>",
        "id": 264318259,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639064222
    },
    {
        "content": "<p>So the low level implementation is the real owner of the data</p>",
        "id": 264318339,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639064256
    },
    {
        "content": "<p>Your approach is better and more mature, in which Lean dictates the rules and then the low level implementation has to accommodate for what's being requested by the user</p>",
        "id": 264318556,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639064344
    },
    {
        "content": "<p>BTW your setup is pushing <code>~</code> files to GitHub like <a href=\"https://github.com/lecopivo/mathlib4/blob/master/Mathlib/Data/Table/Basic.lean~\">this</a> and <a href=\"https://github.com/lecopivo/mathlib4/blob/master/Mathlib/Data/Table/Common.lean~\">this</a>, just in case you haven't noticed</p>",
        "id": 264320010,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639064927
    },
    {
        "content": "<p>I feel like taking your approach can get really ugly really fast. Do you pick row major or column major matrices? How are you going to deal with symmetric, anti-symmetric, diagonal, block matrices? Do you want to write custom C code for every type? And custom code for every pair-wise interaction?</p>",
        "id": 264320146,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639064992
    },
    {
        "content": "<blockquote>\n<p>BTW your setup is pushing ~ files to GitHub like this and this, just in case you haven't noticed</p>\n</blockquote>\n<p>Yeah sometime I accidentally do that :( I would add <code>*~</code> to gitignore</p>",
        "id": 264320263,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639065022
    },
    {
        "content": "<p>fixed <span aria-label=\"wink\" class=\"emoji emoji-1f609\" role=\"img\" title=\"wink\">:wink:</span></p>",
        "id": 264320476,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639065119
    },
    {
        "content": "<p>Anyway I do not want to completely detract you from your approach, I would be actually quite interested how far you can get. What will work well and what won't.</p>",
        "id": 264320684,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639065198
    },
    {
        "content": "<p>The raw data is just an <a href=\"https://github.com/arthurpaulino/NumLean/blob/5269b16547df31b95ea08d0b9623e9fececcfd57/cpp/ffi.cpp#L23\">array of doubles</a> (in contrast to arrays of arrays of doubles). I started this simple because I thought it would be easier to plug in CUDA or some other lib</p>",
        "id": 264321516,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639065537
    },
    {
        "content": "<p>But <a href=\"https://github.com/arthurpaulino/NumLean/blob/5269b16547df31b95ea08d0b9623e9fececcfd57/cpp/ffi.cpp#L67\">this</a> (<code>m-&gt;data[j + i * m-&gt;n_cols]</code>) decides it is a row major matrix.</p>",
        "id": 264321871,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639065648
    },
    {
        "content": "<p>Does it though? It's just a computation to get the real index. It doesn't impose serious restrictions like when you have to do indexing of indexing</p>",
        "id": 264322278,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639065785
    },
    {
        "content": "<p>Well you are using it in matrix multiplication and you will be using matrix multiplication in other functions and that way you will more or less commit to row major matrices.</p>",
        "id": 264322655,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639065907
    },
    {
        "content": "<p>Ah, I see where the row major commitment is now. It's in the fact that the data is disposed in the array as the sequence of rows unfold</p>",
        "id": 264323964,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639066349
    },
    {
        "content": "<p>Yup :)</p>",
        "id": 264324173,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639066419
    },
    {
        "content": "<p>That is why I want to externally implement only ByteArrays, in C/C++/cuda/opencl, and to all of the other logic on Lean level.</p>",
        "id": 264324475,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639066547
    },
    {
        "content": "<p>I'm gonna read your full code (now that I know where it is :D) and try to understand your reasoning</p>",
        "id": 264326724,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639067397
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"346070\">@Tomas Skrivan</span> do you have this line of thought organized/documented somewhere?</p>",
        "id": 264341221,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639073027
    },
    {
        "content": "<p>Let me clean it up and I will set up a repo.</p>",
        "id": 264342248,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639073471
    },
    {
        "content": "<p>I am very interested in it and I want to understand more details about it. For instance, what is the role of ByteArrays in your approach? Wouldn't it cause translation overhead slowdown (as opposed to communicating with C directly via instances of <code>Array Float</code>)?</p>",
        "id": 264342553,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639073592
    },
    {
        "content": "<p>However, I still haven't figured out how to translate an array of <code>double</code> in C to an instance of <code>Array Float</code> in lean. But I am quite sure it can be done</p>",
        "id": 264343037,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639073682
    },
    {
        "content": "<p>What you have done is basically reimplement ByteArray, or rather DoubleArray</p>",
        "id": 264343491,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1639073820
    },
    {
        "content": "<p>Lean has a few unboxed array types that look like this</p>",
        "id": 264343565,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1639073842
    },
    {
        "content": "<p><code>Array Float</code> is a boxed array type, you won't get C-like performance with this data structure</p>",
        "id": 264343704,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1639073891
    },
    {
        "content": "<p>Doesn't this function return the pointer to the double array's head?<br>\n<code>static inline double * lean_float_array_cptr(b_lean_obj_arg a)</code><br>\nMaybe it's why I am facing <a href=\"#narrow/stream/270676-lean4/topic/C.20FFI.20usage/near/264195916\">these issues</a>?</p>",
        "id": 264344091,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639074059
    },
    {
        "content": "<p>EEh, nevermind. I just tried to access data from a <code>Array Float</code> in C and it didn't work the way I expected, so ByteArrays do seem to be the way to go</p>",
        "id": 264346396,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639074933
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"451983\">@Arthur Paulino</span> there is <code>FloatArray</code> though for unboxed C arrays of <code>double</code>.</p>",
        "id": 264350277,
        "sender_full_name": "Mac",
        "timestamp": 1639076526
    },
    {
        "content": "<p>Ah!! Thanks! I got confused and thought I'd have to use <code>Float Array</code> in Lean, but it's <code>FloatArray</code>!</p>",
        "id": 264351014,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639076867
    },
    {
        "content": "<p>Ok have put my sketch of a code into a repo, <a href=\"https://github.com/lecopivo/lean4-karray\">https://github.com/lecopivo/lean4-karray</a> </p>\n<p>The idea is to provide generic array of unboxed values of type <code>α</code> called <code>KArray k α</code>, where <code>k : Kernel</code> specifies if it is cpu/gpu or whatever memory.</p>",
        "id": 264355768,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639079058
    },
    {
        "content": "<p>I guess start by reading KArray.lean and look up definitions in Kernel.lean as they come up.</p>",
        "id": 264356531,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639079394
    },
    {
        "content": "<p>Do you prefer PRs from a fork or from non-protected branches (if you invite me)?</p>",
        "id": 264356805,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639079508
    },
    {
        "content": "<p>I don't know :D I just invite you and give you full access.</p>",
        "id": 264356966,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639079566
    },
    {
        "content": "<p>Sure, just add a license first and I will be more comfortable</p>",
        "id": 264357066,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639079617
    },
    {
        "content": "<p>License suggestion? MIT?</p>",
        "id": 264357168,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639079647
    },
    {
        "content": "<p>MIT or Apache 2.0 should be fine</p>",
        "id": 264357228,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639079672
    },
    {
        "content": "<p>I'm fan of beerware :D ok jokes aside MIT it is then.</p>",
        "id": 264357896,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639079948
    },
    {
        "content": "<p>I think that in general in the community we've licensed projects using the same license as lean itself (ie Apache) but I don't know the legal reasons for this</p>",
        "id": 264381568,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1639091996
    },
    {
        "content": "<p>Using the same license as Lean itself makes it easy to move code from/to core Lean. Big corporations with lots of lawyers (read: Microsoft) tend to prefer Apache over MIT since it's more precise, and addresses other forms of intellectual property including patents. So I would advocate Apache for your project if it's not too late :)</p>",
        "id": 264423927,
        "sender_full_name": "Anne Baanen",
        "timestamp": 1639129977
    },
    {
        "content": "<p>I'm ok switching it to Apache <span class=\"user-mention\" data-user-id=\"451983\">@Arthur Paulino</span>  ok with you too?</p>",
        "id": 264425394,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1639130794
    },
    {
        "content": "<p>Sure</p>",
        "id": 264436011,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1639137177
    },
    {
        "content": "<p>Cool project. I added a nix flake build <a href=\"https://github.com/arthurpaulino/NumLean/pull/1\">https://github.com/arthurpaulino/NumLean/pull/1</a></p>",
        "id": 264439268,
        "sender_full_name": "Anders Christiansen Sørby",
        "timestamp": 1639139086
    },
    {
        "content": "<p>I've wanted to do something like this too, but Lean is quite fast itself so much of the code can be written in Lean too.</p>",
        "id": 264439417,
        "sender_full_name": "Anders Christiansen Sørby",
        "timestamp": 1639139164
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"451983\">Arthur Paulino</span> <a href=\"#narrow/stream/270676-lean4/topic/a.20numerical.20lib.20for.20Lean.204/near/264436011\">said</a>:</p>\n<blockquote>\n<p>Sure</p>\n</blockquote>\n<p>Thank you! <span aria-label=\"heart\" class=\"emoji emoji-2764\" role=\"img\" title=\"heart\">:heart:</span></p>",
        "id": 264440539,
        "sender_full_name": "Anne Baanen",
        "timestamp": 1639139791
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"346070\">@Tomas Skrivan</span> I added one for KArray too if you want it <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span>  <a href=\"https://github.com/lecopivo/lean4-karray/pull/2\">https://github.com/lecopivo/lean4-karray/pull/2</a></p>",
        "id": 264442550,
        "sender_full_name": "Anders Christiansen Sørby",
        "timestamp": 1639140989
    },
    {
        "content": "<p>Having a GPU library for Lean would be gold <span aria-label=\"heart of gold\" class=\"emoji emoji-1f49b\" role=\"img\" title=\"heart of gold\">:heart_of_gold:</span></p>",
        "id": 264442739,
        "sender_full_name": "Anders Christiansen Sørby",
        "timestamp": 1639141108
    },
    {
        "content": "<p>Here's another simple <a href=\"https://github.com/microsoft/ELL/blob/master/libraries/math/include/Matrix.h\">Matrix C++ implementation</a> - also has vector and tensor and supports different layouts.  It would would be interesting to compare.  This implementation can also be optimized by an <a href=\"https://www.openblas.net/\">OpenBlas</a> back end and can be code generated to optimized bitcode using LLVM.  One could imagine a Lean implementation of such things that is compiled by a LLVM-based Lean compiler to achieve the same thing - but with all the proofs you want to ensure the code is correct.</p>",
        "id": 267147551,
        "sender_full_name": "Chris Lovett",
        "timestamp": 1641526276
    },
    {
        "content": "<p>I was curious about the status of this (and any other linear algebra projects) in Lean.  Are any numerical libraries still being worked on?</p>\n<p>I have some primitives (BitVecs, ByteVec, polymorphic vectors and polymorphic matrices)  in my crypto side project.<br>\nMathlib seems to define matrices as functions.  I think this is great for proving, but for computation we may want a variety of largely isomorphic representations of transforms.</p>\n<p>I think it'd be great to support a variety of different approaches with different tradeoffs (in trust, performance, hardware requirements), but allow theorems to be soundly shared.</p>\n<p>Thoughts on whether convergence to a single representation is feasible or practices to support reuse across implementations?</p>",
        "id": 297828114,
        "sender_full_name": "Joe Hendrix",
        "timestamp": 1662657325
    },
    {
        "content": "<p>My general sense on this topic is that it's fairly difficult to construct a computational type without a specific application in mind. The mathlib definition should be viewed as the noncomputable \"ideal\" definition, while specific applications will have some other bespoke type with the desired properties, and then you can prove isomorphism to the ideal definition and transfer all the theorems across that isomorphism</p>",
        "id": 297834235,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1662659215
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 297834815,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1662659420
    },
    {
        "content": "<p>We could have a few specific classes of computational matrices (e.g. a 2D <code>Array A</code>, a <code>ByteArray</code> encoding a bitvector, a <code>FloatArray</code> but this one isn't a ring) in a general library but it's easy to miss the mark if you don't know the characteristics of the application</p>",
        "id": 297834973,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1662659468
    },
    {
        "content": "<p>For matrices doesn't one typically have several implementations for computing, depending for example on whether you know your matrix is sparse or not? I'm a bit unclear about how one is supposed to handle this kind of thing in Lean 4.</p>\n<p>I'm also particularly interested in this kind of question at the minute, because in a few days I'll be (virtually) attending a conference at AIM on \"Computational mathematics in computer assisted proofs\" and someone pointed out to me that \"Lean 4\" might be a potential answer to a lot of questions that people have. Here's the participant list</p>\n<p><a href=\"http://admin.aimath.org/resources/compproofsv/participantlist/\">http://admin.aimath.org/resources/compproofsv/participantlist/</a></p>\n<p>and as you can see from the statements of interest, several people attending would probably want to hear what's going on in the Lean 4 community in this regard.</p>",
        "id": 297834982,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1662659470
    },
    {
        "content": "<p>Yes I'm working on this on and off. I went through multiple iterations and currently the main interface is done through the relatively new <code>GetElem</code> typeclass.</p>\n<hr>\n<p><strong>Interface</strong></p>\n<p>For example, to get <code>n × m</code> matrix I would provide instance:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code>  <span class=\"kd\">instance</span> <span class=\"o\">{</span><span class=\"n\">n</span> <span class=\"n\">m</span><span class=\"o\">}</span> <span class=\"o\">:</span> <span class=\"n\">GetElem</span> <span class=\"o\">{</span><span class=\"n\">a</span> <span class=\"o\">:</span> <span class=\"n\">FloatArray</span> <span class=\"bp\">//</span> <span class=\"n\">n</span> <span class=\"bp\">*</span> <span class=\"n\">m</span> <span class=\"bp\">=</span> <span class=\"n\">a.size</span><span class=\"o\">}</span> <span class=\"o\">(</span><span class=\"n\">Fin</span> <span class=\"n\">n</span> <span class=\"bp\">×</span> <span class=\"n\">Fin</span> <span class=\"n\">m</span><span class=\"o\">)</span> <span class=\"n\">Float</span> <span class=\"o\">(</span><span class=\"bp\">λ</span> <span class=\"n\">_</span> <span class=\"n\">_</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">True</span><span class=\"o\">)</span>\n    <span class=\"o\">:=</span> <span class=\"o\">⟨</span><span class=\"bp\">λ</span> <span class=\"n\">a</span> <span class=\"n\">ij</span> <span class=\"n\">_</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">a.1</span><span class=\"o\">[(</span><span class=\"n\">Enumtype.toFin</span> <span class=\"n\">ij</span><span class=\"o\">)</span><span class=\"bp\">.</span><span class=\"mi\">1</span><span class=\"o\">]</span><span class=\"bp\">!</span><span class=\"o\">⟩</span>\n</code></pre></div>\n<p>where <code>Enumtype</code> is a typeclass that has isomorphism between a finite type and <code>Fin _</code>. In this case, <code>Fin n × Fin m ≈ Fin (n*m)</code>.  The type <code>Fin n × Fin m</code> has lexicographical ordering, so you naturally get row-major matrix. </p>\n<p>I have couple of other typeclasses for setting, modifying elements and introducing a new container</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">class</span> <span class=\"n\">SetElem</span> <span class=\"o\">(</span><span class=\"n\">Cont</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">u</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">Idx</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">v</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">Elem</span> <span class=\"o\">:</span> <span class=\"n\">outParam</span> <span class=\"o\">(</span><span class=\"kt\">Type</span> <span class=\"n\">w</span><span class=\"o\">))</span> <span class=\"n\">where</span>\n  <span class=\"n\">setElem</span> <span class=\"o\">:</span> <span class=\"o\">(</span><span class=\"n\">x</span> <span class=\"o\">:</span> <span class=\"n\">Cont</span><span class=\"o\">)</span> <span class=\"bp\">→</span> <span class=\"o\">(</span><span class=\"n\">i</span> <span class=\"o\">:</span> <span class=\"n\">Idx</span><span class=\"o\">)</span> <span class=\"bp\">→</span> <span class=\"o\">(</span><span class=\"n\">xi</span> <span class=\"o\">:</span> <span class=\"n\">Elem</span><span class=\"o\">)</span> <span class=\"bp\">→</span> <span class=\"n\">Cont</span>\n\n<span class=\"kd\">class</span> <span class=\"n\">ModifyElem</span> <span class=\"o\">(</span><span class=\"n\">Cont</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">u</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">Idx</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">v</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">Elem</span> <span class=\"o\">:</span> <span class=\"n\">outParam</span> <span class=\"o\">(</span><span class=\"kt\">Type</span> <span class=\"n\">w</span><span class=\"o\">))</span> <span class=\"n\">where</span>\n  <span class=\"n\">modifyElem</span> <span class=\"o\">:</span> <span class=\"o\">(</span><span class=\"n\">x</span> <span class=\"o\">:</span> <span class=\"n\">Cont</span><span class=\"o\">)</span> <span class=\"bp\">→</span> <span class=\"o\">(</span><span class=\"n\">i</span> <span class=\"o\">:</span> <span class=\"n\">Idx</span><span class=\"o\">)</span> <span class=\"bp\">→</span> <span class=\"o\">(</span><span class=\"n\">Elem</span> <span class=\"bp\">→</span> <span class=\"n\">Elem</span><span class=\"o\">)</span> <span class=\"bp\">→</span> <span class=\"n\">Cont</span>\n\n<span class=\"kd\">class</span> <span class=\"n\">HasIntro</span> <span class=\"o\">{</span><span class=\"n\">X</span> <span class=\"n\">Y</span><span class=\"o\">}</span> <span class=\"o\">(</span><span class=\"n\">T</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span><span class=\"o\">)</span> <span class=\"o\">[</span><span class=\"n\">FunType</span> <span class=\"n\">T</span> <span class=\"n\">X</span> <span class=\"n\">Y</span><span class=\"o\">]</span> <span class=\"n\">where</span>\n  <span class=\"n\">intro</span> <span class=\"o\">:</span> <span class=\"o\">(</span><span class=\"n\">X</span> <span class=\"bp\">→</span> <span class=\"n\">Y</span><span class=\"o\">)</span> <span class=\"bp\">→</span> <span class=\"n\">T</span>\n  <span class=\"n\">toFun_intro</span> <span class=\"o\">:</span> <span class=\"bp\">∀</span> <span class=\"n\">f</span> <span class=\"n\">x</span><span class=\"o\">,</span> <span class=\"o\">(</span><span class=\"n\">intro</span> <span class=\"n\">f</span><span class=\"o\">)[</span><span class=\"n\">x</span><span class=\"o\">]</span> <span class=\"bp\">=</span> <span class=\"n\">f</span> <span class=\"n\">x</span>\n</code></pre></div>\n<p>Maybe the <code>SetElem</code> should also have the <code>(dom : outParam (cont → idx → Prop))</code> parameter. For example, you can modify only diagonal elements for diagonal matrix. I have to think about it a bit more as it should also support sparse matrices.</p>\n<p>You can see the code <a href=\"https://github.com/lecopivo/SciLean/blob/master/SciLean/Data/FunType/Basic.lean\">here</a>.</p>\n<p>To get notation like <code>x[i] += ... </code> in do blocks. You can do</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">syntax</span> <span class=\"n\">atomic</span><span class=\"o\">(</span><span class=\"n\">Term.ident</span><span class=\"o\">)</span> <span class=\"n\">noWs</span> <span class=\"s2\">\"[\"</span> <span class=\"n\">term</span> <span class=\"s2\">\"]\"</span> <span class=\"s2\">\" += \"</span> <span class=\"n\">term</span> <span class=\"o\">:</span> <span class=\"n\">doElem</span>\n<span class=\"n\">macro_rules</span>\n<span class=\"bp\">|</span> <span class=\"bp\">`</span><span class=\"o\">(</span><span class=\"n\">doElem</span><span class=\"bp\">|</span> <span class=\"bp\">$</span><span class=\"n\">x</span><span class=\"o\">:</span><span class=\"n\">ident</span><span class=\"o\">[</span> <span class=\"bp\">$</span><span class=\"n\">i</span><span class=\"o\">:</span><span class=\"n\">term</span> <span class=\"o\">]</span> <span class=\"bp\">+=</span> <span class=\"bp\">$</span><span class=\"n\">xi</span><span class=\"o\">)</span> <span class=\"bp\">=&gt;</span> <span class=\"bp\">`</span><span class=\"o\">(</span><span class=\"n\">doElem</span><span class=\"bp\">|</span> <span class=\"bp\">$</span><span class=\"n\">x</span><span class=\"o\">:</span><span class=\"n\">ident</span> <span class=\"o\">:=</span> <span class=\"n\">modifyElem</span> <span class=\"o\">(</span><span class=\"bp\">$</span><span class=\"n\">x</span><span class=\"o\">:</span><span class=\"n\">ident</span><span class=\"o\">)</span> <span class=\"bp\">$</span><span class=\"n\">i</span> <span class=\"o\">(</span><span class=\"bp\">λ</span> <span class=\"n\">val</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">val</span> <span class=\"bp\">+</span> <span class=\"bp\">$</span><span class=\"n\">xi</span><span class=\"o\">))</span>\n</code></pre></div>\n<hr>\n<p><strong>Carrier</strong></p>\n<p>What should the <code>Cont</code> type be? I mostly use <code>FloatArray</code>. I also have wrapper for <a href=\"https://github.com/lecopivo/EigenLean\">C++ Eigen matrices</a>, but it is just a proof of concept and I didn't touch it in a long time as I'm mostly focusing on symbolic computations.</p>",
        "id": 297838388,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1662660553
    },
    {
        "content": "<p>My main worry with this approach is that the index type for matrices <code>Fin n × Fin m</code> is using polymorphic product which boxes its elements, so the final code can be slow if the boxing is not eliminated.</p>",
        "id": 297838795,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1662660696
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"346070\">Tomas Skrivan</span> <a href=\"#narrow/stream/270676-lean4/topic/a.20numerical.20lib.20for.20Lean.204/near/297838795\">said</a>:</p>\n<blockquote>\n<p>My main worry with this approach is that the index type for matrices <code>Fin n × Fin m</code> is using polymorphic product which boxes its elements, so the final code can be slow if the boxing is not eliminated.</p>\n</blockquote>\n<p>That shouldn't be a problem as long as everything in sight is marked <code>@[inline]</code>; lean can remove stuff like projections on a pair so as long as the user code passes <code>arr[(i, j)]</code> I would expect it to be untupled in the generated code</p>",
        "id": 297839862,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1662661060
    },
    {
        "content": "<p>Yes that is my hope that it can be eliminated with sufficient in lining. Also, there should be some kind of compile time simplifier that might help with this too.</p>",
        "id": 297840491,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1662661265
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110994\">Joe Hendrix</span> <a href=\"#narrow/stream/270676-lean4/topic/a.20numerical.20lib.20for.20Lean.204/near/297828114\">said</a>:</p>\n<blockquote>\n<p>Thoughts on whether convergence to a single representation is feasible or practices to support reuse across implementations?</p>\n</blockquote>\n<p>We definitely need multiple representations. Just for matrices we need row/column-major, triangular, block, diagonal matrices, also is for CPU, GPU or distributed across machines?</p>",
        "id": 297852685,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1662665972
    },
    {
        "content": "<p>Are there any well-established libraries for matrix operations that we can shamelessly grift an API from?</p>",
        "id": 297865376,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1662671295
    },
    {
        "content": "<p>I don't know that we need to care about the efficiency of stuff like <code>GetElem</code> esque operations, since performance-sensitive matrix code should be exclusively using large-step operations like matrix mult/add/sub, factorization, etc...</p>",
        "id": 297865630,
        "sender_full_name": "James Gallicchio",
        "timestamp": 1662671445
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"346070\">@Tomas Skrivan</span>  I like the typeclasses.  It seems like the ModifyElem/SetElem type classes would be worth moving into Lean or MathLib.  For my current purposes, it'd also be great to have comprehensions (including parallel comprehensions) generalized to support other types such as vectors/matrices.</p>\n<p>I think the approach I'll take is to show my implementation types and definitions are isomorphic to the Mathlib definitions.</p>",
        "id": 297866992,
        "sender_full_name": "Joe Hendrix",
        "timestamp": 1662672136
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"407274\">James Gallicchio</span> <a href=\"#narrow/stream/270676-lean4/topic/a.20numerical.20lib.20for.20Lean.204/near/297865376\">said</a>:</p>\n<blockquote>\n<p>Are there any well-established libraries for matrix operations that we can shamelessly grift an API from?</p>\n</blockquote>\n<p>That is exactly what I want to do with wrapping <a href=\"https://github.com/lecopivo/EigenLean\">C++ Eigen library</a>. It is a fairly popular linear algebra library in C++ with a nice collection of dense and sparse solvers. Someone just needs to sit down and write down all the wrapper functions. So far I wrote only a single  wrapper for LDLT to demonstrate how to do it.</p>",
        "id": 297868996,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1662673075
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"407274\">James Gallicchio</span> <a href=\"#narrow/stream/270676-lean4/topic/a.20numerical.20lib.20for.20Lean.204/near/297865630\">said</a>:</p>\n<blockquote>\n<p>I don't know that we need to care about the efficiency of stuff like <code>GetElem</code> esque operations, since performance-sensitive matrix code should be exclusively using large-step operations like matrix mult/add/sub, factorization, etc...</p>\n</blockquote>\n<p>My hope is that if you effectively write C code with Lean then equivalent C code will be generated. Maybe with some special annotations to the compiler or something. But definitely not something I'm too worried about in the near future.</p>",
        "id": 297869384,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1662673257
    }
]