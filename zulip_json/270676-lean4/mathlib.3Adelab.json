[
    {
        "content": "<p>There is still a lot of uncertainty about how to structure the textual port, but one high-level strategy that has been floated is to push heuristic delaboration as far as possible before manually touching files. I just wrote a toy demo of how this might work to start the discussion: <a href=\"https://gist.github.com/dselsam/bed905f85021dc4b41b971ad2c95a8c2\">https://gist.github.com/dselsam/bed905f85021dc4b41b971ad2c95a8c2</a> Here is a tentative proposal:</p>\n<ol>\n<li>\n<p>We implement delaborator round-tripping <a href=\"https://github.com/leanprover/lean4/issues/368\">https://github.com/leanprover/lean4/issues/368</a> . At this point, we should be able to (in principle) delaborate mathlib into large and unreadable files.</p>\n</li>\n<li>\n<p>We iterate the following:</p>\n<ul>\n<li>find an ostensibly-tactic-compressible part of a delaborated proof (e.g. by simp, ring, etc.)</li>\n<li>implement a heuristic delaboration rule for it (implementing the tactics as needed)</li>\n<li>rerun the delaborator</li>\n</ul>\n</li>\n<li>\n<p>Baseless speculation is that we can produce reasonable <code>.lean</code> files for the entire library this way with (say) a few hundred auto-placed <code>sorry</code>s for large proof-terms that can't be compressed, before we reach diminishing returns.</p>\n</li>\n<li>\n<p>We fill in the <code>sorry</code>s manually, looking at the old lean3 tactic scripts for guidance.</p>\n</li>\n<li>\n<p>Once the textual port is complete, we do a manual pass to use lean4 constructions instead of auto-ported lean3 constructions. For example, lean3 definitions that use the equation compiler will translate as definitions in terms of <code>foo._main</code>, which will be defined by <code>brec_on</code>, and there will be a ton of explicit equation lemmas. These will all start out in the delaborated <code>.lean</code> files. So we delete all this cruft, and write the definition using the equation compiler, consulting the lean3 definitions as necessary. I don't expect this kind of change to propagate very far, since most things will be def-eq.</p>\n</li>\n</ol>\n<p>Thoughts?</p>",
        "id": 234607673,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618454414
    },
    {
        "content": "<p>The example for 5 doesn't sound like it needs to be a manual pass</p>",
        "id": 234608123,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618454858
    },
    {
        "content": "<p>We have visibility into the fact that the lean 3 definition was done with the equation compiler so we can use it</p>",
        "id": 234608219,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618454896
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234608219\">said</a>:</p>\n<blockquote>\n<p>We have visibility into the fact that the lean 3 definition was done with the equation compiler so we can use it</p>\n</blockquote>\n<p>True, we could separately export from lean3 the fully elaborated equations, and then have a special equations-delaborator on the lean4 side</p>",
        "id": 234608405,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618455099
    },
    {
        "content": "<p>But I am not sure if there are enough uses to merit this though.</p>",
        "id": 234608514,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618455196
    },
    {
        "content": "<p>There's another variation on this plan, where we put in enough work to extract a lean 3 AST and then map it to reasonable substitutes in lean 4. It will look good but most likely will be slightly broken all over the place; but it seems like a better starting point for manual editing</p>",
        "id": 234608525,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618455212
    },
    {
        "content": "<p>Yes, a different and somewhat compatible high-level strategy is to export parsed lean3 tactic scripts, automate some of the work of making it lean4 syntax (e.g. lambda <code>,</code> -&gt; <code>=&gt;</code>), and then manually tweaking to make it type-check. As you said it will be slightly broken everywhere though. With the delab approach the <code>sorry</code> damage will be controlled and localized.</p>",
        "id": 234608682,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618455331
    },
    {
        "content": "<p>We can definitely do this for the <code>sorry</code> stage, but I am hoping there will be few enough sorries that it is easier to just copy-paste and manually tweak the syntax.</p>",
        "id": 234608760,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618455382
    },
    {
        "content": "<p>I'm not as positive about the outlook of step 2</p>",
        "id": 234608818,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618455458
    },
    {
        "content": "<p>it will be difficult to get the tactics to actually reproduce the proof terms we want to compress</p>",
        "id": 234608830,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618455481
    },
    {
        "content": "<p>A lower bar is producing reasonably short proof terms that type-check, even if they are slightly weird and not how a human would have written it.</p>",
        "id": 234608908,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618455525
    },
    {
        "content": "<p>I am not so worried about <code>simp</code> and <code>ring</code> so much as the structural tactics. The elaborator differences are going to be a huge pain</p>",
        "id": 234608917,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618455541
    },
    {
        "content": "<p>What do you mean by a structural tactic?</p>",
        "id": 234608946,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618455573
    },
    {
        "content": "<p><code>change</code>, <code>cases</code>, <code>induction</code>, <code>refine</code>, <code>apply</code></p>",
        "id": 234609010,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618455605
    },
    {
        "content": "<p>These are tactics that already exist but don't do exactly the same thing</p>",
        "id": 234609027,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618455629
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234608818\">said</a>:</p>\n<blockquote>\n<p>I'm not as positive about the outlook of step 2</p>\n</blockquote>\n<p>Also, if I were positive, I wouldn't even bother posting :) I am not at all positive, and I am hoping people share their concerns about potential roadblocks.</p>",
        "id": 234609075,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618455647
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234609027\">said</a>:</p>\n<blockquote>\n<p>These are tactics that already exist but don't do exactly the same thing</p>\n</blockquote>\n<p>This is why heuristic delaboration is likely to be more reliable than heuristic translation -- it doesn't matter what the lean3 tactics did.</p>",
        "id": 234609138,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618455693
    },
    {
        "content": "<p>specifically, \"a few hundred <code>sorry</code>s\" sounds like an extremely high bar</p>",
        "id": 234609142,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618455695
    },
    {
        "content": "<p>I'm expecting more like ten thousand sorrys</p>",
        "id": 234609155,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618455704
    },
    {
        "content": "<p>At what granularity are you expecting? I mean, will we be able to stick <code>sorry</code>s deep inside otherwise OK proof terms, or will we effectively need to <code>sorry</code> out entire proofs?</p>",
        "id": 234609314,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618455817
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"230999\">Daniel Selsam</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234609138\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234609027\">said</a>:</p>\n<blockquote>\n<p>These are tactics that already exist but don't do exactly the same thing</p>\n</blockquote>\n<p>This is why heuristic delaboration is likely to be more reliable than heuristic translation -- it doesn't matter what the lean3 tactics did.</p>\n</blockquote>\n<p>Yes, but the issue with delaboration is that it's mostly a one way street - you can't easily reconstruct the original proof and will have to consult the lean 3 proof heavily anyway. I doubt the term will even help that much beyond being able to act as a kind of long winded version of <code>sorry</code></p>",
        "id": 234609322,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618455821
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"230999\">Daniel Selsam</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234609314\">said</a>:</p>\n<blockquote>\n<p>At what granularity are you expecting? I mean, will we be able to stick <code>sorry</code>s deep inside otherwise OK proof terms, or will we effectively need to <code>sorry</code> out entire proofs?</p>\n</blockquote>\n<p>If the bar is \"terms that are too big even after iterating step 2 to fixpoint\" I would guess there will be one in almost every proof</p>",
        "id": 234609420,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618455887
    },
    {
        "content": "<p>AST translation is much more likely to be helpful to human editors</p>",
        "id": 234609466,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618455934
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234609322\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"230999\">Daniel Selsam</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234609138\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234609027\">said</a>:</p>\n<blockquote>\n<p>These are tactics that already exist but don't do exactly the same thing</p>\n</blockquote>\n<p>This is why heuristic delaboration is likely to be more reliable than heuristic translation -- it doesn't matter what the lean3 tactics did.</p>\n</blockquote>\n<p>Yes, but the issue with delaboration is that it's mostly a one way street - you can't easily reconstruct the original proof and will have to consult the lean 3 proof heavily anyway. I doubt the term will even help that much beyond being able to act as a kind of long winded version of <code>sorry</code></p>\n</blockquote>\n<p>I agree that this is a risk. Specifically, that even if it delaborates to something short enough, that when it comes time to refactor, the proof is still so unconventional that people just look to the old lean3 version anyway.</p>",
        "id": 234609550,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618455985
    },
    {
        "content": "<p>I would probably do an AST translation and then splitscreen with the lean 3 proof to see intermediate states so I can repair the broken bits</p>",
        "id": 234609561,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618455996
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234609466\">said</a>:</p>\n<blockquote>\n<p>AST translation is much more likely to be helpful to human editors</p>\n</blockquote>\n<p>I agree.</p>",
        "id": 234609566,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618456002
    },
    {
        "content": "<p>So it really seems to hinge on how dense the <code>sorry</code>s will be after iterating (2), and how easy it will be for a human to align a <code>sorry</code> within a delaborated proof with the corresponding part of the corresponding lean3 tactic script.</p>",
        "id": 234609683,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618456109
    },
    {
        "content": "<p>We can certainly do tests for that</p>",
        "id": 234609729,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618456147
    },
    {
        "content": "<p>This can't really start until we have most mathlib tactics first though</p>",
        "id": 234609820,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618456210
    },
    {
        "content": "<p>It will take a while to develop the delaborator to test these hypotheses though. I am not even sure how long the initial (1) step will take -- probably easy for Sebastian but I'll need to get up to speed on a good chunk of the frontend first.</p>",
        "id": 234609843,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618456231
    },
    {
        "content": "<p>step 1 sounds a bit like an open research question <span aria-label=\"oops\" class=\"emoji emoji-1f643\" role=\"img\" title=\"oops\">:oops:</span></p>",
        "id": 234609902,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618456289
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234609820\">said</a>:</p>\n<blockquote>\n<p>This can't really start until we have most mathlib tactics first though</p>\n</blockquote>\n<p>We don't need all the tactics to do the experiment. We already have analogues of simp, cases, and induction, and we can easily detect goals that could be proven by a future norm_num, ring, or linarith (without needing them to be implemented yet)</p>",
        "id": 234609912,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618456305
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234609902\">said</a>:</p>\n<blockquote>\n<p>step 1 sounds a bit like an open research question <span aria-label=\"oops\" class=\"emoji emoji-1f643\" role=\"img\" title=\"oops\">:oops:</span></p>\n</blockquote>\n<p>Maybe a research question to prove it works, but we may be able to get very far just iterating some form of:</p>\n<p>- try delab<br>\n  - detect error message<br>\n  - add more detail to the subterm with the message</p>",
        "id": 234610050,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618456413
    },
    {
        "content": "<p>There are a lot of tactics other than those though. I'm thinking of the other 90% of tactics that do silly little things like <code>contradiction</code>, <code>existsi</code>, <code>constructor</code>, <code>choose</code></p>",
        "id": 234610053,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618456416
    },
    {
        "content": "<p>If you look in logic.basic, nat.basic, and list.basic you won't find much <code>linarith</code> but quite a bit of <code>simp</code>, lots of <code>induction</code> and a bit of <code>cases</code> and <code>rcases</code></p>",
        "id": 234610155,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618456486
    },
    {
        "content": "<p>Even without those tactics implemented, the proofs will <code>delab</code> to simple and concise things. But that kind of little tactic shouldn't be hard to implement.</p>",
        "id": 234610156,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618456488
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234610155\">said</a>:</p>\n<blockquote>\n<p>If you look in logic.basic, nat.basic, and list.basic you won't find much <code>linarith</code> but quite a bit of <code>simp</code>, lots of <code>induction</code> and a bit of <code>cases</code> and <code>rcases</code></p>\n</blockquote>\n<p>This is a good starting point to experiment with. We could even start experimenting with (2) before doing (1), since this kind of basic thing will probably work with <code>pp.default</code>.</p>",
        "id": 234610214,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618456541
    },
    {
        "content": "<p>I'll try those three files tomorrow.</p>",
        "id": 234610259,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618456564
    },
    {
        "content": "<p>plus the lemmas in nat.basic (or at least init.data.nat.lemmas) are actually kind of important, I seem to run across a half dozen of them when I try to prove anything at all (see findLeast thread)</p>",
        "id": 234610328,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618456627
    },
    {
        "content": "<p>so some of them will need to end up in the mathlib prelude most likely</p>",
        "id": 234610354,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618456660
    },
    {
        "content": "<p>Will the mathlib prelude be a stand-alone lean4 repo with no mathport dependency?</p>",
        "id": 234610428,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618456703
    },
    {
        "content": "<p>that's the plan</p>",
        "id": 234610444,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618456720
    },
    {
        "content": "<p>And the goal is mainly to replicate <code>src/tactic</code> right? As opposed to starting a separate bottom-up porting process.</p>",
        "id": 234610506,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618456777
    },
    {
        "content": "<p>I need to understand better how compilation and dependencies work in lean 4 but I think we need tactics to be in a separate project for them to be compiled for use in mathlib</p>",
        "id": 234610509,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618456783
    },
    {
        "content": "<p>yes, it's only for tactic stuff and supporting lemmas, like lean 3 core (which is a bit bigger than lean 4 core is right now) + mathlib <code>tactic/</code></p>",
        "id": 234610603,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1618456836
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234610509\">said</a>:</p>\n<blockquote>\n<p>I need to understand better how compilation and dependencies work in lean 4 but I think we need tactics to be in a separate project for them to be compiled for use in mathlib</p>\n</blockquote>\n<p>I believe this is currently the case, yes.</p>",
        "id": 234610615,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618456857
    },
    {
        "content": "<p>Is that planned to change?</p>",
        "id": 234617370,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1618462707
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"230999\">Daniel Selsam</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234607673\">said</a>:</p>\n<blockquote>\n<p>[...] definitions in terms of <code>foo._main</code>, which will be defined by <code>brec_on</code> [...]</p>\n</blockquote>\n<p>Delaborating proofs is one challenge, and it's good it's being worked on.  But I believe that these auxiliary definitions pose a much bigger issue in automatic porting because they are used extensively in mathlib.  As you've already noticed, there are auxiliary definitions created by Lean, such as <code>_proof_*</code> or <code>_match_*</code>, etc.  But there's also lots of automatically generated code from mathlib:</p>\n<ul>\n<li><code>@[to_additive]</code> duplicates every definition it is tagged with</li>\n<li><code>@[ext]</code>, <code>@[mk_iff]</code>, <code>@[simps]</code>, etc., generate auxiliary lemmas</li>\n<li><code>@[derive]</code> also exists in Lean 3</li>\n</ul>\n<p>And these are just the common ones.  If the automatically ported file contains the expanded versions of these, then the task is not \"fill in a few sorrys\", but rather \"delete it and port the Lean 3 version manually\".</p>",
        "id": 234629902,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1618471710
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234617370\">said</a>:</p>\n<blockquote>\n<p>Is that planned to change?</p>\n</blockquote>\n<p>No, because a package seems like a sensible code unit to generate a shared library from. But maybe people are confused about what the implications of \"separate packages\" are - there is absolutely no reason that you couldn't put multiple packages into the same repo. It's just that leanpkg hasn't been extended in such a way yet.</p>",
        "id": 234630147,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1618471840
    },
    {
        "content": "<p>Well, separate packages might not be necessary if we could JIT compile Lean programs, but those are dreams of the future. Shared libraries we can produce right now.</p>",
        "id": 234630343,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1618471948
    },
    {
        "content": "<p>Now, I don't think that that is necessarily a bad strategy.  Let's say we can port all of mathlib to Lean 4 automatically, even if every proof is sorry and all <code>to_additive</code> are expanded, etc.  Then at least we can parallelize the manual porting process afterwards.  Because it becomes possible to replace an ugly automatically-ported Lean 4 file by a manually ported version, and have CI check that that everything still builds.</p>",
        "id": 234630374,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1618471969
    },
    {
        "content": "<p>Also pinging <span class=\"user-mention\" data-user-id=\"399706\">@Aurélien Saue</span>, who has been experimenting with a similar automatic porting tool.</p>",
        "id": 234630460,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1618472008
    },
    {
        "content": "<blockquote>\n<p>I don't expect this kind of change to propagate very far, since most things will be def-eq.</p>\n</blockquote>\n<p>If you write <code>def foo := foo._main</code> manually instead of <code>def foo := 42</code>, this changes several things, even though they are definitionally equal:</p>\n<ul>\n<li><code>rw foo</code> produces a different result (and also <code>simp</code>, <code>delta</code>, etc.).  This is because the equational lemmas are different.</li>\n<li>Unification behaves differently, exposing <code>brec_on</code>.  If you use pattern matching, Lean will use smart unfolding instead.</li>\n</ul>",
        "id": 234630864,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1618472249
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110024\">Sebastian Ullrich</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234630147\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234617370\">said</a>:</p>\n<blockquote>\n<p>Is that planned to change?</p>\n</blockquote>\n<p>No, because a package seems like a sensible code unit to generate a shared library from. But maybe people are confused about what the implications of \"separate packages\" are - there is absolutely no reason that you couldn't put multiple packages into the same repo. It's just that leanpkg hasn't been extended in such a way yet.</p>\n</blockquote>\n<p>But what about our tactics that, e.g. rely on part of the category theory library before you can even write them, and then get used in later parts of the category theory library? e.g. the recent <code>elementwise</code> I wrote needs to know about particular lemmas.</p>",
        "id": 234643443,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1618478645
    },
    {
        "content": "<p>I believe we can still use tactics immediately in the same file.  It's just they will be interpreted (as slow as in Lean 3).  They only need to be in a different project if we want them to be compiled.</p>",
        "id": 234643933,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1618478886
    },
    {
        "content": "<p>I see. I guess we'll actually adapt to that pretty easily. If you look at the current import graph for mathlib there is a very obvious horizontal line, before which there is no interesting maths, and after which there are no substantial tactics. We can just split mathlib on that line.</p>",
        "id": 234644378,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1618479116
    },
    {
        "content": "<p>The Lean 4 interpreter is actually quite a bit faster than in Lean 3 IIRC. Also, compilation only matters for tactics that do significant work themselves. If most time is spent in a nested <code>simp</code>, it will use the native code for that anyway.</p>",
        "id": 234644524,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1618479166
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110043\">Gabriel Ebner</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234630374\">said</a>:</p>\n<blockquote>\n<p>Now, I don't think that that is necessarily a bad strategy.  Let's say we can port all of mathlib to Lean 4 automatically, even if every proof is sorry and all <code>to_additive</code> are expanded, etc.  Then at least we can parallelize the manual porting process afterwards.  Because it becomes possible to replace an ugly automatically-ported Lean 4 file by a manually ported version, and have CI check that that everything still builds.</p>\n</blockquote>\n<p>So that has been the approach I have been trying to explore, and I think it would be a good first step. After time, these sorries would be replaced by proper proofs but at least we have a buildable first version. For it to be comfortable to use for users we could also include all the Lean3 proofs as comments after the <code>sorry</code> for them not to have to look up the Lean3 files all the time.</p>",
        "id": 234647098,
        "sender_full_name": "Aurélien Saue",
        "timestamp": 1618480429
    },
    {
        "content": "<p>For step one, is the idea to delaborate from the mathport generated <code>olean</code> files?</p>",
        "id": 234647567,
        "sender_full_name": "Aurélien Saue",
        "timestamp": 1618480651
    },
    {
        "content": "<p>Regarding delaborating from mathport oleans: is it plausible for us to modify lean3 tactics so that they insert \"wrappers\" into the proof terms, which essentially serve as instructions for a mathport specific delaboration step?</p>",
        "id": 234651850,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1618482794
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110043\">Gabriel Ebner</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234630374\">said</a>:</p>\n<blockquote>\n<p>Now, I don't think that that is necessarily a bad strategy.  Let's say we can port all of mathlib to Lean 4 automatically, even if every proof is sorry and all <code>to_additive</code> are expanded, etc.  Then at least we can parallelize the manual porting process afterwards.  Because it becomes possible to replace an ugly automatically-ported Lean 4 file by a manually ported version, and have CI check that that everything still builds.</p>\n</blockquote>\n<p>So you would effectively use the delaborator not for its source output to iterate upon but to move from Lean 4-compatible Lean 3 .olean files to equivalent ones that conform to the output of native Lean 4 declarations, e.g. regarding equations, is that right?</p>",
        "id": 234653204,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1618483549
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110024\">Sebastian Ullrich</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234653204\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"110043\">Gabriel Ebner</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234630374\">said</a>:<br>\nSo you would effectively use the delaborator not for its source output to iterate upon [...]</p>\n</blockquote>\n<p>Yes.  It would still produce source output, but the output is only/mostly there to make mathlib4 build while we port files individually.  The advantage of using Lean 4 source files instead of converted olean files is that 1) they are producing the native equation lemmas, etc., and 2) that we can modify them during porting.<br>\nFor example the category theory library extensively uses automation that is integrated into the definitions.  There is lots of auto_params with custom tactics.  Say we begin by changing these auto_param tactics to Lean 4 equivalents.  This will certainly break downstream files.  But you can't start with the downstream files either, because doing category theory without automation is pointless.</p>",
        "id": 234658070,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1618486215
    },
    {
        "content": "<p>There are other parts of mathlib that are much easier to port.  For example, I fully expect the delaboration-based porting tool to produce a usable version of <code>logic.basic</code>.</p>",
        "id": 234658363,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1618486379
    },
    {
        "content": "<p>I see, makes sense to me. But that also means that the delaborator output wouldn't have to be \"great\", i.e. using the current state with \"try the default options; if it doesn't round-trip, use <code>pp.all</code>\" could be sufficient (assuming there are no pp.all bugs). It could still be improved in parallel to manual porting if you do want to reuse its output for such files.</p>",
        "id": 234661235,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1618487716
    },
    {
        "content": "<p>I just want to tell you all that I am still a newbie but if during this process you encounter some task that does not require too much of an in-depth knowledge and that you would like to delegate, I would be happy to give it my best try :)</p>",
        "id": 234667202,
        "sender_full_name": "Aurélien Saue",
        "timestamp": 1618490365
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110043\">Gabriel Ebner</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234630864\">said</a>:</p>\n<blockquote>\n<p>If you write <code>def foo := foo._main</code> manually instead of <code>def foo := 42</code>, this changes several things, even though they are definitionally equal:</p>\n<ul>\n<li><code>rw foo</code> produces a different result (and also <code>simp</code>, <code>delta</code>, etc.).  This is because the equational lemmas are different.</li>\n</ul>\n</blockquote>\n<p>Yes but this one is at the tactic level, which wouldn't matter if the downstream proofs are generated by the delaborator.</p>\n<blockquote>\n<ul>\n<li>Unification behaves differently, exposing <code>brec_on</code>.  If you use pattern matching, Lean will use smart unfolding instead.</li>\n</ul>\n</blockquote>\n<p>Actually, when importing mathlib binaries we still get smart unfolding, because <code>foo._sunfold</code> is generated and ported as well and Lean4 just checks for the name. The smart unfolding behavior is a little different between lean3 and lean4 (in particular, there is no smart unfolding anymore for non-recursive definitions), but I think most recursive smart unfolds will be the same.</p>",
        "id": 234699978,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618501032
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234651850\">said</a>:</p>\n<blockquote>\n<p>Regarding delaborating from mathport oleans: is it plausible for us to modify lean3 tactics so that they insert \"wrappers\" into the proof terms, which essentially serve as instructions for a mathport specific delaboration step?</p>\n</blockquote>\n<p>Yes. We could create an inductive type <code>MyExtraInfoForLean4</code> and define a tagging function:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">axiom</span> <span class=\"n\">MyExtraInfoForLean4</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span>\n<span class=\"kd\">def</span> <span class=\"n\">id_tag4</span> <span class=\"o\">{</span><span class=\"n\">α</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span><span class=\"o\">}</span> <span class=\"o\">(</span><span class=\"n\">tag</span> <span class=\"o\">:</span> <span class=\"n\">MyExtraInfoForLean4</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">x</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">α</span> <span class=\"o\">:=</span> <span class=\"n\">x</span>\n</code></pre></div>\n<p>Even if <code>MyExtraLean4Info</code> uses strings and names and other types that don't align perfectly, mathport can still decode concrete values into the corresponding Lean4 values. It already does this for <code>auto_param</code> names.</p>",
        "id": 234700746,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618501280
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"230999\">Daniel Selsam</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234699978\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"110043\">Gabriel Ebner</span> <a href=\"#narrow/stream/270676-lean4/topic/mathlib.3Adelab/near/234630864\">said</a>:</p>\n<blockquote>\n<p>If you write <code>def foo := foo._main</code> manually instead of <code>def foo := 42</code>, this changes several things, even though they are definitionally equal:</p>\n<ul>\n<li><code>rw foo</code> produces a different result (and also <code>simp</code>, <code>delta</code>, etc.).  This is because the equational lemmas are different.</li>\n</ul>\n</blockquote>\n<p>Yes but this one is at the tactic level, which wouldn't matter if the downstream proofs are generated by the delaborator.</p>\n</blockquote>\n<p>In that case the delaborated files can't be used as is and still need to be cleaned up in an API-changing way.  Which breaks all the nicely delaborated proofs afterwards.</p>",
        "id": 234701075,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1618501395
    },
    {
        "content": "<p>We can also get rid of the <code>foo._main</code>s during mathport, and fuse them with <code>foo</code>.</p>",
        "id": 234702012,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1618501717
    }
]