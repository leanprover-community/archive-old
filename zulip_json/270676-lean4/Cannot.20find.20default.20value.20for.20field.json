[
    {
        "content": "<p>As discussed in <a href=\"https://github.com/leanprover/lean4/issues/813\">https://github.com/leanprover/lean4/issues/813</a>, I've tried to make Function.const and Function.comp semireducible.  <a href=\"https://github.com/leanprover/lean4/compare/master...gebner:compconstsemired?expand=1\">https://github.com/leanprover/lean4/compare/master...gebner:compconstsemired?expand=1</a></p>\n<p>However I ran into a weird problem:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">Init</span><span class=\"bp\">/</span><span class=\"n\">Control</span><span class=\"bp\">/</span><span class=\"n\">Lawful.lean</span><span class=\"o\">:</span><span class=\"mi\">169</span><span class=\"o\">:</span><span class=\"mi\">63</span><span class=\"o\">:</span> <span class=\"n\">error</span><span class=\"o\">:</span> <span class=\"n\">field</span> <span class=\"bp\">'</span><span class=\"n\">comp_map'</span> <span class=\"n\">is</span> <span class=\"n\">missing</span>\n<span class=\"n\">Init</span><span class=\"bp\">/</span><span class=\"n\">Control</span><span class=\"bp\">/</span><span class=\"n\">Lawful.lean</span><span class=\"o\">:</span><span class=\"mi\">215</span><span class=\"o\">:</span><span class=\"mi\">63</span><span class=\"o\">:</span> <span class=\"n\">error</span><span class=\"o\">:</span> <span class=\"n\">field</span> <span class=\"bp\">'</span><span class=\"n\">comp_map'</span> <span class=\"n\">is</span> <span class=\"n\">missing</span>\n<span class=\"n\">Init</span><span class=\"bp\">/</span><span class=\"n\">Control</span><span class=\"bp\">/</span><span class=\"n\">Lawful.lean</span><span class=\"o\">:</span><span class=\"mi\">297</span><span class=\"o\">:</span><span class=\"mi\">62</span><span class=\"o\">:</span> <span class=\"n\">error</span><span class=\"o\">:</span> <span class=\"n\">field</span> <span class=\"bp\">'</span><span class=\"n\">comp_map'</span> <span class=\"n\">is</span> <span class=\"n\">missing</span>\n</code></pre></div>\n<p>But I didn't change anything about <code>comp_map</code> (except the reducibility of a function in its type), it's still got the same default value as before.  The default value is not an auto param either.</p>\n<p>Any ideas what could be going wrong here?  I can't find anything relevant in the Meta.isDefEq and Elab.  It even mentions the default value: <code>[Elab.struct] elabStruct comp_map := &lt;default&gt;, ...</code></p>",
        "id": 262437745,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1637663898
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110043\">@Gabriel Ebner</span> I pushed a fix for 813. I also had problems with <code>Lawful.lean</code>, but I think it was just broken proofs for me.</p>",
        "id": 262476917,
        "sender_full_name": "Leonardo de Moura",
        "timestamp": 1637683934
    },
    {
        "content": "<p>I'm using <code>comp</code> and similarly defined <code>curry</code>, <code>uncurry</code> all over the place when stating typeclass instance. Removing reducible breaks my code now. </p>\n<p>For example now there is a difference between:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">instance</span> <span class=\"o\">:</span> <span class=\"n\">IsLinear</span> <span class=\"o\">(</span><span class=\"bp\">λ</span> <span class=\"n\">x</span> <span class=\"o\">:</span> <span class=\"n\">X</span><span class=\"bp\">×</span><span class=\"n\">X</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">x.1</span><span class=\"bp\">+</span><span class=\"n\">x.2</span><span class=\"o\">)</span> <span class=\"o\">:=</span> <span class=\"gr\">sorry</span>\n</code></pre></div>\n<p>and </p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">instance</span> <span class=\"o\">:</span> <span class=\"n\">IsLinear</span> <span class=\"o\">(</span><span class=\"n\">uncurry</span> <span class=\"o\">(</span><span class=\"n\">HAdd.hAdd</span> <span class=\"o\">:</span> <span class=\"n\">X</span> <span class=\"bp\">→</span> <span class=\"n\">X</span> <span class=\"bp\">→</span> <span class=\"n\">X</span><span class=\"o\">))</span> <span class=\"o\">:=</span> <span class=\"gr\">sorry</span>\n</code></pre></div>\n<p>Not a real issue, but now I have to prefer one over the other. Not sure which one as sometimes it is easier to write one over the other.</p>",
        "id": 262622349,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1637777012
    },
    {
        "content": "<p>If you are relying on reducibility of <code>comp</code>, then you should probably be using the lambda form, with these functions already unfolded</p>",
        "id": 262622531,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1637777120
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span> In my opinion, that greatly reduces the readability of the code. Functions like <code>comp</code>, <code>curry</code>, <code>uncurry</code> are much prettier than their lambda counterparts and much more natural for those coming from a functional programming language background (e.g., Haskell).</p>",
        "id": 262663174,
        "sender_full_name": "Mac",
        "timestamp": 1637810507
    },
    {
        "content": "<p>Yes, I know. Pointfree style is not as well supported in lean as in haskell, but it's not clear how much of that is just a side effect of the fact that haskellers aren't trying to prove facts about their code</p>",
        "id": 262663244,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1637810614
    },
    {
        "content": "<p>For something like <span class=\"user-mention silent\" data-user-id=\"346070\">Tomas Skrivan</span> 's <code>IsLinear</code> typeclass, which consists of a bunch of carefully stated lemmas to prove a nontrivial property about a class of functions using type class inference, I think it is to be expected that the lemma statements have certain constraints on them which may not correspond to \"mathematical naturality\" so to speak. For general lemmas you can usually afford to be more lax</p>",
        "id": 262663366,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1637810763
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span> I feel like this change is unnecessarily bias in a particular direction whereas there are vey good arguments for the opposite approach. I think it would be most helpful if there was both a reducible (or macro) and semi-reducible versions of these functions, since there are times both are useful.</p>",
        "id": 262663405,
        "sender_full_name": "Mac",
        "timestamp": 1637810799
    },
    {
        "content": "<p>a macro that eliminates itself would be ideal, but it might be difficult to get it to do the right thing in all sorts of higher order scenarios (which seems to be the main reason to use it)</p>",
        "id": 262663434,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1637810879
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span> what problems do you foresee? My naive implementation would just be:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">macro</span> <span class=\"o\">(</span><span class=\"n\">priority</span> <span class=\"o\">:=</span> <span class=\"n\">high</span><span class=\"o\">)</span> <span class=\"n\">f</span><span class=\"o\">:</span><span class=\"n\">term</span><span class=\"o\">:</span><span class=\"mi\">91</span> <span class=\"s2\">\" ∘ \"</span> <span class=\"n\">g</span><span class=\"o\">:</span><span class=\"n\">term</span><span class=\"o\">:</span><span class=\"mi\">90</span> <span class=\"o\">:</span> <span class=\"n\">term</span> <span class=\"bp\">=&gt;</span>\n  <span class=\"bp\">`</span><span class=\"o\">(</span><span class=\"k\">fun</span> <span class=\"n\">x</span> <span class=\"bp\">=&gt;</span> <span class=\"bp\">$</span><span class=\"n\">f</span> <span class=\"o\">(</span><span class=\"bp\">$</span><span class=\"n\">g</span> <span class=\"n\">x</span><span class=\"o\">))</span>\n\n<span class=\"kd\">def</span> <span class=\"n\">comp</span> <span class=\"o\">(</span><span class=\"n\">f</span> <span class=\"o\">:</span> <span class=\"n\">β</span> <span class=\"bp\">→</span> <span class=\"n\">δ</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">g</span> <span class=\"o\">:</span> <span class=\"n\">α</span> <span class=\"bp\">→</span> <span class=\"n\">β</span><span class=\"o\">)</span> <span class=\"o\">:=</span> <span class=\"n\">f</span> <span class=\"bp\">∘</span> <span class=\"n\">g</span>\n</code></pre></div>\n<p>This way both sides can be made happy. But I imagine I may be missing something here.</p>",
        "id": 262663628,
        "sender_full_name": "Mac",
        "timestamp": 1637811140
    },
    {
        "content": "<p>If you do something like <code>comp comp comp</code> you will get a bunch of beta redexes</p>",
        "id": 262663648,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1637811173
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span> what do you think of my suggestion?</p>",
        "id": 262663818,
        "sender_full_name": "Mac",
        "timestamp": 1637811409
    },
    {
        "content": "<p>I think the macro is the more Lean-y choice than an abbreviation (e.g. <code>$</code> is also a macro and not a definition).  Note that we already some macros for function composition, you can write <code>(f $ g $ h ·)</code> instead of <code>f ∘ g ∘ h</code>.</p>",
        "id": 262684585,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1637833352
    },
    {
        "content": "<blockquote>\n<p>much more natural for those coming from a functional programming language background (e.g., Haskell).</p>\n</blockquote>\n<p>Whether comp etc. is reducible or not basically only makes a difference when used in type-class arguments or when writing proofs (using simp).  I don't know the current state of dependent haskell, but for a long time you couldn't write type classes like <code>IsLinear</code> at all in haskell.  So I don't think you can bring this as an argument for what haskell users would expect.  (And even then I don't know if ghc reduces <code>∘</code> during type class search).</p>",
        "id": 262685015,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1637833682
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110043\">@Gabriel Ebner</span> fyi, my reference to /Haskell was simply to highlight that there is a subset of programmers who prefer the operator for function composition to its lambda representation, which, in turn, was just a piece of evidence as to why losing the ability to do so in typeclass signatures could be viewed as a feature regression.</p>",
        "id": 262688108,
        "sender_full_name": "Mac",
        "timestamp": 1637835546
    }
]