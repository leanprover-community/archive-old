[
    {
        "content": "<p>I have created a large inductive type with upwards of 260 constructors and noticed slowed compilation times and sluggish VSCode responsiveness (likely a direct consequence). I have since extracted some constructor parameters into separate functions and into different files to get around the problem (it does seem a bit more modular approach anyway). So I am no longer directly impacted by this.</p>\n<p>In any case, I am curious as to how the dev team troubleshoots these and what kinds of tools to use (perf seems to be one of these tools and there was another one someone mentioned here recently). I would be happy if I could figure out how to find the hotspot(s) myself.</p>\n<p>In addition, let me know if the dev team has any interest in this .lean file and I am happy to share it.</p>",
        "id": 285436375,
        "sender_full_name": "Yuri de Wit",
        "timestamp": 1654714086
    },
    {
        "content": "<p>Yes, perf is always a good idea. Just running <code>perf top</code> while editing a file can already give you a good idea.</p>",
        "id": 285438680,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1654715132
    },
    {
        "content": "<p>For big inductives specifically, you might want to try <code>set_option genInjectivity false</code></p>",
        "id": 285438712,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1654715154
    },
    {
        "content": "<p>Setting <code>set_option genInjectivity false</code> improves the performance roughly by around 10%.</p>\n<p>Here is the <code>perf</code> report without the genInjectivity set:<br>\n<a href=\"/user_uploads/3121/XpM6-gStL-yl2hz7tpdr0dmS/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/XpM6-gStL-yl2hz7tpdr0dmS/image.png\" title=\"image.png\"><img src=\"/user_uploads/3121/XpM6-gStL-yl2hz7tpdr0dmS/image.png\"></a></div><p>This is just running a plain <code>perf record lean myfile.lean</code>. So no priming the pump etc. Let me try to run perf top against the Lean server.</p>",
        "id": 285447001,
        "sender_full_name": "Yuri de Wit",
        "timestamp": 1654719123
    },
    {
        "content": "<p>Here is a flamegraph based on a DEBUG version of Lean4.</p>\n<p><a href=\"/user_uploads/3121/bcdNQ8mGcSW4ZTcuHo6qKfWp/AttributeContent.svg\">AttributeContent.svg</a> </p>\n<p>I cant make much sense of it, but maybe somebody else can.</p>",
        "id": 285468032,
        "sender_full_name": "Yuri de Wit",
        "timestamp": 1654732327
    },
    {
        "content": "<p>Long stack traces are truncated, so it's hard to tell where the <code>replace_rec_fn</code> is coming from. Might be the compiler, which you could test with <code>set_option codegen false</code></p>",
        "id": 285496585,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1654760011
    },
    {
        "content": "<p>Though the very first step should probably be running <code>lean</code> with <code>--profile</code></p>",
        "id": 285496623,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1654760038
    },
    {
        "content": "<p>I encountered this issue for enum style inductive types here: <a href=\"https://github.com/leanprover/lean4/issues/654\">https://github.com/leanprover/lean4/issues/654</a>, this was then solved with a specialised code path. I think potentially the general case causes has still the same slowdown.</p>",
        "id": 285548783,
        "sender_full_name": "Christian Pehle",
        "timestamp": 1654787213
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"130511\">@Christian Pehle</span> Note, though, <a href=\"https://github.com/leanprover/lean4/commit/70f2200778bd20ab959d8f99ffa32fde4bbfcfe5\">https://github.com/leanprover/lean4/commit/70f2200778bd20ab959d8f99ffa32fde4bbfcfe5</a></p>",
        "id": 285549324,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1654787408
    },
    {
        "content": "<p>Yes, I didn't find that commit, but as I understood the alternative solution also contains a special case for \"enum\" like inductive types. There was also a Zulip discussion at the time. But I didn't find it.</p>",
        "id": 285553713,
        "sender_full_name": "Christian Pehle",
        "timestamp": 1654789125
    },
    {
        "content": "<p>Ah yes, it's the previous commit skipping stage0 updates <a href=\"https://github.com/leanprover/lean4/commit/a7c621854e0f81707ca5c30cf99727b626c394a1\">https://github.com/leanprover/lean4/commit/a7c621854e0f81707ca5c30cf99727b626c394a1</a></p>",
        "id": 285555474,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1654789914
    },
    {
        "content": "<p>This is the result of compiling with <code>--profile</code> with <code>set_option genInjectivity false</code>:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kn\">import</span> <span class=\"n\">took</span> <span class=\"mi\">118</span><span class=\"n\">ms</span>\n<span class=\"n\">elaboration</span> <span class=\"n\">took</span> <span class=\"mi\">5</span><span class=\"bp\">.</span><span class=\"mi\">61</span><span class=\"n\">s</span>\n<span class=\"n\">cumulative</span> <span class=\"n\">profiling</span> <span class=\"n\">times</span><span class=\"o\">:</span>\n    <span class=\"n\">elaboration</span> <span class=\"mi\">5</span><span class=\"bp\">.</span><span class=\"mi\">61</span><span class=\"n\">s</span>\n    <span class=\"kn\">import</span> <span class=\"mi\">118</span><span class=\"n\">ms</span>\n    <span class=\"n\">initialization</span> <span class=\"mi\">34</span><span class=\"bp\">.</span><span class=\"mi\">4</span><span class=\"n\">ms</span>\n    <span class=\"n\">interpretation</span> <span class=\"mi\">1</span><span class=\"bp\">.</span><span class=\"mi\">43</span><span class=\"n\">ms</span>\n    <span class=\"n\">parsing</span> <span class=\"mi\">5</span><span class=\"bp\">.</span><span class=\"mi\">72</span><span class=\"n\">ms</span>\n    <span class=\"n\">typeclass</span> <span class=\"n\">inference</span> <span class=\"mi\">73</span><span class=\"bp\">.</span><span class=\"mi\">3</span><span class=\"n\">ms</span>\n</code></pre></div>\n<p>And with <code>set_option genInjectivity true</code> (close to no real diff):</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kn\">import</span> <span class=\"n\">took</span> <span class=\"mi\">129</span><span class=\"n\">ms</span>\n<span class=\"n\">elaboration</span> <span class=\"n\">took</span> <span class=\"mi\">5</span><span class=\"bp\">.</span><span class=\"mi\">55</span><span class=\"n\">s</span>\n<span class=\"n\">cumulative</span> <span class=\"n\">profiling</span> <span class=\"n\">times</span><span class=\"o\">:</span>\n    <span class=\"n\">elaboration</span> <span class=\"mi\">5</span><span class=\"bp\">.</span><span class=\"mi\">55</span><span class=\"n\">s</span>\n    <span class=\"kn\">import</span> <span class=\"mi\">129</span><span class=\"n\">ms</span>\n    <span class=\"n\">initialization</span> <span class=\"mi\">30</span><span class=\"bp\">.</span><span class=\"mi\">4</span><span class=\"n\">ms</span>\n    <span class=\"n\">interpretation</span> <span class=\"mi\">1</span><span class=\"bp\">.</span><span class=\"mi\">47</span><span class=\"n\">ms</span>\n    <span class=\"n\">parsing</span> <span class=\"mi\">5</span><span class=\"bp\">.</span><span class=\"mi\">96</span><span class=\"n\">ms</span>\n    <span class=\"n\">typeclass</span> <span class=\"n\">inference</span> <span class=\"mi\">68</span><span class=\"bp\">.</span><span class=\"mi\">9</span><span class=\"n\">ms</span>\n</code></pre></div>\n<p>This is nowhere near the time documented in <a href=\"https://github.com/leanprover/lean4/issues/654\">https://github.com/leanprover/lean4/issues/654</a>.</p>\n<p>Aside from the fact that I am using this as a motivation to learn the compiler etc, the biggest concern would be interactive use cases: it gets annoying fairly quickly. But, that means profiling VSCode + Lean Server instead of this simple batch compilation experiment.</p>",
        "id": 285559339,
        "sender_full_name": "Yuri de Wit",
        "timestamp": 1654791514
    },
    {
        "content": "<p>There shouldn't be any performance difference between the server and batch mode at least</p>",
        "id": 285560523,
        "sender_full_name": "Sebastian Ullrich",
        "timestamp": 1654791961
    }
]