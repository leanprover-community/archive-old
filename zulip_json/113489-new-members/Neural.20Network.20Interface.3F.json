[
    {
        "content": "<p>Hi all,</p>\n<p>I'm an AI PhD student, new to Lean (I have some experience with Agda, and I've played around a bit with the Lean tutorials).  So far I'm really enjoying Lean, thinking of sticking with it long-term.  (Quotient and topological structures in Lean are especially nice!  I've had a lot of trouble dealing with those in Agda in the past.)</p>\n<p>I've read a lot of discussion on here about using neural networks to assist theorem proving in Lean.  But I'm working the other way around:  Use formal verification (say in Lean) to check that a neural network has nice properties.</p>\n<p>My question is:  Is there an already implemented / canonical way to interface neural networks with Lean?  Ideally I'd like to be able to have a neural network written in (say) C++ with Tensorflow, and then do the verification via Lean's FFI.  But I'm aware that Lean's FFI only handles primitive types, so this probably wouldn't work.  Alternatively, I could implement a neural network library in Lean, but I'd really rather not reinvent the wheel.</p>\n<p>Thanks for your time!<br>\nCaleb</p>",
        "id": 305962415,
        "sender_full_name": "Caleb Kisby",
        "timestamp": 1666678391
    },
    {
        "content": "<p>Hi Caleb! I'm not aware of any work having been done in that direction, but that's definitely something that would be very cool (I'd personally be very interested in that)</p>",
        "id": 305965025,
        "sender_full_name": "Paul Lezeau",
        "timestamp": 1666679984
    },
    {
        "content": "<p>In terms of the mathematics needed, Lean definitely has everything you would need to define fully connected neural networks</p>",
        "id": 305965242,
        "sender_full_name": "Paul Lezeau",
        "timestamp": 1666680116
    },
    {
        "content": "<p>Welcome <span class=\"user-mention\" data-user-id=\"556217\">@Caleb Kisby</span> . There are a few projects which use NNs in conjunction with Lean. Off the top of my head, we have <a class=\"stream\" data-stream-id=\"274007\" href=\"/#narrow/stream/274007-lean-gptf\">#lean-gptf</a> , which is a stream you might want to subscribe to. There is also Azerbayev and Ayers' Lean Chat, see <a href=\"https://xenaproject.wordpress.com/2022/08/16/the-future-of-interactive-theorem-proving/\">this blog post</a>.</p>",
        "id": 305965355,
        "sender_full_name": "Bolton Bailey",
        "timestamp": 1666680172
    },
    {
        "content": "<p>You might also be interested in the <a class=\"stream\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving\">#Machine Learning for Theorem Proving</a> stream</p>",
        "id": 305965384,
        "sender_full_name": "Bolton Bailey",
        "timestamp": 1666680195
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"556217\">@Caleb Kisby</span> what sort of mathematical properties of neural networks would you be studying ?</p>",
        "id": 305965592,
        "sender_full_name": "Paul Lezeau",
        "timestamp": 1666680324
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"376152\">@Paul Lezeau</span> Well, sure, I could implement it myself.  I suppose I'm hoping there's a nice library or FFI way to avoid me writing it from scratch (plus, this would make it easier for people to plug their own net into my system!).</p>\n<p>Thanks for the welcome and suggestions <span class=\"user-mention\" data-user-id=\"282271\">@Bolton Bailey</span>!  I'll check out the Lean Chat github to see how they interface the net.</p>",
        "id": 305965873,
        "sender_full_name": "Caleb Kisby",
        "timestamp": 1666680478
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"556217\">@Caleb Kisby</span> That's fair enough ! But I'm sure that's something you could get other people interested in working on with you were you to end up doing it ;)</p>",
        "id": 305966149,
        "sender_full_name": "Paul Lezeau",
        "timestamp": 1666680639
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"376152\">@Paul Lezeau</span> Whoops, I missed your very first comment (I'm new to Zulip)!  I didn't mean to be rude :-)</p>\n<p>At the moment I have a humble modal logic with modalities T ('typically', interpreted as the neural network's activation pattern on an input) and [P+] (interpreted as a Hebbian update operator on the net).  The idea is that axioms stated in this language express properties about what the net finds typical after unsupervised (Hebbian) learning, e.g.<br>\n[P+}TQ -&gt; T[P+]Q<br>\nsays (roughly) \"if after learning P, the neural network predicts Q, then the neural network would have expected Q in the first place\"</p>",
        "id": 305966871,
        "sender_full_name": "Caleb Kisby",
        "timestamp": 1666681037
    },
    {
        "content": "<p>The language is basic, and I'm still figuring out what things it can express.  But I do have soundness results, and I'm starting by implementing these (hopefully in Lean).  Plus, since it's a modal logic it's at least decidable. <br>\n(Shameless plug for my paper:  <a href=\"https://journals.flvc.org/FLAIRS/article/download/130735/133901\">https://journals.flvc.org/FLAIRS/article/download/130735/133901</a>)</p>",
        "id": 305967160,
        "sender_full_name": "Caleb Kisby",
        "timestamp": 1666681159
    },
    {
        "content": "<p>So technically I'd like to prove in Lean properties of the <em>logic</em>, but the logic is defined using functions from the neural network.  I might just bite the bullet and whip up a quick ANN in Lean... <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span></p>",
        "id": 305968213,
        "sender_full_name": "Caleb Kisby",
        "timestamp": 1666681667
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"556217\">Caleb Kisby</span> <a href=\"#narrow/stream/113489-new-members/topic/Neural.20Network.20Interface.3F/near/305966871\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"376152\">Paul Lezeau</span> Whoops, I missed your very first comment (I'm new to Zulip)!  I didn't mean to be rude :-)</p>\n<p>At the moment I have a humble modal logic with modalities T ('typically', interpreted as the neural network's activation pattern on an input) and [P+] (interpreted as a Hebbian update operator on the net).  The idea is that axioms stated in this language express properties about what the net finds typical after unsupervised (Hebbian) learning, e.g.<br>\n[P+}TQ -&gt; T[P+]Q<br>\nsays (roughly) \"if after learning P, the neural network predicts Q, then the neural network would have expected Q in the first place\"</p>\n</blockquote>\n<p>No worries at all;)</p>",
        "id": 305968824,
        "sender_full_name": "Paul Lezeau",
        "timestamp": 1666681970
    },
    {
        "content": "<p>I had no area this kind of stuff was being researched in AI, that's pretty cool!</p>",
        "id": 305968869,
        "sender_full_name": "Paul Lezeau",
        "timestamp": 1666681992
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"556217\">Caleb Kisby</span> <a href=\"#narrow/stream/113489-new-members/topic/Neural.20Network.20Interface.3F/near/305968213\">said</a>:</p>\n<blockquote>\n<p>So technically I'd like to prove in Lean properties of the <em>logic</em>, but the logic is defined using functions from the neural network.  I might just bite the bullet and whip up a quick ANN in Lean... <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span></p>\n</blockquote>\n<p>I see ! Well that's definitely something I'm interested in so feel free to ping me if you ever want someone to have a look at you code;)</p>",
        "id": 305969135,
        "sender_full_name": "Paul Lezeau",
        "timestamp": 1666682156
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"556217\">@Caleb Kisby</span> You might be interested in <a href=\"https://github.com/dselsam/certigrad\">https://github.com/dselsam/certigrad</a></p>",
        "id": 305969217,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1666682176
    },
    {
        "content": "<p>Right!?  At the moment, there are only a handful of people bridging connectionism and logic in this specific way -- I'm sort of resuscitating some forgotten work from the 90's, since it's helpful to the neuro-symbolic crowd.  Thanks for the support, I'll keep you updated!</p>",
        "id": 305969363,
        "sender_full_name": "Caleb Kisby",
        "timestamp": 1666682269
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"112680\">Johan Commelin</span> <a href=\"#narrow/stream/113489-new-members/topic/Neural.20Network.20Interface.3F/near/305969217\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"556217\">Caleb Kisby</span> You might be interested in <a href=\"https://github.com/dselsam/certigrad\">https://github.com/dselsam/certigrad</a></p>\n</blockquote>\n<p>Whoah, nice!  And they have Lean code for training a neural network!  This might be exactly what I was hoping for <span aria-label=\"smile cat\" class=\"emoji emoji-1f638\" role=\"img\" title=\"smile cat\">:smile_cat:</span></p>",
        "id": 305970082,
        "sender_full_name": "Caleb Kisby",
        "timestamp": 1666682591
    },
    {
        "content": "<p>In the <a href=\"#narrow/stream/113489-new-members/topic/starting.20Lean.20and.20Lean.20version\">recent thread</a> <span class=\"user-mention\" data-user-id=\"416965\">@Martin (egLanghaus)</span>  is interested in somewhat similar thing i.e. reasoning about neural networks.</p>",
        "id": 305972140,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1666683477
    },
    {
        "content": "<p>Currently reading the ONNX and ONNX-ML syntax and semantics <a href=\"https://github.com/onnx/onnx/blob/main/docs/IR.md\">here</a>.</p>\n<p>Goal is to read actual architectures into Lean and prove input/output relations with an eye toward XAI (explainability), and to check if in fact (as has been claimed) that DNNs are so complex as to make interactive proof assistants useless in verifying them.</p>",
        "id": 305976763,
        "sender_full_name": "Martin (egLanghaus)",
        "timestamp": 1666685426
    }
]