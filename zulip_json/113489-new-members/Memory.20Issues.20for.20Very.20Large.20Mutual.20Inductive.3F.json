[
    {
        "content": "<p>Hi , Lean Scrub here. I'm working with my colleagues to embed a rapidly growing DSL in Lean. We're tied into Lean as we needs its excellent semantics/math formalisms.  Right now, I'm running into pesky \"excessive memory consumption\" issues stemming from maybe 800-1000 LOC and a few ~100-200 line mutual inductives. These mutual inductives might need to reach &gt; 1000 LOC (maybe a few thousand, if possible). Maybe I'm being stupid, but I can't find any way online to increase the memory allocated to Lean. More info: Developing out of VSCode with the Lean plugin on an Ubuntu Docker. Is increasing the memory even an option? Any pointers or documentation on how to do that? Would compiling instead be the way to go for us? Sorry to bother and greatly appreciate any help!</p>",
        "id": 205003581,
        "sender_full_name": "Andrew Elsey",
        "timestamp": 1595682967
    },
    {
        "content": "<p>You can increase the <code>Lean: Memory Limit</code> option in VSCode, which defaults to something like 4gb iirc.</p>",
        "id": 205003671,
        "sender_full_name": "Rob Lewis",
        "timestamp": 1595683157
    },
    {
        "content": "<p>Oh duh, see that. Thank you! That's a little scary, however...if I'm running into memory issues at 4gb, when we scale to an order of magnitude+, it sounds like our only hope is compiling?</p>",
        "id": 205004047,
        "sender_full_name": "Andrew Elsey",
        "timestamp": 1595683820
    },
    {
        "content": "<p>I certainly recommend putting stuff in different files and compiling them. It will give some speedup. Not sure if it will save much memory, though.</p>",
        "id": 205004068,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1595683911
    },
    {
        "content": "<p>I guess we'll probably have to go that route. Great, thank you for the information!</p>",
        "id": 205004422,
        "sender_full_name": "Andrew Elsey",
        "timestamp": 1595684580
    },
    {
        "content": "<p>Also, hopefully, you've seen the various tales of woe and warning about working with <code>mutual</code> here, and considered the advice that usually it's better to avoid that keyword and just \"roll your own\"?</p>",
        "id": 205004964,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1595685499
    },
    {
        "content": "<p>I haven't, actually. Not sure what you mean by roll my own. If you have any protips, they're very welcome. The issue is a lot of our grammar productions interact with each other, and have the potential to become very big, so mutual seems ostensibly necessary in my limited understanding</p>",
        "id": 205006147,
        "sender_full_name": "Andrew Elsey",
        "timestamp": 1595687497
    },
    {
        "content": "<p>Mutual inductive types are automatically unraveled by lean 3 into inductive types, but humans can sometimes do this process better -- \"rolling their own\".</p>",
        "id": 205006614,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1595688222
    },
    {
        "content": "<p>Okay, thanks, I'll look into it!</p>",
        "id": 205007931,
        "sender_full_name": "Andrew Elsey",
        "timestamp": 1595690243
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"301362\">@Andrew Elsey</span> I describe the general technique in <a href=\"#narrow/stream/113489-new-members/topic/Another.20basic.20question.3A.20prove.20equality.20of.20inductive.20type.20arg/near/200314611\">this post</a></p>",
        "id": 205011474,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1595695761
    },
    {
        "content": "<p>Thanks Mario, that's a huge help, I'm going to try to apply that</p>",
        "id": 205012788,
        "sender_full_name": "Andrew Elsey",
        "timestamp": 1595697546
    }
]