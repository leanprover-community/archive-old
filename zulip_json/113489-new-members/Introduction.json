[
    {
        "content": "<p>Hi Lean community, I just joined the Zulip and I'm excited to get to know you all. I've been working on automated theorem proving for about 1.5 years, and I'm mainly interested in the goal of translating natural language into Lean. Nice to meet you all!</p>",
        "id": 258977314,
        "sender_full_name": "Cody Johnson",
        "timestamp": 1635176231
    },
    {
        "content": "<p>Does anyone know what happened to Hales' work on a controlled natural language for Lean?</p>",
        "id": 258983359,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1635178746
    },
    {
        "content": "<p>I know that Barnet-Lamb has also been thinking about this kind of thing, relating the Ganelasingham work to Lean.</p>",
        "id": 258983454,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1635178801
    },
    {
        "content": "<p>Hi <span class=\"user-mention\" data-user-id=\"400362\">@Cody Johnson</span>!   What does \"translating natural language into Lean\" mean to you?  As for what I mean, here are some possible interpretations:</p>\n<ol>\n<li>Automatically translate natural language math (either statements, definitions, and/or proofs) into Lean code (<em>auto-formalization</em> as it is sometimes called).</li>\n<li>Manually convert math (usually definitions and theorem statements) into something resembling natural language  (<em>controlled natural language</em>), but which is also machine readable and convertible automatically to Lean code.</li>\n<li>Take a math theorem and it's proof and formalize it in Lean or another formal proof language.</li>\n</ol>",
        "id": 259033479,
        "sender_full_name": "Jason Rute",
        "timestamp": 1635203992
    },
    {
        "content": "<p>Hi <span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> , I'd say 1. My (admittedly over-ambitious) goal is to be able to take raw English/LaTeX and automatically output the Lean code it represents. In order to do this, I've been analyzing commonly used words and phrases in math proofs and using it to specify a PEG grammar for English/LaTeX.</p>",
        "id": 259035680,
        "sender_full_name": "Cody Johnson",
        "timestamp": 1635206110
    },
    {
        "content": "<p>I bet it's impossible to write a nice grammar that is actually useful to convert real-world papers from natural language to Lean.</p>",
        "id": 259035957,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1635206376
    },
    {
        "content": "<p>Yeah, it's sure challenging. I'm currently trying to translate some existing papers just as an exercise to see firsthand what makes it so hard.</p>",
        "id": 259036205,
        "sender_full_name": "Cody Johnson",
        "timestamp": 1635206554
    },
    {
        "content": "<p>I tend to agree with Yury.  I do think modern neural language modeling is nearly up for the task however.  The big challenges are (1) lack of good data (in particular low amounts of Lean data), and (2) for any statement about a new or uncommon mathematical idea, you have to formalize the definition as well so it isn't really like natural language translation.</p>",
        "id": 259036330,
        "sender_full_name": "Jason Rute",
        "timestamp": 1635206678
    },
    {
        "content": "<p>I guess, it might be possible to use machine learning to extract some statement (and AFAIR someone was working on this) but I have no experience with machine learning.</p>",
        "id": 259036346,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1635206691
    },
    {
        "content": "<p>If we also have a cucumber-style way to state Lean theorems (should be possible with new Lean 4 macro features), a mathematician without Lean background should be able to proofread the output.</p>",
        "id": 259036466,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1635206804
    },
    {
        "content": "<p>One problem with neural language modeling is they aren't able to get 100% accuracy which this problem really needs. At very least you'd need your neural nets to be able to identify when they're outputting junk for people to be able to trust them for peer review (false positives). I think grammar based approaches are able to achieve this accuracy, plus with PCFG methods you're able to interact with the user and say \"I tried to translate this and got it wrong. Did you mean ____?\" Plus grammars are pretty mature, for instance the Penn Treebank system is almost 30 years old.</p>",
        "id": 259036734,
        "sender_full_name": "Cody Johnson",
        "timestamp": 1635207099
    },
    {
        "content": "<p>Szegedy's N2Formal team at Google has been interested in this for a while.  Their manifesto is <a href=\"https://doi.org/10.1007/978-3-030-53518-6_1\">A Promising Path Towards Autoformalization and General Artificial Intelligence</a>  (It used to be freely available as a preprint, but I guess not anymore.)  Also, they have a talk about some partial progress (where they ran into a lot of roadblocks).  It is the last talk on <a href=\"http://grid01.ciirc.cvut.cz/~mptp/zoomaitp/2020-09-15%2014.01.06%20AITP%202020%2099935445683/zoom_1.mp4\">this group of AITP 2020 talks</a>.</p>\n<p>Further, Josef Urban, Qingxiang Wang, et al  have been playing around with this for a while.  I think they have some impressive smaller scale results, for example <a href=\"https://arxiv.org/abs/1805.06502\">First Experiments with Neural Translation of Informal to Formal Mathematics</a> and other results by Qingxiang Wang.</p>",
        "id": 259036839,
        "sender_full_name": "Jason Rute",
        "timestamp": 1635207207
    },
    {
        "content": "<p>Sure accuracy is an issue (and sometime even an issue in human interpretation of mathematics because of subtleties), but I personally think of grammars and the like as only ever being able to reach a small local maximum.  We need more flexible tools to handle the messiness of natural language, and then we need to improve those tools to give better results.</p>",
        "id": 259037034,
        "sender_full_name": "Jason Rute",
        "timestamp": 1635207374
    },
    {
        "content": "<p>But I also don't mean to get into a flame war here.  (I did that once and it wasn't fun.)  I'm happy to disagree and be proved wrong later.</p>",
        "id": 259037072,
        "sender_full_name": "Jason Rute",
        "timestamp": 1635207442
    },
    {
        "content": "<p>An important problem with reading (and formalizing) natural language proof is that something like this is acceptable in a paper: “The following lemma was proved in [5] for $C^2$ smooth functions. The proof works with minor modifications for $C^{2+\\alpha}$ smooth functions and gives the following estimates.”, where [5] is a 50-pages long paper and there is neither theorem nor page number in the reference.</p>",
        "id": 259037150,
        "sender_full_name": "Yury G. Kudryashov",
        "timestamp": 1635207516
    },
    {
        "content": "<p>And \"minor modifications\" is often an understatement.</p>",
        "id": 259037256,
        "sender_full_name": "Jason Rute",
        "timestamp": 1635207612
    },
    {
        "content": "<p>This is the exact reason why automated peer review is so important, for catching things like these.</p>",
        "id": 259101572,
        "sender_full_name": "Cody Johnson",
        "timestamp": 1635257410
    },
    {
        "content": "<p>I mean, I don't think \"catching\" is the right word here. The reviewers read that sentence, and probably knew perfectly well that [5] is 50-pages long and required modifications. A good reviewer would have even spent some time thinking about whether they believed the changes would be \"easy\". Everyone involved, author/reviewer/editor/reader would be unhappy if they were told that one wasn't allowed to do this.</p>",
        "id": 259180093,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1635294827
    }
]