[
    {
        "content": "<p>Greetings! I am brand new to Lean, I just completed the natural number game, great fun. I am totally on-board with this general project though, I think it's great.</p>\n<p>I am a researcher in the general field of mathematical optimization. I prove theorems about algorithms like gradient descent. As far as I know, <em>almost no one</em> in the math programming community is using Lean. Am I wrong? Does anyone know of formalizations of, for example, the proof that gradient descent converges to a minimizer of a smooth convex function? Or that the convergence rate is 1/k... </p>\n<p>I feel this is completely open territory... The proofs in math optimization are very algebra heavy and ripe for automation. Yet I don't see anyone doing it. Perhaps there are reasons. Perhaps no one could be bothered yet. Or there were no tools like Lean...</p>\n<p>Anyway, if anyone knows of work in Lean related to proving convergence properties of optimization algorithms like gradient descent, Newton's method etc. let me know.</p>\n<p>Thanks,</p>",
        "id": 253962527,
        "sender_full_name": "Patrick Johnstone",
        "timestamp": 1632075976
    },
    {
        "content": "<p>To put your \"as far as I know\" into some kind of context, almost no-one in any mathematical community is using any theorem prover at all.</p>",
        "id": 253962656,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1632076130
    },
    {
        "content": "<p>One thing I discovered very early on is that you can just do stuff which is regarded as totally basic in your field, but do it in a theorem prover, and then get a publication :D (because nobody did anything like it before)</p>",
        "id": 253962680,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1632076169
    },
    {
        "content": "<p>Hey! <span class=\"user-mention silent\" data-user-id=\"214703\">Yury G. Kudryashov</span>, <span class=\"user-mention silent\" data-user-id=\"311453\">Frédéric Dupuis</span>, <span class=\"user-mention silent\" data-user-id=\"240862\">Oliver Nash</span>, <span class=\"user-mention silent\" data-user-id=\"308899\">Yakov Pechersky</span>  and myself (at least! hope I didn't forget anyone) are working on and around convex analysis. I don't know about convex optimization specifically.</p>",
        "id": 253962793,
        "sender_full_name": "Yaël Dillies",
        "timestamp": 1632076263
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"441939\">@Patrick Johnstone</span> There is <a href=\"https://github.com/dselsam/certigrad\">https://github.com/dselsam/certigrad</a> by <span class=\"user-mention\" data-user-id=\"230999\">@Daniel Selsam</span> .</p>",
        "id": 253963158,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1632076649
    },
    {
        "content": "<p>There is a youtube talk about this as well, by Daniel</p>",
        "id": 253963192,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1632076681
    },
    {
        "content": "<p>Thank you! This is definitely along the lines of what I'm interested in. Although I don't think they proved convergence of the optimization algorithm, but they do prove the method produces the right stochastic gradients, which is neat.</p>",
        "id": 253963618,
        "sender_full_name": "Patrick Johnstone",
        "timestamp": 1632077094
    },
    {
        "content": "<p>That's good to know. Would these be publications in journals related to formal verification? Or in the field of the work itself. Because I don't know how optimization people would react to theorem provers, they might not be welcoming.</p>",
        "id": 253966038,
        "sender_full_name": "Patrick Johnstone",
        "timestamp": 1632079561
    },
    {
        "content": "<p>Right, journals related to formal verification (if you are pushing these systems to do things they've never done before)</p>",
        "id": 253966102,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1632079596
    },
    {
        "content": "<p>Journals and conference proceedings (which is a standard venue for publication in computer science).</p>",
        "id": 253966133,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1632079649
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"129120\">@Alexander Bentkamp</span> and I have begun to explore another way of using proof assistants to solve optimization problems: <a href=\"http://www.andrew.cmu.edu/user/avigad/Papers/verified_optimization_wip_paper.pdf\">http://www.andrew.cmu.edu/user/avigad/Papers/verified_optimization_wip_paper.pdf</a>. We argue that applied mathematics is a natural market for formal methods. They allow you to specify complex models more precisely and use symbolic and numeric software more rigorously.</p>",
        "id": 253975648,
        "sender_full_name": "Jeremy Avigad",
        "timestamp": 1632089760
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110865\">Jeremy Avigad</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/253975648\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"129120\">Alexander Bentkamp</span> and I have begun to explore another way of using proof assistants to solve optimization problems: <a href=\"http://www.andrew.cmu.edu/user/avigad/Papers/verified_optimization_wip_paper.pdf\">http://www.andrew.cmu.edu/user/avigad/Papers/verified_optimization_wip_paper.pdf</a>. We argue that applied mathematics is a natural market for formal methods. They allow you to specify complex models more precisely and use symbolic and numeric software more rigorously.</p>\n</blockquote>\n<p>Great, thanks. Do you have a github for this project yet? </p>\n<p>My interest is more in convergence proofs for optimization algorithms -  since that's what my research focuses on. But it's definitely related to what you are working on.</p>",
        "id": 253987313,
        "sender_full_name": "Patrick Johnstone",
        "timestamp": 1632102199
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"387244\">Yaël Dillies</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/253962793\">said</a>:</p>\n<blockquote>\n<p>Hey! <span class=\"user-mention silent\" data-user-id=\"214703\">Yury G. Kudryashov</span>, <span class=\"user-mention silent\" data-user-id=\"311453\">Frédéric Dupuis</span>, <span class=\"user-mention silent\" data-user-id=\"240862\">Oliver Nash</span>, <span class=\"user-mention silent\" data-user-id=\"308899\">Yakov Pechersky</span>  and myself (at least! hope I didn't forget anyone) are working on and around convex analysis. I don't know about convex optimization specifically.</p>\n</blockquote>\n<p>Great, I don't think you can do much convex optimization without at least some basic convex analysis.</p>",
        "id": 253987383,
        "sender_full_name": "Patrick Johnstone",
        "timestamp": 1632102256
    },
    {
        "content": "<p>I think it's a great time for this sort of stuff to be formalised. When we transition to Lean 4 (\"soon\"), it will be possible to write algorithms that run fast, and prove theorems about them, in the same language.</p>\n<p>(That said, algorithms that involve manipulating real numbers are hard to formalise naively, because floats are horrible.)</p>",
        "id": 254008991,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1632123436
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/254008991\">said</a>:</p>\n<blockquote>\n<p>I think it's a great time for this sort of stuff to be formalised. When we transition to Lean 4 (\"soon\"), it will be possible to write algorithms that run fast, and prove theorems about them, in the same language.</p>\n<p>(That said, algorithms that involve manipulating real numbers are hard to formalise naively, because floats are horrible.)</p>\n</blockquote>\n<p>I hadn't thought about the floating point issue before. In optimization we simply prove theorems about infinite precision algorithms. Normally not a care in the world goes into the fact that we actually implement them with floats. </p>\n<p>When you say floats are horrible, has anyone tried to formalize floats in lean? Like have a float datatype and prove stuff about them?</p>",
        "id": 254142154,
        "sender_full_name": "Patrick Johnstone",
        "timestamp": 1632186751
    },
    {
        "content": "<p>mathlib is fine for proving theorems about infinite precision algorithms --- of course they can't be run, so my point about Lean4 being fast is irrelevant.</p>\n<p>I'm not an expert on the float datatype. My understanding is that there are astonishingly few true theorems about it. :-)</p>",
        "id": 254145944,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1632190236
    },
    {
        "content": "<p>There is <a href=\"https://leanprover-community.github.io/mathlib_docs/data/fp/basic.html\">docs#data.fp.basic</a></p>",
        "id": 254147207,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1632191347
    },
    {
        "content": "<p>which hasn't been touched in years</p>",
        "id": 254147300,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1632191406
    },
    {
        "content": "<p>there are even a few low hanging fruits in that file requiring a proof (they were postponed because the proofs weren't the focus); all the <code>meta def</code>s are only <code>meta</code> because they use <code>undefined</code> instead of <code>sorry</code></p>",
        "id": 254147381,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1632191498
    },
    {
        "content": "<p>So basically we can prove that your algorithms work in theory, but not in practice :-)</p>",
        "id": 254160548,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1632205175
    },
    {
        "content": "<p>I don't think the finite precision issue is a deal-breaker. I had a look today and there are a few optimization papers on the effects of finite precision, but mostly this is not studied. Probably there is just a lot of accumulated wisdom and empirical experience that round off errors tend to be benign for optimization algorithms, so it's not attractive to study theoretically.</p>",
        "id": 254299127,
        "sender_full_name": "Patrick Johnstone",
        "timestamp": 1632271094
    },
    {
        "content": "<p>And when you do have true theorems about floats, there's still lots of room for bugs to creep in in the gap between what the true theorems actually say and what you need for the real algorithm implementation in some programming language.</p>\n<p>There are lots of new floating-point functions in the next (2023) version of the C standard, many of which I've been implementing for glibc. For some of those functions, it's convenient to use a standard floating-point technique (round-to-odd), the correctness of which is the subject of a true theorem (formalized in Coq some years ago). Despite the functions being simple and the implementation technique being formally verified, I've found quite a few bugs in the implementations that  come in some way from that gap between the theorem and the implementation (sometimes in parts of the gap that might be a lot harder to formalize than floating point itself) - including bugs that survived in some functions for a few years between when I originally implemented them and when I recently discovered them accidentally while implementing more such functions.</p>",
        "id": 254615472,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1632436007
    },
    {
        "content": "<p>Hi all,<br>\nI have been tinkering with Lean in my spare time for the last few months. </p>\n<p>I wanted to clarify some things I've gathered in my reading: if I define a function from \\R\\to\\R, Lean cannot #eval it, correct? </p>\n<p>Like, even for \"computable\" functions like f(x)=2*x or f(x)=x+5 or f(x)=sin(x). These are \"computable\" according to certain definitions of Turing machines over the reals. I understand that a real number has potentially infinitely many digits, so computable here means informally \"can compute an arbitrary number of digits\".</p>\n<p>So if I write <br>\n#eval (λ x:ℝ,x) 14</p>\n<p>then I am doomed to get gibberish. </p>\n<p>And further, there is no way to \"force\" lean to just use floating point representations? I see that there is a native.float type, so one could potentially just define a flag and switch everything over to native.float if one wants to do any computation...</p>\n<p>I assume the certigrad code has a way around this, because they prove stuff about their code assuming infinite precision reals but then allow computation using an external linear algebra package. I had a brief look through the code but couldn't fully understand it. I think they somehow defines their own \"real numbers\" and lists a bunch of axioms it must satisfy.  </p>\n<p>Thanks for your help in advance...</p>",
        "id": 266478407,
        "sender_full_name": "Patrick Johnstone",
        "timestamp": 1640921548
    },
    {
        "content": "<p>Yup, currently in Lean 3 you can not compute with <code>ℝ</code> directly. If you want to compute, you need to use tactics that do the computation for you.</p>",
        "id": 266485443,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1640932626
    },
    {
        "content": "<p>In fact, you can do a bit of computations with reals if you're lucky and the functions happen to be computable according to Lean, but mathlib has not been designed to keep computable real functions computable.</p>",
        "id": 266506454,
        "sender_full_name": "Anne Baanen",
        "timestamp": 1640961112
    },
    {
        "content": "<p>The gibberish that you're getting is because <a href=\"https://leanprover-community.github.io/mathlib_docs/find/real\">docs#real</a> is defined as some quotient of cauchy sequences, so you're seeing the <code>λ</code> term defining the sequence</p>",
        "id": 266506513,
        "sender_full_name": "Anne Baanen",
        "timestamp": 1640961191
    },
    {
        "content": "<p>You can define a custom <a href=\"https://leanprover-community.github.io/mathlib_docs/find/has_repr\">docs#has_repr</a> instance to convert it to a readable string:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kn\">import</span> <span class=\"n\">data.real.basic</span>\n\n<span class=\"kd\">instance</span> <span class=\"o\">:</span> <span class=\"n\">has_repr</span> <span class=\"n\">ℝ</span> <span class=\"o\">:=</span>\n<span class=\"o\">{</span> <span class=\"n\">repr</span> <span class=\"o\">:=</span> <span class=\"bp\">λ</span> <span class=\"n\">x</span><span class=\"o\">,</span> <span class=\"n\">x.cauchy.lift</span> <span class=\"o\">(</span><span class=\"bp\">λ</span> <span class=\"o\">(</span><span class=\"n\">xs</span> <span class=\"o\">:</span> <span class=\"n\">cau_seq</span> <span class=\"n\">ℚ</span> <span class=\"n\">abs</span><span class=\"o\">),</span> <span class=\"n\">repr</span> <span class=\"o\">(</span><span class=\"n\">xs.1</span> <span class=\"mi\">100</span><span class=\"o\">))</span>\n  <span class=\"gr\">sorry</span> <span class=\"c\">/-</span><span class=\"cm\"> this is actually not true (since `0.9999...` and `1.000...` should have the same `repr` but don't if we don't round the value above -/</span> <span class=\"o\">}</span>\n\n<span class=\"k\">#eval</span> <span class=\"o\">(</span><span class=\"mi\">1</span> <span class=\"bp\">+</span> <span class=\"mi\">1</span> <span class=\"o\">:</span> <span class=\"n\">ℝ</span><span class=\"o\">)</span> <span class=\"c1\">-- 2</span>\n</code></pre></div>",
        "id": 266506688,
        "sender_full_name": "Anne Baanen",
        "timestamp": 1640961438
    },
    {
        "content": "<p>Just don't try <code>#eval (1/2 + 1/2 : ℝ) </code>.</p>\n<p>Think about it in general: in Lean we defined pi to be twice the smallest positive real root of the cosine function. Then pi is an uncomputable but well-defined real number (we proved cos(0)=1, cos(2)&lt;0 and that cos was continuous). What can <code>#eval</code> do with this? We proved a lot of theorems about pi such as sin(n*pi)=0 etc but it was quite a long time before we proved pi&gt;3; this was not necessary for any trig computations. We did happen to know that cos(1)&gt;0 and that cos was decreasing on [0,2] so it wasn't too hard to deduce from this that <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>2</mn><mo>&lt;</mo><mi>π</mi><mo>&lt;</mo><mn>4</mn></mrow><annotation encoding=\"application/x-tex\">2&lt;\\pi&lt;4</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6835em;vertical-align:-0.0391em;\"></span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">4</span></span></span></span> but that was all we had for quite some time (even though we had a bunch of theorems about trig functions and pi)</p>",
        "id": 266507417,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1640962352
    },
    {
        "content": "<p>Is Lean 4 different?</p>",
        "id": 266508309,
        "sender_full_name": "Patrick Johnstone",
        "timestamp": 1640963375
    },
    {
        "content": "<p>Not in this regard!</p>",
        "id": 266508828,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1640963936
    },
    {
        "content": "<p>Real numbers are not floats. You have to think about them in a totally different way. They are the uncountable type which mathematicians use. Mathematicians can prove theorems about real numbers without ever having some kind of algorithm which can be used to write down an expression which attempts to represent, or approximate, the real number. I'm assuming you're expecting an answer in base 10. But this is a purely human construct. Real numbers are abstract objects in Lean. Floats are totally different. There are only finitely many and they do not satisfy the axioms of e.g. an abelian group; they are a highly imperfect representation of the reals. Mathematicians do not need that representation to prove theorems about or involving real numbers.</p>",
        "id": 266508958,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1640964093
    },
    {
        "content": "<p>A (maybe simpler) example are the natural numbers, which usually have an inductive definition in formal systems (being zero or the successor of a natural number). This definition is sufficient to prove results about natural numbers, but it's not the best representation for actually performing operations on the natural numbers.</p>\n<p>For the later purpose, a low level byte array would be more suitable for the CPU. Hence the difference between, say, <code>UInt32</code> and <code>Nat</code> in Lean 4. And again, a mathematical limitation that's similar to the one that Kevin pointed out arises. <code>UInt32</code> can't represent infinite numbers and may overflow. You can think of <code>Float</code> and <code>UInt32</code> as computational tricks for mimicking mathematical objects like the real and natural numbers respectively.</p>",
        "id": 266511181,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1640966755
    },
    {
        "content": "<p>Thanks. Makes sense. So I suppose there is little support for \"floating point extraction\"? I.e: define an algorithm/function in Lean for the Reals, prove stuff about it, then extract a floating point approximation in another language or in Lean itself.</p>",
        "id": 266511634,
        "sender_full_name": "Patrick Johnstone",
        "timestamp": 1640967324
    },
    {
        "content": "<p>There's nothing like that in Lean 3 or 4 but I'm sure other people would be interested. For computational real numbers I should think you'd be much better off with Coq right now.</p>",
        "id": 266511724,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1640967460
    },
    {
        "content": "<p>On that direction, Lean 4 supports accessing low level (C) implementations via FFI. For example:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[extern \"c_sqrt_sqrt\"]</span> <span class=\"kd\">def</span> <span class=\"n\">sqrtSqrt</span> <span class=\"o\">(</span><span class=\"n\">x</span> <span class=\"o\">:</span> <span class=\"n\">Float</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">Float</span> <span class=\"o\">:=</span>\n  <span class=\"n\">Float.sqrt</span> <span class=\"o\">(</span><span class=\"n\">Float.sqrt</span> <span class=\"n\">x</span><span class=\"o\">)</span>\n</code></pre></div>\n<p>You would be able to reason and prove results about <code>sqrtSqrt</code> in Lean, but executing <code>sqrtSqrt</code> would trigger a computation on a function called <code>c_sqrt_sqrt</code> that you would need to provide C code for (and call it that way). The responsibility for the consistency of the result, however, would be totally on the author of the C implementation.</p>",
        "id": 266512071,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1640967853
    },
    {
        "content": "<p>Then if you wanted to write functions on <code>ℝ^n → Float</code>, you would need to unwrap (the term adopted by the FFI is actually \"unbox\") the real number representation in C, extract a <code>double</code> from it, perform the computations and return the result</p>",
        "id": 266512412,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1640968259
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"441939\">Patrick Johnstone</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/266511634\">said</a>:</p>\n<blockquote>\n<p>Thanks. Makes sense. So I suppose there is little support for \"floating point extraction\"? I.e: define an algorithm/function in Lean for the Reals, prove stuff about it, then extract a floating point approximation in another language or in Lean itself.</p>\n</blockquote>\n<p>What I'm currently doing is to define reals as <code>def Real := Float</code> and just postulate that <code>Real</code> form a field. This way you keep the computability(executing with floats) and still be able to do proofs about <code>Real</code>. </p>\n<p>Doing this can maybe(I do not know) introduce inconsistency i.e. ability to prove <code>False</code>. However, I was unable to do so as everything about <code>Float</code> is hidden behind <code>constant</code>.</p>",
        "id": 266563202,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1641052675
    },
    {
        "content": "<p>I'd guess that rounding and loss of significance/cancellation make this approach inconsistent somehow</p>",
        "id": 266563526,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1641053085
    },
    {
        "content": "<p>But are you actually able to prove <code>False</code>? I don't think so. Of course, the program might not be doing what you have proven it is supposed to be doing because of the rounding errors.</p>",
        "id": 266563786,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1641053489
    },
    {
        "content": "<p>You are proving only computations on some hypothetical machine capable of computing with reals. If you can prove, in addition, that your program is a continuous function, then you have a proof that the program is doing the correct thing in the limit of infinite precision.</p>",
        "id": 266563901,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1641053649
    },
    {
        "content": "<p>I would guess that due to cancellation one might be able to proof that two things that are not actually equally are equal due to the field axioms? But I'm unsure whether the framework around floats allows for that.</p>",
        "id": 266564069,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1641053995
    },
    {
        "content": "<p>Can you prove that <code>1.0 + 0.1 = 1.1</code>? I do not know how.</p>\n<p>What about this:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">def</span> <span class=\"n\">x</span> <span class=\"o\">:</span> <span class=\"n\">Float</span> <span class=\"o\">:=</span> <span class=\"mi\">1</span><span class=\"bp\">.</span><span class=\"mi\">0000000000000000000000</span>\n<span class=\"kd\">def</span> <span class=\"n\">y</span> <span class=\"o\">:</span> <span class=\"n\">Float</span> <span class=\"o\">:=</span> <span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">00000000000000000000001</span>\n\n<span class=\"kd\">example</span> <span class=\"o\">:</span> <span class=\"o\">(</span><span class=\"n\">x</span> <span class=\"bp\">+</span> <span class=\"n\">y</span><span class=\"o\">)</span> <span class=\"bp\">-</span> <span class=\"n\">x</span> <span class=\"bp\">=</span> <span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">0</span> <span class=\"o\">:=</span> <span class=\"gr\">sorry</span>   <span class=\"c1\">-- If you can prove this then using `Real := Float` is bad</span>\n<span class=\"kd\">example</span> <span class=\"o\">:</span> <span class=\"o\">(</span><span class=\"n\">x</span> <span class=\"bp\">+</span> <span class=\"n\">y</span><span class=\"o\">)</span> <span class=\"bp\">-</span> <span class=\"n\">x</span> <span class=\"bp\">=</span> <span class=\"n\">y</span>   <span class=\"o\">:=</span> <span class=\"gr\">sorry</span>   <span class=\"c1\">-- You can prove this using `Real := Float`</span>\n</code></pre></div>",
        "id": 266564137,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1641054082
    },
    {
        "content": "<p>Yeah that's exactly what I don't know either :/</p>",
        "id": 266564142,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1641054112
    },
    {
        "content": "<p>What about trying to prove that <code>y^2=0</code>?  Is that any easier?</p>",
        "id": 266564290,
        "sender_full_name": "Damiano Testa",
        "timestamp": 1641054347
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"321459\">Damiano Testa</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/266564290\">said</a>:</p>\n<blockquote>\n<p>What about trying to prove that <code>y^2=0</code>?  Is that any easier?</p>\n</blockquote>\n<p>I do not think so, exponentiation on floats is defined as: (in Lean 4, probably similarly in Lean 3 too)</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">@[extern \"pow\"]</span> <span class=\"kd\">constant</span> <span class=\"n\">Float.pow</span> <span class=\"o\">:</span> <span class=\"n\">Float</span> <span class=\"bp\">→</span> <span class=\"n\">Float</span> <span class=\"bp\">→</span> <span class=\"n\">Float</span>\n</code></pre></div>\n<p>i.e. with constant so you are not able to prove anything about it. You just know some kind of function like that exists.</p>",
        "id": 266564398,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1641054490
    },
    {
        "content": "<p>I suspect that operations involving floats are ultimately hidden behind the FFI. It's not like you can get to the bottom of things in terms of Lean declarations</p>",
        "id": 266564561,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1641054833
    },
    {
        "content": "<p>Yes exactly, so the interesting question is: If you postulate that <code>Float</code> form a field, can you prove <code>False</code>?</p>",
        "id": 266564732,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1641055083
    },
    {
        "content": "<p>I don't think so. The problem is that you wouldn't account for floating point errors, which would most certainly break your consistency in practice</p>",
        "id": 266564856,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1641055304
    },
    {
        "content": "<p>If you can't, then I would argue that postulating <code>Float</code> as a field(maybe additionally Archimedean property and completenes to really get reals) is a viable option how to approach computations with reals.</p>\n<p>To actually prove that your program is doing what you have proven in the limit of infinite precision. You would have to, for example, show that your program is continuous. Even better, if you prove your program to be Lipshitz, then you can have some meaningful bound on the error.</p>",
        "id": 266564924,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1641055404
    },
    {
        "content": "<p>Not a serious trouble if you're satisfied with C's <code>double</code> precision</p>",
        "id": 266564925,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1641055407
    },
    {
        "content": "<p>Yeah, the approach I see as most complete is offering some guarantee of error boundary</p>",
        "id": 266564990,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1641055528
    },
    {
        "content": "<p>So you'd formally account for imprecisions</p>",
        "id": 266565058,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1641055627
    },
    {
        "content": "<p>But not having this guarantee wouldn't stop me from using your package if needed :D</p>",
        "id": 266565164,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1641055803
    },
    {
        "content": "<p>I would assume you cannot prove everything about reals just because you postulate that <code>Float</code> is a field and treating it like reals though right?</p>",
        "id": 266565198,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1641055877
    },
    {
        "content": "<p>So the interesting question to me would be, what additional things would you need to actually treat <code>Float</code> like a real.</p>",
        "id": 266565275,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1641055998
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"395550\">Henrik Böving</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/266565198\">said</a>:</p>\n<blockquote>\n<p>I would assume you cannot prove everything about reals just because you postulate that <code>Float</code> is a field and treating it like reals though right?</p>\n</blockquote>\n<p>Well you need these <a href=\"https://en.wikipedia.org/wiki/Construction_of_the_real_numbers#Axioms\">axioms</a>, i.e. field + total order + compatibility of order and arithmetic + completeness.</p>",
        "id": 266565337,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1641056095
    },
    {
        "content": "<p>Floats satisfy very few of these axioms though, or am I misunderstanding this conversation?</p>",
        "id": 266565474,
        "sender_full_name": "Marc Huisinga",
        "timestamp": 1641056283
    },
    {
        "content": "<p>This requires one additional data: <code>sup</code> of a bounded sets. Everything else should be in <code>Prop</code>.</p>",
        "id": 266565476,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1641056284
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"221921\">Marc Huisinga</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/266565474\">said</a>:</p>\n<blockquote>\n<p>Floats satisfy very few of these axioms though, or am I misunderstanding this conversation?</p>\n</blockquote>\n<p>Floats don't even qualify as a field if you view at the actual values they produce, however (at least in Lean 4) float operations are (this is an hypothesis of us) exposed in a way that doesn't allow you to actually reason about them to the point where you could show that the assumption that float is a field is inconsistent. This would in theory allow value extraction from computation on reals by just treating Float like reals.</p>",
        "id": 266565592,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1641056421
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"221921\">Marc Huisinga</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/266565474\">said</a>:</p>\n<blockquote>\n<p>Floats satisfy very few of these axioms though, or am I misunderstanding this conversation?</p>\n</blockquote>\n<p>Yes they don't, but the question is: can you prove <code>False</code> if you postulate these axioms about floats? If not, you can treat <code>Float</code> as reals and keep your programs runnable.</p>",
        "id": 266565634,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1641056455
    },
    {
        "content": "<p>So basically instead of the current mathlib approach to reals we would have a typeclass <code>Real</code> that is a combination of these 4 structures and then just <code>instance : Real Float := sorry</code>(well not exactly sorry, we would have to put the operations there and sorry the laws out), which should allow real functions to just be used with float input right?</p>",
        "id": 266565718,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1641056592
    },
    {
        "content": "<p>Addition on float is provably not associative so if you assume it is then surely you can prove false</p>",
        "id": 266565808,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1641056746
    },
    {
        "content": "<p>We are aware of that, but the way that it is exposed in Lean 4 is as a <code>constant</code> so you cannot actually prove anything about addition on floats.</p>",
        "id": 266565855,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1641056811
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"395550\">Henrik Böving</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/266565718\">said</a>:</p>\n<blockquote>\n<p>So basically instead of the current mathlib approach to reals we would have a typeclass <code>Real</code> that is a combination of these 4 structures and then just <code>instance : Real Float := sorry</code>(well not exactly sorry, we would have to put the operations there and sorry the laws out), which should allow real functions to just be used with float input right?</p>\n</blockquote>\n<p>Hmm, in my current code I just do <code>def Real := Float</code> and then provide <code>instance : Add Real := Float.add</code> etc. and postulate <code>instance : Field Real := { ... := sorry }</code>(I make sure that I sorry only Prop)</p>",
        "id": 266565870,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1641056848
    },
    {
        "content": "<p>Are you saying you can't prove e.g. <code>0 ≠ 1</code> in <code>float</code>?</p>",
        "id": 266565924,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1641056895
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/266565924\">said</a>:</p>\n<blockquote>\n<p>Are you saying you can't prove e.g. <code>0 ≠ 1</code> in <code>float</code>?</p>\n</blockquote>\n<p>At least, I do not know how.</p>",
        "id": 266565938,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1641056941
    },
    {
        "content": "<p>That I don't know, but I'm saying you cannot prove: <code>1 + 0 = 1</code> or <code>1 * 1 = 1</code> in float due to the way the API is built.</p>",
        "id": 266565946,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1641056958
    },
    {
        "content": "<p>It seems a lot easier to me to just make your algorithms polymorphic on the underlying type, assuming <code>HasAdd</code> <code>HasMul</code> etc on that type, show that they are correct for a mathematical definition of the reals, and then run them for Float? Am I missing something?</p>",
        "id": 266565953,
        "sender_full_name": "Alex J. Best",
        "timestamp": 1641056972
    },
    {
        "content": "<p>Does <code>float</code> not have decidable equality?</p>",
        "id": 266566005,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1641057031
    },
    {
        "content": "<p>Lean 4 says it doesn't, I'd have to check for lean 3</p>",
        "id": 266566012,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1641057049
    },
    {
        "content": "<p>I just tried <code>example : (0.0 : Float) ≠ (1.0 : Float) := by simp [OfScientific.ofScientific, Float.ofBinaryScientific]</code> in Lean 4 and it broke my server <span aria-label=\"upside down\" class=\"emoji emoji-1f643\" role=\"img\" title=\"upside down\">:upside_down:</span></p>",
        "id": 266566089,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1641057160
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/266565808\">said</a>:</p>\n<blockquote>\n<p>Addition on float is provably not associative so if you assume it is then surely you can prove false</p>\n</blockquote>\n<p>The thing is that all Float operations in Lean 4 are constants, so you know nothing about them except that the type is inhabited. You can use them to evaluate stuff, but for the purpose of proof, they're just as good as arbitrary types. So postulating that they have certain structure should be fine (as long as what you postulated isn't inconsistent itself).<br>\nThat said, I'm not sure if this approach is super practical. My intuition is that things with floats can go wrong badly, even if your proof over reals says that things are fine.<br>\nIf I wanted to build a model of floats that's practical for proofs, I'd probably go for something like <a href=\"http://smtlib.cs.uiowa.edu/papers/BTRW15.pdf\">http://smtlib.cs.uiowa.edu/papers/BTRW15.pdf</a>, and not try to model them as bit vectors.</p>",
        "id": 266566106,
        "sender_full_name": "Marc Huisinga",
        "timestamp": 1641057203
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"127136\">Alex J. Best</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/266565953\">said</a>:</p>\n<blockquote>\n<p>It seems a lot easier to me to just make your algorithms polymorphic on the underlying type, assuming <code>HasAdd</code> <code>HasMul</code> etc on that type, show that they are correct for a mathematical definition of the reals, and then run them for Float? Am I missing something?</p>\n</blockquote>\n<p>Yes but what if I wanted to e.g. reason about the derivative of my function? Surely one would want to use the mathlib tools that are available for this right? But this is not possible with these type class constraints. If we instead made <code>Real</code> itself a typeclass and provide an instance for <code>Float</code> where the axioms are sorried out (which is hopefully valid, we don't know this for sure) and mathlib would switch to this approach on reals one should be able to reason about the derivative of a function of the form: <code>(R : Type) [Real R] : R -&gt; R</code> using mathlib tools AND compute it using floats.</p>",
        "id": 266566109,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1641057219
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"127136\">Alex J. Best</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/266565953\">said</a>:</p>\n<blockquote>\n<p>It seems a lot easier to me to just make your algorithms polymorphic on the underlying type, assuming <code>HasAdd</code> <code>HasMul</code> etc on that type, show that they are correct for a mathematical definition of the reals, and then run them for Float? Am I missing something?</p>\n</blockquote>\n<p>If you really want to run the algorithm, you might not trust the specializer enough or you might want to do things that don't generalize (e.g. using unboxed arrays of <code>Float</code>).</p>",
        "id": 266566174,
        "sender_full_name": "Reid Barton",
        "timestamp": 1641057314
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"395550\">Henrik Böving</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/266566012\">said</a>:</p>\n<blockquote>\n<p>Lean 4 says it doesn't, I'd have to check for lean 3</p>\n</blockquote>\n<p>In lean 4 there is <code>floatDecLe</code> for decidable le though, so you could give a decidable equality check assuming the le relation was irreflexive</p>",
        "id": 266566386,
        "sender_full_name": "Alex J. Best",
        "timestamp": 1641057647
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"451983\">Arthur Paulino</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/266566089\">said</a>:</p>\n<blockquote>\n<p>I just tried <code>example : (0.0 : Float) ≠ (1.0 : Float) := by simp [OfScientific.ofScientific, Float.ofBinaryScientific]</code> in Lean 4 and it broke my server <span aria-label=\"upside down\" class=\"emoji emoji-1f643\" role=\"img\" title=\"upside down\">:upside_down:</span></p>\n</blockquote>\n<p>I don't know why it broke the server, but <code>ofScientific</code> and the like also use constants, such as <code>scaleB</code>. The same should be true for equality; see <a href=\"https://github.com/leanprover/lean4/blob/b65da42b7ec7cf25e97a111a48f0a662a27fe02a/src/Init/Data/Float.lean#L30\">this</a> (the type used for Floats, here Unit, is hidden behind a constant), so I think you can do nothing with Float equality at the proof level either.</p>",
        "id": 266566557,
        "sender_full_name": "Marc Huisinga",
        "timestamp": 1641057943
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"221921\">Marc Huisinga</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/266566106\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/266565808\">said</a>:</p>\n<blockquote>\n<p>Addition on float is provably not associative so if you assume it is then surely you can prove false</p>\n</blockquote>\n<p>The thing is that all Float operations in Lean 4 are constants, so you know nothing about them except that the type is inhabited. You can use them to evaluate stuff, but for the purpose of proof, they're just as good as arbitrary types. So postulating that they have certain structure should be fine (as long as what you postulated isn't inconsistent itself).<br>\nThat said, I'm not sure if this approach is super practical. My intuition is that things with floats can go wrong badly, even if your proof over reals says that things are fine.<br>\nIf I wanted to build a model of floats that's practical for proofs, I'd probably go for something like <a href=\"http://smtlib.cs.uiowa.edu/papers/BTRW15.pdf\">http://smtlib.cs.uiowa.edu/papers/BTRW15.pdf</a>, and not try to model them as bit vectors.</p>\n</blockquote>\n<p>Let me be a bit adversarial here :) All these approaches(those I have seen) to model errors of floating point arithmetic in my opinion/for what I want to do  are really unsatisfactory. They usually deal with simple arithmetic expression involving handful of variables. I want do to numerical linear algebra and have some proper bounds on the error.</p>\n<p>I want to see some framework that can give me some proper bounds on floating point arithmetic in Conjugate Gradient(CG) method or GMRES. (I took a full semester course on studying floating point errors in Conjugate Gradient method. It was super tough and we didn't even dare to analyze GMRES)</p>\n<p>Until someone provides me such a framework, I will just not bother proving anything about floating point arithmetic and just follow best practices to hopefully dodge any/most problems with it.</p>",
        "id": 266566688,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1641058118
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110032\">Reid Barton</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/266566174\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"127136\">Alex J. Best</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/266565953\">said</a>:</p>\n<blockquote>\n<p>It seems a lot easier to me to just make your algorithms polymorphic on the underlying type, assuming <code>HasAdd</code> <code>HasMul</code> etc on that type, show that they are correct for a mathematical definition of the reals, and then run them for Float? Am I missing something?</p>\n</blockquote>\n<p>If you really want to run the algorithm, you might not trust the specializer enough or you might want to do things that don't generalize (e.g. using unboxed arrays of <code>Float</code>).</p>\n</blockquote>\n<p>What does trusting the specializer mean in this context?<br>\nThe second reason definitely makes sense though, but I would in that situation definitely trust a proof that an implementation with unboxed array of floats agrees with a reference implementation that is correct for reals.</p>",
        "id": 266566763,
        "sender_full_name": "Alex J. Best",
        "timestamp": 1641058206
    },
    {
        "content": "<p>Trust in the sense that it will deliver good performance, of course correctness is not in question.<br>\nThe generic implementation (look up the <code>add</code> method in the class dictionary and call it via a function pointer, while passing boxed <code>Float</code>s) might be ~1000 times as expensive as the specialized/inlined implementation (a single instruction).</p>",
        "id": 266566986,
        "sender_full_name": "Reid Barton",
        "timestamp": 1641058613
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"395550\">Henrik Böving</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/266566109\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"127136\">Alex J. Best</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/266565953\">said</a>:</p>\n<blockquote>\n<p>It seems a lot easier to me to just make your algorithms polymorphic on the underlying type, assuming <code>HasAdd</code> <code>HasMul</code> etc on that type, show that they are correct for a mathematical definition of the reals, and then run them for Float? Am I missing something?</p>\n</blockquote>\n<p>Yes but what if I wanted to e.g. reason about the derivative of my function? Surely one would want to use the mathlib tools that are available for this right? But this is not possible with these type class constraints. If we instead made <code>Real</code> itself a typeclass and provide an instance for <code>Float</code> where the axioms are sorried out (which is hopefully valid, we don't know this for sure) and mathlib would switch to this approach on reals one should be able to reason about the derivative of a function of the form: <code>(R : Type) [Real R] : R -&gt; R</code> using mathlib tools AND compute it using floats.</p>\n</blockquote>\n<p>I certainly agree that having a typeclass that is equivalent to <code>real</code> is a good thing (I even wrote one for lean 3), I just don't still understand why Float needs to have an instance <code>Real Float</code> to do what you are saying, looking at the definition of <code>has_deriv_at</code> in lean 3 <a href=\"https://leanprover-community.github.io/mathlib_docs/find/has_deriv_at\">docs#has_deriv_at</a> the type of the function <code>f</code> is <code>f : 𝕜 → F</code>, so if you define polymorphic functions <code>def f {T :Type} [Add T] [Mul T] .. </code> which only use the data fields of the <code>Real</code> typeclass you can reason about their derivatives over fields satisfying the axioms, but still evaluate them on floats.</p>",
        "id": 266567017,
        "sender_full_name": "Alex J. Best",
        "timestamp": 1641058673
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"127136\">Alex J. Best</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/266567017\">said</a>:</p>\n<blockquote>\n<p>I certainly agree that having a typeclass that is equivalent to <code>real</code> is a good thing (I even wrote one for lean 3), I just don't still understand why Float needs to have an instance <code>Real Float</code> to do what you are saying, looking at the definition of <code>has_deriv_at</code> in lean 3 <a href=\"https://leanprover-community.github.io/mathlib_docs/find/has_deriv_at\">docs#has_deriv_at</a> the type of the function <code>f</code> is <code>f : 𝕜 → F</code>, so if you define polymorphic functions <code>def f {T :Type} [Add T] [Mul T] .. </code> which only use the data fields of the <code>Real</code> typeclass you can reason about their derivatives over fields satisfying the axioms, but still evaluate them on floats.</p>\n</blockquote>\n<p>I do not have a solid reason for it, but I would certainly get tired of typing <code>[Add T] [Mul T] [Sub T] [Neg T] [Inv T] [HPow T Nat T] ...</code>, of course I can define  <code>class RealData (T : Type) extends Add T, Mul T ...</code>. Still I would get tired of writing <code>foo {X} [RealData X] (x : X)</code> instead of <code>foo (x : Real)</code></p>\n<p>I'm playing around with differentiable programming and some of my function definitions look like this:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">def</span> <span class=\"n\">foo</span> <span class=\"o\">(</span><span class=\"n\">f</span> <span class=\"o\">:</span> <span class=\"o\">(</span><span class=\"n\">ℝ</span> <span class=\"bp\">⟿</span> <span class=\"n\">ℝ</span><span class=\"o\">))</span> <span class=\"o\">(</span><span class=\"n\">t</span> <span class=\"o\">:</span> <span class=\"n\">ℝ</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"o\">(</span><span class=\"n\">ℝ</span> <span class=\"bp\">⟿</span> <span class=\"n\">ℝ</span><span class=\"o\">)</span> <span class=\"o\">:=</span> <span class=\"bp\">...</span>\n</code></pre></div>\n<p>where <code>(ℝ ⟿ ℝ)</code> is a set of all smooth function from reals to reals. Of course, I could have definition like <code>def foo (f : (X -&gt; X)) (t : X) : (X -&gt; X)</code> and then provide a theorem that if <code>f : X -&gt; X</code> is smooth then <code>foo f t</code> is smooth. Again, this is too much additional typing that I do not want to do, plus it is making things look more complicated then they truly are.</p>",
        "id": 266567711,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1641059693
    },
    {
        "content": "<p>You could have a <code>variable {ℝ: Type} [RealData ℝ]</code> at the top of your file / section....or agree on some default representation of reals that is actually exported as <code>Real</code>.</p>",
        "id": 266568035,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1641060173
    },
    {
        "content": "<p>But you can't have <code>(ℝ ⟿ ℝ)</code> because that requires notion of differentiability that you can't define if you only have <code>RealData</code>.</p>",
        "id": 266568617,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1641061185
    },
    {
        "content": "<p>You certainly can't define differentiability on <code>float</code> though ;-)</p>",
        "id": 266568667,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1641061221
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/266568667\">said</a>:</p>\n<blockquote>\n<p>You certainly can't define differentiability on <code>float</code> though ;-)</p>\n</blockquote>\n<p><span aria-label=\"grinning\" class=\"emoji emoji-1f600\" role=\"img\" title=\"grinning\">:grinning:</span> That is the whole point of the discussion. With the definition of <code>Float</code> as it is in Lean 4 you can hopefully postulate all axioms of real numbers without getting into inconsistency and thus you can define differentiability on <code>Float</code>.</p>",
        "id": 266568760,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1641061384
    },
    {
        "content": "<p>And what would it say?</p>",
        "id": 266568767,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1641061411
    },
    {
        "content": "<p>What would be the point, though? Aren't you just proving things about \\R at that point, rather than about floats?</p>",
        "id": 266569079,
        "sender_full_name": "Ruben Van de Velde",
        "timestamp": 1641061917
    },
    {
        "content": "<p>The usual stuff, definition through a limit. Probably using somewhere non-computable function <code>sup</code> defined on bounded sets that would just be postulated to exist. <code>Float</code> would effectively turn into reals for any sake formal reasoning. <br>\nThe way I see it now:</p>\n<ol>\n<li><code>Float</code> is type representing floating point numbers, it is defined though constants therefore you can't do any form of reasoning.  Like proving <code>1.0 + 0.1 = 1.1</code> but you can do computations <code>#eval (1.1 : Float) + (0.1 : Float)</code></li>\n<li><code>real</code> in mathlib is completely non-computational(not 100% sure about this). You can't do <code>#eval (1 : real) + (0.1 : real)</code> but can prove <code>1.0 + 0.1 = 1.1</code> in <code>real</code></li>\n</ol>\n<p>Why not to merge these two types together? Define <code>def Real := Float</code> and postulate axioms of real numbers on <code>Real</code>. Now you can prove stuff about <code>Real</code> and do computations with <code>#eval</code>. What you prove will not 100% correspond to what you compute with <code>#eval</code> but I still find it useful.</p>",
        "id": 266569220,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1641062133
    },
    {
        "content": "<p>The reason not to merge the types together is presumably because, as you've just shown, they're completely different objects :-) Attempting to identify them is probably dangerous in terms of consistency?</p>",
        "id": 266575909,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1641072120
    },
    {
        "content": "<p>I feel like we are arguing in a circle :) sure I'm worried about consistency too. If you can prove <code>False</code> from assuming axioms of reals on <code>Float</code> then I will agree it is a bad idea. However, many people want extract runable code by replacing reals with floats. This can be easily done by merging these two types together as I propose.</p>",
        "id": 266576912,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1641073499
    },
    {
        "content": "<p>Can you make a MWE of what you propose?</p>",
        "id": 266576943,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1641073552
    },
    {
        "content": "<p>And perhaps put it in another thread? We're talking about Lean 4, right? How about you start in the lean 4 stream with a mwe of what you propose to do and then perhaps other people can have some fun trying to prove <code>false</code> from it. This conversation has drifted and the current thread/stream are no longer appropriate.</p>",
        "id": 266577003,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1641073606
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/266576943\">said</a>:</p>\n<blockquote>\n<p>Can you make a MWE of what you propose?</p>\n</blockquote>\n<p><a href=\"#narrow/stream/270676-lean4/topic/Treating.20.60Float.60.20as.20reals.2C.20inconsistent.3F\">Here it is</a> and in a new thread as you suggested.</p>",
        "id": 266579398,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1641076179
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"127136\">Alex J. Best</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/266565953\">said</a>:</p>\n<blockquote>\n<p>It seems a lot easier to me to just make your algorithms polymorphic on the underlying type, assuming <code>HasAdd</code> <code>HasMul</code> etc on that type, show that they are correct for a mathematical definition of the reals, and then run them for Float? Am I missing something?</p>\n</blockquote>\n<p>I really like this idea. Here is my beginner attempt at making gradient descent polymorphic</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">def</span> <span class=\"n\">gd_poly</span> <span class=\"o\">(</span><span class=\"n\">α</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span><span class=\"o\">)</span>\n            <span class=\"o\">(</span><span class=\"n\">hsub</span> <span class=\"o\">:</span> <span class=\"n\">has_sub</span> <span class=\"n\">α</span><span class=\"o\">)</span>\n            <span class=\"o\">(</span><span class=\"n\">hmul</span> <span class=\"o\">:</span> <span class=\"n\">has_mul</span> <span class=\"n\">α</span><span class=\"o\">)</span>\n            <span class=\"o\">(</span><span class=\"n\">η</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">x0</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">gradf</span> <span class=\"o\">:</span> <span class=\"n\">α</span> <span class=\"bp\">→</span> <span class=\"n\">α</span><span class=\"o\">):</span> <span class=\"o\">(</span><span class=\"n\">ℕ</span> <span class=\"bp\">→</span> <span class=\"n\">α</span><span class=\"o\">)</span>\n<span class=\"bp\">|</span> <span class=\"mi\">0</span>      <span class=\"o\">:=</span> <span class=\"n\">x0</span>\n<span class=\"bp\">|</span> <span class=\"o\">(</span><span class=\"n\">n</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span>  <span class=\"o\">:=</span> <span class=\"n\">gd_poly</span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"o\">)</span> <span class=\"bp\">-</span> <span class=\"n\">η</span><span class=\"bp\">*</span><span class=\"n\">gradf</span><span class=\"o\">(</span><span class=\"n\">gd_poly</span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"o\">))</span>\n</code></pre></div>",
        "id": 266583768,
        "sender_full_name": "Patrick Johnstone",
        "timestamp": 1641081991
    },
    {
        "content": "<p>Then </p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"k\">#check</span> <span class=\"n\">gd_poly</span> <span class=\"n\">ℝ</span> <span class=\"n\">real.has_sub</span> <span class=\"n\">real.has_mul</span> <span class=\"o\">(</span><span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">1</span> <span class=\"o\">:</span> <span class=\"n\">ℝ</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"mi\">2</span> <span class=\"o\">:</span> <span class=\"n\">ℝ</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"bp\">λ</span> <span class=\"n\">x</span><span class=\"o\">:</span><span class=\"n\">ℝ</span><span class=\"o\">,</span><span class=\"n\">x</span><span class=\"o\">)</span> <span class=\"mi\">10</span>\n</code></pre></div>\n<p>and</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"k\">#eval</span> <span class=\"n\">gd_poly</span> <span class=\"n\">native.float</span> <span class=\"n\">native.float.has_sub</span> <span class=\"n\">native.float.has_mul</span> <span class=\"o\">(</span><span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">1</span> <span class=\"o\">:</span> <span class=\"n\">native.float</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"mi\">2</span> <span class=\"o\">:</span> <span class=\"n\">native.float</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"bp\">λ</span> <span class=\"n\">x</span><span class=\"o\">:</span><span class=\"n\">native.float</span><span class=\"o\">,</span><span class=\"n\">x</span><span class=\"o\">)</span> <span class=\"mi\">10</span>\n</code></pre></div>\n<p>seem to work, although verbose.</p>",
        "id": 266583842,
        "sender_full_name": "Patrick Johnstone",
        "timestamp": 1641082099
    },
    {
        "content": "<p>You can omit the type class instances (has_sub and has_mul) by passing them in <code>[]</code> instead of <code>()</code> which will let the type class system figure them out for you.ALso since the arguments already contain the type <code>α</code> you can make it implicit by putting in in <code>{}</code> instead of <code>()</code> which will let lean figure the type argument out based on the arguments, that way it should become  a lot less verbose already <span class=\"user-mention\" data-user-id=\"441939\">@Patrick Johnstone</span></p>",
        "id": 266586768,
        "sender_full_name": "Henrik Böving",
        "timestamp": 1641086756
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"395550\">Henrik Böving</span> <a href=\"#narrow/stream/113489-new-members/topic/Patrick.20Johnstone.20.28mathematical.20optimizer.29/near/266586768\">said</a>:</p>\n<blockquote>\n<p>You can omit the type class instances (has_sub and has_mul) by passing them in <code>[]</code> instead of <code>()</code> which will let the type class system figure them out for you.ALso since the arguments already contain the type <code>α</code> you can make it implicit by putting in in <code>{}</code> instead of <code>()</code> which will let lean figure the type argument out based on the arguments, that way it should become  a lot less verbose already <span class=\"user-mention silent\" data-user-id=\"441939\">Patrick Johnstone</span></p>\n</blockquote>\n<p>Much better, see below, thanks.</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">def</span> <span class=\"n\">gd_poly</span> <span class=\"o\">{</span><span class=\"n\">α</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span><span class=\"o\">}</span>\n            <span class=\"o\">[</span><span class=\"n\">has_sub</span> <span class=\"n\">α</span><span class=\"o\">]</span>\n            <span class=\"o\">[</span><span class=\"n\">has_mul</span> <span class=\"n\">α</span><span class=\"o\">]</span>\n            <span class=\"o\">(</span><span class=\"n\">η</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">x0</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">gradf</span> <span class=\"o\">:</span> <span class=\"n\">α</span> <span class=\"bp\">→</span> <span class=\"n\">α</span><span class=\"o\">):</span> <span class=\"o\">(</span><span class=\"n\">ℕ</span> <span class=\"bp\">→</span> <span class=\"n\">α</span><span class=\"o\">)</span>\n<span class=\"bp\">|</span> <span class=\"mi\">0</span>      <span class=\"o\">:=</span> <span class=\"n\">x0</span>\n<span class=\"bp\">|</span> <span class=\"o\">(</span><span class=\"n\">n</span><span class=\"bp\">+</span><span class=\"mi\">1</span><span class=\"o\">)</span>  <span class=\"o\">:=</span> <span class=\"n\">gd_poly</span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"o\">)</span> <span class=\"bp\">-</span> <span class=\"n\">η</span><span class=\"bp\">*</span><span class=\"n\">gradf</span><span class=\"o\">(</span><span class=\"n\">gd_poly</span><span class=\"o\">(</span><span class=\"n\">n</span><span class=\"o\">))</span>\n\n<span class=\"k\">#eval</span> <span class=\"n\">gd_poly</span> <span class=\"o\">(</span><span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">1</span> <span class=\"o\">:</span> <span class=\"n\">native.float</span><span class=\"o\">)</span> <span class=\"mi\">2</span> <span class=\"o\">(</span><span class=\"bp\">λ</span> <span class=\"n\">x</span><span class=\"o\">,</span><span class=\"n\">x</span><span class=\"o\">)</span> <span class=\"mi\">15</span>\n<span class=\"k\">#check</span> <span class=\"n\">gd_poly</span> <span class=\"o\">(</span><span class=\"mi\">0</span><span class=\"bp\">.</span><span class=\"mi\">1</span> <span class=\"o\">:</span> <span class=\"n\">ℝ</span><span class=\"o\">)</span> <span class=\"mi\">2</span> <span class=\"o\">(</span><span class=\"bp\">λ</span> <span class=\"n\">x</span><span class=\"o\">,</span><span class=\"n\">x</span><span class=\"o\">)</span> <span class=\"mi\">10</span>\n</code></pre></div>",
        "id": 266624430,
        "sender_full_name": "Patrick Johnstone",
        "timestamp": 1641144887
    },
    {
        "content": "<p>I am newbie to lean and i just set it up in vs code, but when i open it it says 'waiting for lean server to start'. Could anyone among you please tell what the problem is and how to solve it</p>",
        "id": 266625484,
        "sender_full_name": "Fadil Ahmed",
        "timestamp": 1641146400
    },
    {
        "content": "<p>Can you please ask this question in a new thread? This is about something else. My guess is that you've not used VS Code's \"open folder\" functionality to open a lean project. You can't just open a random lean file and expect it to work.</p>",
        "id": 266625999,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1641147021
    }
]