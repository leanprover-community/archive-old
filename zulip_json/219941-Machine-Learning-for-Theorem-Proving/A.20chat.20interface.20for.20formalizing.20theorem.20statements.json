[
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"121918\">@Edward Ayers</span> and I have developed an OpenAI Codex-powered chat interface for formalizing natural language theorem statements. The interface is a widget that runs in the Lean infoview. Here is an example of a multi-turn conversation with the bot: </p>\n<p><a href=\"/user_uploads/3121/HhZp2em64JvhA1KMS6sJNWCr/Screenshot-from-2022-06-15-17-41-10.png\">Screenshot-from-2022-06-15-17-41-10.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/HhZp2em64JvhA1KMS6sJNWCr/Screenshot-from-2022-06-15-17-41-10.png\" title=\"Screenshot-from-2022-06-15-17-41-10.png\"><img src=\"/user_uploads/3121/HhZp2em64JvhA1KMS6sJNWCr/Screenshot-from-2022-06-15-17-41-10.png\"></a></div><p>Our repo is <a href=\"https://github.com/zhangir-azerbayev/lean-chat\">here</a>. </p>\n<p>Unfortunately, you need an OpenAI API key to use the interface,  but we hope that in a future version you won't. In the meantime, I'm happy to run any suggestions from the replies on my machine. I've tried this bot on some exercises from undergraduate textbooks, and in my experience thus far it gets about 25% of statements correct  on the first try and about 75% correct with further suggestions. </p>\n<p>If you're curious about what's under the hood, we're wrapping the user input in a few shot prompt before querying the OpenAI API.  The current version of the interface is still very much in the proof of concept stage, so please point out any bugs or glitches you find. </p>\n<p>We were inspired by the <a href=\"https://arxiv.org/abs/2205.12615\">Autoformalization with Large Language Models</a> paper from the N2Formal group at Google.</p>",
        "id": 286282648,
        "sender_full_name": "Zhangir Azerbayev",
        "timestamp": 1655331775
    },
    {
        "content": "<p>Very cool looking project!  Can you try these hard examples that <span class=\"user-mention\" data-user-id=\"110865\">@Jeremy Avigad</span> often uses to talk about <a href=\"https://www.andrew.cmu.edu/user/avigad/Talks/ioannina.pdf#page=46\">type inference in natural mathematics</a>? <a href=\"/user_uploads/3121/LdQFe3b0KSGnxzlL9366D7Tt/Screen-Shot-2022-06-15-at-10.09.18-PM.png\">Screen-Shot-2022-06-15-at-10.09.18-PM.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/LdQFe3b0KSGnxzlL9366D7Tt/Screen-Shot-2022-06-15-at-10.09.18-PM.png\" title=\"Screen-Shot-2022-06-15-at-10.09.18-PM.png\"><img src=\"/user_uploads/3121/LdQFe3b0KSGnxzlL9366D7Tt/Screen-Shot-2022-06-15-at-10.09.18-PM.png\"></a></div>",
        "id": 286298402,
        "sender_full_name": "Jason Rute",
        "timestamp": 1655345488
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"284997\">Zhangir Azerbayev</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/A.20chat.20interface.20for.20formalizing.20theorem.20statements/near/286282648\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"121918\">Edward Ayers</span> and I have developed an OpenAI Codex-powered chat interface for formalizing natural language theorem statements. The interface is a widget that runs in the Lean infoview. Here is an example of a multi-turn conversation with the bot: </p>\n<p><a href=\"/user_uploads/3121/HhZp2em64JvhA1KMS6sJNWCr/Screenshot-from-2022-06-15-17-41-10.png\">Screenshot-from-2022-06-15-17-41-10.png</a></p>\n<p>Our repo is <a href=\"https://github.com/zhangir-azerbayev/lean-chat\">here</a>. </p>\n<p>Unfortunately, you need an OpenAI API key to use the interface,  but we hope that in a future version you won't. In the meantime, I'm happy to run any suggestions from the replies on my machine. I've tried this bot on some exercises from undergraduate textbooks, and in my experience thus far it gets about 25% of statements correct  on the first try and about 75% correct with further suggestions. </p>\n<p>If you're curious about what's under the hood, we're wrapping the user input in a few shot prompt before querying the OpenAI API.  The current version of the interface is still very much in the proof of concept stage, so please point out any bugs or glitches you find. </p>\n<p>We were inspired by the <a href=\"https://arxiv.org/abs/2205.12615\">Autoformalization with Large Language Models</a> paper from the N2Formal group at Google.</p>\n</blockquote>\n<p>Very impressive stuff! I wonder if it is possible to extend this interface beyond Lean? I would have had a much enjoyable time debugging Isabelle statements for the autoformalisation work if this interface were around :)</p>",
        "id": 286384110,
        "sender_full_name": "Albert Jiang",
        "timestamp": 1655399659
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"258175\">@Albert Jiang</span>  I think you would just need to replace the prompts in <a href=\"https://github.com/zhangir-azerbayev/lean-chat/blob/main/src/prompting.lean\">https://github.com/zhangir-azerbayev/lean-chat/blob/main/src/prompting.lean</a>. It would still run as a Lean widget, but it would give Isabelle (or whatever) results.</p>",
        "id": 286384892,
        "sender_full_name": "Jason Rute",
        "timestamp": 1655400088
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/A.20chat.20interface.20for.20formalizing.20theorem.20statements/near/286384892\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"258175\">Albert Jiang</span>  I think you would just need to replace the prompts in <a href=\"https://github.com/zhangir-azerbayev/lean-chat/blob/main/src/prompting.lean\">https://github.com/zhangir-azerbayev/lean-chat/blob/main/src/prompting.lean</a>. It would still run as a Lean widget, but it would give Isabelle (or whatever) results.</p>\n</blockquote>\n<p>Thanks!</p>",
        "id": 286386165,
        "sender_full_name": "Albert Jiang",
        "timestamp": 1655400618
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/A.20chat.20interface.20for.20formalizing.20theorem.20statements/near/286298402\">said</a>:</p>\n<blockquote>\n<p>Very cool looking project!  Can you try these hard examples that <span class=\"user-mention silent\" data-user-id=\"110865\">Jeremy Avigad</span> often uses to talk about <a href=\"https://www.andrew.cmu.edu/user/avigad/Talks/ioannina.pdf#page=46\">type inference in natural mathematics</a>? <a href=\"/user_uploads/3121/LdQFe3b0KSGnxzlL9366D7Tt/Screen-Shot-2022-06-15-at-10.09.18-PM.png\">Screen-Shot-2022-06-15-at-10.09.18-PM.png</a></p>\n</blockquote>\n<p>I managed to eventually get each of these three examples formalized. The first and the third took a few turns of back and forth, and the chatbot got the second on the first try (albeit with deprecated syntax).  <br>\n<a href=\"/user_uploads/3121/zmDh-HMJy7HXK6COIi6Ivui6/Screenshot-from-2022-06-16-14-07-04.png\">Screenshot-from-2022-06-16-14-07-04.png</a> <br>\n<a href=\"/user_uploads/3121/wTyvAIqCCAOcnhxuHzvY8Eu6/Screenshot-from-2022-06-16-14-10-50.png\">Screenshot-from-2022-06-16-14-10-50.png</a> <br>\n<a href=\"/user_uploads/3121/uRXG2cbBKRyR2PhcuO9UelhW/Screenshot-from-2022-06-16-14-36-23.png\">Screenshot-from-2022-06-16-14-36-23.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/zmDh-HMJy7HXK6COIi6Ivui6/Screenshot-from-2022-06-16-14-07-04.png\" title=\"Screenshot-from-2022-06-16-14-07-04.png\"><img src=\"/user_uploads/3121/zmDh-HMJy7HXK6COIi6Ivui6/Screenshot-from-2022-06-16-14-07-04.png\"></a></div><div class=\"message_inline_image\"><a href=\"/user_uploads/3121/wTyvAIqCCAOcnhxuHzvY8Eu6/Screenshot-from-2022-06-16-14-10-50.png\" title=\"Screenshot-from-2022-06-16-14-10-50.png\"><img src=\"/user_uploads/3121/wTyvAIqCCAOcnhxuHzvY8Eu6/Screenshot-from-2022-06-16-14-10-50.png\"></a></div><div class=\"message_inline_image\"><a href=\"/user_uploads/3121/uRXG2cbBKRyR2PhcuO9UelhW/Screenshot-from-2022-06-16-14-36-23.png\" title=\"Screenshot-from-2022-06-16-14-36-23.png\"><img src=\"/user_uploads/3121/uRXG2cbBKRyR2PhcuO9UelhW/Screenshot-from-2022-06-16-14-36-23.png\"></a></div>",
        "id": 286395738,
        "sender_full_name": "Zhangir Azerbayev",
        "timestamp": 1655404854
    },
    {
        "content": "<p>Impressive work <span class=\"user-mention\" data-user-id=\"284997\">@Zhangir Azerbayev</span> <span class=\"user-mention\" data-user-id=\"121918\">@Edward Ayers</span> !</p>",
        "id": 286398472,
        "sender_full_name": "Yuhuai Tony Wu",
        "timestamp": 1655406074
    },
    {
        "content": "<p>This is awesome. Nice work!</p>",
        "id": 286409116,
        "sender_full_name": "Leonardo de Moura",
        "timestamp": 1655411342
    },
    {
        "content": "<p>It has this habit of putting <code>:</code> at the start of the main statement. What can we infer about the age of Codex's training data?</p>",
        "id": 286412895,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1655413246
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224323\">Junyan Xu</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/A.20chat.20interface.20for.20formalizing.20theorem.20statements/near/286412895\">said</a>:</p>\n<blockquote>\n<p>It has this habit of putting <code>:</code> at the start of the main statement. What can we infer about the age of Codex's training data?</p>\n</blockquote>\n<p>I think that might have to do with the prompt: <a href=\"https://github.com/zhangir-azerbayev/lean-chat/blob/main/src/prompting.lean\">https://github.com/zhangir-azerbayev/lean-chat/blob/main/src/prompting.lean</a>. Maybe change the : in the prompt and see what happens?</p>",
        "id": 286419735,
        "sender_full_name": "Albert Jiang",
        "timestamp": 1655416937
    },
    {
        "content": "<p>Thanks! It didn't come to my mind that the prompt is the issue.</p>\n<p>If colon at the beginning has never been the mathlib style, then in the training data, this style might correlate with the author being a new Lean user who never contributed to mathlib, and with unfamiliarity with mathlib APIs, etc. So I think it's best to move colons to the end of the previous line in the official prompt.</p>",
        "id": 286446017,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1655441514
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"284997\">Zhangir Azerbayev</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/A.20chat.20interface.20for.20formalizing.20theorem.20statements/near/286395738\">said</a>:</p>\n<blockquote>\n<p><a href=\"/user_uploads/3121/zmDh-HMJy7HXK6COIi6Ivui6/Screenshot-from-2022-06-16-14-07-04.png\">Screenshot-from-2022-06-16-14-07-04.png</a> </p>\n</blockquote>\n<p>Lol @ trying to get to infinity by repeatedly applying <code>nat.succ</code></p>",
        "id": 286447432,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1655443274
    },
    {
        "content": "<p>Do you think the evaluation function goes up by 2^{-n} when you add the n'th succ because we're getting a bit closer?</p>",
        "id": 286474849,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1655464147
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"258175\">Albert Jiang</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/A.20chat.20interface.20for.20formalizing.20theorem.20statements/near/286419735\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"224323\">Junyan Xu</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/A.20chat.20interface.20for.20formalizing.20theorem.20statements/near/286412895\">said</a>:</p>\n<blockquote>\n<p>It has this habit of putting <code>:</code> at the start of the main statement. What can we infer about the age of Codex's training data?</p>\n</blockquote>\n<p>I think that might have to do with the prompt: <a href=\"https://github.com/zhangir-azerbayev/lean-chat/blob/main/src/prompting.lean\">https://github.com/zhangir-azerbayev/lean-chat/blob/main/src/prompting.lean</a>. Maybe change the : in the prompt and see what happens?</p>\n</blockquote>\n<p>I tried changing the prompt as you suggested and it does seem to improve performance. Here is the field characteristic p example with the new prompt. <br>\n<a href=\"/user_uploads/3121/JHR2SIBvPjPDo-nUiqcYOYNd/Screenshot-from-2022-06-17-12-51-30.png\">Screenshot-from-2022-06-17-12-51-30.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/JHR2SIBvPjPDo-nUiqcYOYNd/Screenshot-from-2022-06-17-12-51-30.png\" title=\"Screenshot-from-2022-06-17-12-51-30.png\"><img src=\"/user_uploads/3121/JHR2SIBvPjPDo-nUiqcYOYNd/Screenshot-from-2022-06-17-12-51-30.png\"></a></div>",
        "id": 286527876,
        "sender_full_name": "Zhangir Azerbayev",
        "timestamp": 1655491209
    },
    {
        "content": "<p>Do the encouraging phases, e.g. “you are almost there” actually help?  (Prompt engineering is so mysterious.)</p>",
        "id": 286538593,
        "sender_full_name": "Jason Rute",
        "timestamp": 1655497483
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/A.20chat.20interface.20for.20formalizing.20theorem.20statements/near/286538593\">said</a>:</p>\n<blockquote>\n<p>Do the encouraging phases, e.g. “you are almost there” actually help?  (Prompt engineering is so mysterious.)</p>\n</blockquote>\n<p>My guess is that it's not, since Lean code is usually contributed by experts already.</p>\n<p>Although why not give it a try with something like \"Translate in the style of Kevin Buzzard\"</p>",
        "id": 286541182,
        "sender_full_name": "Albert Jiang",
        "timestamp": 1655498938
    },
    {
        "content": "<p>I've made a <a href=\"https://github.com/zhangir-azerbayev/lean-chat/compare/main...alreadydone:patch-1\">version in the style of mathlib docstrings</a> (untested, I have GPT API key but not Codex) and I'm curious to see how it performs :) If I fill in the sorries in the prompt will it spit out proofs?</p>",
        "id": 286548126,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1655503422
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"125393\">@Junyan Xu</span> The Autoformalization with Large Language Models paper (at the top of the discussed) mentioned that the choice of prompt matters a lot.  If you have examples using the right vocabulary then that would probably help a lot.  Of course the burden is on the user then to come up with good example prompts for their use case (prompt engineering).</p>",
        "id": 286552949,
        "sender_full_name": "Jason Rute",
        "timestamp": 1655507256
    },
    {
        "content": "<p>If you fill in the sorries in the prompt with proofs it would indeed output “proofs”.  I would also be curious what the proof outputs look like and if they are correct.</p>",
        "id": 286553448,
        "sender_full_name": "Jason Rute",
        "timestamp": 1655507664
    },
    {
        "content": "<p>Yes, <span class=\"user-mention\" data-user-id=\"224933\">@Yao Liu</span> already <a href=\"https://twitter.com/arankomatsuzaki/status/1529278580189908993\">commented</a> down the tweet advertising this chat interface, and suggested using “let’s think step by step”, which intuitively doesn't apply to the current task of formalization, which is more like translation. But he's alluding to <a href=\"https://twitter.com/arankomatsuzaki/status/1529278580189908993\">this recent research which shows prompts can matter a lot</a>, and it's important to experiment with many different prompts.</p>\n<div class=\"inline-preview-twitter\"><div class=\"twitter-tweet\"><a href=\"https://twitter.com/arankomatsuzaki/status/1529278580189908993\"><img class=\"twitter-avatar\" src=\"https://uploads.zulipusercontent.net/1f233c3ea6eddb6128e6429f85d49e229df6076d/68747470733a2f2f7062732e7477696d672e636f6d2f70726f66696c655f696d616765732f313530373938323833313433393532333834302f4849504861365a695f6e6f726d616c2e6a7067\"></a><p>Large Language Models are Zero-Shot Reasoners\n\nSimply adding “Let’s think step by step” before each answer increases the accuracy on MultiArith from 17.7% to 78.7% and GSM8K from 10.4% to 40.7% with GPT-3.\n\n<a href=\"https://t.co/ebvxSbac1K\">https://arxiv.org/abs/2205.11916</a> <a href=\"https://t.co/lpZwDTf06m\">https://twitter.com/arankomatsuzaki/status/1529278580189908993/photo/1</a></p><span>- Aran Komatsuzaki (@arankomatsuzaki)</span><div class=\"twitter-image\"><a href=\"https://t.co/lpZwDTf06m\"><img src=\"https://uploads.zulipusercontent.net/94577bff225fd909db537e51c0ff902308fbdc7f/68747470733a2f2f7062732e7477696d672e636f6d2f6d656469612f46546b576f666f567341416e7175322e706e673a736d616c6c\"></a></div></div></div>",
        "id": 286554017,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1655508163
    },
    {
        "content": "<p>Should one expect this to work with a key from the gpt-f beta? When I try to use mine, I just see <code>codex: error</code>. Is this a different model and I need to re-apply at the link then?</p>",
        "id": 286731804,
        "sender_full_name": "Julian Berman",
        "timestamp": 1655675374
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"321696\">Julian Berman</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/A.20chat.20interface.20for.20formalizing.20theorem.20statements/near/286731804\">said</a>:</p>\n<blockquote>\n<p>Should one expect this to work with a key from the gpt-f beta? When I try to use mine, I just see <code>codex: error</code>. Is this a different model and I need to re-apply at the link then?</p>\n</blockquote>\n<p>Yes, as far as I know Codex and the gpt-f beta are separate keys.</p>",
        "id": 286812474,
        "sender_full_name": "Zhangir Azerbayev",
        "timestamp": 1655739869
    },
    {
        "content": "<p>Modulo waiting for codex access, hacking support in to <code>lean.nvim</code> was somewhat trivial :P, so I suspect this works now there too (possibly with the exception of the paste button needing a tweak). </p>\n<p><a href=\"/user_uploads/3121/7dqEcfD7Id3q7uv4a_4t3aRk/Screen-Recording-2022-06-20-at-17.24.04.gif\">Screen-Recording-2022-06-20-at-17.24.04.gif</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/7dqEcfD7Id3q7uv4a_4t3aRk/Screen-Recording-2022-06-20-at-17.24.04.gif\" title=\"Screen-Recording-2022-06-20-at-17.24.04.gif\"><img src=\"/user_uploads/3121/7dqEcfD7Id3q7uv4a_4t3aRk/Screen-Recording-2022-06-20-at-17.24.04.gif\"></a></div><p>Obviously the UX could be tweaked a bit more for the terminal and if I get really evil I'll render the latex to png and show that in the terminal... but yeah excited to try this out there too.</p>",
        "id": 286840372,
        "sender_full_name": "Julian Berman",
        "timestamp": 1655760464
    },
    {
        "content": "<p>GitHub Copilot just went public: <a href=\"https://twitter.com/github/status/1539283958441160712\">https://twitter.com/github/status/1539283958441160712</a><br>\n$10/month, or 2-month free trial + $100/year afterwards.<br>\nSince Copilot uses Codex for code completion under the hood, I think there's no loss from using Copilot instead of Codex directly for our task of autoformalization.<br>\nWould Microsoft make Lean code completion free to promote Lean?</p>\n<div class=\"inline-preview-twitter\"><div class=\"twitter-tweet\"><a href=\"https://twitter.com/github/status/1539283958441160712\"><img class=\"twitter-avatar\" src=\"https://uploads.zulipusercontent.net/3264504319ebf3ea94f6fdd893220e08e7892144/68747470733a2f2f7062732e7477696d672e636f6d2f70726f66696c655f696d616765732f313431343939303536343430383236323636312f723659656d7646395f6e6f726d616c2e6a7067\"></a><p>GitHub Copilot helps you get better focus and build faster by instantly suggesting code—and is now available for developers everywhere.\n\n<a href=\"https://t.co/R6ZqAEtLJF\">https://github.blog/2022-06-21-github-copilot-is-generally-available-to-all-developers/</a></p><span>- GitHub (@github)</span></div></div>",
        "id": 286978505,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1655848070
    },
    {
        "content": "<p>Wow, Free for verified students and maintainers of popular open source projects. I hope mathlib qualifies!</p>",
        "id": 286978693,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1655848203
    },
    {
        "content": "<p><a href=\"https://github.com/pricing#faq-copilot\">https://github.com/pricing#faq-copilot</a><br>\nPeople who maintain popular open source projects receive a credit to have 12 months of GitHub Copilot access for free. A maintainer of a popular open source project is defined as someone who has write or admin access to one or more of the most popular open source projects on GitHub. Simply visit the GitHub Copilot subscription page to see if you are one of the open source maintainers that meet our criteria for a complimentary subscription. If you do, you should see that you can add GitHub Copilot for no charge. If you see a charge on the purchase page then this means that you do not qualify at this time. Once awarded, if you are still a maintainer of a popular open source project when your initial 12 months subscription expires then you will be able to renew your subscription for free.</p>",
        "id": 286979189,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1655848536
    },
    {
        "content": "<p>Apparently I don't have free access. Could any <span class=\"user-group-mention\" data-user-group-id=\"2494\">@maintainers</span> try? <a href=\"https://github.com/github-copilot/signup\">https://github.com/github-copilot/signup</a></p>",
        "id": 286979493,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1655848735
    },
    {
        "content": "<p>I don't think I have free access either</p>",
        "id": 286979702,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1655848847
    },
    {
        "content": "<p>There is no way mathlib could qualify as \"one of the most popular open source projects on GitHub\".</p>",
        "id": 286980104,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1655849112
    },
    {
        "content": "<p>There is a precise measure here: each GitHub user can give one star to any project. mathlib has 1.2k stars. VSCode for instance has 133k stars.</p>",
        "id": 286980223,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1655849187
    },
    {
        "content": "<p>Yes mathlib probably would not qualify based on popularity, but in terms of activity the gap is smaller. The number of PRs opened is about 1/10 of vscode, 1/5 of pytorch, or 1/4 of tensorflow. (What if we count lines of code?) The stated criterion is popularity though.</p>",
        "id": 286981095,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1655849820
    },
    {
        "content": "<p>I'm not sure that's the metric they use, I have free access</p>",
        "id": 287044634,
        "sender_full_name": "Julian Berman",
        "timestamp": 1655900350
    },
    {
        "content": "<p>Though I can't tell if it's from the education side, they conflate the two a bit</p>",
        "id": 287044718,
        "sender_full_name": "Julian Berman",
        "timestamp": 1655900402
    },
    {
        "content": "<blockquote>\n<p>If you’re a student and want to participate in the program, apply for the GitHub Student Pack to get started. </p>\n</blockquote>\n<p><a href=\"https://docs.github.com/en/education/explore-the-benefits-of-teaching-and-learning-with-github-education/use-github-for-your-schoolwork/apply-for-a-student-developer-pack\">https://docs.github.com/en/education/explore-the-benefits-of-teaching-and-learning-with-github-education/use-github-for-your-schoolwork/apply-for-a-student-developer-pack</a></p>\n<p>If you never applied, I'd assume it comes from one of your open source projects (you have a lot)! I've heard people claiming they got access due to a 200+ star repo.</p>\n<p>I suspect GitHub doesn't have an easy way to distinguish mathlib maintainers vs. normal contributors with non-master write access; do they have difference in GitHub privileges (not bors privileges)? The announcement mentions \"write or admin access\"; can maintainers commit directly to master? I've also heard people suspecting they didn't get access because their project is under an organization, like mathlib is.</p>",
        "id": 287064890,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1655909450
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"224323\">@Junyan Xu</span> I'm just curious, have you used copilot (with lean or other languages)? Is it worth $10/month?</p>",
        "id": 287065419,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1655909663
    },
    {
        "content": "<p>No I have not, neither do I have Codex access; Copilot is now commercialized but Codex API is still in free private beta.<br>\nI reported the news here only because Copilot is using Codex, which is used by the chat interface in this topic.</p>",
        "id": 287065949,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1655909872
    },
    {
        "content": "<p>For all those discussing API keys/copilot, once we update lean-chat to comply with all of OpenAI's safety requirements, we plan to go through their app review process. If we are approved, lean-chat will no longer require the user to have their own API key.</p>",
        "id": 287085161,
        "sender_full_name": "Zhangir Azerbayev",
        "timestamp": 1655918138
    },
    {
        "content": "<p>I have used copilot for lean, it is occasionally very helpful, providing autocompletion for statements that are fairly nontrivial, I'm not sure I'd pay $10 a month for it though</p>",
        "id": 287101818,
        "sender_full_name": "Alex J. Best",
        "timestamp": 1655926164
    }
]