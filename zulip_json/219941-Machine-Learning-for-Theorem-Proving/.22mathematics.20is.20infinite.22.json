[
    {
        "content": "<p>I just gave a talk at some CERN conference and I mentioned AI and the possibility of computers proving theorems. Two basic questions came up about this after the talk and I wasn't really in a position to answer them :-(</p>\n<p>The first one I can only half remember -- it was \"are the AI techniques which are used to try and solve mathematics analytical techniques or...something else\". I know that people have posted a whole host of technical information in this stream but I know 0 about AI. Is there a simple answer to this question?</p>\n<p>The second question I understand much better. This goes back to a conversation I had with Leo some time ago, where he said that his impression was that the AI people were saying \"well we've done board games, so maths is next\". Leo was arguing that getting AI to play maths well was far far far harder than getting it to play chess/go well, and I'm sure he's right, but my interpretation of the main reasons why this was the case was that (1) mathematics is infinite, so we have infinitely many possibilities for our moves at any stage, and (2) the payoff function is 0/1 -- either you've proved it or you haven't. In the questions afterwards, someone challenged me on (1): they said sure maths was infinite, but go was big enough to be considered infinite in practice. Can one really leverage the fact that there are \"only\" 300 or so moves that one can make in a typical go position, whereas one really can add x to both sides of an equation for infinitely many x?</p>\n<p>Sorry for the vague questions! My impression is that the AI people are getting more and more interested in Lean (e.g. I'm meeting someone from Facebook later on this week who wants to talk about Lean and AI) so I'd better know something :-)</p>",
        "id": 262980099,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1638175943
    },
    {
        "content": "<p>You can certainly express theorem proving such that it has a finite branching factor, and I agree with the person that said that go is effectively infinite, we aren't solving these problems by exhausting the space in any sense</p>",
        "id": 262981123,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1638176510
    },
    {
        "content": "<p>To me a better argument of the hardness of maths is that it is <em>the hardest problem</em> in a formal sense, like NP complete problems. There is a theorem whose provability is equivalent to finding an optimal strategy in go</p>",
        "id": 262981369,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1638176636
    },
    {
        "content": "<p>Now you might say that just because there are really hard problems in the space doesn't mean that the interesting problems are there, we might just get lucky and avoid those areas. But mathematicians are attracted to hard problems, so this is probably too optimistic</p>",
        "id": 262981534,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1638176747
    },
    {
        "content": "<p>Someone else asked \"what are you going to do about the fact that there are undecidable statements?\" and here I was more confident, my reply was \"mathematicians are attracted to problems which we believe are decidable\".</p>",
        "id": 262982011,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1638177069
    },
    {
        "content": "<p>while mathematicians like to stick to the decidable statements, they also like to toe arbitrarily close to the line separating them from the undecidable statements, so from a computational point of view it doesn't make a difference and may as well be undecidable</p>",
        "id": 262984373,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1638178520
    },
    {
        "content": "<p>also mathematicians are known to be wrong about their intuitions on decidability sometimes (c.f. Hilbert)</p>",
        "id": 262984466,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1638178567
    },
    {
        "content": "<p>One thing that I don't understand is why people believe these approaches have to either be fully automated or not work at all. I think something like Github's co-pilot for formalized mathematics could be reasonably attainable with current technologies and would help a lot even though it probably won't come out with an automagic proof of the Riemann Hypothesis or such.</p>",
        "id": 262998635,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1638187237
    },
    {
        "content": "<p>The scary branching factor when writing a tactic proof is at the <code>have</code> statements. Looking at proofs mathematicians write (either in lean or on paper), often there are steps where something unexpected is introduced by a <code>have</code>. However often there is a perfectly reasonable motivation, but I worry that we never write this down in a tactic proof (and all too infrequently in paper proofs, too).</p>\n<p>I like the example we like to use in Lean demos, of the infinitude of primes. It's not actually the most trivial argument: there are two \"surprise\" steps in the version used in demos (<code>let M := N.factorial + 1</code> and <code>let p := min_fac M</code>). How does one write down an account of this proof that doesn't reach for surprises? Reasonably you decide to proceed by contradiction, and after a bit of tidying up you have an N such that all primes are &lt; N, and quite plausibly decide to try to construct a prime &gt;= N. It's not too big a leap to then try to construct a number &gt;= N which is not divisible by any prime. At this point you could either notice you've got a finite list of primes to avoid, or you could decide to construct something \"easier\" given the context, i.e. a number &gt;= N which is not divisible by anything &lt; N. Still, making that \"not too big a leap\" seems hard for a ML prover, and finishing from this point without access to \"surprises\"/<code>have</code> statements is still quite challenging.</p>",
        "id": 262998842,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1638187357
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"315434\">@Andrés Goens</span>, who believes that? I suspect there isn't anyone. :-) The <code>gptf</code> tactic for Lean is pretty exciting.</p>",
        "id": 262998899,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1638187409
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/.22mathematics.20is.20infinite.22/near/262998899\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"315434\">Andrés Goens</span>, who believes that? I suspect there isn't anyone. :-) The <code>gptf</code> tactic for Lean is pretty exciting.</p>\n</blockquote>\n<p>I guess you're right, no-one is stating that explicitly, but to me it sounds like the implicit assumption in discussions like the one Kevin Buzzard is describing above, when talking about things like \"solving mathematics\" or the fact that some problems are undecidable. </p>\n<p>Perhaps indeed a better question is how far are we from having AI come up with novel and creative proofs, using things like the unexpected <code>have</code> steps you discuss above.</p>",
        "id": 262999654,
        "sender_full_name": "Andrés Goens",
        "timestamp": 1638187971
    },
    {
        "content": "<p>I have discussed this question with many AI people and mathematicians, and all agreed that the branching factor is far far larger for mathematical proof than for Go.  Even if one does not consider options like \"add a specific number x to both sides of the equation\", the number of \"functions from the library\" times \"candidate function arguments of the right type in the current context\" is large.  But so is the number of words in the English language, yet state of the art transformer language models generate grammatical and very plausible English sentences,<br>\nthough not very meaningful ones.   By itself the language model can achieve local coherence but not global, nor can it plan very well.<br>\nThe combination of LM and formal verifier has the great advantage that the LM just has to get the right answer with &gt; 1% probability or so, then the verifier picks a correct one.  OpenAI's code generating system Codex works this way, see their paper or the demo at <br>\n<a href=\"https://www.youtube.com/watch?v=SGUCcjHTmGY\">https://www.youtube.com/watch?v=SGUCcjHTmGY</a><br>\nI think the state of the art is well represented by OpenAI's work, besides Codex and gptf see <a href=\"https://openai.com/blog/grade-school-math/\">https://openai.com/blog/grade-school-math/</a></p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"SGUCcjHTmGY\" href=\"https://www.youtube.com/watch?v=SGUCcjHTmGY\"><img src=\"https://uploads.zulipusercontent.net/3da32fa9597e2187e2af932f1ac92dd0744d7e83/68747470733a2f2f692e7974696d672e636f6d2f76692f53475543636a48546d47592f64656661756c742e6a7067\"></a></div>",
        "id": 263047475,
        "sender_full_name": "Michael R Douglas",
        "timestamp": 1638209810
    },
    {
        "content": "<p>If I may add a bit of color on the \"infinitude of maths\" vs \"infinitude of go\" one way of seeing that there is a very big difference is the following: </p>\n<p>Go action space is very finite (19x19) but larger than Chess which leads to a very high branching factor which leads to basic search procedures being quite intractable, and that's what people call Go's \"infinite or very large search space\". Maths on the other end has not only a very very large search space but they also have an actually infinite action space: you have an infinite choice at each action / branch in the search space (as <span class=\"user-mention\" data-user-id=\"110087\">@Scott Morrison</span> pointed out this is well illustrated by cut introduction which are crucial in order to construct tractable proofs (I believe there's a theorem that say you can get away without cuts but your proof size explodes??).</p>\n<p>You could eventually reframe maths as a finite action space, just write the proof and the action is just the next token, but here we see that the search space explodes as well as the length of a proof becomes very challenging (one tactic being roughly the size of a full chess game).</p>\n<p>This well-behaved action space vs infinite action space is one of the crucial difference we have to deal with when applying AI techniques to Maths compared to Go. The other big one is that there is no obvious way to do self play, you're playing against statements instead of an opponent and if one statement is too hard there is no obvious game setup that will let you reframe it to make it easier. Self-play gives you that smooth curriculum in games which is also crucial to train neural networks.</p>\n<p>Initial AI x Maths systems actually approximated the infinite action space with a finite one by limiting it to the space of \"Tactics x Known Theorems\" but these systems where not capable of introducing cuts or witnesses (from far away they're one and the same) whose mathematical terms are exogenous to the current context (eg <code>let p := min_fac M</code> the term <code>min_fac M</code> is nowhere to be found in the context as we tackle that proof). This is what we were motivated to tackle heads-on when we introduced GPT-f which uses a language model to sample plausible actions from that infinite action space and apply search on top of that.</p>",
        "id": 263284278,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1638363038
    },
    {
        "content": "<p>The point I was feebly attempting to make above was that although <code>let p := min_fac M</code> appears \"completely out of the blue\" / \"exogenous to the current context\", there is of course some thinking going on that makes it quite plausible. Unfortunately this thinking is not in any way reflected in the tactic script, so an ML agent, language model driven or otherwise, has little opportunity to learn to imitate it because there is no training data.</p>\n<p>(The thought comes after having decided to look at <code>let M := N.factorial + 1</code> e.g. because it is coprime to all possible primes. \"Hmm, but how are we going to prove it is prime? One option would be to notice and use the lemma that if you're not prime, you're divisible by some prime. Another option would be to not use <code>M</code> itself, but some prime extracted from it that is still big enough, so let's look for functions that take a natural number and produce a prime.\" Either option is a viable path to a proof. In the second option, it's completely plausible without a large branch factor to notice <code>min_fac</code>. But it is generating/evaluating those two options that seems very hard to train.)</p>",
        "id": 263357631,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1638392704
    },
    {
        "content": "<p>I think that for brilliant ideas such as this it's easier just to tell them to the AI as training data</p>",
        "id": 263360616,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1638394394
    },
    {
        "content": "<p>Well that's my point --- how does that training data ever come into existence if we write proofs that don't reflect the ideas?</p>",
        "id": 263363228,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1638395719
    },
    {
        "content": "<p>I'm saying that before any <code>let M := N.factorial + 1</code> or <code>let p := min_fac M</code> line there are intermediate thoughts that are not actually particularly clever, and that an ML agent could certainly learn. But I think it's absurdly unreasonable to expect it to learn without being shown examples of the intermediate thoughts.</p>",
        "id": 263363447,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1638395854
    },
    {
        "content": "<p>I've got no idea how alpha zero figures out chess openings, but it does. However I don't think we're quite there with proving yet ;-)</p>",
        "id": 263371986,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1638400876
    },
    {
        "content": "<p>I'm not familiar with the state of the art in AI-assisted mathematics, but to what extent can you precisely characterize a metric for saying AI is good at math?  Go has the easy route of playing AI against itself while textual generation like gpt-3 also has metrics.  With math do you delete all lemmas and hope the AI proves the theorem along with identifying them?</p>",
        "id": 263752104,
        "sender_full_name": "Joe Hendrix",
        "timestamp": 1638684445
    },
    {
        "content": "<p>The usual performance measure for provers is the fraction of statements taken from a benchmark list which the system can prove.<br>\nFor serious competitions (e.g. see <a href=\"http://www.tptp.org/CASC/\">http://www.tptp.org/CASC/</a>) each system is run on the same computer with the same time limit.<br>\nFor the systems used in CS (SAT solvers, first order logic provers) one gives all of the required axioms with each statement.<br>\nFor a system with a large mathematical library like Lean or Mizar, one usually splits the library into two sets of lemmas, a training set and a testing set.  The system can see the training statements and their proofs, and do whatever it wants with them to learn how to do proofs.<br>\nThen it is given the testing statements and it has to come up with their proofs by interacting with the prover.<br>\nThe best results I've heard of are around 75% , e.g. see Josef Urban's group (for Mizar) <a href=\"https://github.com/ai4reason/ATP_Proofs\">https://github.com/ai4reason/ATP_Proofs</a><br>\nor the \"Large Theory Batch\" results (for Isabelle) in <a href=\"http://www.tptp.org/CASC/28/WWWFiles/DivisionSummary1.html\">http://www.tptp.org/CASC/28/WWWFiles/DivisionSummary1.html</a> <br>\nThere has been steady progress but clearly still some ways to go.<br>\nOther aspects of automated math such as generating conjectures, search engines etc. are not yet as systematized.<br>\nA similar benchmark approach is always used but the test problems and other details vary from work to work.</p>",
        "id": 263779505,
        "sender_full_name": "Michael R Douglas",
        "timestamp": 1638725664
    },
    {
        "content": "<p>It would be great if someone could propose an analog of \"the system playing against itself\" for doing mathematics.<br>\nThis might lead to major advances.</p>",
        "id": 263779525,
        "sender_full_name": "Michael R Douglas",
        "timestamp": 1638725707
    },
    {
        "content": "<p>Here is a shot at a setup for reinforcement learning.</p>\n<ul>\n<li>Simple form - generate statements in order of increasing complexity and try to prove or disprove them.</li>\n<li>Adversarial form (like GANs) - one system generates simple statements that the other cannot prove/disprove (points won when problems cannot be solved, more points for simpler statements).</li>\n<li>Competition - generate statements that a system can prove/disprove and challenge the other system - points if the other system cannot solve it.</li>\n</ul>\n<p>One needs refinements clearly because of logical dependencies of statements - one can make infinitely many hard problems of the form P =&gt; Riemann hypothesis so long as P is true. So reducing one posed problem to another should be a \"solution\"</p>",
        "id": 263805402,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1638761612
    },
    {
        "content": "<p>How do you measure whether a statement is simple or complex?</p>",
        "id": 263812258,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1638771235
    },
    {
        "content": "<p>Is <code>x ^ n + y ^ n = z ^ n → x * y * z = 0</code> a simple statement?</p>",
        "id": 263812308,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1638771284
    },
    {
        "content": "<p>I agree complexity is not canonical, but depends on the generating rules and the (weighted) initial generators. One should take reursion and definitions of inductive types as generating rules, so that is not horribly complex with nothing else.</p>\n<p>What I feel is a reasonable option is to take a generating set and generating rules corresponding to occurence in mathlib (traded off with entropy of generators).</p>",
        "id": 263813619,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1638773083
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"266304\">@Siddhartha Gadgil</span> But how do you prevent generating tons of true statements that are very simple to state but incredibly difficult to prove?</p>",
        "id": 263813846,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1638773491
    },
    {
        "content": "<p>FLT is the most famous, but there are thousands of other Diophantine equations.</p>",
        "id": 263813851,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1638773506
    },
    {
        "content": "<p>In that sense, I think your \"Competition\" format is the most promising.</p>",
        "id": 263813913,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1638773554
    },
    {
        "content": "<p>But you still have to make sure that the AI doesn't score points because of long but pointless proofs. If I were competing, I would do 1000 simple random proof steps, look at the type of the term I generated, and declare that as the theorem that the other competitors have to prove.</p>",
        "id": 263813975,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1638773651
    },
    {
        "content": "<p>If you do this very naively, then the type might give away which 1000 steps you need to take, by looking at its structure. But slightly smarter methods will generate incredibly hard problems.</p>",
        "id": 263813992,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1638773705
    },
    {
        "content": "<p>Here a neutral version of complexity will help</p>",
        "id": 263813996,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1638773709
    },
    {
        "content": "<p>Even better: just challenge the others to solve discrete logarithms. Then they need to break RSA (and co) to prove your challenges.</p>",
        "id": 263814009,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1638773746
    },
    {
        "content": "<p>I agree that it is not canonical, and indeed different domains can be defined by different generating sets. But given this the poinless proof strategy will be weak.</p>",
        "id": 263814012,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1638773760
    },
    {
        "content": "<p>Again, those statements are relatively simple. So even \"neutral complexity\" might not rule them out.</p>",
        "id": 263814053,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1638773766
    },
    {
        "content": "<p>Good point - there are many inverse problems.</p>",
        "id": 263814064,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1638773783
    },
    {
        "content": "<p>I have no idea how to avoid them.</p>",
        "id": 263814074,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1638773806
    },
    {
        "content": "<p>Ramdom search for a barely 3-colourable graph may also give a challenge.</p>",
        "id": 263814094,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1638773852
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"266304\">Siddhartha Gadgil</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/.22mathematics.20is.20infinite.22/near/263814074\">said</a>:</p>\n<blockquote>\n<p>I have no idea how to avoid them.</p>\n</blockquote>\n<p>[tongue in cheek] By teaching the computer about the <em>beauty</em> of mathematics, so that it recognises such problems as ugly and distasteful <span aria-label=\"stuck out tongue wink\" class=\"emoji emoji-1f61c\" role=\"img\" title=\"stuck out tongue wink\">:stuck_out_tongue_wink:</span></p>",
        "id": 263814148,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1638773899
    },
    {
        "content": "<p>I actually find it hard to understand what even a \"hard analyst\" for example considers beauty.</p>",
        "id": 263814258,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1638774011
    },
    {
        "content": "<p>But in group theory or topology for example, I do not know if there are that many easy to state but hard to prove results.</p>",
        "id": 263814322,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1638774070
    },
    {
        "content": "<p>I suppose one could ask for word problems.</p>",
        "id": 263814337,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1638774093
    },
    {
        "content": "<p>But for most groups one can try many things - lower central series, representations etc.</p>",
        "id": 263814392,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1638774129
    },
    {
        "content": "<p>Even for diaphontine equations, I would imageine that often reducing to finite fields is enough for a negative answer. But I know very little number theory so cannot judge how often that happens.</p>",
        "id": 263814435,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1638774210
    },
    {
        "content": "<p>group theory: the odd order theorem isn't too hard to state</p>",
        "id": 263814535,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1638774334
    },
    {
        "content": "<p>but is very important</p>",
        "id": 263814547,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1638774358
    },
    {
        "content": "<p>I mean easy to state, hard to solve and unimportant questions.</p>",
        "id": 263814596,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1638774376
    },
    {
        "content": "<p>yeah, got it</p>",
        "id": 263814600,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1638774384
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"112680\">Johan Commelin</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/.22mathematics.20is.20infinite.22/near/263814148\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"266304\">Siddhartha Gadgil</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/.22mathematics.20is.20infinite.22/near/263814074\">said</a>:</p>\n<blockquote>\n<p>I have no idea how to avoid them.</p>\n</blockquote>\n<p>[tongue in cheek] By teaching the computer about the <em>beauty</em> of mathematics, so that it recognises such problems as ugly and distasteful <span aria-label=\"stuck out tongue wink\" class=\"emoji emoji-1f61c\" role=\"img\" title=\"stuck out tongue wink\">:stuck_out_tongue_wink:</span></p>\n</blockquote>\n<p>I actually thought this was where the GAN approach was going. One side proves things, the other side finds nice theorem statements that are hard to prove.</p>",
        "id": 263814654,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1638774478
    },
    {
        "content": "<p>Why will it find <em>nice</em> theorems?</p>",
        "id": 263814742,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1638774561
    },
    {
        "content": "<p>It's clear that niceness also needs to be a subject of the machine learning, but there are some obvious ways to start it off, e.g. shortness</p>",
        "id": 263814827,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1638774679
    },
    {
        "content": "<p>whereupon you get theorem provers competing over small diophantine equations. Harvey Friedman would be proud</p>",
        "id": 263814845,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1638774713
    },
    {
        "content": "<p>Note that the \"conjecturing\" team loses points for guessing false theorem statements, although open questions are fine. Not sure if this is enough to have niceness evolve well</p>",
        "id": 263814979,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1638774840
    },
    {
        "content": "<p>I think you also need a \"library effect\" like in DreamCoder: constructs that are used in proofs can be made into definitions, which makes later theorem statements about them look nicer</p>",
        "id": 263815136,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1638774985
    },
    {
        "content": "<p>with some luck you might be able to exit the diophantine battlefield that way</p>",
        "id": 263815156,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1638775042
    },
    {
        "content": "<p>The danger is with inverse problems. One possible example: a somewhat complicated expression using trignometric functions, compositions etc, differentiate it and ask for a proof that the indefinite integral has a closed form.</p>",
        "id": 263818816,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1638778480
    },
    {
        "content": "<p>A related question in case someone here knows - how good are <em>recommendation systems</em> or <em>premise selection</em> systems for lean currently (and what are good ones)? I know that there is a <code>suggest</code> tactic and <code>library_search</code> - are these rule based and do they rank suggestions?</p>",
        "id": 263819460,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1638778978
    },
    {
        "content": "<p><code>suggest</code> ranks merely by length of the pretty printed term. (<code>suggest</code> tries to apply a lemma from the library with the visible head symbol in the goal, then tries to discharge subgoals using <code>solve_by_elim</code>). <code>library_search</code> just filters <code>suggest</code> for results that successfully close all subgoals, and returns at most one solution.</p>",
        "id": 263819712,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1638779144
    },
    {
        "content": "<p>So I take it both suggest functions that can be applied, but not arguments to functions which may appear in the proof.</p>",
        "id": 263820131,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1638779449
    },
    {
        "content": "<p>It will try to fill in arguments with local hypotheses.</p>",
        "id": 263820266,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1638779554
    },
    {
        "content": "<p>But it will not try to fill in arguments using a recursive call to <code>suggest</code>. That would become very slow very fast.</p>",
        "id": 263820325,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1638779600
    },
    {
        "content": "<p>I see. What I meant was is there some tactic that mines mathlib in advance and uses that to suggest ingredients of proofs.</p>",
        "id": 263820435,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1638779675
    },
    {
        "content": "<p>Aah, I'm not aware of something that does just that. <code>gpt-f</code> is an overpowered version of that idea, maybe?</p>",
        "id": 263820530,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1638779760
    },
    {
        "content": "<p>Yes, I meant something like that but simpler.</p>",
        "id": 263820608,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1638779801
    },
    {
        "content": "<p>To be used interactively or as a library function in other tactics.</p>",
        "id": 263820651,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1638779827
    },
    {
        "content": "<p>I will try this once mathlib4 is ready, but there will be many far more expert than me at this.</p>",
        "id": 263820702,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1638779865
    },
    {
        "content": "<p>We can <a href=\"https://www.nature.com/articles/s41586-021-04086-x\">change the experts captcha’s</a> to select the “meaningful conjectures”</p>",
        "id": 263835365,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1638789037
    },
    {
        "content": "<p>Has anyone built a bot that predicts MathOverflow scores?</p>",
        "id": 263995353,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1638881289
    },
    {
        "content": "<p>You mean guessing how many upvotes a question/answer will get? This is really hard! I remember once asking a question on MO and getting a ton of upvotes and then someone commenting that the only reason it got a ton of upvotes was that someone respectable had asked it, and it wasn't really that good a question. So you have to take into account my cunning ability to psychologically manipulate people into upvoting me.</p>",
        "id": 264005702,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1638885970
    },
    {
        "content": "<p>\"Beautiful/deep/good mathematics\" is in large part a social construct so factors like you say certainly need to be accounted for. </p>\n<p>If you wanted to somehow automate answering the question of \"Is this a good question?\", MO is a good place to start poking at. It would be very interesting to see what comes out of that.</p>",
        "id": 264006512,
        "sender_full_name": "Matthew Ballard",
        "timestamp": 1638886330
    },
    {
        "content": "<p>Can't the competing AIs just pick theorems from mathlib instead of generating them? Theorems like in mathlib are the ones we care about.  In some perverse way, there is not \"much\" of a difference between generating an integer to index theorems in mathlib and generating an integer that encodes syntactically correct statement.<br>\nThis way you do not have to worry about what are the interesting theorems and you have a natural measure of complexity by measuring the portion of mathlib the theorem depends on.</p>",
        "id": 264034789,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1638897244
    },
    {
        "content": "<p>95% of the stuff in mathlib is uninteresting. I don't mean that in a bad way. At least right now, we need that stuff to make mathlib work. But 95% wouldn't make it into an undergraduate textbook, because it is obvious.</p>",
        "id": 264035517,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1638897512
    },
    {
        "content": "<p>There might be good reasons to decide that \"definitely useful, even if uninteresting\" should be included in the dataset.</p>",
        "id": 264035612,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1638897556
    },
    {
        "content": "<p>If those theorems are obvious why do people write tactic proofs manually? Or differently, can AI prove 95% of mathlib now? I can imagine that it is the case indeed, but the tooling is not there yet so we do not know :/</p>",
        "id": 264037613,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1638898235
    },
    {
        "content": "<p>What will you train the AI on? If you train it on mathlib it will be able to prove 100% of mathlib. If you train it on nothing it won't be able to do much. Humans had to write this code</p>",
        "id": 264038550,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1638898611
    },
    {
        "content": "<p>Training in style of AlphaGo Zero?</p>",
        "id": 264038866,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1638898737
    },
    {
        "content": "<p>AlphaGo Zero can play go against itself because go is a two player game. Maths is a puzzle game, ie a one player game</p>",
        "id": 264039178,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1638898849
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"346070\">Tomas Skrivan</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/.22mathematics.20is.20infinite.22/near/264037613\">said</a>:</p>\n<blockquote>\n<p>If those theorems are obvious why do people write tactic proofs manually? Or differently, can AI prove 95% of mathlib now? I can imagine that it is the case indeed, but the tooling is not there yet so we do not know :/</p>\n</blockquote>\n<p>I think that auto-generating this stuff would be great. I recognise that this is not a trivial task however. There is a disconnect between what is easy to auto-generate, and what is considered \"interesting enough for inclusion in an informal maths text\".</p>",
        "id": 264039545,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1638898954
    },
    {
        "content": "<p>You can play a two player game and then figure out who won. If you randomly apply tactics to a goal and change it to another goal, how can you tell if you're winning? Fermat's last theorem looks like a very nice goal to reduce a problem to because it's short and it's a simple statement about the naturals. Are we winning if we reduce the goal to this?</p>",
        "id": 264039603,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1638898976
    },
    {
        "content": "<p>I don't know a thing about AI, so I currently can't be of much help about how to autogenerate this stuff.</p>",
        "id": 264039615,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1638898980
    },
    {
        "content": "<p>I was thinking about something along the lines of <a href=\"https://www.quora.com/What-were-the-renaissance-mathematics-competitions-in-Italy\">renaissance mathematics competitions in Italy</a>. That is a two player game.</p>",
        "id": 264040047,
        "sender_full_name": "Tomas Skrivan",
        "timestamp": 1638899108
    },
    {
        "content": "<p>I'm not so sure that it is -- if you're happy to let an AI generate questions then that's fine, but I'm not convinced that a machine which has been trained to solve questions generated by another machine will be then able to solve 95% of mathlib. But again I'm no expert. I agree that generating theorems and then generating solutions makes a good two player game. I think Facebook are having some success with this method.</p>",
        "id": 264045369,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1638900384
    },
    {
        "content": "<p>Just for context, the original Go champion software Alpha Go learnt by <em>behaviour cloning</em> - trying to make the same moves as experts, before refining by self-play. Alpha Go Zero went beyond this. Mathematics being much harder it makes sense to try to have behaviour cloning as a learning component instead of jumping in to try pure self-play.</p>",
        "id": 264097906,
        "sender_full_name": "Siddhartha Gadgil",
        "timestamp": 1638925244
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"249373\">Stanislas Polu</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/.22mathematics.20is.20infinite.22/near/263284278\">said</a>:</p>\n<blockquote>\n<p>If I may add a bit of color on the \"infinitude of maths\" vs \"infinitude of go\" one way of seeing that there is a very big difference is the following: </p>\n<p>Go action space is very finite (19x19) but larger than Chess which leads to a very high branching factor which leads to basic search procedures being quite intractable, and that's what people call Go's \"infinite or very large search space\". Maths on the other end has not only a very very large search space but they also have an actually infinite action space: you have an infinite choice at each action / branch in the search space (as <span class=\"user-mention silent\" data-user-id=\"110087\">Scott Morrison</span> pointed out this is well illustrated by cut introduction which are crucial in order to construct tractable proofs (I believe there's a theorem that say you can get away without cuts but your proof size explodes??).</p>\n<p>You could eventually reframe maths as a finite action space, just write the proof and the action is just the next token, but here we see that the search space explodes as well as the length of a proof becomes very challenging (one tactic being roughly the size of a full chess game).</p>\n<p>This well-behaved action space vs infinite action space is one of the crucial difference we have to deal with when applying AI techniques to Maths compared to Go. The other big one is that there is no obvious way to do self play, you're playing against statements instead of an opponent and if one statement is too hard there is no obvious game setup that will let you reframe it to make it easier. Self-play gives you that smooth curriculum in games which is also crucial to train neural networks.</p>\n<p>Initial AI x Maths systems actually approximated the infinite action space with a finite one by limiting it to the space of \"Tactics x Known Theorems\" but these systems where not capable of introducing cuts or witnesses (from far away they're one and the same) whose mathematical terms are exogenous to the current context (eg <code>let p := min_fac M</code> the term <code>min_fac M</code> is nowhere to be found in the context as we tackle that proof). This is what we were motivated to tackle heads-on when we introduced GPT-f which uses a language model to sample plausible actions from that infinite action space and apply search on top of that.</p>\n</blockquote>\n<p>I guess this is still very useful in interactive theorem proving, if we can let the user introduce cuts but left everything else to a search procedure (imagine if I could just write a sequence of <code>have</code> statements without bothering to provide justification for each one...) Anyway, when the automation is still weak, most time are spent on the \"leaf-level\" of proofs, so even a small improvement can lead to much better results.</p>\n<p>And afaik things like \"add x to both sides\" can be made finite, as one always does so in order to make some theorems applicable later on, so instead of enumerating x we can enumerate the next theorem used, find out how much freedom is left on the choice of x, then apply the theorem and goes on to enumerate the next theorem etc. (which is the idea of \"tableaux with unification\"?) Though the branching factor is still proportional to the number of premises (theorems)...</p>",
        "id": 266125236,
        "sender_full_name": "Zhanrong Qiao",
        "timestamp": 1640548710
    }
]