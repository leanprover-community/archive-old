[
    {
        "content": "<p>(This continues discussion in <a class=\"stream-topic\" data-stream-id=\"219941\" href=\"/#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/HOList.20or.20Lean.3F\">#Machine Learning for Theorem Proving &gt; HOList or Lean?</a> but with an easier-to-search title)</p>\n<p>Thank you <span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span> for putting together <a href=\"https://github.com/openai/lean-gym\">lean-gym</a>! I'm excited to get started using it but I have a couple of questions after poking around a bit.</p>\n<p>First, I noticed that the goal loaded in the REPL is sometimes different from the goal of the same name extracted with <a href=\"https://github.com/jasonrute/lean-proof-recording-public\">lean-proof-recording-public</a>. For example, the first state in proving <code>buffer.write_eq_write'</code> is loaded in the REPL as </p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">⊢</span> <span class=\"bp\">∀</span> <span class=\"o\">{</span><span class=\"n\">α</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">u</span><span class=\"o\">}</span> <span class=\"o\">(</span><span class=\"n\">b</span> <span class=\"o\">:</span> <span class=\"n\">buffer</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">i</span> <span class=\"o\">:</span> <span class=\"n\">ℕ</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">i</span> <span class=\"bp\">&lt;</span> <span class=\"n\">b.size</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">v</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">),</span> <span class=\"n\">b.write</span> <span class=\"o\">⟨</span><span class=\"n\">i</span><span class=\"o\">,</span> <span class=\"n\">h</span><span class=\"o\">⟩</span> <span class=\"n\">v</span> <span class=\"bp\">=</span> <span class=\"n\">b.write'</span> <span class=\"n\">i</span> <span class=\"n\">v</span>\n</code></pre></div>\n<p>but appears in the data as</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">α</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">u</span><span class=\"o\">,</span>  <span class=\"n\">b</span> <span class=\"o\">:</span> <span class=\"n\">buffer</span> <span class=\"n\">α</span><span class=\"o\">,</span>   <span class=\"n\">i</span> <span class=\"o\">:</span> <span class=\"n\">ℕ</span><span class=\"o\">,</span>   <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">i</span> <span class=\"bp\">&lt;</span> <span class=\"n\">b.size</span><span class=\"o\">,</span>  <span class=\"n\">v</span> <span class=\"o\">:</span> <span class=\"n\">α</span>  <span class=\"bp\">⊢</span> <span class=\"n\">b.write</span> <span class=\"o\">⟨</span><span class=\"n\">i</span><span class=\"o\">,</span> <span class=\"n\">h</span><span class=\"o\">⟩</span> <span class=\"n\">v</span> <span class=\"bp\">=</span> <span class=\"n\">b.write'</span> <span class=\"n\">i</span> <span class=\"n\">v</span>\n</code></pre></div>\n<p>presumably because the universe <code>u</code> and variable <code>α</code> are defined globally within buffer.lean. In this case just running <code>intros</code> is sufficient to change one into the other, but I'm worried that minor differences like these might trip up a language model. Do you know what other differences I should expect between the REPL and the training data?</p>\n<p>Second (though this might be more of a question for <span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span>): it seems that for some \"compressed\" proofs using tactic combinators, there are also \"split-up\" proofs. Using the same example of <code>buffer.write_eq_write'</code>, the proof in buffer.lean is a one-liner <code>by cases b; unfold write write'; simp [array.write_eq_write']</code>. The training data includes this, but also the 3 tactics individually. Am I interpreting the origin of these \"extra proof steps\" correctly?</p>\n<p>Finally, what are the correct data splits to use when comparing to PACT? The paper references a test theorem count of 3071. Using <a href=\"https://github.com/jasonrute/lean-proof-recording-public\">lean-proof-recording-public</a> I see 3651 test theorems (cleaned_training_data/test.names), and using <a href=\"https://github.com/openai/lean-gym\">lean-gym</a> I see 998 test theorems (data/mathlib-test.names).</p>",
        "id": 241098804,
        "sender_full_name": "Aidan Swope",
        "timestamp": 1622600126
    },
    {
        "content": "<p>As for <code>lean-proof-recording-public</code>, it doesn't have a particular \"first tactic state\".  It just includes all the places where tactics are run.  <a href=\"https://leanprover-community.github.io/mathlib_docs/find/buffer.write_eq_write'\">docs#buffer.write_eq_write'</a> appears in the code as:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">lemma</span> <span class=\"n\">write_eq_write'</span> <span class=\"o\">(</span><span class=\"n\">b</span> <span class=\"o\">:</span> <span class=\"n\">buffer</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">i</span> <span class=\"o\">:</span> <span class=\"n\">nat</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">i</span> <span class=\"bp\">&lt;</span> <span class=\"n\">b.size</span><span class=\"o\">)</span> <span class=\"o\">(</span><span class=\"n\">v</span> <span class=\"o\">:</span> <span class=\"n\">α</span><span class=\"o\">)</span> <span class=\"o\">:</span>\n  <span class=\"n\">write</span> <span class=\"n\">b</span> <span class=\"o\">⟨</span><span class=\"n\">i</span><span class=\"o\">,</span> <span class=\"n\">h</span><span class=\"o\">⟩</span> <span class=\"n\">v</span> <span class=\"bp\">=</span> <span class=\"n\">write'</span> <span class=\"n\">b</span> <span class=\"n\">i</span> <span class=\"n\">v</span> <span class=\"o\">:=</span>\n<span class=\"kd\">by</span> <span class=\"n\">cases</span> <span class=\"n\">b</span><span class=\"bp\">;</span> <span class=\"n\">unfold</span> <span class=\"n\">write</span> <span class=\"n\">write'</span><span class=\"bp\">;</span> <span class=\"n\">simp</span> <span class=\"o\">[</span><span class=\"n\">array.write_eq_write'</span><span class=\"o\">]</span>\n</code></pre></div>\n<p>So even though lean stores it internally as a universal statement, the proof starts with <code>b</code>, <code>i</code>, <code>h</code>, and <code>v</code> in the local context.  In this case, yes, a few <code>intro</code>s will get you there.  Also, you are correct on the origin of the \"extra proof steps\".</p>",
        "id": 241100301,
        "sender_full_name": "Jason Rute",
        "timestamp": 1622602295
    },
    {
        "content": "<p>I should also point out some other examples, so you see how the proof recording data works.  Consider <a href=\"https://leanprover-community.github.io/mathlib_docs/find/nat.add_assoc\">docs#nat.add_assoc</a>.  In that case, the proof is mostly a term proof, but one branch included a short tactic proof (starting with <code>by</code>).  Only the tactic branch is recorded.</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kn\">protected</span> <span class=\"kd\">lemma</span> <span class=\"n\">add_assoc</span> <span class=\"o\">:</span> <span class=\"bp\">∀</span> <span class=\"n\">n</span> <span class=\"n\">m</span> <span class=\"n\">k</span> <span class=\"o\">:</span> <span class=\"n\">ℕ</span><span class=\"o\">,</span> <span class=\"o\">(</span><span class=\"n\">n</span> <span class=\"bp\">+</span> <span class=\"n\">m</span><span class=\"o\">)</span> <span class=\"bp\">+</span> <span class=\"n\">k</span> <span class=\"bp\">=</span> <span class=\"n\">n</span> <span class=\"bp\">+</span> <span class=\"o\">(</span><span class=\"n\">m</span> <span class=\"bp\">+</span> <span class=\"n\">k</span><span class=\"o\">)</span>\n<span class=\"bp\">|</span> <span class=\"n\">n</span> <span class=\"n\">m</span> <span class=\"mi\">0</span>        <span class=\"o\">:=</span> <span class=\"n\">rfl</span>\n<span class=\"bp\">|</span> <span class=\"n\">n</span> <span class=\"n\">m</span> <span class=\"o\">(</span><span class=\"n\">succ</span> <span class=\"n\">k</span><span class=\"o\">)</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">add_succ</span><span class=\"o\">,</span> <span class=\"n\">add_succ</span><span class=\"o\">,</span> <span class=\"n\">add_assoc</span><span class=\"o\">]</span>\n</code></pre></div>",
        "id": 241100303,
        "sender_full_name": "Jason Rute",
        "timestamp": 1622602301
    },
    {
        "content": "<p>I don't have another example off hand, but you can easily see complicated proofs that have parts like: <code>try {refl; rw [by refl : foo]}</code>.  Here <code>try {refl; rw [by refl : foo]}</code> is a tactic, and so is <code>refl; rw [by refl : foo]</code>, <code>refl</code>, <code>rw [by refl : foo]</code>.  Further, inside this tactic block is a whole other tactic block <code>by refl</code> and we record <code>refl</code> too.  If you are particularly interested in getting the outermost tactics, for example for testing the REPL, you may want to look deeper into the data being generated by the proof recording process.  There is a lot more there specifying the structure of the proof.  It isn't well documented but I'm happy to help.</p>",
        "id": 241100304,
        "sender_full_name": "Jason Rute",
        "timestamp": 1622602303
    },
    {
        "content": "<p>As for other differences between the REPL and training data, I would watch out for any differences in how tactic states are printed.  (However, in your example, those are two different tactic states, so they should print differently.)  The printing code might not be perfectly aligned (which is of course bad, and it should be addressed).</p>",
        "id": 241100438,
        "sender_full_name": "Jason Rute",
        "timestamp": 1622602529
    },
    {
        "content": "<p>As for the differences in theorem numbers, I think the lean-gym numbers are from a newer version of lean_proof_recording where we modified the test ratio to be smaller.  (<span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span> we should make that public soon.)  Also, I think different versions of lean or mathlib could also explain the small differences.</p>",
        "id": 241100621,
        "sender_full_name": "Jason Rute",
        "timestamp": 1622602768
    },
    {
        "content": "<p>Also, this is really subtle, but I believe lean-gym carried over from gptf a small rewrite tactic optimization.  Our language model would sometimes make long rewrite chains like <code>rw [foo1, foo2, foo3, .., foo7]</code>.  Since most of the rewrites were good, but one bad apple ruined the bunch, I think we added some special logic in how we parse<code>rw</code> tactics.  <span class=\"user-mention\" data-user-id=\"116045\">@Jesse Michael Han</span> knows the details better.  I wonder (and I'm opening speculating here) if this is a good feature to keep in lean-gym, or if it just adds unnecessary confusion.</p>",
        "id": 241100825,
        "sender_full_name": "Jason Rute",
        "timestamp": 1622603049
    },
    {
        "content": "<p>yeah this was implemented by <span class=\"user-mention\" data-user-id=\"121918\">@Edward Ayers</span>, we try to run a <code>squeeze_rewrite</code> function while parsing tactics from the strings emitted by the model (<a href=\"https://github.com/jesse-michael-han/lean-gptf/blob/e58515bc0eee4ed785b7fe753e0f54073503f723/src/tactic/gptf/utils/util.lean#L436\">link</a>)</p>",
        "id": 241107332,
        "sender_full_name": "Jesse Michael Han",
        "timestamp": 1622611687
    },
    {
        "content": "<p>Thanks, this definitely helps me understand the proof recording better. The case mentioned above isn't such an issue because the initial REPL state is only an <code>intros</code> away from the initial state faced by a person, but are there other cases where you'd expect the difference to be bigger? (I'd guess not because the only case I can think of involve implicit universes / variables, but I'm not certain)</p>",
        "id": 241109082,
        "sender_full_name": "Aidan Swope",
        "timestamp": 1622614166
    },
    {
        "content": "<p>Hi Aidan, to compare with PACT precisely you would have to use lean-tpe and proper labels on lean_proof_recording and lean-step. Over the past few weeks I worked on bumping mathlib and including lean-liquid in lean_proof_recording and lean-step. Doing so, as mentioned by <span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> I also reduced the test/valid ratios a notch which explains the discrepancy in number of test/valid theorems.</p>\n<p>All in all, if you run an eval using lean-gym against the current valid/test set, I would say that the pass rate numbers should be roughly comparable to PACT (maybe PACT would be a bit under-estimated depending on your use of lean-gym (lean-tpe on top of the OpenAI API is prolly a bit less stable/more error-prone than our current lean-gym setup as an example)). We consider these numbers comparable for what it's worth.</p>\n<p>Concerning the tactic state, it is indeed one intros away from what exist in the training set. I'll let <span class=\"user-mention\" data-user-id=\"116045\">@Jesse Michael Han</span> provide some color on that, but will note that this was the case for PACT as well and that we have hardly seen evidence of this hurting our models.</p>\n<p>Hope this helps!</p>",
        "id": 241113397,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1622618429
    },
    {
        "content": "<p>Also worth mentioning that lean-gym publishes splits for mathlib, lean-liquid and miniF2F separately, to compare to PACT you would want to use the mathlib split of course.</p>",
        "id": 241117900,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1622621647
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116045\">Jesse Michael Han</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/Getting.20started.20with.20lean-gym/near/241107332\">said</a>:</p>\n<blockquote>\n<p>yeah this was implemented by <span class=\"user-mention silent\" data-user-id=\"121918\">Edward Ayers</span>, we try to run a <code>squeeze_rewrite</code> function while parsing tactics from the strings emitted by the model (<a href=\"https://github.com/jesse-michael-han/lean-gptf/blob/e58515bc0eee4ed785b7fe753e0f54073503f723/src/tactic/gptf/utils/util.lean#L436\">link</a>)</p>\n</blockquote>\n<p>My point is that this should be documented or removed.  Otherwise the users will be confused as to why <code>rw</code> tactics behave differently in <code>lean-gym</code> than in Lean.  Do you think this optimization makes a big difference in lean gptf?</p>",
        "id": 241131985,
        "sender_full_name": "Jason Rute",
        "timestamp": 1622630580
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"349892\">@Aidan Swope</span> Here is how I think of it.  Think of an analogy with board games.  In this analogy a proof is like the play of a (one-player) board game.  Lean-gym is like a gym interface that let's an AI play (Lean) board games.  It always starts at the initial state of the game.  Now, lean-proof-recording is a bunch of recored player data.  Because of fundamental limitations in the recording process, we don't have every move in the board game. For some games we do have recorded opening moves (usually <code>intro</code> or <code>intros</code>), but for other games we only have the moves for positions deeper into the game.  Since the opening game is pretty consistent, this probably isn't a big deal.  It isn't a misalignment issue as much as a missing data issue.  Also, there aren't necessarily easy ways to fill in this missing data.  It is part of the messiness of real world data.</p>",
        "id": 241136725,
        "sender_full_name": "Jason Rute",
        "timestamp": 1622633947
    },
    {
        "content": "<p>Ok, now, before I beat this analogy to death, let me just talk about Lean directly now.  There are lots of ways in Lean for users to prove things outside tactic mode.  None of these things will be recorded in lean-proof-recording because lean-proof-recording is only capable of recording tactics executed in interactive mode:</p>\n<ul>\n<li>Putting the parameters on the left side of the colon automatically starts the proof with lambdas (the same thing you would get from applying <code>intro</code> tactics).</li>\n<li>Using the induction/case-matching syntax as in the proof of <code>nat.assoc</code> above.</li>\n<li>Using <code>calc</code> syntax.</li>\n<li>Giving a term proof (possibly using human sugar coating syntax like <code>match</code>, <code>assume</code>, etc.).</li>\n</ul>",
        "id": 241136731,
        "sender_full_name": "Jason Rute",
        "timestamp": 1622633953
    },
    {
        "content": "<p>All of these things, in addition to tactic proofs, are turned by Lean into low-level term proofs.  Those proofs are stored in Lean, and we do use those term proofs (in a number of ways) as additional training data in the PACT training framework.  (See the PACT paper for the specifics.)</p>",
        "id": 241136737,
        "sender_full_name": "Jason Rute",
        "timestamp": 1622633960
    },
    {
        "content": "<p>Now, there is also another area where lean-gym and lean-proof-recording differ in scope which we have already talked about.  lean-gym takes the simplistic approach that a proof is linear and of the form:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">begin</span>\n<span class=\"n\">tactic_1</span><span class=\"o\">,</span>\n<span class=\"n\">tactic_2</span><span class=\"o\">,</span>\n<span class=\"bp\">...</span><span class=\"o\">,</span>\n<span class=\"n\">tactic_n</span>\n<span class=\"kd\">end</span>\n</code></pre></div>\n<p>whereas actual Lean proofs can be more tree like.  (For what it is worth, this is pretty consistent with other such projects like HOList.  The only exception is that HOList works on an individual goal at a time, where lean-gym works on the whole goal stack every time even though most tactics only modify the first goal.)  For example, one can combine tactics with all sorts of combinators, like <code>tac1;tac2</code> to chain tactics and make sure <code>tac2</code> is applied to <em>all</em> subgoals of applying <code>tac1</code>.  We record the whole combination (and indeed Lean gptf is pretty good at using the <code>;</code> combinator), as well as every instance of <code>tac1</code> and <code>tac2</code> (note, there are as many instances of <code>tac2</code> as there are subgoals of applying <code>tac1</code>).   Another common combinator is <code>{...}</code> which focuses on the first goal and solves it.  Again, our model is trained to use <code>{...}</code> and also trained on the tactics inside.  This way it can give a one-line tactic <code>{...}</code> or separately apply all the tactics inside.  Usually, <code>{...}</code> is just a convenient book keeping mechanism more than an integral part of the proof.  In short, even though lean-gym (and lean-gptf) are making the simplifying assumption that proofs need to be linear, the training data includes information about many levels of tactic execution so hopefully the final model can learn to construct linear proofs, either by (1) synthesizing whole tactic combinators, or (2) providing a (possibly long and repetitive) proof made of lots of simple steps.</p>",
        "id": 241136751,
        "sender_full_name": "Jason Rute",
        "timestamp": 1622633969
    },
    {
        "content": "<p>One future challenge with Lean4 is that the <a href=\"https://leanprover.github.io/lean4/doc/tactics.html\">tactic framework</a> seems to be even less linear, with a more programing like syntax full of combinators.  I don't know if the mathlib community really wants to follow this pattern, but if they do, then it will be an even bigger challenge to record proofs and build a gym around this proof framework.</p>",
        "id": 241136754,
        "sender_full_name": "Jason Rute",
        "timestamp": 1622633972
    },
    {
        "content": "<p>(Ok, after writing all that, I think I understand your concern a bit better <span class=\"user-mention\" data-user-id=\"349892\">@Aidan Swope</span>.  You are worried about there being a distribution shift between the states in recorded proof data and the states in the lean-gym.  This is certainly going to be true for the reasons above.  You mention universes.  I don't think there will be a distribution shift in universe names, but I could be mistaken. Nonetheless, with the diverse data we use for PACT, it doesn't seem to be a significant issue.  Also, I'm sure adding reinforcement learning would significantly help distribution shift since it would push the training data distribution of tactic states to align with those tactic states encountered by the agent in the environment.)</p>",
        "id": 241138080,
        "sender_full_name": "Jason Rute",
        "timestamp": 1622634997
    },
    {
        "content": "<p>Another thing I should mention is that I discovered lean-gym allows the <code>sorry</code> tactic as well as any other tactic commands which are based on <code>sorry</code>, like <code>exact sorry</code>, <code>try {sorry}</code>, etc.  I think any user of lean-gym would be prudent to put a guard on any AI to make sure \"sorry\" isn't in the tactic being tried.  Also, there are aliases for <code>sorry</code> in some projects, so checking for the \"sorry\" string may not be a perfect solution.  The silver lining is that unless the training data mentions <code>sorry</code>,  a language model should not know it exists.  I'm pretty sure there are no <code>sorry</code>s in mathlib.  (Also, note HOList has the same problem with the CHEAT_TAC.  If using a language model on HOList, it would be prudent to check for CHEAT_TAC especially since I think it is used to \"prove\" axioms in HOL Light and may have made its way into the training data, but I'm not certain.)</p>",
        "id": 241146943,
        "sender_full_name": "Jason Rute",
        "timestamp": 1622639938
    },
    {
        "content": "<p>PSA: <code>lean-gym</code> now checks that generated proofs don't rely on <code>sorry</code> and actually match the type of the original goal: <a href=\"https://github.com/openai/lean-gym/pull/5\">https://github.com/openai/lean-gym/pull/5</a><br>\nSee <a href=\"#narrow/stream/239415-metaprogramming-.2F.20tactics/topic/Check.20for.20sorry.20in.20tactic.20proof/near/241747563\">this topic</a> for more details.</p>\n<p>And MiniF2F now boasts 136 Lean valid statements! (h/t <span class=\"user-mention\" data-user-id=\"408484\">@Kunhao Zheng</span>)</p>",
        "id": 241835535,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1623097496
    },
    {
        "content": "<p><code>lean-gym</code> now also protects against the use of <code>undefined</code> (see the <a href=\"#narrow/stream/239415-metaprogramming-.2F.20tactics/topic/Check.20for.20sorry.20in.20tactic.20proof/near/241881651\">same topic</a> for more details). And miniF2F has 133 Lean test statements (h/t <span class=\"user-mention\" data-user-id=\"408484\">@Kunhao Zheng</span>).</p>",
        "id": 242040048,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1623232049
    },
    {
        "content": "<p>I've also added a Code of Conduct to MiniF2F's README:</p>\n<blockquote>\n<p>MiniF2F is meant to serve as a shared and useful resource for the machine learning community working on formal mathematics. It is still a TODO to determine how we'll exchange respective results on the benchmark in a way that is the most useful to the community.</p>\n<p>In the meantime, if you're using miniF2F and are discovering new proofs (manually or automatically) please contribute them back to the benchmark.</p>\n</blockquote>\n<p>On the first point I think we don't want to over-engineer anything. We'll probably introduce a versioning system so that papers car refer to versions of MiniF2F in papers and call it a day so that it's all simple and easy. Concerning the second point, hope to see as many contributions as possible! Feedback very welcome on this obviously.</p>",
        "id": 242040366,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1623232237
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span>  I've noticed that lean-gym and lean-step-public use the same Lean version and mathlib revision, but lean-proof-recording-public uses an older version. This results in some theorems being assigned to different splits in the data vs evaluation environments. For example, <code>stream.mem_map</code> is in the test set in lean-gym and lean-step-public, but the validation set for lean-proof-recording-public.</p>\n<p>I think it'd be good to pin the versions used by these three repositories since they seem to collectively make up the benchmark, and I'd worry that people down the line wouldn't be careful enough to check the versions and might report overconfident results.</p>",
        "id": 243207850,
        "sender_full_name": "Aidan Swope",
        "timestamp": 1624049911
    },
    {
        "content": "<p>FYI here is a bare-bones proof-of-concept tactic repl for Lean4: <a href=\"https://github.com/dselsam/lean-gym\">https://github.com/dselsam/lean-gym</a> The main missing feature is that there is no way yet to import <em>until</em> a given declaration. TBD the best way to handle this in Lean4</p>",
        "id": 243210622,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1624052249
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span> Do you recall what Lean version / mathlib revision you used to make the <code>mathlib-{train,valid,test}</code> files in lean-gym? They don't seem to match the results from lean-proof-recording-public using either the commit listed there or in lean-gym (in leanpkg.toml).</p>",
        "id": 243215946,
        "sender_full_name": "Aidan Swope",
        "timestamp": 1624058120
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/Getting.20started.20with.20lean-gym/near/241136754\">said</a>:</p>\n<blockquote>\n<p>One future challenge with Lean4 is that the <a href=\"https://leanprover.github.io/lean4/doc/tactics.html\">tactic framework</a> seems to be even less linear, with a more programing like syntax full of combinators.  I don't know if the mathlib community really wants to follow this pattern, but if they do, then it will be an even bigger challenge to record proofs and build a gym around this proof framework.</p>\n</blockquote>\n<p>Can you please clarify your concern? What does it mean for the tactic framework to be \"even less linear\"?  What of importance is missing from the hundred line <a href=\"https://github.com/dselsam/lean-gym/blob/master/Gym.lean\">https://github.com/dselsam/lean-gym/blob/master/Gym.lean</a> (besides importing upto a declaration)?</p>",
        "id": 243222441,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1624068352
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"349892\">@Aidan Swope</span>, let me work with Stan to publish a public version of lean_proof_recording (or a data) which aligns more closely to lean gym.  For the mean time, I've invited you (<code>maxwells-daemons</code> which I got from Googling your name) to the private GitHub repo which should be more closely aligned.</p>",
        "id": 243228689,
        "sender_full_name": "Jason Rute",
        "timestamp": 1624077017
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"230999\">@Daniel Selsam</span> Just a quick note.  I'll look more closely at your prototype (which is great to have!) soon.  When I said \"less linear\", consider this example from the <a href=\"https://leanprover.github.io/lean4/doc/tactics.html\">Lean 4 manual</a>:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">theorem</span> <span class=\"n\">ex</span> <span class=\"o\">(</span><span class=\"n\">x</span> <span class=\"o\">:</span> <span class=\"n\">Nat</span><span class=\"o\">)</span> <span class=\"o\">{</span><span class=\"n\">y</span> <span class=\"o\">:</span> <span class=\"n\">Nat</span><span class=\"o\">}</span> <span class=\"o\">(</span><span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">y</span> <span class=\"bp\">&gt;</span> <span class=\"mi\">0</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">x</span> <span class=\"bp\">%</span> <span class=\"n\">y</span> <span class=\"bp\">&lt;</span> <span class=\"n\">y</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">induction</span> <span class=\"n\">x</span><span class=\"o\">,</span> <span class=\"n\">y</span> <span class=\"n\">using</span> <span class=\"n\">Nat.mod.inductionOn</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">ind</span> <span class=\"n\">x</span> <span class=\"n\">y</span> <span class=\"n\">h₁</span> <span class=\"n\">ih</span> <span class=\"bp\">=&gt;</span>\n    <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">Nat.mod_eq_sub_mod</span> <span class=\"n\">h₁.2</span><span class=\"o\">]</span>\n    <span class=\"n\">exact</span> <span class=\"n\">ih</span> <span class=\"n\">h</span>\n  <span class=\"bp\">|</span> <span class=\"n\">base</span> <span class=\"n\">x</span> <span class=\"n\">y</span> <span class=\"n\">h₁</span> <span class=\"bp\">=&gt;</span>\n     <span class=\"k\">have</span> <span class=\"o\">:</span> <span class=\"bp\">¬</span> <span class=\"mi\">0</span> <span class=\"bp\">&lt;</span> <span class=\"n\">y</span> <span class=\"bp\">∨</span> <span class=\"bp\">¬</span> <span class=\"n\">y</span> <span class=\"bp\">≤</span> <span class=\"n\">x</span> <span class=\"o\">:=</span> <span class=\"n\">Iff.mp</span> <span class=\"o\">(</span><span class=\"n\">Decidable.notAndIffOrNot</span> <span class=\"bp\">..</span><span class=\"o\">)</span> <span class=\"n\">h₁</span>\n     <span class=\"k\">match</span> <span class=\"n\">this</span> <span class=\"k\">with</span>\n     <span class=\"bp\">|</span> <span class=\"n\">Or.inl</span> <span class=\"n\">h₁</span> <span class=\"bp\">=&gt;</span> <span class=\"n\">exact</span> <span class=\"n\">absurd</span> <span class=\"n\">h</span> <span class=\"n\">h₁</span>\n     <span class=\"bp\">|</span> <span class=\"n\">Or.inr</span> <span class=\"n\">h₁</span> <span class=\"bp\">=&gt;</span>\n       <span class=\"k\">have</span> <span class=\"n\">hgt</span> <span class=\"o\">:</span> <span class=\"n\">y</span> <span class=\"bp\">&gt;</span> <span class=\"n\">x</span> <span class=\"o\">:=</span> <span class=\"n\">Nat.gtOfNotLe</span> <span class=\"n\">h₁</span>\n       <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"bp\">←</span> <span class=\"n\">Nat.mod_eq_of_lt</span> <span class=\"n\">hgt</span><span class=\"o\">]</span> <span class=\"n\">at</span> <span class=\"n\">hgt</span>\n       <span class=\"n\">assumption</span>\n</code></pre></div>",
        "id": 243229915,
        "sender_full_name": "Jason Rute",
        "timestamp": 1624079062
    },
    {
        "content": "<p>If I'm not mistaken (and correct me if I am), this is just one tactic command, right?  So if one puts that into your gym, it would have to go in as a single entry, right?  If all (or most) induction examples in the dataset are like this, then it would be hard for a model like lean gptf to get started on an induction proof since it would have to generate the whole proof in one go.  Of course Lean 3 has lots of nonlinear tactic proofs as well, and as discussed above that is a distribution shift from the linear paradigm that lean gym enforces.  But the Lean 4 syntax seems to blend term proofs and tactic proofs even more.  Overall, this seems like a useful thing, except as a source of training data to a linear proof generator. <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span>  One could argue, of course, that the problem is with the linear proof assumption of Lean gym and Lean GPT-f (and most similar projects).  The Lean gptf approach wouldn't work on say Lean3 term proofs without first converting them into some tactic language or just generating each term proof in one-go with no intermediate goal information.</p>",
        "id": 243229918,
        "sender_full_name": "Jason Rute",
        "timestamp": 1624079068
    },
    {
        "content": "<p>My comment about \"the mathlib community\" is entirely based on <a class=\"stream-topic\" data-stream-id=\"270676\" href=\"/#narrow/stream/270676-lean4/topic/missing.20tactics\">#lean4 &gt; missing tactics</a> which in hindsight, I'm reading too much into.  Anyway, in that thread, Kevin talks about how he doesn't like the built in Lean4 <code>cases</code> tactic and was looking for a tactic more like the Lean3 <code>split</code> tactic.</p>",
        "id": 243229919,
        "sender_full_name": "Jason Rute",
        "timestamp": 1624079075
    },
    {
        "content": "<p>Since we are on this topic, how easy do you think it would be, <span class=\"user-mention\" data-user-id=\"230999\">@Daniel Selsam</span>, to get a (proof-of-concept) training dataset of Lean4 proofs broken up by goal-tactic pairs similar to what I did for Lean 3?  (As for nested tactics, ideally one would enumerate the outer tactic as well as any inner tactics.)</p>",
        "id": 243229920,
        "sender_full_name": "Jason Rute",
        "timestamp": 1624079077
    },
    {
        "content": "<p>Thanks <span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> for inviting <span class=\"user-mention\" data-user-id=\"349892\">@Aidan Swope</span>. </p>\n<p><span class=\"user-mention\" data-user-id=\"349892\">@Aidan Swope</span> we indeed need to publish the latest version of lean_proof_recording. <span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> I think your private version is ready for that?</p>",
        "id": 243230395,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1624079974
    },
    {
        "content": "<p>Thanks <span class=\"user-mention\" data-user-id=\"230999\">@Daniel Selsam</span> for the prototype. This is hugely exciting! </p>\n<p>Very interested to have your take ok <span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span>’s question. Would love to see in particular built in proof tracing infrastructure 👍</p>",
        "id": 243231142,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1624081466
    },
    {
        "content": "<p>Thanks for the invite! I'll look into using the data from here.</p>",
        "id": 243239771,
        "sender_full_name": "Aidan Swope",
        "timestamp": 1624094868
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> <span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span> I don't see an issue, but I think I understand why you thought there might be. The tactic block above <em>looks</em> monolithic. But internally, evaluating the <code>induction</code> tactic will recursively call <code>evalTactic</code> on the syntax for the subgoals. Similar with the <code>match</code> tactic.  And then evaluating the sequences at the leaves will also call <code>evalTactic</code> on the elements in sequence. So, we can collect the data by adding one line to <code>evalTactic</code> to print out the goal and the \"cleaned up\" syntax (i.e. where all recursive tactics are replaced with placeholders). Note: this would trace even for search branches that failed, but we can easily fix this too by having <code>evalTactic</code> instead store the datapoint in the backtracking part of the tactic state, so we only look at them for successful branches.</p>",
        "id": 243258628,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1624121904
    },
    {
        "content": "<p>In other words, the proof you posted above is isomorphic to one with explicit decomposition into steps, and we can trace the former as if it were the latter:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">example</span> <span class=\"o\">(</span><span class=\"n\">x</span> <span class=\"o\">:</span> <span class=\"n\">Nat</span><span class=\"o\">)</span> <span class=\"o\">{</span><span class=\"n\">y</span> <span class=\"o\">:</span> <span class=\"n\">Nat</span><span class=\"o\">}</span> <span class=\"o\">(</span><span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">y</span> <span class=\"bp\">&gt;</span> <span class=\"mi\">0</span><span class=\"o\">)</span> <span class=\"o\">:</span> <span class=\"n\">x</span> <span class=\"bp\">%</span> <span class=\"n\">y</span> <span class=\"bp\">&lt;</span> <span class=\"n\">y</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">induction</span> <span class=\"n\">x</span><span class=\"o\">,</span> <span class=\"n\">y</span> <span class=\"n\">using</span> <span class=\"n\">Nat.mod.inductionOn</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">ind</span> <span class=\"n\">x</span> <span class=\"n\">y</span> <span class=\"n\">h₁</span> <span class=\"n\">ih</span> <span class=\"bp\">=&gt;</span> <span class=\"bp\">?</span><span class=\"n\">i1</span>\n  <span class=\"bp\">|</span> <span class=\"n\">base</span> <span class=\"n\">x</span> <span class=\"n\">y</span> <span class=\"n\">h₁</span>   <span class=\"bp\">=&gt;</span> <span class=\"bp\">?</span><span class=\"n\">i2</span>\n\n  <span class=\"n\">case</span> <span class=\"n\">i1</span> <span class=\"bp\">=&gt;</span>\n    <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">Nat.mod_eq_sub_mod</span> <span class=\"n\">h₁.2</span><span class=\"o\">]</span>\n    <span class=\"n\">exact</span> <span class=\"n\">ih</span> <span class=\"n\">h</span>\n\n  <span class=\"n\">case</span> <span class=\"n\">i2</span> <span class=\"bp\">=&gt;</span>\n    <span class=\"k\">have</span> <span class=\"o\">:</span> <span class=\"bp\">¬</span> <span class=\"mi\">0</span> <span class=\"bp\">&lt;</span> <span class=\"n\">y</span> <span class=\"bp\">∨</span> <span class=\"bp\">¬</span> <span class=\"n\">y</span> <span class=\"bp\">≤</span> <span class=\"n\">x</span> <span class=\"o\">:=</span> <span class=\"n\">Iff.mp</span> <span class=\"o\">(</span><span class=\"n\">Decidable.notAndIffOrNot</span> <span class=\"bp\">..</span><span class=\"o\">)</span> <span class=\"n\">h₁</span>\n    <span class=\"k\">match</span> <span class=\"n\">this</span> <span class=\"k\">with</span>\n    <span class=\"bp\">|</span> <span class=\"n\">Or.inl</span> <span class=\"n\">h₁</span> <span class=\"bp\">=&gt;</span> <span class=\"bp\">?</span><span class=\"n\">i21</span>\n    <span class=\"bp\">|</span> <span class=\"n\">Or.inr</span> <span class=\"n\">h₁</span> <span class=\"bp\">=&gt;</span> <span class=\"bp\">?</span><span class=\"n\">i22</span>\n\n    <span class=\"n\">case</span> <span class=\"n\">i21</span> <span class=\"bp\">=&gt;</span>\n      <span class=\"n\">exact</span> <span class=\"n\">absurd</span> <span class=\"n\">h</span> <span class=\"n\">h₁</span>\n\n    <span class=\"n\">case</span> <span class=\"n\">i22</span> <span class=\"bp\">=&gt;</span>\n      <span class=\"k\">have</span> <span class=\"n\">hgt</span> <span class=\"o\">:</span> <span class=\"n\">y</span> <span class=\"bp\">&gt;</span> <span class=\"n\">x</span> <span class=\"o\">:=</span> <span class=\"n\">Nat.gtOfNotLe</span> <span class=\"n\">h₁</span>\n      <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"bp\">←</span> <span class=\"n\">Nat.mod_eq_of_lt</span> <span class=\"n\">hgt</span><span class=\"o\">]</span> <span class=\"n\">at</span> <span class=\"n\">hgt</span>\n      <span class=\"n\">assumption</span>\n</code></pre></div>",
        "id": 243271874,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1624141161
    },
    {
        "content": "<p>Yes.  This makes sense.  This would of course have to be reflected in both the gym interface (by adding support for that <code>?i1</code> syntax which I assume are not valid lean code, right?) and in the training data (by explicitly tracing this type of data).  I guess this approach would even work for Lean 3, although there aren’t as many tactic combinators in Lean 3.</p>",
        "id": 243276046,
        "sender_full_name": "Jason Rute",
        "timestamp": 1624147550
    },
    {
        "content": "<p>The <code>?i1</code> syntax is valid lean 4, although I think it needs to be wrapped in a tactic like <code>refine</code> because it is a term, not a tactic (which creates a goal called <code>i1</code> for the named metavariable)</p>",
        "id": 243277408,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1624149587
    },
    {
        "content": "<p>Oh, it does appear to be valid syntax, or at least it works in this example:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">theorem</span> <span class=\"n\">ex1</span> <span class=\"o\">:</span> <span class=\"n\">p</span> <span class=\"bp\">∨</span> <span class=\"n\">q</span> <span class=\"bp\">→</span> <span class=\"n\">q</span> <span class=\"bp\">∨</span> <span class=\"n\">p</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">intro</span> <span class=\"n\">h</span>\n  <span class=\"n\">cases</span> <span class=\"n\">h</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">inl</span> <span class=\"n\">h1</span> <span class=\"bp\">=&gt;</span>\n    <span class=\"n\">apply</span> <span class=\"n\">Or.inr</span>\n    <span class=\"n\">exact</span> <span class=\"n\">h1</span>\n  <span class=\"bp\">|</span> <span class=\"n\">inr</span> <span class=\"n\">h2</span> <span class=\"bp\">=&gt;</span>\n    <span class=\"n\">apply</span> <span class=\"n\">Or.inl</span>\n    <span class=\"n\">assumption</span>\n</code></pre></div>\n<p>can be rewritten as</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"kd\">theorem</span> <span class=\"n\">ex1</span> <span class=\"o\">:</span> <span class=\"n\">p</span> <span class=\"bp\">∨</span> <span class=\"n\">q</span> <span class=\"bp\">→</span> <span class=\"n\">q</span> <span class=\"bp\">∨</span> <span class=\"n\">p</span> <span class=\"o\">:=</span> <span class=\"kd\">by</span>\n  <span class=\"n\">intro</span> <span class=\"n\">h</span>\n  <span class=\"n\">cases</span> <span class=\"n\">h</span> <span class=\"k\">with</span>\n  <span class=\"bp\">|</span> <span class=\"n\">inl</span> <span class=\"n\">h1</span> <span class=\"bp\">=&gt;</span> <span class=\"bp\">?</span><span class=\"n\">i1</span>\n  <span class=\"bp\">|</span> <span class=\"n\">inr</span> <span class=\"n\">h2</span> <span class=\"bp\">=&gt;</span> <span class=\"bp\">?</span><span class=\"n\">i2</span>\n\n  <span class=\"n\">case</span> <span class=\"n\">i1</span> <span class=\"bp\">=&gt;</span>\n    <span class=\"n\">apply</span> <span class=\"n\">Or.inr</span>\n    <span class=\"n\">exact</span> <span class=\"n\">h1</span>\n\n  <span class=\"n\">case</span> <span class=\"n\">i2</span> <span class=\"bp\">=&gt;</span>\n    <span class=\"n\">apply</span> <span class=\"n\">Or.inl</span>\n    <span class=\"n\">assumption</span>\n</code></pre></div>",
        "id": 243279437,
        "sender_full_name": "Jason Rute",
        "timestamp": 1624152669
    },
    {
        "content": "<p>Hey <span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span>, I've had some difficulty loading MiniF2F theorems through lean-gym. I'm seeing <code>not_a_theorem</code> errors for all of them. Could you explain how to set up for loading those please?</p>",
        "id": 243428498,
        "sender_full_name": "Aidan Swope",
        "timestamp": 1624302462
    },
    {
        "content": "<p>Did you run one of the setup scripts under the scripts/ directory?</p>",
        "id": 243428598,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1624302494
    },
    {
        "content": "<p>If the theorems are from mathlib, a typical leanpkg setup should do the trick?</p>",
        "id": 243428681,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1624302525
    },
    {
        "content": "<p>Oh, woops, I only ran <code>scripts/setup.sh</code>, not <code>scripts/setup_miniF2F.sh</code>. That does it, thanks!</p>",
        "id": 243429312,
        "sender_full_name": "Aidan Swope",
        "timestamp": 1624302840
    },
    {
        "content": "<p>Is there a way so that we could provide custom tactic state or declare new theorem name in the <code>lean-gym</code>. Fro some of the theorems, (for eg. <code>invertible_div</code>) I am getting <code>not_a_theorem</code> error. Any help regarding this or workaround would be helpful!</p>",
        "id": 274879024,
        "sender_full_name": "Ayush Agrawal",
        "timestamp": 1646938386
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"439607\">Ayush Agrawal</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Getting.20started.20with.20lean-gym/near/274879024\">said</a>:</p>\n<blockquote>\n<p>Is there a way so that we could provide custom tactic state or declare new theorem name in the <code>lean-gym</code>. Fro some of the theorems, (for eg. <code>invertible_div</code>) I am getting <code>not_a_theorem</code> error. Any help regarding this or workaround would be helpful!</p>\n</blockquote>\n<p>Depending on what you are trying to accomplish, you might just want to skip non theorems. Otherwise, I don't see at a glance why you couldn't just comment out the check @ <a href=\"https://github.com/openai/lean-gym/blob/main/src/repl.lean#L172-L184\">https://github.com/openai/lean-gym/blob/main/src/repl.lean#L172-L184</a></p>",
        "id": 274921859,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1646963252
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"230999\">@Daniel Selsam</span> thanks. Commenting that part is working. However, I get a warning: <code>/home/t-agrawala/Desktop/lean_work/lean-gym/src/ayush_repl.lean:16:0: warning: imported file '/home/t-agrawala/Desktop/lean_work/lean-gym/src/tools/shrink_proof.lean' uses sorry</code>. It would be helpful if you have some workaround to declare a new tactic state and initiating that for lean-gym so that one can also run new examples that are not part of the mathlib/or does not have any name for now  in lean-gym</p>",
        "id": 274991210,
        "sender_full_name": "Ayush Agrawal",
        "timestamp": 1647013144
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"439607\">Ayush Agrawal</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Getting.20started.20with.20lean-gym/near/274991210\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"230999\">Daniel Selsam</span> thanks. Commenting that part is working. However, I get a warning: <code>/home/t-agrawala/Desktop/lean_work/lean-gym/src/ayush_repl.lean:16:0: warning: imported file '/home/t-agrawala/Desktop/lean_work/lean-gym/src/tools/shrink_proof.lean' uses sorry</code>. It would be helpful if you have some workaround to declare a new tactic state and initiating that for lean-gym so that one can also run new examples that are not part of the mathlib/or does not have any name for now  in lean-gym</p>\n</blockquote>\n<p>See e.g. <a href=\"https://github.com/openai/lean-gym/blob/main/scripts/setup_miniF2F.sh\">https://github.com/openai/lean-gym/blob/main/scripts/setup_miniF2F.sh</a> for a (very hacky) way of adding other projects to the environment. Basically you just need to add your favorite package to the <code>leanpkg.toml</code> and define an <code>all.lean</code> (which will be imported by the cryptic <code>import all</code> in <code>repl.lean</code>. You can also just add a file in <code>lean-gym</code> itself with the declarations you want and import that instead. Lean4 gym will be less hacky when the time comes.</p>",
        "id": 275043486,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1647037869
    },
    {
        "content": "<p>Hi guys, can anyone please give some causes of the <code>gen_tac_and_capture_res_failed</code> error. From the repl file, it says : <code>if there are remaining subgoals</code>. However, I didn't understand the idea clearly</p>",
        "id": 278427569,
        "sender_full_name": "Ayush Agrawal",
        "timestamp": 1649534109
    },
    {
        "content": "<p>One more doubt:<br>\nI am trying this theorem in lean-gym:<br>\n<code>lemma sum_two_pow_lt_iff_lt (A B : finset ℕ) :\n  ∑ i in A, 2^i &lt; ∑ i in B, 2^i ↔ A.to_colex &lt; B.to_colex :=\nbegin\n  have z : ∀ (A B : finset ℕ), A.to_colex &lt; B.to_colex → ∑ i in A, 2^i &lt; ∑ i in B, 2^i,\n  { intros A B,\n    rw [← sdiff_lt_sdiff_iff_lt, colex.lt_def],\n    rintro ⟨k, z, kA, kB⟩,\n    rw ← sdiff_union_inter A B,\n    conv_rhs { rw ← sdiff_union_inter B A },\n    rw [sum_union (disjoint_sdiff_inter _ _), sum_union (disjoint_sdiff_inter _ _),\n        inter_comm, add_lt_add_iff_right],\n    apply lt_of_lt_of_le (@nat.sum_two_pow_lt k (A \\ B) _),\n    { apply single_le_sum (λ _ _, nat.zero_le _) kB },\n    intros x hx,\n    apply lt_of_le_of_ne (le_of_not_lt (λ kx, _)),\n    { apply (ne_of_mem_of_not_mem hx kA) },\n    have := (z kx).1 hx,\n    rw mem_sdiff at this hx,\n    exact hx.2 this.1 },\n  refine ⟨λ h, (lt_trichotomy A B).resolve_right (λ h₁, h₁.elim _ (not_lt_of_gt h ∘ z _ _)), z A B⟩,\n  rintro rfl,\n  apply irrefl _ h\nend</code></p>\n<p>However, I got error with <code>have:</code><br>\n<code>[\"init_search\",[\"colex.sum_two_pow_lt_iff_lt\",\"\"]]\n{\"error\":null,\"proof_steps\":[],\"search_id\":\"0\",\"tactic_state\":\"⊢ ∀ (A B : finset ℕ), A.sum (λ (i : ℕ), 2 ^ i) &lt; B.sum (λ (i : ℕ), 2 ^ i) ↔ A.to_colex &lt; B.to_colex\",\"tactic_state_id\":\"0\"}\n[\"run_tac\",[\"0\",\"0\",\"have z : ∀ (A B : finset ℕ), A.to_colex &lt; B.to_colex → ∑ i in A, 2^i &lt; ∑ i in B, 2^i\"]]\n{\"error\":\"gen_tac_and_capture_res_failed: pos=none msg=parse_itactic failed on </code>have z : ∀ (A B : finset ℕ), A.to_colex &lt; B.to_colex → ∑ i in A, 2^i &lt; ∑ i in B, 2^i<code>\",\"proof_steps\":[],\"search_id\":null,\"tactic_state\":null,\"tactic_state_id\":null}\n[\"run_tac\",[\"0\",\"0\",\"intros\"]]\n{\"error\":null,\"proof_steps\":[],\"search_id\":\"0\",\"tactic_state\":\"A B : finset ℕ\\n⊢ A.sum (λ (i : ℕ), 2 ^ i) &lt; B.sum (λ (i : ℕ), 2 ^ i) ↔ A.to_colex &lt; B.to_colex\",\"tactic_state_id\":\"1\"}\n[\"run_tac\",[\"0\",\"0\",\"have z : ∀ (A B : finset ℕ), A.to_colex &lt; B.to_colex → ∑ i in A, 2^i &lt; ∑ i in B, 2^i\"]]\n{\"error\":\"gen_tac_and_capture_res_failed: pos=none msg=parse_itactic failed on </code>have z : ∀ (A B : finset ℕ), A.to_colex &lt; B.to_colex → ∑ i in A, 2^i &lt; ∑ i in B, 2^i<code>\",\"proof_steps\":[],\"search_id\":null,\"tactic_state\":null,\"tactic_state_id\":null}\n</code><br>\nCan anyone help? Thanks!</p>",
        "id": 278429315,
        "sender_full_name": "Ayush Agrawal",
        "timestamp": 1649536567
    },
    {
        "content": "<p>My first guess would be that you are missing the finset open. Would that work with <code>[\"init_search\",[\"colex.sum_two_pow_lt_iff_lt\",\"finset\"]]</code> ?</p>",
        "id": 279063687,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1650014543
    },
    {
        "content": "<p>Generally speaking you need to pass as second argument the open namespace as we don't have a good way to infer it from the declaration name only. Open locales should be fine and properly set.</p>",
        "id": 279063762,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1650014614
    }
]