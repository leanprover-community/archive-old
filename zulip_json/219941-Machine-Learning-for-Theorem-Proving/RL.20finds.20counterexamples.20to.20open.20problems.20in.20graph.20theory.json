[
    {
        "content": "<p><a href=\"https://arxiv.org/abs/2104.14516\">https://arxiv.org/abs/2104.14516</a><br>\n<a href=\"https://twitter.com/wtgowers/status/1388458562775654401\">https://twitter.com/wtgowers/status/1388458562775654401</a></p>\n<div class=\"inline-preview-twitter\"><div class=\"twitter-tweet\"><a href=\"https://twitter.com/wtgowers/status/1388458562775654401\"><img class=\"twitter-avatar\" src=\"https://uploads.zulipusercontent.net/043e623bcf0cb73850557e6e19a9e4b7a47f079e/68747470733a2f2f7062732e7477696d672e636f6d2f70726f66696c655f696d616765732f313235393133343138353939313738323430322f70783552367147655f6e6f726d616c2e6a7067\"></a><p>An interesting paper by Adam Wagner appeared on arXiv a couple of days ago (thanks to Imre Leader for drawing my attention to it), which uses reinforcement learning to find non-trivial counterexamples to several conjectures in graph theory. 1/\n\n<a href=\"https://t.co/TrwnRNTGa4\">https://arxiv.org/pdf/2104.14516.pdf</a></p><span>- Timothy Gowers (@wtgowers)</span></div></div>",
        "id": 238877949,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1621064817
    },
    {
        "content": "<p>I am curious how important the RL/MLP component actually is in these results. It would be nice to see local-search baselines, i.e. considering local transformations in encoding space that improve the score, rather than nonlinearly warping the space with an MLP.</p>",
        "id": 238902313,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1621089406
    }
]