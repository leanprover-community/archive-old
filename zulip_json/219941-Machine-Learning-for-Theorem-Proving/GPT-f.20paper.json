[
    {
        "content": "<p>Hi! We (OpenAI) just released a paper describing GPT-f, a Transformer-based automated theorem prover. It covers a lot of work we've been doing with Metamath <img alt=\":metamath:\" class=\"emoji\" src=\"https://zulip-avatars.s3.amazonaws.com/3121/emoji/images/17589.gif\" title=\"metamath\"> and that could be applied to Lean. </p>\n<p>Full abstract:</p>\n<blockquote>\n<p>We explore the application of transformer-based language models to automated theorem proving. This work is motivated by the possibility that a major limitation of automated theorem provers compared to humans – the generation of original mathematical terms – might be addressable via generation from language models. We present an automated prover and proof assistant, GPT-f, for the Metamath formalization language, and analyze its performance. GPT-f found new short proofs that were accepted into the main Metamath library, which is to our knowledge, the first time a deep learning based system has contributed proofs that were adopted by a formal mathematics community.</p>\n</blockquote>\n<p>arXiv link: <a href=\"https://arxiv.org/abs/2009.03393\">https://arxiv.org/abs/2009.03393</a></p>",
        "id": 209486101,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1599641488
    },
    {
        "content": "<p>Any feedback/suggestions or questions are obviously welcome. I also hope to meet some of you at AITP next week to discuss it!</p>",
        "id": 209486170,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1599641522
    },
    {
        "content": "<p>Nice! I'll try to read it soon</p>",
        "id": 209486444,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1599641737
    },
    {
        "content": "<p>Abstract looks promising!</p>",
        "id": 209486453,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1599641747
    },
    {
        "content": "<p>I also look forward to reading it.  (I’m on honeymoon this week, so don’t expect much of a response soon.)</p>",
        "id": 209524897,
        "sender_full_name": "Jason Rute",
        "timestamp": 1599664365
    },
    {
        "content": "<p>However, one quick question: Are you working on applying it to Lean, or is that an exercise for the reader?</p>",
        "id": 209524991,
        "sender_full_name": "Jason Rute",
        "timestamp": 1599664405
    },
    {
        "content": "<p>Oh great, I remember you had to postpone your wedding because of Covid, but it looks like it happened in the end, congratulations!</p>",
        "id": 209527773,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1599665481
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span> I haven't read through everything in detail, because I don't know enough about ML. But I'm very impressed by the fact that GPT-f found several shorter proofs than those that were in <a href=\"http://set.mm\">set.mm</a> at the time.</p>",
        "id": 209536955,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1599670076
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> we're still at an exploratory stage, but short answer is yes, definitely!</p>",
        "id": 209548439,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1599675516
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"112680\">@Johan Commelin</span> Thank you! (I have to admit we were ourselves super excited by this result as well :))</p>",
        "id": 209548716,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1599675681
    },
    {
        "content": "<p>during proof search, is the model conditioned on the proof tree / previously expanded goals?</p>",
        "id": 209560443,
        "sender_full_name": "Jesse Michael Han",
        "timestamp": 1599681756
    },
    {
        "content": "<p>No it's not due to the size of the expressions involved being already quite large. That being said, we experimented with conditioning on the top goal and were not able to demonstrate a huge lift. But this was very exploratory so I wouldn't bet my money on it.</p>",
        "id": 209601565,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1599720872
    },
    {
        "content": "<p>This is impressive! And it makes me quite excited for what the future holds. Two small corrections if you care about that sort of thing:<br>\nPg. 8, the <code>ring</code> footnote points to the <a href=\"https://leanprover-community.github.io/mathlib_docs/algebra/ring/basic.html#ring\">class</a> rather than the <a href=\"https://leanprover-community.github.io/mathlib_docs/tactic/ring.html\">tactic</a><br>\nTable 3: Matmath -&gt; Metamath?</p>",
        "id": 209725970,
        "sender_full_name": "Wojciech Nawrocki",
        "timestamp": 1599784004
    },
    {
        "content": "<p>Thanks a lot <span class=\"user-mention\" data-user-id=\"128280\">@Wojciech Nawrocki</span> for the kind words as well as the feedback. Duly noted and factored in the next version of the paper <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span> Thanks!</p>",
        "id": 209759873,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1599817384
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span> What is considered a valid proof step?  GPT-f will return both a theorem and substitutions, which then must unify with the goal.  If the substitutions don't unify, then I'm sure it is marked invalid.  However, what if the theorem isn't in the list of previously proved theorems?  What does GPT-f do?</p>\n<ol>\n<li>Try to prove that theorem,</li>\n<li>consider this an invalid proof step, or</li>\n<li>restrict the output to only known theorems?<br>\n(I assume it is the first option, but I want to check.)</li>\n</ol>",
        "id": 209950827,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600033391
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> Good questions!</p>\n<ul>\n<li>If the unification fails, the kernel rejects the proof step and it is not even considered in the proof tree search (not added to the tree or queue, nor valued by the value function).</li>\n<li>If the theorem statement generated is not in the theorem database, currently and in the experiments reported in the paper, the kernel rejects it as well. That being said we're experimenting with letting the model prove such conjectures if they are considered interesting by the value function. In that case we simply add the theorem itself as a subgoal (with a special tag to make sure we re-check the distinct variables once a proof is found (DVs are a metamath technicality that is ok to abstract in your thinking and revisit later if you don't know how they work)) and the subgoal is valued and added to the queue accordingly.</li>\n</ul>",
        "id": 209974134,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600069959
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span> Another follow up question: When validating or testing the model, do you have any kind of dependency restriction on theorems?  For example, in most of these papers, to prove 0 = 0 (if it is in the test set), one must use theorems which came before 0 = 0.  I believe the Holophrasm and MetaGen papers do this.  The MetaGen paper calls these \"background theorems\".  (This is not perfect however for tactic based provers, since 0 = 0 might be provable with a tactic which came along after the proof of 0=0.  I have more thoughts on better ways to do this, but that is for another time.)  Does your paper do this?   I ask, because without a restriction like this, you could have a much higher percentage of theorems solved.</p>",
        "id": 210004095,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600089946
    },
    {
        "content": "<p>Yep this is mentioned in the paper (I believe?). We enforce theorem ordering as we evaluate on <a href=\"http://set.mm\">set.mm</a> <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span></p>",
        "id": 210004253,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600090010
    },
    {
        "content": "<p>Sorry.  I had trouble finding it.  I see it now, on the middle of page 4.  Thanks!</p>",
        "id": 210005785,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600090676
    },
    {
        "content": "<p>(FWIW the lift you generally get from waiving that constraint is 2-3% success rate)</p>",
        "id": 210007974,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600091730
    },
    {
        "content": "<p>I should mention that there are a few threads talking about GPT-f on the Internet besides this one:</p>\n<ul>\n<li>Twitter: <a href=\"https://twitter.com/spolu/status/1303578985276887042\">https://twitter.com/spolu/status/1303578985276887042</a></li>\n<li>Reddit: <a href=\"https://www.reddit.com/r/MachineLearning/comments/ipdu7m/r_gptf_a_new_sota_for_automated_mathematical/\">GPT-f: a new SOTA for automated mathematical proofs : MachineLearning</a></li>\n<li>MetaMath Google Group: <a href=\"https://groups.google.com/g/metamath/c/gZPfD-DlQBI\">GPT-f paper</a></li>\n</ul>\n<div class=\"inline-preview-twitter\"><div class=\"twitter-tweet\"><a href=\"https://twitter.com/spolu/status/1303578985276887042\"><img class=\"twitter-avatar\" src=\"https://pbs.twimg.com/profile_images/2008060134/423231_3486704046246_1230777314_33453905_1333098466_n_normal.jpeg\"></a><p>Posted my first paper on arXiv<span aria-label=\"boom\" class=\"emoji emoji-1f4a5\" role=\"img\" title=\"boom\">:boom:</span><span aria-label=\"raised hands\" class=\"emoji emoji-1f64c\" role=\"img\" title=\"raised hands\">:raised_hands:</span>\n\nGPT-f is a Transformer-based automated theorem prover. We show that Transformer + Search is suitable to formal reasoning and continuous self-improvement 🦾\n\n<a href=\"https://t.co/VllDcCV3Kc\">https://arxiv.org/abs/2009.03393</a> <a href=\"https://t.co/5ttVX0MNBC\">https://twitter.com/spolu/status/1303578985276887042/photo/1</a></p><span>- Stanislas Polu (@spolu)</span><div class=\"twitter-image\"><a href=\"https://t.co/5ttVX0MNBC\"><img src=\"https://pbs.twimg.com/media/Ehc-LRsXYAEObi-.jpg:medium\"></a></div><div class=\"twitter-image\"><a href=\"https://t.co/5ttVX0MNBC\"><img src=\"https://pbs.twimg.com/media/Ehc-LRrWkAA4PDt.jpg:thumb\"></a></div><div class=\"twitter-image\"><a href=\"https://t.co/5ttVX0MNBC\"><img src=\"https://pbs.twimg.com/media/Ehc-LRtXcAEdoMM.jpg:thumb\"></a></div><div class=\"twitter-image\"><a href=\"https://t.co/5ttVX0MNBC\"><img src=\"https://pbs.twimg.com/media/Ehc-LRjWoAEn-NG.jpg:thumb\"></a></div></div></div>",
        "id": 210087014,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140073
    },
    {
        "content": "<p>As usual, I’m going to try to summarize the paper for an audience who knows more about theorem provers than neural networks.</p>",
        "id": 210087032,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140105
    },
    {
        "content": "<p>In many ways GPT-f is similar to other theorem provers which have come before, HOList/DeepMath, CoqGym/ASTTactic, TacticToe, etc.  What all of these have in common is that they treat theorem proving as a tree search.  What has been known for a long time is that one can avoid combinatorial explosion in tree (and graph) search by adopting smart heuristics.  What AlphaGo and its successors has taught us is that these heuristics can be entirely learned either from examples or from bootstrapping and reinforcement learning.  GPT-f is no different in this regard.  (I’m not going to say much more about the specific tree search algorithm used by GPT-f, since I don’t think their approach is especially optimized more than any other similar paper.)</p>",
        "id": 210087086,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140137
    },
    {
        "content": "<p>Currently GPT-f is a system for MetaMath, but that is just a design choice.  The MetaMath system is embarrassingly simple, but at the same time user-friendly enough to have developed a large library.  That makes it a good candidate for a first experiment.  Also, as we will see, GPT-f has no problem handling the most difficult part about MetaMath automation.</p>",
        "id": 210087095,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140150
    },
    {
        "content": "<p>From a certain point of view, one can think of MetaMath as a tactic-based prover with only one tactic.  If one reads a MetaMath proof backward, at every point there is one or more goals, say <code>( 3 + 2 ) = 5</code>.  One can then apply a previously proved theorem, for example transitivity: <code>{ A = B, B = C } |- A = C</code> and specify how to substitute the free variables.  After substitution, the conclusion must equal the goal.  Therefore, in this example the substitutions for <code>A</code> and <code>C</code> must be <code>A = ( 3 + 2 )</code>  and <code>C = 5</code>, while <code>B</code> could be anything.  The trick, of course, is to substitute something useful for <code>B</code>.  If you choose <code>B = 4 + 1</code> , then after applying this theorem (backwards), one gets a new goal for each hypothesis: <code>( 3 + 2 ) = ( 4 + 1 )</code> and <code>( 4 + 1 ) = 5</code>.  The latter happens to be a theorem (the definition of <code>5</code> in MetaMath), which would close that particular goal.</p>",
        "id": 210087108,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140163
    },
    {
        "content": "<p>In most of the work applying deep learning to (tactic-based) theorem proving, there are four main tasks:</p>\n<ul>\n<li><em>tactic selection</em>: Given a goal, find the best tactic.  The nice thing about tactic selection is that there is a fixed list of tactics.  Choosing the best thing from a fixed list is easy for deep learning systems.  For MetaMath, it is trivial, since there is only one tactic.</li>\n<li><em>premise/lemma selection</em>: Given a goal (and a tactic), find the best theorem to apply (assuming the tactic takes one or more theorems as parameters, e.g. a rewrite tactic).  There are multiple ways to do this.  Many systems assign each theorem a vector, a key, and assign the goal another vector, a query, and try to find the theorem(s) whose keys most closely match the query.    Other systems, try to find the goal most similar in the training data and use whatever tactic and premises that goal used.  GPT-f takes a unique approach here as we will see.</li>\n<li><em>parameter selection</em>: Besides any theorems, there are often other parameters that need to be selected for a tactic as well.  HOList handles this by avoiding tactics with such parameters (or filling in the parameters with constant values).  CoqGym has a fixed, limited grammar from which those parameters can be taken.  Other provers allow using local variables and subterms.  Still others find a similar example in the training data and use those parameters. For MetaMath, the choice of parameters is especially important and not at all trivial.  Previous Metamath AIs (Holophrasm and MetaGen) both use recurrent neural networks to guess at the substitution.  This is where GPT-f will shine, since transformers are especially good at “making stuff up”.</li>\n<li><em>value estimation</em>: Finally, to make the tree search more efficient, usually a score is applied to each goal to say how “provable” it is.</li>\n</ul>",
        "id": 210087115,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140179
    },
    {
        "content": "<p>One comment on the above four steps is that the first three are called a <em>policy</em> and can be done together or separately.  Also, in, say, Lean, it is not uncommon to see tactics like <code>apply (lem p)</code>  which don’t fit cleanly into the above paradigm.  The “premise” is technically <code>lem p</code> but morally the premise is <code>lem</code> and one modifies <code>lem</code> by instantiating the universal quantifier with the term <code>p</code>.  GPT-f (if applied to Lean) would show a lot of promise for handling situations like this as well.</p>",
        "id": 210087124,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140193
    },
    {
        "content": "<p>GPT-f is based on a transformer architecture.  (See <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/Papers.20on.20Neural.20Conjecturing\">my notes on transformers here</a>.)  Without getting into the details, it basically is a (really good!) text generator.  You give it a prompt and it completes the prompt.  In this case, the system was trained to take prompts like this:</p>\n<div class=\"codehilite\"><pre><span></span><code>GOAL [[]] |- (3 + 2) = 5 PROOFSTEP\n</code></pre></div>\n\n\n<p>and then complete that prompt with something like the following (except without the new lines which I added for readability):</p>\n<div class=\"codehilite\"><pre><span></span><code>GOAL [[]] |- ( 3 + 2 ) = 5\nPROOFSTEP\n[[ |- A = B |- C = B ]] |- A = C\n{{ A : ( 3 + 2 ) }}\n{{ B : ( 4 + 1 ) }}\n{{ C : 5 }}\n&lt;|endoftext|&gt;\n</code></pre></div>",
        "id": 210087130,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140214
    },
    {
        "content": "<p>The way the text is generated allows for generating multiple stochastic completions to the prompt.  Each completion is scored and checked by MetaMath to see if it is a valid proof step.  If so, it is plugged into the tree search.  (The value function is generated similarly, but trained via reinforcement learning similar to HOList/DeepMath.  See the GPT-f paper for details.)</p>",
        "id": 210087134,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140223
    },
    {
        "content": "<p>What separates this paper from other similar works is a few small but important details.  Whereas other models might design a custom machine learning architecture for the exact logic at hand, transformers take the viewpoint: “As long as its text, I can handle it.”</p>",
        "id": 210087136,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140232
    },
    {
        "content": "<p>There have been a number of papers recently showing that transformers can mimic logical reasoning.  (The most famous is the paper showing that transformers can solve integrals.)  I hope it is very clear to any remaining skeptics that if we are willing to pay for the computer power (more on that in a second…), then we basically have a general purpose tool which can begin to mimic advanced human reasoning on novel tasks.   I’m not saying it can come up with a proof of a Millennium Problem, but it can solve straightforward proofs in whatever ITP you want.  There is nothing special here about tactic-mode proofs vs term mode vs Isar-style vs first-order logic.  In the end, they can all be implemented by a tree search guided by a (transformer) neural network.  The only thing stopping us is (1) engineering and (2) computer power.</p>",
        "id": 210087181,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140248
    },
    {
        "content": "<p>Getting back to the “it’s just text” theme, probably the most surprising thing about this paper is the way the model was pre-trained.  GPT-style transformer models are most famously known for generating fake realistic text, be it a screen play or question answering.  It is well known that to achieve the best results one must pre-train the model on a large corpus of text, usually public domain books and websites.  GPT-f is no different.  The model improved by 8 percentage points when pre-trained on such information. It even did a few points better when trained on more mathematical text, including arXiv, GitHub, and Math StackExchange.  (I have so many questions about what the model is getting out of these datasets.  It is just about recognizing math terminology and parentheses matching, or is it somehow memorizing common proofs?)</p>",
        "id": 210087193,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140275
    },
    {
        "content": "<p>Another thing which is fascinating about GPT-style transformers is that they don’t use a fixed vocabulary.  This can really be a problem for other models.  What if a user uses a new definition, or just picks a unique variable name?  GPT uses something called <em>byte pair encoding</em> which scans the training data for common groupings of symbols.  Those then become the tokens.  A common word may be its own token, but an uncommon word may be made of multiple tokens, possibly just a token for each letter.  This allows any new words at test time.</p>",
        "id": 210087201,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140299
    },
    {
        "content": "<p>Now, as for MetaMath, the transformer architecture provides a number of interesting possibilities.  First, notice that when the transformer returned the theorem to apply, it didn’t call it by name or look it up from a list of theorems.  It called it by the statement of the theorem.  To be clear, this is a design choice, but it is a really interesting one.  There are two related ways to look at this: (1) the transformer has memorized the theorems in the dataset.  (2) the transformer says “hey, what I really need here is a theorem of the form …”.  Of course, it is probably a little of both cases.  However, the second case leads to the possibility of conjecturing.  If the “theorem” isn’t in the dataset, then one could set out to prove it anyway.  (As <span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span>  said above, they don’t do this yet.)</p>",
        "id": 210087212,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140313
    },
    {
        "content": "<p>The second interesting thing is that unlike a lot of similar systems, the transformer has little or no problem filling in the variable substitutions.  It can just “guess” a substitution.  Of course it may not be useful or even type check, but MetaMath can check that the proof step is valid and the tree search will test it for usefulness. <span class=\"user-mention\" data-user-id=\"239426\">@Christian Szegedy</span>  has also said he thinks that GPT-style text generation is also a promising best path forward when a theorem prover needs to come up with new ideas.</p>",
        "id": 210087221,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140334
    },
    {
        "content": "<p>Before I get into the negatives, I want to really commend <span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span>  and team on making this not only into a paper, but into <a href=\"https://groups.google.com/g/metamath/c/D09W2QVR-_I\">a usable tool</a> that the MetaMath community can use.  I think this back-and-forth interaction with the community is what is going to drive AI for ITPs forward.</p>",
        "id": 210087267,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140371
    },
    {
        "content": "<p>Ok, now for the negatives.  Basically, this is a great experiment and I’m glad OpenAI is fitting the bill for this system, but to be clear this is a quite expensive project.  It shows what is possible, but it probably isn’t scalable to the average MetaMath user level right now.  I doubt any of us could build a comparable system without the backing of a large research lab like Google, Facebook, OpenAI, or DeepMind.</p>",
        "id": 210087277,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140403
    },
    {
        "content": "<p>It’s well known that transformers are computationally expensive.  They require O(n^2) computations to compute a sequence of length n (including the prompt).  They also have more parameters that many other neural network types.</p>",
        "id": 210087280,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140414
    },
    {
        "content": "<p>To run the larger model once over the training data required 20,000 GPU-hours on a V100.  Contrast this with the first HOList/DeepHOL paper.  While the DeepHOL model took a lot of iterations to train via reinforcement learning (eight V100 GPUs running for an unspecified amount of time), the trained version is something I could run on my Macbook Air.  When doing the “reinforcement learning”, the GPT-f model is only iterated twice since it is so expensive to run, compared to the thousands of iterations used by HOList/DeepHOL.</p>",
        "id": 210087285,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140429
    },
    {
        "content": "<p>To put it in dollars, a V100 GPU-hour costs on the order of $1 per GPU-hour, so this is $20,000 to run an already trained model once across the training data.  I’m very curious what their MetaMath proof assistant web-tool is costing OpenAI.</p>",
        "id": 210087290,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140443
    },
    {
        "content": "<p>Nonetheless, there is a lot of room for optimization.  I think I’ve seen five or so papers in the last few months suggesting how to make transformers behave closer to O(n).</p>",
        "id": 210087293,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140459
    },
    {
        "content": "<p>Also, I’m still of the opinion that since formulas have so much built-in structure, that using some of that structure as an inductive bias is still valuable.  <a href=\"https://papers.nips.cc/paper/9376-novel-positional-encodings-to-enable-tree-based-transformers.pdf\">It’s been shown</a> (<a href=\"https://arxiv.org/pdf/2003.04218.pdf\">more than once</a>) that transformers trained with tree-based position encodings do much better at symbolic reasoning tasks.  However, I also realize that such encodings would limit the pre-training options.  I recall N2Formal (<span class=\"user-mention\" data-user-id=\"239426\">@Christian Szegedy</span>) suggesting ideas for pre-training which may be helpful here.  Also, it might be useful to try to gather a large dataset of formula-like data from the web parsed into a tree or graph structure.</p>",
        "id": 210087335,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140487
    },
    {
        "content": "<p>I can also think of a number of other possible optimizations.  While having a transformer which guesses everything is a nice experiment, it might still be more efficient to fill in the constrained substitutions using a Prolog like system instead.   It also might still be faster to use the theorem database more directly for lookup of theorems.  For example, <a href=\"https://ai.googleblog.com/2020/08/realm-integrating-retrieval-into.html\">Google recently showed the possibility of using transformers to lookup data from a database</a>.</p>",
        "id": 210087337,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140498
    },
    {
        "content": "<p>Finally, the holy grail is code generation.  Why have an expensive black box when you can have an AI that generates code (custom tactics in this case)?  This code would be reusable, fast, and interpretable.  Of course, transformers are being used for code generation too. :)</p>",
        "id": 210087339,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140516
    },
    {
        "content": "<p>One last thought.  It is so difficult to compare results since we don’t have standard datasets, but they report a success rate of 56% for their best model, which is much better than the previous SOTA of 21%.  I’d love it if they try this out on the HOList dataset so that they can directly compare with Google’s state of the art.  Even then however, I feel that the best judge is to put this in the hands of ITP users and to ask them what it does well on and doesn’t do well on.  Again, I’m really glad for their engagement with the MetaMath community.</p>",
        "id": 210087346,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140550
    },
    {
        "content": "<p>Overall, I am really grateful for this paper.  It is well-written (if you know a bit about transformers at least), and I think it shows that we have a lot of the tools at least to start building high powered experimental tools.  Hopefully, we can then turn to making these systems useful to the average ITP user.  I’m really looking forward to what the future brings.</p>",
        "id": 210087347,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600140575
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span> can, of course, correct all my misconceptions. :)</p>",
        "id": 210087683,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600141162
    },
    {
        "content": "<ul>\n<li>\n<p>For comparison, on the HOl-Light corpus, we can reach 70% proof success rate (67% without any imitation on exsisting proofs). I'm not sure how it compares, but my guess would be that HOL-Light is a bit harder the metamath.</p>\n</li>\n<li>\n<p>In the beginning of the year, we have also tried the approach of using transformer in autoregressive manner to generate the whole tactic invocation together with all the substitutions, theorem labels, etc. and while the results seemed somewhat comparable, it was so much more expensive to run computationally, that it just did not seem to make a lot of sense to us.</p>\n</li>\n</ul>\n<p>That's why we started to look for tasks where generative transformers would shine: conjecturing, filling in assumptions, etc.</p>\n<p>I don't say that GPT-f does not make sense, we have a very similar system for more than half a year, but it was simply not justifiable from a practicabality point of view at this point in time, especially that HOLst was also criticized for being slow, while we use a few minutes per proof attempt on CPU.</p>",
        "id": 210089700,
        "sender_full_name": "Christian Szegedy",
        "timestamp": 1600144356
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> thank you for the thoughtful comments. This is a great summary and glad to see our work put in perspective this way.</p>\n<p>Commenting quickly on the 20k GPU.hours. They are required for the data generation/augmentation process (running proof searches on the train set) which is in turn used to train the value function you refer to in your post (same was true for alphago/zero, the data generation, aka exploration, is where you pay the price). So, the number is definitely accurate but just wanted to point out that the training of the model itself is less expensive (more like 500-1k GPU.hours).</p>\n<p>As for the user experience of the ITP, I'll be demonstrating it today at AITP'20. I'll gladly make another video for folks here if interested. As you'll see the model is fast enough for it to be a somewhat pleasing experience (once you've climbed the Metamath learning curve that is :p)</p>\n<p>(Also, I'm pretty confident OpenAI will be happy to foot the bill, for the foreseeable future, for usage of these systems once we manage to port them to Lean, as we do today with Metamath. The main challenge/problem I believe and as you point out is to make a useful system and share it effectively with the community <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span>)</p>",
        "id": 210097727,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600154632
    },
    {
        "content": "<p>To attend the talk same as what Daniel said <a href=\"#narrow/stream/208328-IMO-grand-challenge/topic/AITP.20invited.20talk/near/210070867\">here</a>. Ping me if interested, it's at ~15h CET (see <a href=\"http://aitp-conference.org/2020/\">AITP Program</a>)</p>",
        "id": 210098050,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600154865
    },
    {
        "content": "<p>But do I understand correctly that for the time being we will depend on external computing power to be able to run GPT-f? You can't extract a trained artifact that I can run on a 16 GB RAM + modern desktop CPU/GPU, or can you? (And expect it to spit back results withing seconds instead of days.)</p>",
        "id": 210098147,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1600154920
    },
    {
        "content": "<p>We can extract a trained artifact that could run correctly on one modern GPU for inference. It's just that this trained artifact, today, is served through the OpenAI API.</p>",
        "id": 210098353,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600155083
    },
    {
        "content": "<p>Ok, cool</p>",
        "id": 210098429,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1600155140
    },
    {
        "content": "<p>I was expecting that simply executing the thing would already require &gt; 20GB RAM</p>",
        "id": 210098451,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1600155164
    },
    {
        "content": "<p>Not yet :p</p>",
        "id": 210098460,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600155177
    },
    {
        "content": "<p>I mean, just fitting the parameters into memory is already a mild feat (-;</p>",
        "id": 210098463,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1600155181
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"239426\">Christian Szegedy</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/GPT-f.20paper/near/210089700\">said</a>:</p>\n<blockquote>\n<ul>\n<li>For comparison, on the HOl-Light corpus, we can reach 70% proof success rate (67% without any imitation on exsisting proofs).</li>\n</ul>\n</blockquote>\n<p>The <a href=\"https://sites.google.com/view/holist/home\">HOList website</a> currently lists 60% as the best success rate.  Was there anything big you did to get it to 70%/67%, or is it just combining the two techniques from your last two HOList papers (GNNs and better reinforcement learning)?  Is there another HOList paper coming?</p>",
        "id": 210257680,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600261418
    },
    {
        "content": "<p>Hi <span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span> - I’m wondering how you converted proof step substitutions generated by your model back into MetaMath (i.e. a sequence of labels). Of course in actual MetaMath proofs one needs to construct the terms that get substituted in. Constructing a complex term could require many steps in a MetaMath proof. Which specific steps (labels) are required is represented only implicitly in the substitutions. It’s not obvious to me how to write a verifier for proof steps written in your substitution format. Can you offer any pointers? Many thanks!</p>",
        "id": 212244013,
        "sender_full_name": "Joe Palermo (S2'17)",
        "timestamp": 1601849721
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"337523\">@Joe Palermo (S2'17)</span> I can't speak for <span class=\"user-mention silent\" data-user-id=\"249373\">Stanislas Polu</span> 's implementation, but it is fairly common for metamath proof assistants to work directly with intermediate statements and infer the substitutions by unification. <a href=\"https://en.wikipedia.org/wiki/Unification_(computer_science)#Syntactic_unification_of_first-order_terms\">First order unification</a> is not a particularly hard problem, it is decidable with a fast algorithm (in contrast to higher order unification, which lean has to deal with sometimes and is undecidable in general).</p>",
        "id": 212247313,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1601855278
    },
    {
        "content": "<p>Hi <span class=\"user-mention\" data-user-id=\"337523\">@Joe Palermo (S2'17)</span> the language model generates the substitutions, then we operate at the term level in our kernel. To ensure correctness, we indeed have to prove that expressions are properly typed, as we work on proof we do by checking that the term we operate on comply to the Metamath grammar (which is encoded by the wff, class, setvar axioms). Only when we want to check the proof with another kernel, we dump the proof in native Metamath format, using our parse trees to generate the full proofs. Hope that answers your question?</p>",
        "id": 212265055,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1601881772
    },
    {
        "content": "<p>If I read the paper correctly, the model doesn't generate the lemma names.  Do you just try all lemmas in <a href=\"http://set.mm\">set.mm</a> and see which one fits the statements produced by the model?</p>",
        "id": 212265128,
        "sender_full_name": "Gabriel Ebner",
        "timestamp": 1601881843
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110043\">@Gabriel Ebner</span> indeed we generate the theorem terms and check that they exist in <a href=\"http://set.mm\">set.mm</a>. We've observed that it helps the machine learning a lot (which kind of makes sense as it makes the distribution of theorems and the distribution of term substitutions more alike and therefore easier to fit together)</p>",
        "id": 212265224,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1601881981
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span> Yes, thank you!</p>",
        "id": 212301627,
        "sender_full_name": "Joe Palermo (S2'17)",
        "timestamp": 1601905994
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span>  Would I be correct in thinking that the axioms required to define this grammar are all the axioms of the form:</p>\n<p>&lt;label&gt; $a wff &lt;expression&gt; $.<br>\n&lt;label&gt; $a class &lt;expression&gt; $.<br>\n&lt;label&gt; $a setvar &lt;expression&gt; $. (seems that this particular pattern doesn't occur in the <a href=\"http://set.mm\">set.mm</a> database)</p>",
        "id": 212622697,
        "sender_full_name": "Joe Palermo (S2'17)",
        "timestamp": 1602106793
    },
    {
        "content": "<p>Since we are asking questions, as for <span class=\"user-mention\" data-user-id=\"110043\">@Gabriel Ebner</span>’s question, can you look up the lemma directly from the output of GPT-f?  In other words, can you plug the output into a hash map and get the lemma (maybe after standardizing variable names)?  Or do you need to do the O(n) operation where you try to unify every earlier occurring lemma against the output of GPT-f.</p>",
        "id": 212625692,
        "sender_full_name": "Jason Rute",
        "timestamp": 1602108750
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"337523\">@Joe Palermo (S2'17)</span> Yes, metamath terms are given by a CFG where each $a with a typecode other than |-  contributes one production (and the nonterminals are wff, class, setvar). The $f variable declaration commands also contribute productions, so the setvar nonterminal is not empty, it only contains variables (as terminals).</p>",
        "id": 212626254,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1602109151
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span> Thank you!</p>",
        "id": 212633137,
        "sender_full_name": "Joe Palermo (S2'17)",
        "timestamp": 1602114177
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> I'm wondering the same thing...</p>",
        "id": 212633187,
        "sender_full_name": "Joe Palermo (S2'17)",
        "timestamp": 1602114231
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> This problem seems pretty similar to the problem of <code>simp</code>: Given a term and a collection of lemmas, find one that unifies. You can do it pretty efficiently with a discrimination tree, and in fact this process is fast enough that the mmj2 metamath proof assistant has a feature where every open goal is automatically unified against everything in the library any time you do anything, as if <code>simp</code> was constantly running in the background. It applies every lemma that makes the goal \"smaller\" in some sense, except for some blacklisted lemmas, and it's quite convenient and effective.</p>",
        "id": 212638461,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1602119654
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> we're just looking up in a hash table constructed from <a href=\"http://set.mm\">set.mm</a> (enforcing ordering here) <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span></p>",
        "id": 212651517,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1602138851
    },
    {
        "content": "<p>The theorem statement generated by GPT-f is pre-unification so it's a simple lookup. GPT-f also generates substitutions that are then checked against the grammar, applied, and the fact that they unify is verified.</p>",
        "id": 212651586,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1602138957
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"337523\">@Joe Palermo (S2'17)</span> As explained by <span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span>, yes <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span></p>",
        "id": 212651699,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1602139077
    },
    {
        "content": "<p>Hi <span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span>. I’m trying to replicate something similar to the MetaMath environment you developed for GPT-f. <span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span>  mentioned to me that he described to you a “KLR(0)” parsing algorithm for MetaMath expressions. Was this the one you ended up implementing? In the paper you refer to a “modified LR(0) parser”.</p>",
        "id": 213313046,
        "sender_full_name": "Joe Palermo (S2'17)",
        "timestamp": 1602691608
    },
    {
        "content": "<p>Yes we implemented an LR(0) parser with basic backtracking as the amount of backtracking necessary to parse the Metamath grammar is well behaved and limited in practice. It's somewhat different than what is implemented in mmj2, in case you looked into it, where the \"backtracking\" is done at parser construction time.</p>",
        "id": 213318189,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1602693754
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span> would you mind sharing some of the documentation on that KLR(0) parser here?</p>",
        "id": 213586586,
        "sender_full_name": "Joe Palermo (S2'17)",
        "timestamp": 1602867674
    },
    {
        "content": "<p>Sure, data dump coming right up. The following example walks through the parsing of <code>{ &lt;. x , y &gt;. }</code> vs <code>{ &lt;. x , y &gt;. | ph }</code> in the <a href=\"http://set.mm\">set.mm</a> grammar, which yields a shift reduce conflict when parsed with LR(0). (This description assumes you know a bit about how LR(0) parse table generation works; see the <a href=\"https://en.wikipedia.org/wiki/LR_parser\">wikipedia page</a> for a primer.)</p>",
        "id": 213588717,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1602868692
    },
    {
        "content": "<p><a href=\"https://github.com/digama0/mmj2/blob/master/src/mmj/verify/LRParser.java#L151-L208\">This</a> is the new part of the code that distinguishes the KLR parser from LR(0). A \"conflict\" is a place where an LR(0) parser would fail outright.</p>",
        "id": 213588733,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1602868704
    },
    {
        "content": "<p>During parse table generation each state is associated with a bunch of partially read productions that agree on a common prefix, and in this case you are stuck at the state:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">-&gt;</span> <span class=\"o\">{</span> <span class=\"n\">o</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">setvar</span> <span class=\"o\">,</span> <span class=\"n\">setvar</span> <span class=\"bp\">&gt;.</span> <span class=\"bp\">|</span> <span class=\"n\">wff</span> <span class=\"o\">}</span>\n<span class=\"bp\">-&gt;</span> <span class=\"o\">{</span> <span class=\"n\">o</span> <span class=\"kd\">class</span> <span class=\"o\">}</span>\n</code></pre></div>\n\n<p>This is known as a shift-reduce conflict, and usually shifting is the right answer, so that's built in as a heuristic, which is why lark takes the first option over the second. But neither choice is \"correct\", because this changes the grammar - you are now rejecting a string that should be valid to the grammar (<code>{ &lt;. x , y &gt;. }</code> in this case) - so essentially you are finding a \"closest LALR(1) approximation\" to the grammar when you use lark with this heuristic.</p>\n<p>To resolve this, the question is what to do from that state if you read a <code>&lt;.</code>. We haven't actually hit the conflict yet. In the first production it's clear that we should step to <code>-&gt; { &lt;. o setvar , setvar &gt;. } | ph }</code>, but the second production requires us to look at the <code>class</code> nonterminals that start with <code>&lt;.</code>. (In fact, in the first state we also have all productions for the class nonterminal, like <code>-&gt; o 1</code> and <code>-&gt; o ( class u. class )</code> and many others. These are represented in a special way in LRParser.java to save space.) Let's step through the states that the example takes. The <code>shift &lt;.</code> step takes us to:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">-&gt;</span> <span class=\"o\">{</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">o</span> <span class=\"n\">setvar</span> <span class=\"o\">,</span> <span class=\"n\">setvar</span> <span class=\"bp\">&gt;.</span> <span class=\"bp\">|</span> <span class=\"n\">wff</span> <span class=\"o\">}</span>\n<span class=\"bp\">-&gt;</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">o</span> <span class=\"kd\">class</span> <span class=\"o\">,</span> <span class=\"kd\">class</span> <span class=\"bp\">&gt;.</span>\n<span class=\"n\">all</span> <span class=\"n\">setvar</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">o</span> <span class=\"n\">rules</span>\n<span class=\"n\">all</span> <span class=\"kd\">class</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">o</span> <span class=\"n\">rules</span>\n</code></pre></div>\n\n<p>and <code>shift x</code> takes us to:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">-&gt;</span> <span class=\"n\">x</span> <span class=\"n\">o</span>\n</code></pre></div>\n\n<p>Since we are now at the end of a production, we can reduce with <code>setvar -&gt; x</code> at this point, and there are no competing productions so this is safe. This <code>reduce x</code> edge pops the stack and acts like a <code>shift setvar</code> edge from the previous step, leading to:</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">-&gt;</span> <span class=\"o\">{</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">setvar</span> <span class=\"n\">o</span> <span class=\"o\">,</span> <span class=\"n\">setvar</span> <span class=\"bp\">&gt;.</span> <span class=\"bp\">|</span> <span class=\"n\">wff</span> <span class=\"o\">}</span>\n<span class=\"bp\">-&gt;</span> <span class=\"n\">setvar</span> <span class=\"n\">o</span>\n</code></pre></div>\n\n<p>The <code>-&gt; setvar o</code> comes from the <code>class -&gt; setvar</code> production. Now we are stuck, because we can both reduce with this production (which gives us a <code>cv</code> node) and shift a comma to continue with the first production. This is a shift-reduce conflict, and lark at this point will throw away the reduce option and shift here, leading to</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">-&gt;</span> <span class=\"o\">{</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">setvar</span> <span class=\"o\">,</span> <span class=\"n\">o</span> <span class=\"n\">setvar</span> <span class=\"bp\">&gt;.</span> <span class=\"bp\">|</span> <span class=\"n\">wff</span> <span class=\"o\">}</span>\n<span class=\"n\">all</span> <span class=\"n\">setvar</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">o</span> <span class=\"n\">rules</span>\n</code></pre></div>\n\n<p>which is not correct, as we have lost the ability to parse <code>{ &lt;. x , y &gt;. }</code>.</p>",
        "id": 213588767,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1602868725
    },
    {
        "content": "<p>What I do instead to resolve this is \"pre-compositing\" the rules. We first got in trouble at</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">-&gt;</span> <span class=\"o\">{</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">setvar</span> <span class=\"n\">o</span> <span class=\"o\">,</span> <span class=\"n\">setvar</span> <span class=\"bp\">&gt;.</span> <span class=\"bp\">|</span> <span class=\"n\">wff</span> <span class=\"o\">}</span>\n<span class=\"bp\">-&gt;</span> <span class=\"n\">setvar</span> <span class=\"n\">o</span>\n</code></pre></div>\n\n<p>which is a \"bad state\" because of the shift-reduce conflict. We want to remove the reduce node, and we do so by backing up to see how we got here. We obtained this state by <code>shift setvar</code> applied to</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">-&gt;</span> <span class=\"o\">{</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">o</span> <span class=\"n\">setvar</span> <span class=\"o\">,</span> <span class=\"n\">setvar</span> <span class=\"bp\">&gt;.</span> <span class=\"bp\">|</span> <span class=\"n\">wff</span> <span class=\"o\">}</span>\n<span class=\"bp\">-&gt;</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">o</span> <span class=\"kd\">class</span> <span class=\"o\">,</span> <span class=\"kd\">class</span> <span class=\"bp\">&gt;.</span>\n<span class=\"n\">all</span> <span class=\"n\">setvar</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">o</span> <span class=\"n\">rules</span>\n<span class=\"n\">all</span> <span class=\"kd\">class</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">o</span> <span class=\"n\">rules</span>\n</code></pre></div>\n\n<p>and we want to repair this state so that we don't hit the train wreck one step from here. So we delete the offending rule <code>-&gt; o setvar</code> and add the composition of <code>class -&gt; setvar</code> with <code>class -&gt; &lt;. class , class &gt;.</code> as a new \"composite rule\" which looks like a production <code>class -&gt; &lt;. setvar , class &gt;.</code>, so that the \"before\" state instead looks like</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">-&gt;</span> <span class=\"o\">{</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">o</span> <span class=\"n\">setvar</span> <span class=\"o\">,</span> <span class=\"n\">setvar</span> <span class=\"bp\">&gt;.</span> <span class=\"bp\">|</span> <span class=\"n\">wff</span> <span class=\"o\">}</span>\n<span class=\"bp\">-&gt;</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">o</span> <span class=\"kd\">class</span> <span class=\"o\">,</span> <span class=\"kd\">class</span> <span class=\"bp\">&gt;.</span>\n<span class=\"bp\">-&gt;</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">o</span> <span class=\"n\">setvar</span> <span class=\"o\">,</span> <span class=\"kd\">class</span> <span class=\"bp\">&gt;.</span>\n<span class=\"n\">all</span> <span class=\"n\">setvar</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">o</span> <span class=\"n\">rules</span>\n<span class=\"n\">all</span> <span class=\"kd\">class</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">o</span> <span class=\"n\">rules</span> <span class=\"n\">except</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">o</span> <span class=\"n\">setvar</span>\n</code></pre></div>\n\n<p>and we <code>shift setvar</code> from here instead, getting to</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">-&gt;</span> <span class=\"o\">{</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">setvar</span> <span class=\"n\">o</span> <span class=\"o\">,</span> <span class=\"n\">setvar</span> <span class=\"bp\">&gt;.</span> <span class=\"bp\">|</span> <span class=\"n\">wff</span> <span class=\"o\">}</span>\n<span class=\"bp\">-&gt;</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">setvar</span> <span class=\"n\">o</span> <span class=\"o\">,</span> <span class=\"kd\">class</span> <span class=\"bp\">&gt;.</span>\n</code></pre></div>\n\n<p>and we have safely cleared the conflict. (The modified \"before\" state is not a real state, it is only used to calculate this new state. This state is replacing the original shift-reduce bad state as the result of <code>shift setvar</code> applied to</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">-&gt;</span> <span class=\"o\">{</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">o</span> <span class=\"n\">setvar</span> <span class=\"o\">,</span> <span class=\"n\">setvar</span> <span class=\"bp\">&gt;.</span> <span class=\"bp\">|</span> <span class=\"n\">wff</span> <span class=\"o\">}</span>\n<span class=\"bp\">-&gt;</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">o</span> <span class=\"kd\">class</span> <span class=\"o\">,</span> <span class=\"kd\">class</span> <span class=\"bp\">&gt;.</span>\n<span class=\"n\">all</span> <span class=\"n\">setvar</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">o</span> <span class=\"n\">rules</span>\n<span class=\"n\">all</span> <span class=\"kd\">class</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">o</span> <span class=\"n\">rules</span>\n</code></pre></div>\n\n<p>.)</p>",
        "id": 213588787,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1602868735
    },
    {
        "content": "<p>To finish the example off, let's make it to the end. The next step is <code>shift ,</code> which takes us to</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">-&gt;</span> <span class=\"o\">{</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">setvar</span> <span class=\"o\">,</span> <span class=\"n\">o</span> <span class=\"n\">setvar</span> <span class=\"bp\">&gt;.</span> <span class=\"bp\">|</span> <span class=\"n\">wff</span> <span class=\"o\">}</span>\n<span class=\"bp\">-&gt;</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">setvar</span> <span class=\"o\">,</span> <span class=\"n\">o</span> <span class=\"kd\">class</span> <span class=\"bp\">&gt;.</span>\n<span class=\"n\">all</span> <span class=\"n\">setvar</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">o</span> <span class=\"n\">rules</span>\n<span class=\"n\">all</span> <span class=\"kd\">class</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">o</span> <span class=\"n\">rules</span>\n</code></pre></div>\n\n<p>(and <code>shift y</code> takes us to the simple <code>-&gt; y o</code> state, so we plan to reduce there and come back here with <code>shift setvar</code>), and <code>shift setvar</code> from here takes us to</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">-&gt;</span> <span class=\"o\">{</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">setvar</span> <span class=\"o\">,</span> <span class=\"n\">setvar</span> <span class=\"n\">o</span> <span class=\"bp\">&gt;.</span> <span class=\"bp\">|</span> <span class=\"n\">wff</span> <span class=\"o\">}</span>\n<span class=\"bp\">-&gt;</span> <span class=\"n\">setvar</span> <span class=\"n\">o</span>\n</code></pre></div>\n\n<p>which is another shift reduce conflict. Again, we analyze the conflict to find out what to composite. We want to apply the <code>class -&gt; setvar</code> *production here, which was considered one step ago because closure over <code>-&gt; &lt;. setvar , o class &gt;.</code> required us to add the <code>-&gt; o setvar</code> production to the state. So we composite <code>class -&gt; &lt;. setvar , class &gt;.</code> and <code>class -&gt; setvar</code> to get a new <code>class -&gt; &lt;. setvar , setvar &gt;.</code> production, create a temporary modified version of the previous state</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">-&gt;</span> <span class=\"o\">{</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">setvar</span> <span class=\"o\">,</span> <span class=\"n\">o</span> <span class=\"n\">setvar</span> <span class=\"bp\">&gt;.</span> <span class=\"bp\">|</span> <span class=\"n\">wff</span> <span class=\"o\">}</span>\n<span class=\"bp\">-&gt;</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">setvar</span> <span class=\"o\">,</span> <span class=\"n\">o</span> <span class=\"kd\">class</span> <span class=\"bp\">&gt;.</span>\n<span class=\"bp\">-&gt;</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">setvar</span> <span class=\"o\">,</span> <span class=\"n\">o</span> <span class=\"n\">setvar</span> <span class=\"bp\">&gt;.</span>\n<span class=\"n\">all</span> <span class=\"n\">setvar</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">o</span> <span class=\"n\">rules</span>\n<span class=\"n\">all</span> <span class=\"kd\">class</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">o</span> <span class=\"n\">rules</span> <span class=\"n\">except</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">o</span> <span class=\"n\">setvar</span>\n</code></pre></div>\n\n<p>and use it to calculate the new result of <code>shift setvar</code>, which is</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">-&gt;</span> <span class=\"o\">{</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">setvar</span> <span class=\"o\">,</span> <span class=\"n\">setvar</span> <span class=\"n\">o</span> <span class=\"bp\">&gt;.</span> <span class=\"bp\">|</span> <span class=\"n\">wff</span> <span class=\"o\">}</span>\n<span class=\"bp\">-&gt;</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">setvar</span> <span class=\"o\">,</span> <span class=\"n\">setvar</span> <span class=\"n\">o</span> <span class=\"bp\">&gt;.</span>\n</code></pre></div>\n\n<p>and we have cleared another shift reduce conflict. There is still one more to go, though, since the next step is <code>shift &gt;.</code> which takes us to</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">-&gt;</span> <span class=\"o\">{</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">setvar</span> <span class=\"o\">,</span> <span class=\"n\">setvar</span> <span class=\"bp\">&gt;.</span> <span class=\"n\">o</span> <span class=\"bp\">|</span> <span class=\"n\">wff</span> <span class=\"o\">}</span>\n<span class=\"bp\">-&gt;</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">setvar</span> <span class=\"o\">,</span> <span class=\"n\">setvar</span> <span class=\"bp\">&gt;.</span> <span class=\"n\">o</span>\n</code></pre></div>\n\n<p>which is again a shift reduce conflict. Now we must backtrack a lot, because we have to go back 5 steps (the length of the current reduce candidate) to find out which production required us to put <code>-&gt; &lt;. setvar , setvar &gt;.</code> into the mix. In fact, five steps ago this production was not even <code>-&gt; &lt;. setvar , setvar &gt;.</code> at all but rather <code>-&gt; &lt;. class , class &gt;.</code> but this makes no difference, we need two productions to do the compositing. This is the first state I posted, which looks like</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">-&gt;</span> <span class=\"o\">{</span> <span class=\"n\">o</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">setvar</span> <span class=\"o\">,</span> <span class=\"n\">setvar</span> <span class=\"bp\">&gt;.</span> <span class=\"bp\">|</span> <span class=\"n\">wff</span> <span class=\"o\">}</span>\n<span class=\"bp\">-&gt;</span> <span class=\"o\">{</span> <span class=\"n\">o</span> <span class=\"kd\">class</span> <span class=\"o\">}</span>\n<span class=\"n\">all</span> <span class=\"kd\">class</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">o</span> <span class=\"n\">rules</span>\n</code></pre></div>\n\n<p>where among the <code>class</code> rules is <code>-&gt; o &lt;. class , class &gt;.</code>. The reason the class rules are there is because of the <code>-&gt; { o class }</code> rule, so we composite <code>class -&gt; { class }</code> with <code>class -&gt; &lt;. setvar , setvar &gt;.</code>  to get the temporary state</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">-&gt;</span> <span class=\"o\">{</span> <span class=\"n\">o</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">setvar</span> <span class=\"o\">,</span> <span class=\"n\">setvar</span> <span class=\"bp\">&gt;.</span> <span class=\"bp\">|</span> <span class=\"n\">wff</span> <span class=\"o\">}</span>\n<span class=\"bp\">-&gt;</span> <span class=\"o\">{</span> <span class=\"n\">o</span> <span class=\"kd\">class</span> <span class=\"o\">}</span>\n<span class=\"bp\">-&gt;</span> <span class=\"o\">{</span> <span class=\"n\">o</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">setvar</span> <span class=\"o\">,</span> <span class=\"n\">setvar</span> <span class=\"bp\">&gt;.</span> <span class=\"o\">}</span>\n<span class=\"n\">all</span> <span class=\"kd\">class</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">o</span> <span class=\"n\">rules</span> <span class=\"n\">except</span> <span class=\"bp\">-&gt;</span> <span class=\"n\">o</span> <span class=\"bp\">&lt;.</span> <span class=\"kd\">class</span> <span class=\"o\">,</span> <span class=\"kd\">class</span> <span class=\"bp\">&gt;.</span>\n</code></pre></div>\n\n<p>and now shift 5 steps forward along <code>&lt;. setvar , setvar &gt;.</code> to get the repaired state</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">-&gt;</span> <span class=\"o\">{</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">setvar</span> <span class=\"o\">,</span> <span class=\"n\">setvar</span> <span class=\"bp\">&gt;.</span> <span class=\"n\">o</span> <span class=\"bp\">|</span> <span class=\"n\">wff</span> <span class=\"o\">}</span>\n<span class=\"bp\">-&gt;</span> <span class=\"o\">{</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">setvar</span> <span class=\"o\">,</span> <span class=\"n\">setvar</span> <span class=\"bp\">&gt;.</span> <span class=\"n\">o</span> <span class=\"o\">}</span>\n</code></pre></div>\n\n<p>Now we have finally cleared the last hurdle, as we can clearly now either <code>shift |</code> or <code>shift }</code> depending on what we see next to parse both <code>{ &lt;. x , y &gt;. | ph }</code> and <code>{ &lt;. x , y &gt;. }</code>. For the purpose of the example let's say we shift <code>}</code> so we get to state</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">-&gt;</span> <span class=\"o\">{</span> <span class=\"bp\">&lt;.</span> <span class=\"n\">setvar</span> <span class=\"o\">,</span> <span class=\"n\">setvar</span> <span class=\"bp\">&gt;.</span> <span class=\"o\">}</span> <span class=\"n\">o</span>\n</code></pre></div>\n\n<p>and a reduce is unambiguous.</p>",
        "id": 213588808,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1602868745
    },
    {
        "content": "<p>But what are we reducing anyway? I've been talking about compositing rules, and what I haven't been showing here is that each production is associated to a partial expression tree. You can imagine them as lambda expressions. The original rules from the grammar will have a result like <code>\\e1 e2. (cpr e1 e2)</code> for the production <code>class -&gt; &lt;. class , class &gt;.</code>, which is to say that we take the two class expressions in the brackets and put them into the two arguments of a <code>cpr</code> node. The arguments aren't always in parse order, for example I think <code>wal</code> takes its arguments in the order <code>wal ph x</code> (because the <code>$f</code> variable declaration of <code>vx</code> comes after <code>wph</code>), so the production <code>wff -&gt; A. setvar wff</code> has result <code>\\e1 e2. (wal e2 e1)</code>.</p>\n<p>Now compositing rules has the effect of a composition of these two expressions. In the first part we composited <code>class -&gt; &lt;. class , class &gt;.</code> with <code>class -&gt; setvar</code>, with associated results <code>\\e1 e2. (cpr e1 e2)</code> and <code>\\e1. (cv e1)</code>, so we insert the <code>cv</code> expression in for <code>e1</code> of the <code>cpr</code> expression to get a new result <code>\\e1 e2. (cpr (cv e1) e2)</code> for the new production <code>class -&gt; &lt;. setvar , class &gt;.</code>. Similarly, the production <code>class -&gt; &lt;. setvar , setvar &gt;.</code> is formed by inserting <code>cv</code> in for <code>e2</code> in this new production, resulting in <code>\\e1 e2. (cpr (cv e1) (cv e2))</code>. And finally, we composited this expression with the <code>class -&gt; { class }</code> production with result <code>\\e1. (csn e1)</code>, and this composition yields, for the composite rule <code>class -&gt; { &lt;. setvar , setvar &gt;. }</code>, the result <code>\\e1 e2. (csn (cpr (cv e1) (cv e2)))</code>. This is what we reduce with.</p>\n<p>So for the example <code>{ &lt;. x , y &gt;. }</code>, we first reduce using <code>setvar -&gt; x := vx</code>, then <code>setvar -&gt; y := vy</code>, then <code>class -&gt; { &lt;. setvar , setvar &gt;. } := \\e1 e2. (csn (cpr (cv e1) (cv e2)))</code> to get the final parse tree <code>(csn (cpr (cv vx) (cv vy)))</code>.</p>",
        "id": 213588821,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1602868751
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span> Thanks very much! Might take me some time to wrap my head around this since I don't know much about parsers. I'll get back to you if I have questions.</p>",
        "id": 213780249,
        "sender_full_name": "Joe Palermo (S2'17)",
        "timestamp": 1603112106
    },
    {
        "content": "<p>It is a repost, so the context might not be exactly right for the venue. Feel free to ask if something is out of context</p>",
        "id": 213780344,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1603112156
    },
    {
        "content": "<p>I'm curious <span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span>  how different/similar is GPT-f vs the GPT used for coding (<a href=\"https://analyticsindiamag.com/open-ai-gpt-3-code-generator-app-building/\">https://analyticsindiamag.com/open-ai-gpt-3-code-generator-app-building/</a>)?</p>",
        "id": 240042826,
        "sender_full_name": "Brando Miranda",
        "timestamp": 1621858587
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"246156\">@Brando Miranda</span> the architecture is the same (smaller model similar in size to GPT-2) but the training objective is quite different (see section 4.2) <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span></p>",
        "id": 240051467,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1621863204
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"249373\">Stanislas Polu</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/GPT-f.20paper/near/240051467\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"246156\">Brando Miranda</span> the architecture is the same (smaller model similar in size to GPT-2) but the training objective is quite different (see section 4.2) <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span></p>\n</blockquote>\n<p>Thanks Stanslas! I appreciate the message. I will check that out.</p>\n<p>Out of curiosity, is there a reason you prefered a transformer model e.g. GPT than an enumerator with a neural recognition model (e.g. as in Dreamcoder, Deepcoder, etc. related work in that path)</p>",
        "id": 240062907,
        "sender_full_name": "Brando Miranda",
        "timestamp": 1621868476
    },
    {
        "content": "<p>Wellll... Dreamcoder and GPT-f objective are not too dissimilar.</p>\n<p>You could view proof search as the wake phase, the model conjecturing capabilities (generating theorem statements during proof search that are not part of the formal library) as the abstraction phase and attempting to prove them as the dream phase.</p>",
        "id": 240075113,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1621873673
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"246156\">Brando Miranda</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/GPT-f.20paper/near/240042826\">said</a>:</p>\n<blockquote>\n<p>I'm curious <span class=\"user-mention silent\" data-user-id=\"249373\">Stanislas Polu</span>  how different/similar is GPT-f vs the GPT used for coding (<a href=\"https://analyticsindiamag.com/open-ai-gpt-3-code-generator-app-building/\">https://analyticsindiamag.com/open-ai-gpt-3-code-generator-app-building/</a>)?</p>\n</blockquote>\n<p>You probably know this, but my understanding of GPT-3 applications, is one doesn't retrain the model.  Instead they come up with a prompt to extract information out of the model.  For example to find the capital of England, you would give GPT-3 a prompt like `France =&gt; Paris, China =&gt; Beijing, England =&gt; \" and the model will complete the string with \"London\".  It's crazy, but with good prompt engineering, you can take this really far.  In this way, GPT-3 can code since there was a lot of code (using standard programming languages) in the training data, and all one has to do if find a good way to engineer prompts.</p>\n<p>GPT-f (as Stan said) uses a smaller model than GPT-3 (more like GPT-2) and therefore can be fine-tuned as is standard with GPT-2 (and BERT) applications.  GPT-f was pretrained on web text and web math, and we fine tune it with tasks like <code>GOAL P Q : Prop ⊢ ((P → Q) → P) → P PROOFSTEP apply or.elim (em P)</code>, following the pattern <code>GOAL &lt;TacticState&gt; PROOFSTEP &lt;Tactic&gt;</code>.  When using it to predict tactics, you give it the prompt <code>GOAL &lt;TacticState&gt; PROOFSTEP </code> and it fills in the tactic.  (The main insight in our paper is that we get a big boost by also co-training it with a number of other tasks.  These tasks are not used for prediction, but nontheless, really help our model.  The details are in the paper.)</p>",
        "id": 240270766,
        "sender_full_name": "Jason Rute",
        "timestamp": 1621993501
    }
]