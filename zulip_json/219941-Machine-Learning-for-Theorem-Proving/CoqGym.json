[
    {
        "content": "<p>This is specifically to talk about <a href=\"https://github.com/princeton-vl/CoqGym\" title=\"https://github.com/princeton-vl/CoqGym\">CoqGym</a> and its API for use in other projects.  It is not so much about ASTactic (which is talked about in <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/Paper.3A.20Learning.20to.20Prove.20Theorems.20via.20Interacting.20with.20Proof\" title=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/Paper.3A.20Learning.20to.20Prove.20Theorems.20via.20Interacting.20with.20Proof\">this thread here</a>).</p>",
        "id": 197053048,
        "sender_full_name": "Jason Rute",
        "timestamp": 1589114110
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"246156\">@Brando Miranda</span> told me (on GitHub) that he finds the CoqGym API very usable.  I'd like to understand the API more.  <span class=\"user-mention\" data-user-id=\"246156\">@Brando Miranda</span> is the best documentation just the README on Github?  Do you have any initial thoughts and commentary on this Gym?</p>",
        "id": 197053156,
        "sender_full_name": "Jason Rute",
        "timestamp": 1589114261
    },
    {
        "content": "<p>Also, how easy would it be to implement a Tactic-Toe style AI in Coq Gym?  That would be a great baseline.  Here is what I mean:</p>\n<ul>\n<li>Don't use neural networks.  Instead, for the embeddings used a fixed hand-coded embedding using the techniques from the recent TacticToe for Coq paper.  (These shouldn't be too hard to code and would be quite useful to anyone else using CoqGym.)</li>\n<li>For tactic selection, use k-nearest neighbors using the prerecorded CoqGym information.</li>\n<li>For premise selection, also use k-nearest neighbors (with both the goal and the premise to select).</li>\n<li>Look again at the CoqGym paper for some of the finer details, such as which tactics to use, how to use them, and how to fill in the non-theorem tactic arguments.</li>\n</ul>",
        "id": 197053484,
        "sender_full_name": "Jason Rute",
        "timestamp": 1589114617
    },
    {
        "content": "<p>Since it is not trained with neural networks or reinforcement learning, it should be much easier to reproduce.</p>",
        "id": 197053530,
        "sender_full_name": "Jason Rute",
        "timestamp": 1589114664
    },
    {
        "content": "<p>Hi everyone! I'm looking for references to theorems that were proved by CoqGym/ASTactic and whose proof was contributed back to the Coq libraries? Git commits or email threads are all welcome. Thanks thanks!</p>",
        "id": 207138116,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1597668268
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span>  Coq now has their own <a href=\"https://coq.zulipchat.com\">Coq Zulip</a> and they also have a stream for <a href=\"https://coq.zulipchat.com/#narrow/stream/252087-Machine-learning.20and.20automation\">#Machine Learning and Automation</a>.  It would probably be best to ask there as well.  (Also, there are other similar projects such as ProverBot9001 and Tactician.  You may want to ask about those as well if I understand your motivation.)</p>",
        "id": 207166357,
        "sender_full_name": "Jason Rute",
        "timestamp": 1597682312
    },
    {
        "content": "<p>Thanks <span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span> will do so <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span></p>",
        "id": 207169868,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1597684250
    }
]