[
    {
        "content": "<p>I noticed the abstracts for <a href=\"http://aitp-conference.org/2020/\" title=\"http://aitp-conference.org/2020/\">AITP 2020</a> got posted recently (not sure when).  I'm really looking forward to reading through them.  I thought I'd also add any comments I have here.  Feel free to add you own as well.</p>",
        "id": 192466509,
        "sender_full_name": "Jason Rute",
        "timestamp": 1585697501
    },
    {
        "content": "<p>(I also assume there is no other public place on the internet where people talk about AITP 2020, right?)</p>",
        "id": 192466577,
        "sender_full_name": "Jason Rute",
        "timestamp": 1585697534
    },
    {
        "content": "<p>The first abstract I want to talk about is <a href=\"http://aitp-conference.org/2020/abstract/paper_7.pdf\" title=\"http://aitp-conference.org/2020/abstract/paper_7.pdf\">Reinforcement Learning for Interactive Theorem Proving in HOL4</a> by <span class=\"user-mention\" data-user-id=\"110187\">@Minchao Wu</span>, Michael Norrish, Christian Walder and Amir Dezfouli.  They built a gym environment for HOL4.  I don't think the code or paper is public yet, but the abstract has a lot of details.  The main idea is that they created a Python environment for reinforcement learning of theorem proving in HOL4.  There are a number of points which make it different from HOList and the other projects.  Rather than go through all the details, I'll give a few quick thoughts:</p>\n<ul>\n<li>\n<p>The main thing I found interesting about this is that they set this up as a Gym compatible environment (so that they could use the REINFORCE algorithm).  By Gym compatible I mean Open AI's Gym interface which is a really simple interface.  You have to be able to start an environment, perform a step in that environment, and the read an observation about the state of that environment.  What makes this different from other interactive theorem proving \"gyms\" that I'm aware of is that it doesn't seem to allow backtracking.  Backtracking (in the form of a tree search) is very important for projects like AlphaGo, solving the Rubik's cube, and HOList.  From what I can tell, they allow for two ways around this:</p>\n<ol>\n<li>They actually do have back-tracking in a sense, since a \"state\" is not single goal stack (with a local context), but instead a \"fringe\".  I'm not entirely clear what a fringe is.  They describe a fringe as all unvisited goal stacks, but it isn't clear to me what \"visited\" means in this context.  Unlike, say, A* search, each goal stack has a very large number of \"neighbors\" since there are a very large number of tactic applications that can be applied to a goal.  It would be unreasonable to visit all of the neighbors.  So maybe every goal set remains in the fringe, but then I don't know what \"unvisited\" means.  (Also later they talk about \"winning\" if the fridge becomes empty, but that also wouldn't make sense since I only need to solve some goal stack, not all of them.)  Another interpretation is that a goal stack is visited when any tactic is applied to it, but then the fringe would only have size 1, right, because each tactic application only creates one new goal stack?  (Clearly I don't understand this well enough.)  Anyway, I think there is some notion of being able to choose which goal stack to explore more.</li>\n<li>The default behavior is to completely ignore the fringe and to just apply your tactic application to the first goal stack in the fringe.  In this case it is basically pure model-free reinforcement learning.  (Also since they are using REINFORCE, it seems they are using this default behavior.)  This however is surprising since I was under the impression that the model-based reinforcement learning used in theorem proving (i.e. using the fact that the agent has access to an accurate simulator of the theorem learning environment) is very important to getting good results in theorem proving.  If that is not the case, then that would be surprising.  (I was just having <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/HOList/near/192462558\" title=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/HOList/near/192462558\">a conversation about this</a> for HOList.)</li>\n</ol>\n</li>\n<li>\n<p>Unlike a lot of theorem proving RL setups which only assign rewards at the end (solved or not), they assign partial negative rewards for picking bad tactics (which fail or don't change the goal) and for running out of time.  This probably helps the agent learn faster.</p>\n</li>\n<li>It is interesting that environments written in Python (like this one) sell it as being easier to use machine learning tools like PyCharm/Tensorflow and environments written in OCaml (like the new <a href=\"https://arxiv.org/abs/2003.09140\" title=\"https://arxiv.org/abs/2003.09140\">TacticToe for Coq</a> paper) sell it as being closer to the theorem prover.  It gets at the following dichotomy.  If we ever hope to use these tools in practice, we need to have them available in the language the theorem prover is written in, but if we want to try things quickly or get machine learning experts involved, then we need to have it in Python environments with clean and well documented APIs.  I think we need both.</li>\n<li>While the environment seems fairly grand, what they have done with it so far seems fairly limited.  I think they have only used it on 10 theorems so far.  Also, I think each theorem is like a whole new world where the agent has to relearn how to prove theorems from scratch.  This is very different from the DeepHOL Zero work where the agent learns stuff from one theorem which it can apply to another.  I hope that this work can be eventually brought to that level.  However, even if that is all that they have planned, I think it will serve as a good Gym environment for Machine Learning researchers to try out theorem proving, but not as competition for say DeepHOL Zero or any of the supervised-learned ML agents, like TacticToe which is currently the state of the art for ML in HOL4.</li>\n</ul>",
        "id": 192603711,
        "sender_full_name": "Jason Rute",
        "timestamp": 1585782569
    },
    {
        "content": "<p>Also, if anyone can fix this, the name of their project is spelled incorrectly at <a href=\"http://aitp-conference.org/2020/\" title=\"http://aitp-conference.org/2020/\">http://aitp-conference.org/2020/</a> : \"leaerning\" -&gt; \"learning\"</p>",
        "id": 192603839,
        "sender_full_name": "Jason Rute",
        "timestamp": 1585782661
    },
    {
        "content": "<p>A fringe is a set of goals (with their corresponding local contexts) that haven’t been proved during a single proof attempt. One starts with the main goal. As one applies tactics, the fringe is expanded with new (sub)goals generated. The main goal is proved when the fringe becomes empty. There is no backtracking because this way is thinking of theorem proving as a single-pass exploration of the tree. The hope is that the “backtracking flavor” should be learned by the policy. In the current setting of environment, one can still implement backtracking by themselves if they wanted to. However, we are working on a new version that would support backtracking in a neater way.</p>",
        "id": 192638469,
        "sender_full_name": "Minchao Wu",
        "timestamp": 1585818618
    },
    {
        "content": "<p>Ok.  I clearly misunderstood.  So a \"fringe\" is what is called a \"goal stack\" in HOL4, right?  (Looking back, I misread that sentence.  Although, it is confusing to say that an edge of the tree is a tactic application, since if a node is a single (sub)goal, all the edges coming out of that node are going to be the same tactic application.)</p>",
        "id": 192655453,
        "sender_full_name": "Jason Rute",
        "timestamp": 1585829520
    },
    {
        "content": "<blockquote>\n<p>There is no backtracking because this way is thinking of theorem proving as a single-pass exploration of the tree.</p>\n</blockquote>\n<p>Is this \"single pass exploration\" approach viable?  It would be as if AlphaZero was only allowed to play go and chess with a single pass through (no MCTS).  Do you think one can train a state of the art HOL4 theorem prover without a tree search?  (Or maybe I'm misunderstanding the goal of this project.)  However, I do admit that by restricting to model-free reinforcement learning that you are opening up a wide field of prebuilt and tuned algorithms which you can apply (as long as you can handle embedding the formulas since that is nonstandard).</p>",
        "id": 192656375,
        "sender_full_name": "Jason Rute",
        "timestamp": 1585830058
    },
    {
        "content": "<blockquote>\n<p>In the current setting of environment, one can still implement backtracking by themselves if they wanted to.</p>\n</blockquote>\n<p>Does the gym-like environment have a mechanism to backtrack?  Maybe <code>get_state</code>and <code>set_state</code> methods (which I've seen in other Gym-like environments)?  (Of course the user could program their own HOL4 simulator, but that seems like overkill. <span aria-label=\"slight smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"slight smile\">:slight_smile:</span>)</p>",
        "id": 192656661,
        "sender_full_name": "Jason Rute",
        "timestamp": 1585830215
    },
    {
        "content": "<blockquote>\n<p>However, we are working on a new version that would support backtracking in a neater way.</p>\n</blockquote>\n<p>Looking forward to seeing this!  As well any other papers, presentations, code, and most of all, public gym-like APIs that come out of this project!</p>",
        "id": 192656868,
        "sender_full_name": "Jason Rute",
        "timestamp": 1585830323
    },
    {
        "content": "<blockquote>\n<p>Is this \"single pass exploration\" approach viable?  It would be as if AlphaZero was only allowed to play go and chess with a single pass through (no MCTS).  Do you think one can train a state of the art HOL4 theorem prover without a tree search? </p>\n</blockquote>\n<p>I wouldn't say that there is no tree search, but the tree search is the learned policy. If you really want some explicit tree search (say MCTS), you still have the option to add them afterwards by treating them as policy improvement operators.</p>\n<blockquote>\n<p>However, I do admit that by restricting to model-free reinforcement learning that you are opening up a wide field of prebuilt and tuned algorithms which you can apply (as long as you can handle embedding the formulas since that is nonstandard).</p>\n</blockquote>\n<p>I don't see how prebuilt and tuned algorithms can be applied directly here at this stage. The learning of the argument policy is non-standard and would require quite some flexibility from the prebuilt algorithms. We wrote our own training algorithms for the AITP version. </p>\n<blockquote>\n<p>Does the gym-like environment have a mechanism to backtrack? Maybe get_state and set_state methods (which I've seen in other Gym-like environments)?</p>\n</blockquote>\n<p>There is <code>get_state</code> but no <code>set_state</code> in the current AITP version. The one we are working on would make it available.  Some of us still believe that the non-backtracking version would be much easier to understand and train (and shouldn't perform too bad), though.</p>",
        "id": 192660432,
        "sender_full_name": "Minchao Wu",
        "timestamp": 1585832027
    },
    {
        "content": "<blockquote>\n<p>If you really want some explicit tree search (say MCTS), you still have the option to add them</p>\n</blockquote>\n<p>To have MCTS (or any tree search), you need a way to jump between states of the environment.  Do you have that?  If I apply a tactic and later decide I didn't want to do that, can I back up (or say \"go to such and such state\")?  Most of the Open AI gym environments don't support this functionality, so it isn't obvious that yours does either?  (EDIT: Maybe they support it in that you can make a deep copy of the state, but I don't know that would be possible with an ITP like HOL4 in the backend.)</p>",
        "id": 192661005,
        "sender_full_name": "Jason Rute",
        "timestamp": 1585832290
    },
    {
        "content": "<blockquote>\n<p>I don't see how prebuilt and tuned algorithms can be applied directly here at this stage.</p>\n</blockquote>\n<p>That is a good point.  I guess you were saying you used REINFORCE, so I didn't think about it too strongly, but yes, the action space is quite unique.</p>",
        "id": 192661129,
        "sender_full_name": "Jason Rute",
        "timestamp": 1585832372
    },
    {
        "content": "<blockquote>\n<p>Most of the Open AI gym environments don't support this functionality, so it isn't obvious that yours does either? </p>\n</blockquote>\n<p>No, at least not at this stage. One would need to do it themselves. The environment can tell you whatever the resulting state is, but the user needs to manage the states themselves.</p>",
        "id": 192661843,
        "sender_full_name": "Minchao Wu",
        "timestamp": 1585832732
    },
    {
        "content": "<p>Can a user save a copy of state and later apply actions to it ? In functional programming terms, I'm trying to figure out if the states are persistent data structures.  If not, I don't see how the user can manage the tree search themselves.  (Although, I guess the user can also just start over and apply the same sequence of tactics again to get back to a previously visited state.)</p>",
        "id": 192662251,
        "sender_full_name": "Jason Rute",
        "timestamp": 1585832915
    },
    {
        "content": "<p>For that you just need something like set_states which is not too difficult to implement. Then one can maintain a history of states on their own and call the environment to rollout. But as you said in (), one can always do it with the minimal help from the environment.</p>",
        "id": 192664342,
        "sender_full_name": "Minchao Wu",
        "timestamp": 1585833891
    },
    {
        "content": "<p>Thanks for posting this!</p>",
        "id": 192991365,
        "sender_full_name": "Rongmin Lu",
        "timestamp": 1586142344
    },
    {
        "content": "<p>I found <a href=\"http://aitp-conference.org/2020/abstract/paper_18.pdf\" title=\"http://aitp-conference.org/2020/abstract/paper_18.pdf\">Wu/Jiang/Grosse/Ba's abstract on proving inequalities</a> very interesting. Their generator is straightforward to reproduce and while the proven equalities/inequalities appear still a bit easy (for the k/l values they took at least), the result and study is pragmatic and well covered.</p>",
        "id": 193050620,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1586183674
    },
    {
        "content": "<p>Does anyone know if it's still possible to attend AITP? (or if it's likely to go online and one can register?)</p>",
        "id": 205380767,
        "sender_full_name": "Brando Miranda",
        "timestamp": 1596040486
    },
    {
        "content": "<p>I think the best thing to do would be to ask Josef Urban directly.</p>",
        "id": 205381499,
        "sender_full_name": "Jason Rute",
        "timestamp": 1596040844
    },
    {
        "content": "<p>How is AITP 2020 going?  Any exciting news?  Is it in-person, remote, or a mix?  Will videos and slides get posted on the website as usual?  I hope it is a good meeting.  So much has happened in the last year!</p>",
        "id": 210034276,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600103104
    },
    {
        "content": "<p>It's a mix, we managed to get to Aussois from CZ</p>",
        "id": 210037485,
        "sender_full_name": "Mikoláš Janota",
        "timestamp": 1600104682
    },
    {
        "content": "<p>Unfortunately, Lasse's talk and <br>\nmine were not recorded because we were distracted by some technical problems.<br>\nFor those interested, here are my slides about self-learned formula synthesis in set theory. <a href=\"/user_uploads/3121/FLAtWcSN3R7NWcLtB-YIM-v7/AITP2020-setsynt.pdf\">AITP2020-setsynt.pdf</a></p>",
        "id": 210066180,
        "sender_full_name": "Thibault Gauthier",
        "timestamp": 1600119286
    },
    {
        "content": "<p>Thanks <span class=\"user-mention\" data-user-id=\"342506\">@Thibault Gauthier</span> out of curiosity, are there similar work out there about propositional logic, since there seems to be a close connection between your graphs and truth tables? And maybe, refactoring a proposition into a simpler form might be useful for some applications?</p>",
        "id": 210092548,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600148879
    },
    {
        "content": "<p>There is something about finite model builder, but I am not sure it's going the same direction. <br>\n<a href=\"https://easychair.org/publications/paper/rZKt\">https://easychair.org/publications/paper/rZKt</a></p>",
        "id": 210109905,
        "sender_full_name": "Thibault Gauthier",
        "timestamp": 1600163703
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span>  <br>\nI really like your talk today about NN-guided search for Metamath.  <br>\nThe multiplication of probabilities makes sense.<br>\nAre you planning to go for reinforcement learning  from scratch (AlphaZero-style) with no training on metamath (and maybe some pretraining on other datasets)?</p>",
        "id": 210137755,
        "sender_full_name": "Thibault Gauthier",
        "timestamp": 1600180486
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"342506\">@Thibault Gauthier</span> thanks! What we do today is Expert Iteration with a Value function which is preeeety close to a full fledged RL loop. The challenge with applying AlphaZero is that the action space is.... enumerable here, so the exploration budget for AlphaZero to work would be humongous :) But luckily DeepMind published a paper recently that will certainly help with that: <a href=\"https://arxiv.org/abs/2007.12509\">https://arxiv.org/abs/2007.12509</a></p>",
        "id": 210138858,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600180996
    },
    {
        "content": "<p>That's something we'll definitely explore once we reach the limits of Expert Iteration <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span></p>",
        "id": 210138908,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600181016
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span> hi hi! To follow-up on your question. Anybody who has applied State of the Art technology to code generation knows how useful are comments in code to train models to translate from informal prompts to usable code. If I was to make one recommendation for the Lean community, that would be to comment Lean code as much as conceivably possible. Future ML experts will thank you for that :)</p>",
        "id": 210139173,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600181123
    },
    {
        "content": "<p>Why has nobody ever told me that before?</p>",
        "id": 210139762,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1600181372
    },
    {
        "content": "<p>:D</p>",
        "id": 210139939,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600181436
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"342506\">@Thibault Gauthier</span> I realize I misread your question. I thiiiink we're more interested in tackling external real-world benchmarks these days (such as exercises statements manually formalized). In that setup,  access to training proofs will be even scarcer and we plan to explore the ability to train against a curriculum of exercise statements without the proofs. We have early results that suggest that it works well; but we do start from the base models that are trained on the Metamath database, not from scratch.</p>",
        "id": 210181857,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600199864
    },
    {
        "content": "<p>I think the RL Holist papers demonstrate that training \"from scratch\" (without proofs but \"scratch\" is still a bit of an abuse of language since you do have the statements) just works in principle with a finite action space. But as far as we're concerned we do need to bootstrap the generative language models so that they are able to generate sensible terms for the substitutions.</p>",
        "id": 210182264,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600200053
    },
    {
        "content": "<p>I hope this time I answered your question <span aria-label=\"grimacing\" class=\"emoji emoji-1f62c\" role=\"img\" title=\"grimacing\">:grimacing:</span></p>",
        "id": 210182337,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600200081
    },
    {
        "content": "<p>Pre-training on other datasets, I think (not verified), would probably not suffice to stumble on correct substitutions early on to go full AlphaZero style.</p>",
        "id": 210182740,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600200240
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"249373\">Stanislas Polu</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/AITP.202020/near/210138858\">said</a>:</p>\n<blockquote>\n<p>But luckily DeepMind published a paper recently that will certainly help with that: <a href=\"https://arxiv.org/abs/2007.12509\">https://arxiv.org/abs/2007.12509</a></p>\n</blockquote>\n<p>I just had a look at this paper.  It's really good.  It's amazing how looking at the mathematical underpinnings of an ad hoc solution can help to optimize it and make it more rigorous.  We must spread the Gospel. <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span>  <strong>If you are going to implement MCTS for RL, use the new and improved version in this paper!</strong></p>",
        "id": 210208376,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600215346
    },
    {
        "content": "<p>Also, speaking of tree search, has anyone else noticed that tactic-based proving is a two-player zero-sum game?  Player A chooses the tactics.  Player B chooses one subgoal to work on.  If Player A has a perfect strategy the theorem is provable.  If Player B does, the theorem is not provable.  I think this could speed up RL for theorem proving (since one doesn't have to explore all subgoals to get meaningful policy and value updates).  It also probably means that maybe we should start on the hardest subgoal instead of the first subgoal (or the easiest subgoal).  Anyway, food for thought...</p>",
        "id": 210208698,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600215597
    },
    {
        "content": "<p>To follow-up on yesterday's talk on the IMO Grand Challenge, which is, no question about it, a very well designed ultimate test for the capabilities of ATPs, I think it's important to recognize that IMOs are also still far out of reach of the current state of the art in general (even if some classes are admittedly within reach, such as some types of inequalities, some types of geometry questions, ...). As a consequence, one thing that the GC does not address is that it does not enable us to effectively measure our progress as a community <strong>today</strong>, if we are, exaggeratedly saying, stuck at 0%.</p>\n<p>On the path to IMOs, I strongly believe (and happy to discuss this point) it would be beneficial for the community to have a set of unified benchmarks of increasing difficulty against which we can measure ourselves and collaborate without relying on the current goto solution that consists in test/valid splits of existing libraries which are siloed by construction, hugely conditioned on how lemmas were split in each of these libraries, and as such not directly comparable across efforts. </p>\n<p>As such, if there is interest for it, I'd love to collaborate on a <strong>mini F2F benchmark</strong> consisting  in its first iteration of problems statements that are \"very easy\", but do require a minimal amount of mathematical thinking and human effort to be demonstrated formally and are challenging enough such that current ATPs will fail to reach 100% as of today. This would create a medium for our different teams to compare themselves against each others which would IMHO foster collaboration and innovation. It should be simple enough such that it can measure our progress effectively, but hard enough such that reaching 100% on the benchmark would convincingly demonstrate that we're making useful progress towards the grand challenge.</p>\n<p>Pragmatically, I think that would simply mean selecting say 50-100 exercises that we believe would fit the bill, publicize them and put in the  small amount of work needed to formalize their statements (only) in various systems.</p>\n<p>I'm very curious to hear what people think about this proposal? Am I missing something? Do people feel convinced that accuracy on test splits of formal libraries is good enough? Or that we're close enough to IMOs to use them as a measure of progress?</p>",
        "id": 210238921,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600248463
    },
    {
        "content": "<p>Is the F2F benchmark supposed to be in a specific language (say, Lean), or would it be in some other forms?</p>",
        "id": 210239654,
        "sender_full_name": "Minchao Wu",
        "timestamp": 1600248964
    },
    {
        "content": "<p>There is a huge source of Olympiad problems available, and Lean is getting to the point where it can understand pretty much all of them, with Joseph Myers' recent work on affine geometry enabling formalisations of problems involving e.g. circles, triangles etc (indeed Joseph just finished formalising all the solutions to this year's British Maths Olympiad round 1). </p>\n<p>I run a formalizing club at Imperial and I also run a puzzle-solving club where we work on Olympiad problems; when it all starts up again in October I could see if I could get the puzzle-solvers formalising olympiad questions.</p>",
        "id": 210240115,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600249407
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"249373\">Stanislas Polu</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/AITP.202020/near/210238921\">said</a>:</p>\n<blockquote>\n<p>Do people feel convinced that accuracy on test splits of formal libraries is good enough?</p>\n</blockquote>\n<p>I think that mathematicians mostly think that testing again formalised libraries is ... barking up the wrong tree? (I'm trying to be politic here --- certainly it's a start.)</p>\n<p>A formalised library looks almost completely unlike \"the process\" of doing maths (wherever in the spectrum of theory-building / problem-solving you mean). I mean, it's great if ML based super-tactics can reproduce and/or help in preparation of formalised libraries, but the \"millions of tiny lemmas\" that you see in mathlib (and most other libraries I've looked at) is a strange artifact of wanting to talk to the computer, not much of a reflection on what human mathematicians do. :-)</p>",
        "id": 210240495,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1600249752
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110187\">@Minchao Wu</span> I think it can easily be cross-language/system:  we just formalize the statements in all systems that make sense (say Lean, Metamath, HOL Family, Coq).</p>",
        "id": 210241553,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600250642
    },
    {
        "content": "<p>One place to start could be to take human solutions to IMO problems and formalize the outline of the argument (including any auxiliary definitions it uses) as statements without formal proofs. Use that as the input, and have the system fill in the proofs, or just use them somehow to produce a proof of the original problem if it prefers (e.g., maybe one of the intermediate statements isn't quite correct).</p>",
        "id": 210241636,
        "sender_full_name": "Reid Barton",
        "timestamp": 1600250690
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110087\">@Scott Morrison</span> completely agreed with that. Hence the motivation for an \"out-of-library\" / \"exercise-type\" benchmark?</p>",
        "id": 210241638,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600250691
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span> I think formalizing the statements only here would be sufficient to produce a benchmark we can share. But again, it does not solve the problem that IMOs may be too hard to efficiently measure progress?</p>",
        "id": 210241790,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600250791
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110032\">@Reid Barton</span> that's an interesting take. Is there a particular motivation for this objective vs simpler exercises?</p>",
        "id": 210241818,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600250820
    },
    {
        "content": "<p>This particular mathematician has no clue whatsoever about machine learning, which is why I am so interested in engaging with the ML community to figure out what they want. I want a program which is capable of helping PhD students to do algebraic geometry in some way which is recognised by other staff members as being tangibly useful.</p>",
        "id": 210242051,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600250965
    },
    {
        "content": "<p>I think longer term goal of IMOs is great. Reid's suggestion provides something intermediate to aim for, that is hopefully actually building in the right direction.</p>",
        "id": 210242057,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1600250971
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110038\">@Kevin Buzzard</span> to make sure I understand,  are you looking for a setup where the student provides the high-level \"hard\" reasoning steps in a natural/easy way and the system provides the glue? Being fine with a system that is somewhat dumb at maths but great at glueing formal proofs together?</p>",
        "id": 210242520,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600251249
    },
    {
        "content": "<p>Oh my need is much broader. I need any kind of system where someone who has no idea about solvers or provers or anything but has a training in mathematics can look at it and say \"hey, that looks useful\". I just care about making these kinds of tools more mainstream in the mathematics community -- this is in some sense the biggest problem I face right now.</p>",
        "id": 210242623,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600251330
    },
    {
        "content": "<p>I guess one could say that this problem is something like getting computers to check the solutions to IMO problems on the same level as humans. It's hard for me to imagine that this isn't a necessary step along the way--but also a system capable of this could be very useful for human and even automated formalization of proofs, which in turn could increase the training data for a system that wants to solve bigger problems, etc.</p>",
        "id": 210242645,
        "sender_full_name": "Reid Barton",
        "timestamp": 1600251351
    },
    {
        "content": "<p>A mathematician looks at something like Z3 or a Sat solver or TPTP and doesn't recognise anything which they could use there.</p>",
        "id": 210242664,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600251362
    },
    {
        "content": "<p>I am currently regarded as an oddity within my community, and getting funding is difficult because mathematicians have 0 use for any of these tools right now.</p>",
        "id": 210242738,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600251399
    },
    {
        "content": "<p>Giving intermediate statements along the path to a proof can also be tuned for difficulty by dropping out some of the steps (or even introducing error in the statements).</p>",
        "id": 210242811,
        "sender_full_name": "Reid Barton",
        "timestamp": 1600251456
    },
    {
        "content": "<p>Saying \"we have SAT solvers which can solve gigantic tedious logic problems\" does not buy much in my community. Even solving this boolean pythag triple problem does not buy you much here, because solving fantastically combinatorially complicated problems in basic number theory using brute force techniques is not passing on the kind of understanding which we are interested in -- we want to see high-level structure.</p>",
        "id": 210242919,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600251509
    },
    {
        "content": "<p>Finally, Lean's current automation would score very poorly on most problems of this form but I think that \"hammers\" available in other systems like Isabelle would come in comfortably far from both 0% and 100%.</p>",
        "id": 210242962,
        "sender_full_name": "Reid Barton",
        "timestamp": 1600251546
    },
    {
        "content": "<p>This is interesting because I believe it uncovers some form of tension here. You want assistance to make formalization easy and natural while ML researchers want to demonstrate that their machine can do non trivial maths.</p>",
        "id": 210243012,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600251583
    },
    {
        "content": "<p>To crack the world of pure mathematics as it actually is (as opposed to how some CS people want to see it) we need stuff which looks more impressive. An Olympiad problem-solver might turn some more heads; a database which can hammer through some sections of the stacks project might too.</p>",
        "id": 210243013,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600251584
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110032\">@Reid Barton</span> This is interesting and might indeed be a sweet spot wrt to the tension above. What would be the artifact? What do you think of  an IMO problem statement and a set of intermediary lemmas statement? And we can arbitrarily mask these lemmas to challenge systems or simply benchmark against the lemmas independently?</p>",
        "id": 210243152,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600251669
    },
    {
        "content": "<p>Anything which would convince a mathematician that machines are capable of making some kind of progress on Olympiad style problems would I'm sure be of interest, whether it's a box which outputs \"I think proving these intermediate lemmas would be helpful\" or \"here is a choice point -- can I have some human input (in particular input from a human who can't solve the problem) to see which way to go next\" or \"here are some lemmas which I can prove and which might be helpful\" -- anything which comes up with a human-understandable step towards solving the problem which clearly looks like it might be going in the right direction would turn a few heads.</p>",
        "id": 210243425,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600251876
    },
    {
        "content": "<p>It is important to note that there are plenty of researchers in maths who have no clue how to solve most olympiad problems. Puzzle-solving (and in particular speed puzzle solving, which is what the IMO is) is a particular kind of skill, which is certainly not an essential prerequisite for being a research mathematician (although of course it can sometimes help in some areas).</p>",
        "id": 210243482,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600251944
    },
    {
        "content": "<p>Yes, this is the sort of thing I had in mind. You'll also need some way to represent auxiliary definitions (e.g. geometric constructions) which some of the intermediate lemmas talk about; so then the data set also needs to know when a lemma's statement depends on a definition. I guess it's also possible that two lemmas depend on each other for their statements, for example, if you prove that some set is nonempty and then prove something about its maximum.</p>",
        "id": 210243483,
        "sender_full_name": "Reid Barton",
        "timestamp": 1600251946
    },
    {
        "content": "<p>So computers making any kind of observations which humans could independently verify as \"progress\" would be of interest to the maths community.</p>",
        "id": 210243569,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600251984
    },
    {
        "content": "<p>Let me right now make a broad and over-general criticism of the ML papers I look at which are claiming to do mathematics. They might say \"OK so we took a bunch of topology lemmas in Mizar, and then we fed them into our prover, and it completely solved 37% of them and made partial progress on another 37%\"</p>",
        "id": 210243741,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600252085
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110032\">@Reid Barton</span> is that the current plan for the IMO GC?</p>",
        "id": 210243752,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600252097
    },
    {
        "content": "<p>and in my experience it is <em>extremely</em> rare that they give explicit examples of things they achieved.</p>",
        "id": 210243788,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600252122
    },
    {
        "content": "<p>This is one trap which the metamath paper did not fall into, because there it says \"here is a proof we found which is better than the proof in the metamath library\"</p>",
        "id": 210243829,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600252160
    },
    {
        "content": "<p>Yes completely agreed with that. But to be fair we're all lacking a meaningful benchmark we can use to do research</p>",
        "id": 210243831,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600252164
    },
    {
        "content": "<p>I see</p>",
        "id": 210243840,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600252171
    },
    {
        "content": "<p>As a mathematician I find these papers which just say 37% extremely difficult to judge, because it is extremely rare to see explicit examples of achievements -- the ML people just regard the dataset as a dataset and I suspect many researchers do not really ever look at it in some sense.</p>",
        "id": 210243935,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600252222
    },
    {
        "content": "<p>Yes</p>",
        "id": 210243963,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600252244
    },
    {
        "content": "<p>When I talk to Urban about what is going on under the hood, my impression is that in some of these papers you put your 50 lemmas into some kind of order, and then each lemma you make a note of which of the earlier lemmas were used to prove it</p>",
        "id": 210243976,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600252259
    },
    {
        "content": "<p>and then you tell your prover to go and re-prove them but you also might tell it which of the previous lemmas to use, for example.</p>",
        "id": 210243994,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600252280
    },
    {
        "content": "<p>I agree with everything Kevin and Reid wrote. In particular I like the IMO challenge idea but Kevin is right to point out that a lot of mathematicians (maybe 99%) have no IMO skill at all.</p>",
        "id": 210244030,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1600252308
    },
    {
        "content": "<p>And then 37% could be interpreted as a very poor return on this</p>",
        "id": 210244034,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600252309
    },
    {
        "content": "<p>And then when you actually do look at some of the things they proved, maybe they proved a trivial corollary to a theorem; maybe in fact 37% of the results in the database were each a trivial corollary of the lemma before; this is often what a formalised database can look like.</p>",
        "id": 210244165,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600252390
    },
    {
        "content": "<p>This is what I see when I read ML papers and these are not results I can sell to my community.</p>",
        "id": 210244186,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600252415
    },
    {
        "content": "<p>There is this team in Oxford trying to compute invariants of mathematical objects and they say things like \"we predicted the rank of 80% of the elliptic curves in this database\"</p>",
        "id": 210244252,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600252454
    },
    {
        "content": "<p>Very aligned and in complete agreement with that.</p>",
        "id": 210244256,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600252464
    },
    {
        "content": "<p>but I have an algorithm which will accurately compute the rank of 99% of elliptic curves in any reasonable database.</p>",
        "id": 210244266,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600252477
    },
    {
        "content": "<p>1) Compute the root number 2) Assume the Birch and Swinnerton-Dyer conjecture 3) if the root number is odd, output \"1\" and if it's even output \"0\"</p>",
        "id": 210244301,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600252514
    },
    {
        "content": "<p>It's the same fallacy as the AI which can predict with 80% certainty whether you are straight or gay from a photo of your face. I can beat that by predicting \"straight\" in all cases.</p>",
        "id": 210244334,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600252553
    },
    {
        "content": "<p>I'm not attempting to be accurate, I'm just attempting to play the odds.</p>",
        "id": 210244380,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600252567
    },
    {
        "content": "<p>So I believe we all agree that there is urgency for a benchmark to emerge against which ML researcher can do research, and designed such that progress on that benchmark is regarded as progress by the math community.</p>",
        "id": 210244393,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600252585
    },
    {
        "content": "<p>What could an IMO benchmark look like?</p>",
        "id": 210244406,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600252602
    },
    {
        "content": "<p>Or more generally an Olympiad benchmark?</p>",
        "id": 210244416,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600252613
    },
    {
        "content": "<p>I think <span class=\"user-mention\" data-user-id=\"110032\">@Reid Barton</span> 's suggestion is good</p>",
        "id": 210244421,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600252617
    },
    {
        "content": "<p>(because for each IMO there are 100 other Olympiad questions, probably publically available, e.g. the British Maths Olympiad has two rounds, and easier questions; it is used as training for the UK IMO team)</p>",
        "id": 210244452,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600252653
    },
    {
        "content": "<p>Statement of exercises + statements of definitions and lemmas required to solve the exercise, in such a way that if a system closes a large number of lemmas a mathematician would say, ok it didn't go all the way to solving the exercise but these lemmas were non trivial and interesting to demonstrate</p>",
        "id": 210244513,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600252685
    },
    {
        "content": "<p>eventually as success rate on lemmas increase and we close more and more exercise we can start masking the intermediary lemmas and report progress</p>",
        "id": 210244535,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600252711
    },
    {
        "content": "<p>and is the idea that you feed the solver the intermediate lemmas, or hope it isolates them?</p>",
        "id": 210244541,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600252715
    },
    {
        "content": "<p>I think the step 0 is attack the lemmas independently</p>",
        "id": 210244551,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600252730
    },
    {
        "content": "<p>then we can condition on the lemmas to solve exercises, and progressively remove them</p>",
        "id": 210244572,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600252753
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"230999\">@Daniel Selsam</span> was talking about these choice points. In an ideal world the computer would sometimes isolate some simpler statement and ask whether it was worth attacking</p>",
        "id": 210244577,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600252756
    },
    {
        "content": "<p>Some IMO problems are just a \"one trick\" thing -- e.g. \"colour the points in the following way and now observe it's easy\"</p>",
        "id": 210244596,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600252790
    },
    {
        "content": "<p>Right but we dive into design/system decisions already here. I think we need something that is applicable to humans as well.</p>\n<p>I'm a beginner I'm lost, but I see some lemmas I can solve so I start with them. Then I get really good at solving these lemmas. Eventually I close all proofs with lemmas, and in the end I don't need the lemmas anymore.</p>",
        "id": 210244702,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600252868
    },
    {
        "content": "<p>In some instances indeed the lemma might divulge the trick but if the lemma is not so trivial to prove itself we already demonstrate capability?</p>",
        "id": 210244732,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600252891
    },
    {
        "content": "<p>These intermediary lemmas serve as both hints and technical mini challenges on which we can make progress.</p>",
        "id": 210244856,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600252986
    },
    {
        "content": "<p>The latter is how they will be used first, the former is how they will be used later on and eventually they won't be needed anymore.</p>",
        "id": 210244878,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600253011
    },
    {
        "content": "<p>Arguably, this representation is already how someone would formalize an IMO problem today. I argue here that we don't need the full proof to have a benchmark that is useful and productive; just formalizing the statements would already go a very long way.</p>",
        "id": 210245315,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600253337
    },
    {
        "content": "<p>There’s some additional challenges for it to be cross-system: some IMO problems may be easily formalizable in one system but not the other, due to the different states of development  of a particular theory required along the way</p>",
        "id": 210245719,
        "sender_full_name": "Minchao Wu",
        "timestamp": 1600253655
    },
    {
        "content": "<p>We don’t know what exactly these problems are, though, until we actually try to formalize them</p>",
        "id": 210245913,
        "sender_full_name": "Minchao Wu",
        "timestamp": 1600253818
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"249373\">Stanislas Polu</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/AITP.202020/near/210243752\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"110032\">Reid Barton</span> is that the current plan for the IMO GC?</p>\n</blockquote>\n<p>These are just my own thoughts on your question of what an intermediate vesrion of the IMO GC goal might look like. However, since we already have a small collection of olympiad problem and solution formalizations, it should be fairly easy to try to produce a small data set along these lines, and see whether there are any immediate roadblocks.</p>",
        "id": 210246484,
        "sender_full_name": "Reid Barton",
        "timestamp": 1600254299
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110187\">@Minchao Wu</span>  Starting with very simple problems alleviate that challenge, but does not fit the bill of making mathematicians turn their heads.  I'm pretty sure most systems out there are still incapable of solving the most trivial inequalities if they are even remotely obfuscated (such as say, <code>a*(a-2) &lt;= 1</code> or <code>a^2 + b^2 = 1 =&gt; a*b + a-b &lt;= 1</code>). I think we have to acknowledge that and create an environment that foster rapid progress towards the grand challenge; that's why I was proposing a very easy benchmark to begin with, and given the discussion still believe that would be valuable as a prelude to a benchmark that would align with the objective of updating mathematicians perspective on formal systems.</p>",
        "id": 210246591,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600254365
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110032\">@Reid Barton</span> yep totally true. Do we have others like this one: <a href=\"https://github.com/jsm28/bmo2-2020-lean\">https://github.com/jsm28/bmo2-2020-lean</a> ?</p>",
        "id": 210246633,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600254399
    },
    {
        "content": "<p>There's also <a href=\"https://github.com/leanprover-community/mathlib/blob/master/archive/imo1988_q6.lean\">https://github.com/leanprover-community/mathlib/blob/master/archive/imo1988_q6.lean</a> and I know some other IMO problems like 2018/5, 2019/1, 2019/4 have been formalized, but perhaps those have not been collected anywhere.</p>",
        "id": 210246939,
        "sender_full_name": "Reid Barton",
        "timestamp": 1600254624
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"249373\">Stanislas Polu</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/AITP.202020/near/210246591\">said</a>:</p>\n<blockquote>\n<p>that's why I was proposing a very easy benchmark to begin with, and given the discussion still believe that would be valuable as a prelude to a benchmark that would align with the objective of updating mathematicians perspective on formal systems.</p>\n</blockquote>\n<p>Totally agreed here</p>",
        "id": 210247015,
        "sender_full_name": "Minchao Wu",
        "timestamp": 1600254698
    },
    {
        "content": "<p>But it might be better to start from natural-language solutions (e.g. the official solutions) and try to translate them as faithfully as possible into formalized versions, rather than work from solutions that are already formalized and maybe as a result fit to the particular prover/library.</p>",
        "id": 210247026,
        "sender_full_name": "Reid Barton",
        "timestamp": 1600254713
    },
    {
        "content": "<p>Getting an AI to prove 1988q6 would be pretty sick. It's one the most famous IMO problems for being impenetrable.</p>",
        "id": 210247128,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1600254777
    },
    {
        "content": "<p>Regarding Kevin's points, I agree it's hard to understand the real significance of proving 37% of the results in the Mizar standard library, even for someone who is in the area of formalizing mathematics.<br>\nBut as far as reception in the broader mathematical community is concerned: my conjecture is that there's no technical achievement feasible in the next couple of years that would really force the generic mathematician to sit up and pay attention. It's just too easy for them to move the goalposts and say that what has been achieved was easy--an effect that must be familiar to AI researchers. Even if we solve the IMO GC, while many mathematicians will surely be excited, there will be others who say: \"I was never any good at IMO problems anyways, so what could they have to do with <em>real</em> mathematics?\"<br>\nSo, as much as I think advocacy efforts like Kevin's are important, and while it might make Kevin's work more difficult, I feel we should not optimize too much for what we could \"sell\" to mathematicians in general, at least at the moment.</p>",
        "id": 210250034,
        "sender_full_name": "Reid Barton",
        "timestamp": 1600256990
    },
    {
        "content": "<p>I'm reminded of a story that Kevin tells in which he met some famous mathematician at a conference and told the mathematician about how he had been working on formalizing mathematics in Lean or whatever, and the mathematician's first question was: \"Can computers tell us anything new?\"<br>\nWell your undergrads can't tell you anything new, can they? But you still teach them Galois theory anyways.<br>\nWhy not teach a computer Galois theory, and problem-solving strategies, and so on?</p>",
        "id": 210250170,
        "sender_full_name": "Reid Barton",
        "timestamp": 1600257114
    },
    {
        "content": "<p>(Poor undergrads <span aria-label=\"laughing\" class=\"emoji emoji-1f606\" role=\"img\" title=\"laughing\">:laughing:</span>)</p>",
        "id": 210250377,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600257246
    },
    {
        "content": "<p>I think what we should focus on is a benchmark that would make people like you, or kevin update their perspective on what these systems can do.</p>",
        "id": 210250448,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600257316
    },
    {
        "content": "<p>By the way, I really like the example problem of this <a href=\"https://dselsam.github.io/posts/2018-06-24-mathematics-our-overlooked-ability.html\">post</a> by <span class=\"user-mention\" data-user-id=\"230999\">@Daniel Selsam</span> as an example of why filling in \"obvious\" steps in proofs can be a lot harder than it might seem (though I suspect he would be more optimistic about our prospects of solving problems like this today <span aria-label=\"upside down\" class=\"emoji emoji-1f643\" role=\"img\" title=\"upside down\">:upside_down:</span>)</p>",
        "id": 210252001,
        "sender_full_name": "Reid Barton",
        "timestamp": 1600258340
    },
    {
        "content": "<p>It was Bryan Birch who asked me if they could tell us anything new</p>",
        "id": 210252174,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600258451
    },
    {
        "content": "<p>It was his first and only question about my new endeavour</p>",
        "id": 210252195,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600258472
    },
    {
        "content": "<p>We were at Swinnerton-Dyers memorial service. Birch and Swinnerton-Dyer used an early computer to compute a bunch of solutions to cubic equations modulo lots of small primes in the 1960s and then made a conjecture which caught on</p>",
        "id": 210252373,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600258585
    },
    {
        "content": "<p>I agree that there are really two advocacy efforts that are fairly disjoint.  One is to convince mathematicians that formalization is of value.  Like Reid said above, I don't think much in the way of technical feats are going to help in the short turn, not until we come up a way to actually help mathematicians solve more new problems in such a way that it builds understanding and theory, which is still down the road in my opinion.  </p>\n<p>The other advocacy is convincing ITP users like Kevin and ITP designers like Leo that ML methods will make a tangible difference in their systems.  Benchmarks are just numbers which can be gamed in a number of different ways.  I think the most important step is to put useable ML-backed tools in the hands of users like Kevin and see if they are useful.  I like what <span class=\"user-mention\" data-user-id=\"306713\">@Lasse</span>, for example, is doing with Tactician, where he uses older-but-more-CPU-capable ML techniques to create a system which can be integrated with Coq and is testing it on Coq users.  Also <span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span> making a MetaMath assistant website which can suggest next steps.  We really need to convince, say, Kevin that ML is the next <code>sledgehammer</code> and the next <code>library_search</code>, and find ways to integrate it into systems like Lean.</p>",
        "id": 210254452,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600259706
    },
    {
        "content": "<p>Completely tangeant, I thiiink that would be a <img alt=\":metamath:\" class=\"emoji\" src=\"https://zulip-avatars.s3.amazonaws.com/3121/emoji/images/17589.gif\" title=\"metamath\"> formalization of Daniel's post's problem.<br>\n<a href=\"/user_uploads/3121/7oJNjUHmmxdqDUlQAjm0BpMI/Screen-Shot-2020-09-16-at-15.12.14.png\">Screen-Shot-2020-09-16-at-15.12.14.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/3121/7oJNjUHmmxdqDUlQAjm0BpMI/Screen-Shot-2020-09-16-at-15.12.14.png\" title=\"Screen-Shot-2020-09-16-at-15.12.14.png\"><img src=\"/user_uploads/3121/7oJNjUHmmxdqDUlQAjm0BpMI/Screen-Shot-2020-09-16-at-15.12.14.png\"></a></div>",
        "id": 210258971,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600262032
    },
    {
        "content": "<p>Generated by GPT-f?</p>",
        "id": 210259055,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1600262055
    },
    {
        "content": "<p>Haha, no, mysefl, you would have to ask Szegedy for an autoformalization system :D</p>",
        "id": 210259140,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600262098
    },
    {
        "content": "<p>Note that you cheated... you recognized that <code>13 = 12 + 1</code> and <code>25 = 2 * 12 + 1</code>. That's an important step, I think.</p>",
        "id": 210259187,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1600262124
    },
    {
        "content": "<p>(For an AI, at least.)</p>",
        "id": 210259213,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1600262142
    },
    {
        "content": "<p>True that, and also made an error doing so, should be K + 1 on the last hypothesis</p>",
        "id": 210259357,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600262200
    },
    {
        "content": "<p>I wanted to go for a general lemma to prevent brute force enumeration</p>",
        "id": 210259591,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600262326
    },
    {
        "content": "<p>For those of you who saw Dan's talk on the IMO Grand Challenge yesterday and would like to learn more, I have a blog post where I discuss the <code>SearchT</code> monad transformer, ARC, and our work on building an IMO geometry solver: <a href=\"https://jesse-michael-han.github.io/blog/imo-gc-geo/\">https://jesse-michael-han.github.io/blog/imo-gc-geo/</a></p>",
        "id": 210260390,
        "sender_full_name": "Jesse Michael Han",
        "timestamp": 1600262732
    },
    {
        "content": "<p>What I like so much about this problem is: how did you know the right generalization was to a string of length <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>2</mn><mi>n</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">2n+1</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">2</span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> containing <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">n+1</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:0.66666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> 'a's unless you already knew roughly how the argument should go?</p>",
        "id": 210261228,
        "sender_full_name": "Reid Barton",
        "timestamp": 1600263105
    },
    {
        "content": "<p>Or is it that we can guess a relationship between 25 and 13 and this guides our search for a proof?</p>",
        "id": 210261395,
        "sender_full_name": "Reid Barton",
        "timestamp": 1600263155
    },
    {
        "content": "<p>There's a lot to unpack in this little step.</p>",
        "id": 210261404,
        "sender_full_name": "Reid Barton",
        "timestamp": 1600263162
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110031\">Patrick Massot</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/AITP.202020/near/210244030\">said</a>:</p>\n<blockquote>\n<p>I agree with everything Kevin and Reid wrote. In particular I like the IMO challenge idea but Kevin is right to point out that a lot of mathematicians (maybe 99%) have no IMO skill at all.</p>\n</blockquote>\n<p>Might these mathematicians be even more appreciative of an automatic \"puzzle\"-solving assistant?</p>",
        "id": 210264976,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1600264652
    },
    {
        "content": "<p>They might think that it is <em>cute</em>.</p>",
        "id": 210268394,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1600266046
    },
    {
        "content": "<p>Until computers start proving lemmas that they need in their daily work, but for which they don't see immediately what the proof is.... they will probably not care too much.</p>",
        "id": 210268542,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1600266113
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/AITP.202020/near/210243829\">said</a>:</p>\n<blockquote>\n<p>This is one trap which the metamath paper did not fall into, because there it says \"here is a proof we found which is better than the proof in the metamath library\"</p>\n</blockquote>\n<p>But even here, how many people looked into the simpler proofs they found, and the existing minimization tools that didn't find them? Here is the first one I looked at: <a href=\"http://us.metamath.org/mpegif/ndmima.html\">http://us.metamath.org/mpegif/ndmima.html</a></p>\n<p>Abstractly, the proof is just the trivial two-step proof that:</p>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"n\">P</span> <span class=\"n\">x</span> <span class=\"n\">y</span>\n<span class=\"n\">P</span> <span class=\"n\">x</span> <span class=\"n\">y</span> <span class=\"bp\">&lt;-&gt;</span> <span class=\"n\">Q</span> <span class=\"n\">x</span> <span class=\"n\">y</span>\n<span class=\"n\">Q</span> <span class=\"n\">x</span> <span class=\"n\">y</span> <span class=\"bp\">&lt;-&gt;</span> <span class=\"n\">R</span> <span class=\"n\">x</span> <span class=\"n\">y</span>\n<span class=\"bp\">|-</span> <span class=\"n\">R</span> <span class=\"n\">x</span> <span class=\"n\">y</span>\n</code></pre></div>\n\n\n<p>There are only a few thousand lemmas in the environment at the time and chances are only a few of them unify with the goal, so it seems the simplest possible back-chaining baseline would find this proof in a few milliseconds. As far as I can tell, the only reason the original manual proof was longer is that it was written in 1998 and the lemma <code>P x y &lt;-&gt; Q x y</code> was not added until 2007.</p>\n<p><a href=\"http://us.metamath.org/mpegif/ndmimaOLD.html\">http://us.metamath.org/mpegif/ndmimaOLD.html</a><br>\n<a href=\"http://us.metamath.org/mpegif/imadisj.html\">http://us.metamath.org/mpegif/imadisj.html</a></p>\n<p>Not all of the simplified proofs look this trivial, but clearly the existing minimization tools do not constitute a strong baseline. I still find the work very difficult to assess in its current state.</p>",
        "id": 210269578,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1600266518
    },
    {
        "content": "<p>I agree that it is probably possible to accomplish what OpenAI did in metamath with a simpler / less computationally intensive framework. But to me the important fact is that they did it, they actually built a system and contributed things to a formal library and now OpenAI is credited to a set of theorems quite respectable for a human contributor</p>",
        "id": 210269986,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1600266692
    },
    {
        "content": "<p>yes, it's easy to look at the problems post hoc and say \"that's easy\" but isn't all math like that?</p>",
        "id": 210270139,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1600266744
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/AITP.202020/near/210269986\">said</a>:</p>\n<blockquote>\n<p>But to me the important fact is that they did it, they actually built a system and contributed things to a formal library and now OpenAI is credited to a set of theorems quite respectable for a human contributor</p>\n</blockquote>\n<p>I agree, this part is great.</p>",
        "id": 210270339,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1600266827
    },
    {
        "content": "<p>I'm not an ML researcher so I can't make any observations regarding what GPT-f means in terms of technical theorem proving ability, but it looks like a step forward in terms of ML/ITP interaction</p>",
        "id": 210270480,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1600266872
    },
    {
        "content": "<p>We only need a solid Lean - MM0 interface, and GPT-f0.<br>\nThen we're all set (-;</p>",
        "id": 210270565,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1600266909
    },
    {
        "content": "<p>:P</p>",
        "id": 210270683,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1600266951
    },
    {
        "content": "<p>I have a question about geometry in the IMO challenge that neither watching the talk nor skimming through the blog post answers. Do you actually have Lean code formalizing geometry problem? Did you formalize Euclidean geometry in Lean 4?</p>",
        "id": 210270846,
        "sender_full_name": "Patrick Massot",
        "timestamp": 1600266998
    },
    {
        "content": "<p>This thread is largely about how to measure incremental progress, with solving IMO problems as one of the long term goals. My point was only that finding simpler proofs to theorems in a large corpora is not an ideal metric, especially in the absence of ablations.</p>",
        "id": 210271001,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1600267064
    },
    {
        "content": "<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"112680\">Johan Commelin</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/AITP.202020/near/210268542\">said</a>:</p>\n<p>Until computers start proving lemmas that they need in their daily work, but for which they don't see immediately what the proof is.... they will probably not care too much.</p>\n</blockquote>\n<p>Yes, I meant that, assuming IMO-style \"puzzles\" do arise in mathematical work periodically, the mathematicians who are less interested in or skilled at puzzle-solving may derive the greatest utility from a (hypothetical) automatic puzzle-solving assistant.</p>",
        "id": 210271964,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1600267411
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/AITP.202020/near/210270139\">said</a>:</p>\n<blockquote>\n<p>yes, it's easy to look at the problems post hoc and say \"that's easy\" but isn't all math like that?</p>\n</blockquote>\n<p>When we were looking at formalising a whole bunch of things about localisations using only the universal property, it looked pretty daunting. Then Strickland came along and pointed out that <code>f : R -&gt; A</code> was a localisation at <code>S</code> iff (three simple-to-write conditions on <code>f</code> which involved no quantification over all R-algebras) and this was a crucial step. I explain this observation, which unblocked schemes II, in talks in seminars sometimes and I always say \"Proof: trivial\". Because it is -- the hard part was isolating the key basic API.</p>",
        "id": 210287396,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600273974
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span> <span class=\"user-mention\" data-user-id=\"110032\">@Reid Barton</span> </p>\n<p>I agree it would be great to have easier milestones along the way, though I feel very strongly that even for these easier milestones, systems must be checksummed before the problem statements are known. How about this as a starting point:</p>\n<p>Every year, before the IMO shortlist is made public, we have a deadline for submitting system checksums. Then, once the shortlist is released, systems can be evaluated on several relaxations of the problems, for example:</p>\n<ul>\n<li>the original problems</li>\n<li>the desired theorem statements to <em>determine</em> problems</li>\n<li>the original problems, where all terms that are used in the official solution are provided</li>\n<li>all intermediate steps of each problem used in the official solution</li>\n<li>various interpolations thereof (e.g. some intermediate steps there, some removed)</li>\n</ul>\n<p>Thoughts?</p>",
        "id": 210287969,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1600274250
    },
    {
        "content": "<p>what do you mean by checksumming here?</p>",
        "id": 210289369,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1600274950
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/AITP.202020/near/210289369\">said</a>:</p>\n<blockquote>\n<p>what do you mean by checksumming here?</p>\n</blockquote>\n<p>Think of it like a hash of the system. Suppose I release a checksum before the problems are released, and then once they are released, I claim my system solves them and I make the system available.  A third party can now run the system, confirm that it solves the problems, and also compare the checksum they compute for the system with the submitted checksum to confirm that it is indeed the exact system as it existed before the problems were released. However, I am not suggesting this approach specifically -- I used \"checksummed\" broadly to mean some way of proving the artifact was finalized before the problems were released.</p>\n<p>Ideally, teams directly submit Docker images before the problems are released, and then we just run them all on Azure once the problems are released. We could give every team an initial gratis resource budget (say $100 Azure dollars per submission) and teams whose systems require more resources could pay extra accordingly.</p>",
        "id": 210291774,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1600276181
    },
    {
        "content": "<p>Note: I am okay with teams hiding arbitrary expenditures during the training process, and I am also not inclined to impose cost restrictions on test-time execution, but I think it is important that the cost of running the system at test time at least be transparent.</p>",
        "id": 210292508,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1600276532
    },
    {
        "content": "<p>Also, although I said \"team\", I want to stress that I see the IMO-GC as first and foremost a community collaboration, not a competition. It is great if some group introduces some special sauce at the end to cross the finish line, but I think all plausible approaches will need to be built on top of the community formalization effort. As I stressed in my talk, I don't see formalizing and compressing historical proofs as merely producing \"training data\"; I see it as effectively building the solver itself.</p>",
        "id": 210293562,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1600277011
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"230999\">Daniel Selsam</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/AITP.202020/near/210287969\">said</a>:</p>\n<blockquote>\n<ul>\n<li>the desired theorem statements to <em>determine</em> problems</li>\n</ul>\n</blockquote>\n<p>Not sure I understand this. What do you mean by that ?</p>\n<blockquote>\n<p>Thoughts?</p>\n</blockquote>\n<p>That seems like a great way to proceed, especially as this will produce a continuous yearly stream of problems against which we can benchmark ourselves as a community.</p>",
        "id": 210294731,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1600277519
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"249373\">Stanislas Polu</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/AITP.202020/near/210294731\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"230999\">Daniel Selsam</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/AITP.202020/near/210287969\">said</a>:</p>\n<blockquote>\n<ul>\n<li>the desired theorem statements to <em>determine</em> problems</li>\n</ul>\n</blockquote>\n<p>Not sure I understand this. What do you mean by that ?</p>\n</blockquote>\n<p>The issue is explained at <a href=\"https://github.com/IMO-grand-challenge/formal-encoding/blob/master/design/determine.lean\">https://github.com/IMO-grand-challenge/formal-encoding/blob/master/design/determine.lean</a></p>",
        "id": 210295166,
        "sender_full_name": "Daniel Selsam",
        "timestamp": 1600277721
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/AITP.202020/near/210240115\">said</a>:</p>\n<blockquote>\n<p>There is a huge source of Olympiad problems available, and Lean is getting to the point where it can understand pretty much all of them, with Joseph Myers' recent work on affine geometry enabling formalisations of problems involving e.g. circles, triangles etc (indeed Joseph just finished formalising all the solutions to this year's British Maths Olympiad round 1). </p>\n<p>I run a formalizing club at Imperial and I also run a puzzle-solving club where we work on Olympiad problems; when it all starts up again in October I could see if I could get the puzzle-solvers formalising olympiad questions.</p>\n</blockquote>\n<p>Actually it was round 2 (easier problems sometimes seem harder to come up with a good formal statement of, because more of the difficulty for the human contestants is in understanding the problem and translating the words into maths, rather than in what goes into the formal proof - though BMO1 is generally hard enough that shouldn't be an issue, even if sometimes there are problems that can be solved by <code>norm_num</code>). But the geometry problem on the most recent BMO round 1 can't be stated until we define \"tangent\", and what it means for a point to be outside a triangle.</p>",
        "id": 210310909,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1600285562
    },
    {
        "content": "<p>Neither of the geometry problems from IMO 2019 can yet be stated cleanly. Problem 2 for fairly trivial reasons: we need to define \"between\" and \"concyclic\". (I have a definition of <code>cospherical</code>, and some basic lemmas for that, ready to PR once <a href=\"https://github.com/leanprover-community/mathlib/issues/4127\">#4127</a> is in; \"concyclic\" is them cospherical plus coplanar.) Problem 6 will need a bit more (incircle plus tangency). Exercise for readers who haven't seen the IMO 2019 shortlist (which becomes public next week): how many of the eight geometry problems on it do you guess could be stated naturally in the current state of mathlib (without needing to work around the lack of definitions that belong in mathlib but aren't there yet)?</p>",
        "id": 210311855,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1600286007
    },
    {
        "content": "<p>A few more comments for people thinking of formalising olympiad problems. (a) Any definitions and lemmas plausibly useful in mathlib should be added there rather than just left as part of the statement of or solution to an individual problem. (b) There are lots of choices to make about how to state a problem, not just about how to solve it, and it may be worth thinking about the relative merits of different styles of formal problem statements. E.g. in my formal statements, I tended to separate out the different pieces of the problem statement into separate <code>def</code>s (convenient for then proving lemmas about those <code>def</code>s separately) which then get combined into the problem statement, whereas the examples in the IMO Grand Challenge repository tend to go for the approach of putting the whole thing in a single very long <code>def</code>. How much should subtypes versus separate hypotheses be used when a statement involves e.g. positive integers? How much should the formal statements avoid depending on things such as <code>nat</code> subtraction or division that deviate from mathematical conventions, to ensure the formal statement means something as close as possible to the informal statement? How close should combinatorial geometry statements be to the geometrical formulation (take IMO 2018 problem 4 as an example; the shortlist version was clearly purely combinatorial, the final IMO wording ended up with the geometrical statement involving <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msqrt><mn>5</mn></msqrt></mrow><annotation encoding=\"application/x-tex\">\\sqrt{5}</annotation></semantics></math></span><span aria-hidden=\"true\" class=\"katex-html\"><span class=\"base\"><span class=\"strut\" style=\"height:1.04em;vertical-align:-0.13278em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.90722em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\">5</span></span></span><span style=\"top:-2.86722em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg height=\"1.08em\" preserveAspectRatio=\"xMinYMin slice\" viewBox=\"0 0 400000 1080\" width=\"400em\"><path d=\"M95,702 c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14 c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54 c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10 s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429 c69,-144,104.5,-217.7,106.5,-221 l0 -0 c5.3,-9.3,12,-14,20,-14 H400000v40H845.2724 s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7 c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z M834 80h400000v40h-400000z\"></path></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.13278em;\"><span></span></span></span></span></span></span></span></span> because one leader noted their students wouldn't be familiar with chess)? (c) This is clearly an area where it makes sense to formalise multiple different solutions to the same problem. (In the IMO 2019 shortlist I encouraged the inclusion of lots of alternative solutions.)</p>",
        "id": 210316573,
        "sender_full_name": "Joseph Myers",
        "timestamp": 1600288265
    },
    {
        "content": "<p>To do something useful for mathematical scientists, one could try to take an existing systematic proof method which is very laborious to use, and make it easier to use.   An example I have thought about is interval arithmetic, which is used as part of  many computer-assisted proofs in ODE and PDE.  In some sense one is dividing the problem into cases and proving bounds, but the computer can handle millions of cases.  Some mathematicians find this interesting and useful, see for example <a href=\"https://aimath.org/workshops/upcoming/compproofs/\">https://aimath.org/workshops/upcoming/compproofs/</a> .<br>\nIt is a lot of work to set up such computations and a lot of work to turn the results into a rigorous proof - see Fabian Immler's thesis<br>\n<a href=\"https://europepmc.org/articles/PMC6044317/\">https://europepmc.org/articles/PMC6044317/</a> for one of the few (only?) cases where this was done using a theorem prover.<br>\nThere are a lot of similar dynamical systems problems and even more PDE problems, so systematizing this would produce a lot of new proofs.</p>",
        "id": 210322150,
        "sender_full_name": "Michael R Douglas",
        "timestamp": 1600291355
    },
    {
        "content": "<p>related: <a href=\"http://www.crm.math.ca/camp-nonlinear/#videos\">http://www.crm.math.ca/camp-nonlinear/#videos</a> computer-assisted mathematical proofs in nonlinear anlysis</p>",
        "id": 210338449,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1600305181
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/AITP.202020/near/210208698\">said</a>:</p>\n<blockquote>\n<p>Also, speaking of tree search, has anyone else noticed that tactic-based proving is a two-player zero-sum game?  Player A chooses the tactics.  Player B chooses one subgoal to work on.  If Player A has a perfect strategy the theorem is provable.  If Player B does, the theorem is not provable.  I think this could speed up RL for theorem proving (since one doesn't have to explore all subgoals to get meaningful policy and value updates).  It also probably means that maybe we should start on the hardest subgoal instead of the first subgoal (or the easiest subgoal).  Anyway, food for thought...</p>\n</blockquote>\n<p>Holophrasm (also for Metamath) <a href=\"https://arxiv.org/abs/1608.02644\">https://arxiv.org/abs/1608.02644</a> has red and blue nodes; your player A selects action at red nodes and B at blue nodes. It uses UCT. \"At a red node, the traversal proceeds to the highest valuation child blue node. At a blue node, the traversal proceeds to the worst-performing child.\" So it's sort of adversarial, though not explicitly stated as a two-player zero-sum game.</p>",
        "id": 210339070,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1600305965
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110038\">Kevin Buzzard</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/AITP.202020/near/210244252\">said</a>:</p>\n<blockquote>\n<p>There is this team in Oxford trying to compute invariants of mathematical objects and they say things like \"we predicted the rank of 80% of the elliptic curves in this database\"</p>\n</blockquote>\n<p>Don't you find such work interesting? \"Deep Learning Gauss--Manin connections\", <a href=\"https://arxiv.org/abs/2007.13786\">https://arxiv.org/abs/2007.13786</a>, involving students of John Voight and Gerard van der Geer.<br>\nAnd is this speaker a member of the Oxford team? <a href=\"http://www.physicsmeetsml.org/posts/sem_2020_07_15/\">http://www.physicsmeetsml.org/posts/sem_2020_07_15/</a> (String data and machine learning, by Andre Lukas) Apparently elliptic curves aren't their main focus.</p>",
        "id": 210341272,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1600308812
    },
    {
        "content": "<p>My experience with this quintic threefold / elliptic curve work is that when I saw a talk about it I had some questions about trying to make sense of the results and the speaker was not able to answer them because they said they never looked at the data, they were just reporting the percentages, so I found it very hard to judge.</p>\n<p>I would revisit this but I am in work hell at the minute with a ton of undergraduate videos to make so need to focus on this for the next three weeks.</p>",
        "id": 210353017,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600324941
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"224323\">@Junyan Xu</span>  I've now found the time to look at the Gauss--Manin work and I find it much more impressive. They explain what they're doing and are not just treating it all as a push-button technique. They give tables of ranks of Picard groups which make it clear that the answer is not \"96% of them are 0\" (this is my general fear in this area).</p>",
        "id": 210360836,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1600331082
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/AITP.202020/near/210269986\">said</a>:</p>\n<blockquote>\n<p>I agree that it is probably possible to accomplish what OpenAI did in metamath with a simpler / less computationally intensive framework. But to me the important fact is that they did it, they actually built a system and contributed things to a formal library and now OpenAI is credited to a set of theorems quite respectable for a human contributor</p>\n</blockquote>\n<p>Actually <span class=\"user-mention\" data-user-id=\"342506\">@Thibault Gauthier</span> 's <code>TacticToe</code> has also contributed proofs to <code>HOL4</code> library:<br>\n<a href=\"https://github.com/HOL-Theorem-Prover/HOL/commit/8990db3c7743feb190d98f4bce666d3163022557\">https://github.com/HOL-Theorem-Prover/HOL/commit/8990db3c7743feb190d98f4bce666d3163022557</a><br>\nBut since <code>TacticToe</code> is not deep learning based, OpenAI's claim (i.e., the first time a deep-learning based system has contributed proofs that were adopted by a formal mathematics community) is still legit.</p>",
        "id": 210472221,
        "sender_full_name": "Minchao Wu",
        "timestamp": 1600394557
    },
    {
        "content": "<p>It looks like the videos and (some of) the slides are posted.  <a href=\"http://aitp-conference.org/2020/\">http://aitp-conference.org/2020/</a></p>",
        "id": 210737890,
        "sender_full_name": "Jason Rute",
        "timestamp": 1600693653
    },
    {
        "content": "<p>It seems that the slides of my talk is not correctly linked. Here it is: <a href=\"https://minchaowu.github.io/assets/pdf/aitp2020talk.pdf\">https://minchaowu.github.io/assets/pdf/aitp2020talk.pdf</a></p>",
        "id": 210754445,
        "sender_full_name": "Minchao Wu",
        "timestamp": 1600700739
    }
]