[
    {
        "content": "<p>Someone pointed me to this paper posted on arXiv:<br>\n<a href=\"https://arxiv.org/abs/2112.15594\">https://arxiv.org/abs/2112.15594</a><br>\nThe abstract begins: \"We demonstrate that a neural network pre-trained on text and fine-tuned on code solves Mathematics problems by program synthesis.\" It ends: \"This is the first work to automatically solve, grade, and generate university-level Mathematics course questions at scale. This represents a milestone for higher education.\"<br>\nI haven't read it yet.</p>",
        "id": 267306286,
        "sender_full_name": "Jeremy Avigad",
        "timestamp": 1641663148
    },
    {
        "content": "<p>Comments:   128 pages, 250 tables</p>",
        "id": 267306565,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1641663545
    },
    {
        "content": "<p>Reddit discussion about the paper: <a href=\"https://www.reddit.com/r/MachineLearning/comments/rutbpv/r_a_neural_network_solves_and_generates/\">https://www.reddit.com/r/MachineLearning/comments/rutbpv/r_a_neural_network_solves_and_generates/</a> .</p>",
        "id": 267306818,
        "sender_full_name": "Zygimantas Straznickas",
        "timestamp": 1641663951
    },
    {
        "content": "<p>It’s really only 8 pages with a really long appendix made up of what looks like example math problems.</p>",
        "id": 267308073,
        "sender_full_name": "Jason Rute",
        "timestamp": 1641665582
    },
    {
        "content": "<p>They used Codex to translate math problems (maybe heavy prompt engineering here, they didn't fine-tune the model) into Python code and executed the code to get the answers. <br>\n(Background: One can hint Codex with some descriptions or docs of a function, and let it generate the function that satisfies the descriptions.) <br>\nHere the descriptions happens to be the math problems itself.<br>\nThe same idea of auto-formalization can be also tried on lean: hinting the Codex the math problems and let it generate lean code w/ proof or only a <code>sorry</code> there.</p>",
        "id": 267349875,
        "sender_full_name": "Kunhao Zheng",
        "timestamp": 1641722265
    },
    {
        "content": "<p>I remember reading another quite similar paper on arXiv months ago. Found it here:</p>\n<blockquote>\n<p>Solving Probability and Statistics Problems by Program Synthesis<br>\n<a href=\"https://arxiv.org/pdf/2111.08267.pdf\">https://arxiv.org/pdf/2111.08267.pdf</a></p>\n</blockquote>\n<p>It doesn't surprise me much that it's from the same group of people.</p>",
        "id": 267356863,
        "sender_full_name": "Kunhao Zheng",
        "timestamp": 1641732938
    },
    {
        "content": "<p>On p.4 it says</p>\n<blockquote>\n<p>Interaction. he original question may not be a prompt that synthesizes a program whose execution results in the correct answer. In addition, the answer may require multiple steps with clear plots or other modalities. We therefore may interactively prompt Codex until reaching the correct answer or visualizations, making the minimum necessary changes from the original question. Panel D in Figure 2 shows an example of interaction to produce multiple plots.</p>\n</blockquote>\n<p>So this step (prompt generation) isn't quite automated yet.</p>",
        "id": 267378456,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1641763389
    },
    {
        "content": "<p>This paragraph</p>\n<blockquote>\n<p>C. Questions and Prompts.We classify the transformations from the original course questions to the Codex prompts resulting in correct solutions into the following three classes: (i) As-is prompt: Original question and Codex prompt are the same, (ii) Automatic prompt transformation: Original question and Codex prompt are different, and the Codex prompt is generated automatically by Codex itself, (iii) Manual prompt transformation: Original question and Codex prompt are different, and the Codex prompt is generated by a human.</p>\n</blockquote>\n<p>as <a href=\"https://www.reddit.com/r/MachineLearning/comments/rutbpv/comment/hr33znc/?utm_source=share&amp;utm_medium=web2x&amp;context=3\">quoted on reddit</a>, appears <a href=\"https://arxiv.org/abs/2112.15594v1\">in the first version</a> of the paper but no longer in the latest version. Not sure what changed from version to version.</p>",
        "id": 267379450,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1641764901
    },
    {
        "content": "<p>Iddo Drori, lead author on these papers, will speak in the New Technologies seminar on March 9.</p>",
        "id": 267381756,
        "sender_full_name": "Michael R Douglas",
        "timestamp": 1641768370
    },
    {
        "content": "<p>starting in 30min</p>",
        "id": 274735450,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1646852375
    },
    {
        "content": "<p>Actually it has already started right now.</p>",
        "id": 274736400,
        "sender_full_name": "Jason Rute",
        "timestamp": 1646852695
    },
    {
        "content": "<p>Oh, my mistake, thanks</p>",
        "id": 274737777,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1646853209
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"201575\">@Michael R Douglas</span> The speaker said he would be able to give a citation for their work on proof synthesis.  Would you be able to follow up with him and post it here?  (He said it was on arXiv, but I can't seem to find any examples of proofs in say <a href=\"https://arxiv.org/pdf/2112.15594.pdf\">https://arxiv.org/pdf/2112.15594.pdf</a>, although it is possible I'm just not searching for the correct keywords or looking in the right papers.)</p>",
        "id": 274746168,
        "sender_full_name": "Jason Rute",
        "timestamp": 1646857037
    },
    {
        "content": "<p>Not really lean related, but might still be interesting for folks in this stream:<br>\n<a href=\"https://arxiv.org/abs/2203.08913\">https://arxiv.org/abs/2203.08913</a></p>",
        "id": 283101195,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1653067359
    },
    {
        "content": "<p>Related HN discussion: <a href=\"https://news.ycombinator.com/item?id=31448360\">https://news.ycombinator.com/item?id=31448360</a></p>",
        "id": 283101476,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1653067501
    },
    {
        "content": "<p>This paper was <a href=\"https://www.pnas.org/doi/full/10.1073/pnas.2123433119\">recently published</a> in PNAS (which is similar to Science or Nature).  I haven’t looked at the new version of the paper but hopefully thorough review helped clarify a lot of the iffy and too-good-to-be-true sounding results from the original arXiv paper.</p>",
        "id": 293461225,
        "sender_full_name": "Jason Rute",
        "timestamp": 1660535814
    },
    {
        "content": "<p>Just mentioning the following paper I came across, in case anyone finds it interesting:<br>\n<a href=\"https://arxiv.org/abs/2211.08671\">https://arxiv.org/abs/2211.08671</a></p>",
        "id": 311753168,
        "sender_full_name": "Adam Topaz",
        "timestamp": 1669178009
    },
    {
        "content": "<p>This isn't an arXiv paper and was published a while ago, but still:<br>\n<a href=\"https://www.pnas.org/doi/10.1073/pnas.2115730119\">Socially situated artificial intelligence enables learning from human interaction</a><br>\nFrom the abstract (emphasis mine):</p>\n<blockquote>\n<p>Humans have long demonstrated an ability to learn from interactions with others. However, AI agents learn in <strong>social isolation</strong>. To create intelligent systems that understand more than a fixed slice of the world, our article formalizes socially situated AI—a framework that enables agents to interact with people as they simultaneously learn <strong>new concepts</strong> about the world around them. Using our framework, we deploy a field experiment on a photo-sharing social network where our agent interacts with hundreds of thousands of people to learn concepts about the visual world. We combine advances in deep learning, <strong>computer vision, natural language processing, and human–computer Interaction</strong> to deliver a human-centered AI that learns from interactions with people in social environments.</p>\n</blockquote>\n<blockquote>\n<p>We manifest our framework as an interactive agent that learns how to ask natural language questions about photos as it broadens its visual intelligence on a large photo-sharing social network. Unlike active-learning methods, which implicitly assume that humans are oracles willing to answer any question, our agent adapts its behavior based on <strong>observed norms of which questions people are or are not interested to answer</strong>. Through an <strong>8-month</strong> deployment where our agent <strong>interacted with 236,000 social media users</strong>, our agent improved its performance at recognizing new visual information by 112%. A controlled field experiment confirmed that our agent outperformed an active-learning baseline by 25.6%.</p>\n</blockquote>\n<p>I think the method could be very relevant when it comes to accelerating AI's absorption of mathematical and scientific knowledge. It could open an avenue of teaching mathematics to machines other than formalizing/mathlib building/simp lemma and tactic writing.</p>\n<p>Meta AI has recently released Galactica and <a href=\"https://www.science.org/doi/10.1126/science.ade9097\">Cicero</a>, and it would be wonderful if we could combine them :) Galactica has apparently generated a lot of activities during the short time it was online, and I think people are willing to hold long form conversations with AI if it could conceivably pay back; if one mathematician demonstrates interest/curiosity about one math topic during conversation, AI may be motivated to acquire it from another person knowledgeable about the topic. Some account system may be needed to keep track of every correspondent's preferences, so as to communicate in a personalized way and avoid triggering adverse reactions (AI is now probably good enough to infer sentiments but an upvote/downvote system could also be nice to have).</p>",
        "id": 312249498,
        "sender_full_name": "Junyan Xu",
        "timestamp": 1669405614
    }
]