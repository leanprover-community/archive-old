[
    {
        "content": "<p>I was showing one of my sons gptf (in the lean-liquid repo) and he suggested that instead of training GPT to generate proofs, could one use it to generate theorem statements? I am not a computer scientist but this sounded like a reasonable enough question to me!</p>",
        "id": 236695144,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1619710211
    },
    {
        "content": "<p>yeah this would be a fun experiment! this has been studied elsewhere: the N2Formal team had some <a href=\"https://openreview.net/pdf?id=YmqAnY0CMEy\">experiments</a> with unconditional generation in HOL Light</p>\n<p>currently the model is trained on theorem naming: lean statement -&gt; <code>theorem_name_in_mathlib</code>, one could reverse the role of the names and statements and then try seeing what happens when you supply a reasonable-looking theorem name it's never seen during training</p>\n<p>one way you can try playing with (goal-conditioned) conjecturing now is to use <code>gptf {prefix := \"have :\"}</code> to force it to synthesize a have-statement</p>",
        "id": 236697437,
        "sender_full_name": "Jesse Michael Han",
        "timestamp": 1619711110
    },
    {
        "content": "<p>If you visit <a href=\"https://beta.openai.com/playground?model=formal-lean-wm-to-tt-m1-m2-v4-c4\">https://beta.openai.com/playground?model=formal-lean-wm-to-tt-m1-m2-v4-c4</a> and sign in (assuming you signed up for the beta they announced some time back) you can play around with just clicking submit and  having the model generate statements and then try and prove them. Basically given any prefix gptf will try and complete it, so you can start with something like </p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"bp\">&lt;|</span><span class=\"n\">endoftext</span><span class=\"bp\">|&gt;</span><span class=\"n\">LN</span><span class=\"o\">]</span> <span class=\"n\">GOAL</span> <span class=\"n\">α</span> <span class=\"o\">:</span> <span class=\"kt\">Type</span> <span class=\"n\">u_1</span><span class=\"o\">,</span> <span class=\"n\">_inst_1</span> <span class=\"o\">:</span> <span class=\"n\">group</span> <span class=\"n\">α</span><span class=\"o\">,</span>  <span class=\"n\">g</span> <span class=\"n\">h</span> <span class=\"o\">:</span> <span class=\"n\">G</span> <span class=\"bp\">⊢</span> <span class=\"n\">g</span> <span class=\"bp\">*</span> <span class=\"n\">h</span>\n</code></pre></div>\n<p>and click submit to see what gptf thinks this term should be, I just tried this a couple of times and got <code>g * h = g * h</code> by <code>rfl</code>, but more interestingly also the theorem</p>\n<div class=\"codehilite\" data-code-language=\"Lean\"><pre><span></span><code><span class=\"n\">g</span> <span class=\"bp\">*</span> <span class=\"n\">h</span> <span class=\"bp\">*</span> <span class=\"n\">h</span><span class=\"bp\">⁻¹</span> <span class=\"bp\">=</span> <span class=\"n\">g</span> <span class=\"n\">PROOFSTEP</span> <span class=\"n\">rw</span> <span class=\"o\">[</span><span class=\"n\">mul_assoc</span><span class=\"o\">,</span> <span class=\"bp\">←</span> <span class=\"n\">gpow_add</span><span class=\"o\">,</span> <span class=\"n\">add_right_cancel_iff</span><span class=\"o\">,</span> <span class=\"n\">one_mul</span><span class=\"o\">]</span>\n</code></pre></div>\n<p>not sure that the proof works in this case <span aria-label=\"grinning\" class=\"emoji emoji-1f600\" role=\"img\" title=\"grinning\">:grinning:</span></p>",
        "id": 236697715,
        "sender_full_name": "Alex J. Best",
        "timestamp": 1619711218
    },
    {
        "content": "<p>neat, thanks Alex! yeah the playground at <code>beta.openai.com</code> might be your best bet for playing with the model while avoiding all the <code>gptf</code> theorem proving machinery</p>",
        "id": 236698387,
        "sender_full_name": "Jesse Michael Han",
        "timestamp": 1619711497
    },
    {
        "content": "<p>And if you want top level theorems with no assumptions, use the prefix <code>GOAL    ⊢</code> or <code>TYPE</code> (and whatever boilerplate you need at the beginning).  The <code>TYPE</code> keyword might be better even since that was just trained on Lean top level theorems (and definitions, maybe).</p>",
        "id": 236699434,
        "sender_full_name": "Jason Rute",
        "timestamp": 1619711903
    },
    {
        "content": "<p>See Figure 4 in <a href=\"https://arxiv.org/pdf/2102.06203.pdf\">https://arxiv.org/pdf/2102.06203.pdf</a> for all the available keywords.</p>",
        "id": 236700001,
        "sender_full_name": "Jason Rute",
        "timestamp": 1619712102
    }
]