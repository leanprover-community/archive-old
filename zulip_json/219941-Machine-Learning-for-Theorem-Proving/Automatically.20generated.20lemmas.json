[
    {
        "content": "<p>Hey, I generated ~180k lemmas without proof. I hope someone has a use for them ;)<br>\n<a href=\"https://github.com/todbeibrot/lemma-set\">https://github.com/todbeibrot/lemma-set</a></p>",
        "id": 300100097,
        "sender_full_name": "Cedric Holle",
        "timestamp": 1663835384
    },
    {
        "content": "<p>Um, are these any more useful than randomly stringing together tokens drawn from mathlib? It doesn't look like anything there would even typecheck.</p>",
        "id": 300100912,
        "sender_full_name": "Scott Morrison",
        "timestamp": 1663835681
    },
    {
        "content": "<p>They all typecheck. They don't necessarily make a lot of sense.</p>",
        "id": 300101415,
        "sender_full_name": "Cedric Holle",
        "timestamp": 1663835863
    },
    {
        "content": "<p>Hey Cedric, do you have more details / maybe some code that describes how these lemmas were generated?</p>",
        "id": 300102292,
        "sender_full_name": "Timothee Lacroix",
        "timestamp": 1663836169
    },
    {
        "content": "<p>I used Deep Reinforcement Learning. It basically uses one definition at each step. It only optimizes for validity (and diversity). I am planning on uploading everything. But it might take a while.</p>",
        "id": 300104077,
        "sender_full_name": "Cedric Holle",
        "timestamp": 1663836858
    },
    {
        "content": "<p>Cool, wouldn't this amount to building the proof term then?( In which case you do have the proof)</p>\n<p>Is there a paper?</p>",
        "id": 300106884,
        "sender_full_name": "Timothee Lacroix",
        "timestamp": 1663838050
    },
    {
        "content": "<p>I second <span class=\"user-mention\" data-user-id=\"359917\">@Timothee Lacroix</span>  request for a paper or more general system description.</p>",
        "id": 300118746,
        "sender_full_name": "Jason Rute",
        "timestamp": 1663843126
    },
    {
        "content": "<p>When you say optimizing for validity, you mean (1) that the lemma statement type checks (as a Prop), (2) that it has a trivial proof solvable with say <code>finish</code>, <code>tidy</code>, <code>simp</code>, or some other simp tactic or set of tactics, (3) that it produces stuff already in mathlib, or (4) that you can synthesize a proof as well also using Deep Reinforcement Learning.</p>",
        "id": 300119239,
        "sender_full_name": "Jason Rute",
        "timestamp": 1663843370
    },
    {
        "content": "<p>Oh, looking at the README, I’m guessing (2), specifically you are trying <code>finish</code> on both the conjecture and it’s negation.  Then you have three possibilities: solved with <code>finish</code>, negated with <code>finish</code>, and not resolvable with<code>finish</code>.  Then I assume you give each option a reward for RL purposes.</p>",
        "id": 300119699,
        "sender_full_name": "Jason Rute",
        "timestamp": 1663843608
    },
    {
        "content": "<p>Also by “uses one definition” at each step, I assume you mean you use “apply &lt;ident&gt;” tactics, right?  I also assume you are using a language model if you are using lean-gym, right?</p>",
        "id": 300153749,
        "sender_full_name": "Jason Rute",
        "timestamp": 1663851749
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"359917\">Timothee Lacroix</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas/near/300106884\">said</a>:</p>\n<blockquote>\n<p>Cool, wouldn't this amount to building the proof term then?( In which case you do have the proof)</p>\n<p>Is there a paper?</p>\n</blockquote>\n<p>Unfortunately no, I only have a proof for the really trivial lemmas. You can find the solving tactic at the end of each line in the comment.</p>\n<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas/near/300153749\">said</a>:</p>\n<blockquote>\n<p>Also by “uses one definition at each step”, I assume you mean you use “apply &lt;ident&gt;” tactics, right?  I also assume you are using a language model if you are using lean-gym, right?</p>\n</blockquote>\n<p>Yes, I proof <code>Prop</code> by using <code>fapply &lt;ident&gt;</code>, where &lt;ident&gt; is selected from a set of definitions in mathlib. The resulting proof is then the new lemma. <br>\nA language model is not required for this task. I use PPO by Stable Baselines3.</p>\n<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas/near/300119699\">said</a>:</p>\n<blockquote>\n<p>Oh, looking at the README, I’m guessing (2), specifically you are trying <code>finish</code> on both the conjecture and it’s negation.  Then you have three possibilities: solved with <code>finish</code>, negated with <code>finish</code>, and not resolvable with<code>finish</code>.  Then I assume you give each option a reward for RL purposes.</p>\n</blockquote>\n<p>Exactly. And <code>try_finish</code>tries <code>trivial</code>, <code>refl</code>, <code>dec_trivial</code>, ...</p>\n<p><span class=\"user-mention silent\" data-user-id=\"115715\">Jason Rute</span> <a href=\"#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas/near/300118746\">said</a>:</p>\n<blockquote>\n<p>I second <span class=\"user-mention silent\" data-user-id=\"359917\">Timothee Lacroix</span>  request for a paper or more general system description.</p>\n</blockquote>\n<p>I would like to write my master's thesis about it and explain every detail. At the moment I'm stuck with the registration. So it might take some time.</p>",
        "id": 300216374,
        "sender_full_name": "Cedric Holle",
        "timestamp": 1663869846
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"452637\">@Cedric Holle</span> As for PPO, of course you don’t need a language model for a classification task, but how do you process the input (i.e. the goal state) which is provided as text since PPO by Stable Baselines3 doesn’t seem to handle text input?  Do you tokenize it and extract features (e.g. n-grams)?  Also do you use the partial proof term at all?  (Feel free to wait until you have a paper to share details if you want.  I’m just curious.)</p>",
        "id": 300222934,
        "sender_full_name": "Jason Rute",
        "timestamp": 1663872277
    },
    {
        "content": "<p>I use a simple dictionary of words to numbers. And when a new word appears, I make a new entry in the dictionary. The dictionary has a limited size because I don't want to change the network architecture. Of course, this can lead to some problems. But if you only prove <code>Prop</code>, the amount of different words remains relatively small.<br>\nI also ignore parts of the goals if they are too long or if there are too many goals.</p>",
        "id": 300246030,
        "sender_full_name": "Cedric Holle",
        "timestamp": 1663880935
    },
    {
        "content": "<p>Hey Cedric, is it possible to derive natural language versions of these lemmas? I m working on autoformalization so that aligned data is much more valuable to me.</p>",
        "id": 300549784,
        "sender_full_name": "Ziyu Zhou",
        "timestamp": 1664032178
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"413313\">@Ziyu Zhou</span> You could just use Codex as in the recent autoformalization paper.</p>",
        "id": 300557042,
        "sender_full_name": "Jason Rute",
        "timestamp": 1664036105
    },
    {
        "content": "<p>To make my remark more clear, I doubt Cedric’s method would lead well to informal statements since he uses Lean to construct the formal version at the level of every token in the definition.  Of course one could systematically translate formal tokens to informal by traversing the formal term but my impression is that past attempts to do that have led to rigid, unnatural translations.  However there has been recent work showing Codex works well on “unformalizing” Isabelle (and likely Lean) code.</p>",
        "id": 300561213,
        "sender_full_name": "Jason Rute",
        "timestamp": 1664038268
    },
    {
        "content": "<p>But if your goal is data for training an autoformalizer, then I guess the question is if Cedric’s data is useful for use in cycle consistency methods where one improves a model by having it translate (formalize) what it just translated (unformalized) in the other direction.</p>",
        "id": 300561220,
        "sender_full_name": "Jason Rute",
        "timestamp": 1664038273
    },
    {
        "content": "<p>I guess this leads to another question: how do we evaluate if a conjecturing model is useful?  What would one even use a conjecturing model for?  It would certainly be a source of synthetic data for other tasks (like automatic theorem proving).  It could also be a tool inside another tool, like a lemma creation module.  It even could be used directly for scientific discovery, but that would require a really good model.</p>",
        "id": 300561702,
        "sender_full_name": "Jason Rute",
        "timestamp": 1664038582
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"115715\">@Jason Rute</span>  Thank you. Codex is powerful, but I would perfer some lightweight model to achieve similar or even better functionality. As for Cedirc's work and my question, actually I just intended to see his idea about it.</p>",
        "id": 300605373,
        "sender_full_name": "Ziyu Zhou",
        "timestamp": 1664078403
    },
    {
        "content": "<p>From my experience and my intuition, Codex will have trouble generalizing to more \"advanced\" mathematical propositions, such as perfectoid space. I'd like to try something new, perhaps somewhat rule-based(but not rigid), but nothing has come of it yet.</p>",
        "id": 300605974,
        "sender_full_name": "Ziyu Zhou",
        "timestamp": 1664079169
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"413313\">@Ziyu Zhou</span> I totally agree with Jason</p>",
        "id": 300622571,
        "sender_full_name": "Cedric Holle",
        "timestamp": 1664095780
    }
]