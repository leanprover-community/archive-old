[
    {
        "content": "<p>An <a href=\"https://openai.com/blog/formal-math/\">OpenAI blog post</a> today that Kevin tweeted. Very exciting!<br>\nThe <code>mathd_train_algebra_217</code> theorem seems to have a typo in the formalization: <code>(h₁ : ∀ x, f x = b * x + a)</code> should be <code>(h₁ : ∀ x, g x = b * x + a)</code>. Hopefully this doesn't exist in the actual dataset.</p>",
        "id": 270443433,
        "sender_full_name": "Bolton Bailey",
        "timestamp": 1643830073
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"282271\">Bolton Bailey</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/Solving.20.28Some.29.20Formal.20Olympiad.20Problems/near/270443433\">said</a>:</p>\n<blockquote>\n<p>An <a href=\"https://openai.com/blog/formal-math/\">OpenAI blog post</a> today that Kevin tweeted. Very exciting!<br>\nThe <code>mathd_train_algebra_217</code> theorem seems to have a typo in the formalization: <code>(h₁ : ∀ x, f x = b * x + a)</code> should be <code>(h₁ : ∀ x, g x = b * x + a)</code>. Hopefully this doesn't exist in the actual dataset.</p>\n</blockquote>\n<p>Oh! Very nice catch! The statement is indeed inaccurate and as a consequence much easier than the original one. The proof remains valid for the statement we show though. This is what happens with releases and having a large number of people looking at our work! :) Thank you for that.</p>\n<p>This is not the first time it happens. These statements have been formalized by student contractors and, as humans, they naturally do make mistakes.</p>\n<p>Let me think about what to do here. I could replace it with another statement but this proof makes a very clear point about the capability of the model we want to expose. Maybe I'll add a footnote disclaimer, would you feel this would be fair?</p>",
        "id": 270447114,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1643831523
    },
    {
        "content": "<p>I think that's perfectly fair, I don't think a minor typo like this is a very big deal, since it doesn't actually affect the truth of the theorem itself.</p>",
        "id": 270449526,
        "sender_full_name": "Bolton Bailey",
        "timestamp": 1643832496
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"282271\">Bolton Bailey</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/Solving.20.28Some.29.20Formal.20Olympiad.20Problems/near/270449526\">said</a>:</p>\n<blockquote>\n<p>I think that's perfectly fair, I don't think a minor typo like this is a very big deal, since it doesn't actually affect the truth of the theorem itself.</p>\n</blockquote>\n<p>Well it does make the problem trivial where it was supposed to be somewhat challenging so we do need to be explicit about it <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span></p>",
        "id": 270450241,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1643832806
    },
    {
        "content": "<p>Alternative interpretation: It actually makes the problem <em>more</em> challenging, in that it includes this unnecessary <code>h₃</code> as a red herring for the prover to puzzle the meaning of <span aria-label=\"grinning\" class=\"emoji emoji-1f600\" role=\"img\" title=\"grinning\">:grinning:</span> .</p>",
        "id": 270450755,
        "sender_full_name": "Bolton Bailey",
        "timestamp": 1643833029
    },
    {
        "content": "<p>That's a very positive way to spin this :D</p>",
        "id": 270451256,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1643833285
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span> There is also a typo in the informal proof of problem 1: it ends with <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi><mo>−</mo><mi>p</mi><mo>=</mo><mi>x</mi><mo>−</mo><mn>2</mn><mo>−</mo><mn>2</mn><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">x-p=x-2- 2p</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8389em;vertical-align:-0.1944em;\"></span><span class=\"mord\">2</span><span class=\"mord mathnormal\">p</span></span></span></span> but it should say <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi><mo>−</mo><mi>p</mi><mo>=</mo><mn>2</mn><mo>−</mo><mn>2</mn><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">x-p=2- 2p</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8389em;vertical-align:-0.1944em;\"></span><span class=\"mord\">2</span><span class=\"mord mathnormal\">p</span></span></span></span></p>",
        "id": 270464545,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1643839003
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"110049\">Mario Carneiro</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/Solving.20.28Some.29.20Formal.20Olympiad.20Problems/near/270464545\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"249373\">Stanislas Polu</span> There is also a typo in the informal proof of problem 1: it ends with <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi><mo>−</mo><mi>p</mi><mo>=</mo><mi>x</mi><mo>−</mo><mn>2</mn><mo>−</mo><mn>2</mn><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">x-p=x-2- 2p</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8389em;vertical-align:-0.1944em;\"></span><span class=\"mord\">2</span><span class=\"mord mathnormal\">p</span></span></span></span> but it should say <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi><mo>−</mo><mi>p</mi><mo>=</mo><mn>2</mn><mo>−</mo><mn>2</mn><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">x-p=2- 2p</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8389em;vertical-align:-0.1944em;\"></span><span class=\"mord\">2</span><span class=\"mord mathnormal\">p</span></span></span></span></p>\n</blockquote>\n<p>Indeed! Let me fix it <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span> Thanks thanks!</p>",
        "id": 270472971,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1643843004
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"110049\">@Mario Carneiro</span> fixed now <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span> <br>\n<span class=\"user-mention\" data-user-id=\"282271\">@Bolton Bailey</span> added the footnote here: <a href=\"https://openai.com/blog/formal-math/#fn3\">https://openai.com/blog/formal-math/#fn3</a> </p>\n<p>Thanks to both of you for catching these up <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span></p>",
        "id": 270481565,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1643848166
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"249373\">@Stanislas Polu</span> <span class=\"user-mention\" data-user-id=\"116045\">@Jesse Michael Han</span> Congrats! Very nice blogpost. Can you please indicate whether the examples posted in the blogpost are \"the first thing the AI came up with\" or \"solution <code>n</code> out of <code>X</code> attempts\".</p>",
        "id": 270506196,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1643869543
    },
    {
        "content": "<p>Impressive!<br>\nIn appendix F, problem <code>mathd_algebra_140</code>, what do you mean by \"This proof is<br>\ninteresting as it demonstrates the model’s ability to evaluate symbolic expressions implicitly.\"?<br>\nIt seems to me that evaluating at any three points on <code>h0</code> would work (but of course <code>1, 2, 3</code> is a very natural choice).</p>",
        "id": 270526445,
        "sender_full_name": "Fabian Glöckle",
        "timestamp": 1643883552
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"112680\">Johan Commelin</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/Solving.20.28Some.29.20Formal.20Olympiad.20Problems/near/270506196\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"249373\">Stanislas Polu</span> <span class=\"user-mention silent\" data-user-id=\"116045\">Jesse Michael Han</span> Congrats! Very nice blogpost. Can you please indicate whether the examples posted in the blogpost are \"the first thing the AI came up with\" or \"solution <code>n</code> out of <code>X</code> attempts\".</p>\n</blockquote>\n<p>I'm not sure this is as meaningful was you think.  If I understand correctly, there are two search loops in that paper.  The inner loop is a best-first tree search where the model comes up with tactics, tries them out in Lean, and chooses which branch of the search tree to explore next.  I assume once they reach \"no goals\" they stop since they found a proof.  The outer loop is continually retraining their model (expert iteration) to get better based on proofs it found to other problems.  So if I understand correctly, that proof is the first proof it found, but that was only after a possibly long search.  So the number of \"attempts\" might be interpreted as how many rounds of expert iteration it took, but a failed attempt is not a suggested proof, but a tree search which didn't find \"no goals\".</p>",
        "id": 270530075,
        "sender_full_name": "Jason Rute",
        "timestamp": 1643885483
    },
    {
        "content": "<p>Aha, but after retraining (in the outer loop) there's a chance the a proof for <code>P</code> that was found before is now no longer found. Or maybe a different proof is found. Does it make sense to ask whether the current model can \"routinely\" solve all the problems that it ever solved?</p>",
        "id": 270530572,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1643885751
    },
    {
        "content": "<p>\"Performance is reported in terms of pass rate (percentage of successful proof searches) as a function of the number of attempts per statement, noted pass@k where k is the number of attempts per statement at test time. To reduce noise in these metrics we generally run more than k attempts at test time (generally 32 to compute pass@1 and pass@8), averaging across attempts as needed to obtain a smoother pass@k value\"</p>",
        "id": 270534208,
        "sender_full_name": "Fabian Glöckle",
        "timestamp": 1643887714
    },
    {
        "content": "<p>And the graphs in the paper report the pass rates as a function of the number of expert iterations (outer loops)</p>",
        "id": 270534533,
        "sender_full_name": "Fabian Glöckle",
        "timestamp": 1643887896
    },
    {
        "content": "<p>I have some random questions:<br>\n(1) There are example proofs found by the model of theorems with proofs already in mathlib. I can tell that the model proofs are sometimes shorter, but I can't really evaluate the code style. Are they less clearly written than mathlib proofs? Are some of them better?<br>\n(2) Some of the proofs have lines that don't do anything in them. Would it make sense to prune these lines before using the proofs as training data for the next iteration, to provide higher-quality work to train on?<br>\n(3) Could one test the quality of the proofsize objective by running it on both true and false statements and seeing how quickly it realizes the true statements are more promising? Specifically I'm thinking of the multiple-choice questions in the data set. If the model runs search starting with a tree consisting of leaves for the true answer and also the wrong answers, what % of time will be spent exploring the wrong answers before finding the solution on the correct answer?</p>",
        "id": 270570146,
        "sender_full_name": "Will Sawin",
        "timestamp": 1643903396
    },
    {
        "content": "<p>(3) is interesting. As people who have looked at the work carefully will realise, there's a problem with multiple choice questions in the sense that you have to decide how to formalise them. The simplest approach is taken here -- just ask the computer to prove the true statement</p>",
        "id": 270574681,
        "sender_full_name": "Kevin Buzzard",
        "timestamp": 1643905005
    },
    {
        "content": "<p>One could also formalize the \"(a) or (b) or (c) or (d)\" statement and hope that the model picks one instead of dark magically proving that some needs to be true without stating which ;) If it uses a deconstructing tactic early in the proof search, this should more or less be equivalent to (3)</p>",
        "id": 270580092,
        "sender_full_name": "Fabian Glöckle",
        "timestamp": 1643907076
    },
    {
        "content": "<p>Concerning Will's other points, a \"proof linter\" might also be a tool our CS people could aim for without any ML magic in it.</p>",
        "id": 270580431,
        "sender_full_name": "Fabian Glöckle",
        "timestamp": 1643907211
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"112680\">Johan Commelin</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/Solving.20.28Some.29.20Formal.20Olympiad.20Problems/near/270530572\">said</a>:</p>\n<blockquote>\n<p>Aha, but after retraining (in the outer loop) there's a chance the a proof for <code>P</code> that was found before is now no longer found. Or maybe a different proof is found. Does it make sense to ask whether the current model can \"routinely\" solve all the problems that it ever solved?</p>\n</blockquote>\n<p>Thanks <span class=\"user-mention\" data-user-id=\"112680\">@Johan Commelin</span></p>\n<p>Throughout expert iterations there is no guarantee that the model will reprove something that it proved before. Generally speaking the performance as measured in pass-rate (as quoted by <span class=\"user-mention\" data-user-id=\"210057\">@Fabian Glöckle</span>) do improve but some challenging theorem may get proved only once throughout the entire process. That being said, it is generally easy to prove it again by taking the latest model and attempting proof search for it many times.</p>\n<p>Hope that answers your question?</p>",
        "id": 270592824,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1643911770
    },
    {
        "content": "<p>Yeah, it does. Thanks!</p>",
        "id": 270593248,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1643911937
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"230900\">Will Sawin</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/Solving.20.28Some.29.20Formal.20Olympiad.20Problems/near/270570146\">said</a>:</p>\n<blockquote>\n<p>I have some random questions:<br>\n(1) There are example proofs found by the model of theorems with proofs already in mathlib. I can tell that the model proofs are sometimes shorter, but I can't really evaluate the code style. Are they less clearly written than mathlib proofs? Are some of them better?<br>\n(2) Some of the proofs have lines that don't do anything in them. Would it make sense to prune these lines before using the proofs as training data for the next iteration, to provide higher-quality work to train on?<br>\n(3) Could one test the quality of the proofsize objective by running it on both true and false statements and seeing how quickly it realizes the true statements are more promising? Specifically I'm thinking of the multiple-choice questions in the data set. If the model runs search starting with a tree consisting of leaves for the true answer and also the wrong answers, what % of time will be spent exploring the wrong answers before finding the solution on the correct answer?</p>\n</blockquote>\n<p>(1) I would defer to mathlib maintainers to answer that <span aria-label=\"grimacing\" class=\"emoji emoji-1f62c\" role=\"img\" title=\"grimacing\">:grimacing:</span> <br>\n(2) We're exploring this actively these days. Completely agreed that it should be beneficial <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span> <br>\n(3) Gathering all multiple choices and testing the value function on this sounds extremely interesting indeed <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span> It would be very neat metric for the quality of the value function that one can easily relate to.</p>",
        "id": 270593531,
        "sender_full_name": "Stanislas Polu",
        "timestamp": 1643912052
    },
    {
        "content": "<p>About (1): the proofs that I've seen so far are very much \"mathlib style\" but with more comments (which is a good thing!)</p>",
        "id": 270596525,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1643913355
    },
    {
        "content": "<p>I think the comments are added by hand afterwards just to explain what is happening to people who don't understand Lean<br>\n(or are you talking about different comments?)</p>",
        "id": 270596891,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1643913491
    },
    {
        "content": "<p>Yeah, I guess that makes sense. Sorry, I should have taken another look before commenting. I just remember that I looked at them yesterday and thought: \"that looks a lot like mathlib style, but with more comments\". But of course this model would be very self-conscious if it writes things like</p>\n<blockquote>\n<p>-- The model directly proposes <code>n + 1</code> as solution.</p>\n</blockquote>",
        "id": 270597722,
        "sender_full_name": "Johan Commelin",
        "timestamp": 1643913881
    },
    {
        "content": "<p>The blog post has reached the Data Science team of the company I work at and it wasn't me posting it. People are loving it <span aria-label=\"smiley\" class=\"emoji emoji-1f603\" role=\"img\" title=\"smiley\">:smiley:</span></p>",
        "id": 270598785,
        "sender_full_name": "Arthur Paulino",
        "timestamp": 1643914378
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"451983\">Arthur Paulino</span> <a href=\"#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/Solving.20.28Some.29.20Formal.20Olympiad.20Problems/near/270598785\">said</a>:</p>\n<blockquote>\n<p>The blog post has reached the Data Science team of the company I work at and it wasn't me posting it. People are loving it <span aria-label=\"smiley\" class=\"emoji emoji-1f603\" role=\"img\" title=\"smiley\">:smiley:</span></p>\n</blockquote>\n<p>Get some of them into Lean too! :-)</p>",
        "id": 270648994,
        "sender_full_name": "Yuri de Wit",
        "timestamp": 1643934339
    }
]