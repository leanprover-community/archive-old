---
layout: archive
title: Zulip Chat Archive
permalink: /stream/274007-lean-gptf/topic/simplicity.html
---

<h2>Stream: <a href="https://leanprover-community.github.io/archive/stream/274007-lean-gptf/index.html">lean-gptf</a></h2>
<h3>Topic: <a href="https://leanprover-community.github.io/archive/stream/274007-lean-gptf/topic/simplicity.html">simplicity</a></h3>

<hr>

<base href="https://leanprover.zulipchat.com/">

<head><link href="/style.css" rel="stylesheet"></head>

{% raw %}

<a name="224620750"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/274007-lean-gptf/topic/simplicity/near/224620750" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Julian Berman <a href="https://leanprover-community.github.io/archive/stream/274007-lean-gptf/topic/simplicity.html#224620750">(Jan 31 2021 at 04:01)</a>:</h4>
<p>Hi -- naive question perhaps, but how does/did gpt-f learn what constitutes a simpler proof than another? Or more specifically, what made it produce this: <a href="https://github.com/leanprover-community/mathlib/pull/5903/files">https://github.com/leanprover-community/mathlib/pull/5903/files</a> -- is it explicitly trained that <code>rw</code> is a simpler tactic than <code>simp</code> even though in terms of number of characters that's longer?</p>



<a name="224620819"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/274007-lean-gptf/topic/simplicity/near/224620819" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Mario Carneiro <a href="https://leanprover-community.github.io/archive/stream/274007-lean-gptf/topic/simplicity.html#224620819">(Jan 31 2021 at 04:03)</a>:</h4>
<p>The comments on the last few gpt-f PR's suggest that it's using the length of <code>pp.all</code> output</p>



<a name="224620866"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/274007-lean-gptf/topic/simplicity/near/224620866" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Julian Berman <a href="https://leanprover-community.github.io/archive/stream/274007-lean-gptf/topic/simplicity.html#224620866">(Jan 31 2021 at 04:04)</a>:</h4>
<p>A ha.</p>



<a name="224621833"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/274007-lean-gptf/topic/simplicity/near/224621833" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jesse Michael Han <a href="https://leanprover-community.github.io/archive/stream/274007-lean-gptf/topic/simplicity.html#224621833">(Jan 31 2021 at 04:34)</a>:</h4>
<p><span class="user-mention silent" data-user-id="110049">Mario Carneiro</span> <a href="#narrow/stream/274007-lean-gptf/topic/simplicity/near/224620819">said</a>:</p>
<blockquote>
<p>The comments on the last few gpt-f PR's suggest that it's using the length of <code>pp.all</code> output</p>
</blockquote>
<p>it is just the length of <code>format.to_string &lt;$&gt; format.flatten &lt;$&gt; tactic.pp $PROOF_TERM</code> with default pretty-printing settings --- they get an order of magnitude larger with <code>pp.all</code> enabled</p>



<a name="224621912"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/274007-lean-gptf/topic/simplicity/near/224621912" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Alex J. Best <a href="https://leanprover-community.github.io/archive/stream/274007-lean-gptf/topic/simplicity.html#224621912">(Jan 31 2021 at 04:36)</a>:</h4>
<p>But it's not trained to output short proofs , is that right? It just happens to find shorter ones sometimes?</p>



<a name="224622014"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/274007-lean-gptf/topic/simplicity/near/224622014" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jesse Michael Han <a href="https://leanprover-community.github.io/archive/stream/274007-lean-gptf/topic/simplicity.html#224622014">(Jan 31 2021 at 04:38)</a>:</h4>
<p>correct, it's not explicitly trained to produce short proofs, nor do we optimize the data collection process in any way for this --- it just tries to predict what it thinks is the most likely tactic for a given tactic state, based on the training data (tactic steps in mathlib)</p>



<a name="224622117"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/274007-lean-gptf/topic/simplicity/near/224622117" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jesse Michael Han <a href="https://leanprover-community.github.io/archive/stream/274007-lean-gptf/topic/simplicity.html#224622117">(Jan 31 2021 at 04:41)</a>:</h4>
<p>we determined which proofs were shorter with another script which replays the proofs found by <code>gptf</code> and compares the proof term to the one already in the environment.</p>



<a name="224646759"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/274007-lean-gptf/topic/simplicity/near/224646759" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Julian Berman <a href="https://leanprover-community.github.io/archive/stream/274007-lean-gptf/topic/simplicity.html#224646759">(Jan 31 2021 at 14:14)</a>:</h4>
<p>Makes sense, thanks! Nonetheless I suppose, during training did it get to see multiple proofs of the same thing at all?</p>



<a name="224649310"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/274007-lean-gptf/topic/simplicity/near/224649310" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jesse Michael Han <a href="https://leanprover-community.github.io/archive/stream/274007-lean-gptf/topic/simplicity.html#224649310">(Jan 31 2021 at 15:17)</a>:</h4>
<p>probably --- remember, its training data is precisely what you see when you step through a tactic proof in <code>mathlib</code>, so for example, it's probably seen <code>false</code> proven from <code>Q</code> and <code>not Q</code> (and other extraneous hypotheses in the context) using <code>contradiction</code>, <code>exact absurd h1 h2</code>, <code>tauto</code>, <code>finish</code>...</p>
<p>we can check this rigorously, but later---our attention is occupied with some other experiments at the moment.</p>



{% endraw %}

<hr><p>Last updated: Jan 25 2023 at 00:06 UTC</p>