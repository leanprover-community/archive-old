---
layout: archive
title: Zulip Chat Archive
permalink: /stream/219941-Machine-Learning-for-Theorem-Proving/topic/Isabelle.20and.20neural.20theorem.20proving.html
---

<h2>Stream: <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/index.html">Machine Learning for Theorem Proving</a></h2>
<h3>Topic: <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Isabelle.20and.20neural.20theorem.20proving.html">Isabelle and neural theorem proving</a></h3>

<hr>

<base href="https://leanprover.zulipchat.com/">

<head><link href="/style.css" rel="stylesheet"></head>

{% raw %}

<a name="284139462"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Isabelle%20and%20neural%20theorem%20proving/near/284139462" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Isabelle.20and.20neural.20theorem.20proving.html#284139462">(May 27 2022 at 14:20)</a>:</h4>
<p>There are two (well three) papers recently on neural theorem proving for Isabelle which is great.  In many ways Isabelle, with its powerful Sledgehammer was at the front of automated theorem proving applied to interactive theorem proving.  But now there are works taking this to the next level by integrating neural tools into Isabelle.  I have to admit I haven't looked at either of these papers in detail yet, but I want to mention them here:</p>



<a name="284139477"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Isabelle%20and%20neural%20theorem%20proving/near/284139477" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Isabelle.20and.20neural.20theorem.20proving.html#284139477">(May 27 2022 at 14:20)</a>:</h4>
<ul>
<li>Isabelle ENIGMA<ul>
<li>Title: The Isabelle ENIGMA</li>
<li>Authors: <span class="user-mention" data-user-id="343286">@Zar Goertzel</span>, Jan Jakubův, Cezary Kaliszyk, <span class="user-mention" data-user-id="133339">@Miroslav Olšák</span>, Jelle Piepenbrock, <span class="user-mention" data-user-id="223577">@Josef Urban</span></li>
<li>arXiv: <a href="https://arxiv.org/abs/2205.01981">https://arxiv.org/abs/2205.01981</a></li>
</ul>
</li>
<li>Thor:<ul>
<li>Title: Thor: Wielding Hammers to Integrate Language Models and Automated Theorem Provers</li>
<li>Authors: <span class="user-mention" data-user-id="258175">@Albert Jiang</span>, <span class="user-mention" data-user-id="384425">@Wenda Li</span>, <span class="user-mention" data-user-id="366958">@Szymon Kitowski</span>, Konrad Czechowski, Tomasz Odrzygóźdź, Piotr Miłoś, <span class="user-mention" data-user-id="240875">@Yuhuai Tony Wu</span> , Mateja Jamnik</li>
<li>Twitter announcement: <a href="https://twitter.com/AlbertQJiang">https://twitter.com/AlbertQJiang</a></li>
<li>arXiv paper: <a href="https://arxiv.org/abs/2205.10893">https://arxiv.org/abs/2205.10893</a></li>
</ul>
</li>
</ul>



<a name="284139486"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Isabelle%20and%20neural%20theorem%20proving/near/284139486" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Isabelle.20and.20neural.20theorem.20proving.html#284139486">(May 27 2022 at 14:21)</a>:</h4>
<p>My very quick understanding is that the first uses machine learning <em>inside</em> Sledgehammer to improve the first order theorem prover and premise selector (lemma selector) used by Sledgehammer.  This is similar to the previous ENGIMA projects but focusing on Isabelle and the Archive of Formal Proofs.   The second on the other hand uses machine learning <em>outside</em> Sledgehammer more similar to GPT-f and other neural tactic-guiding tools to guide tactics and Sledgehammer, but also to delegate to Sledgehammer for certain tasks like premise selection.  Superficially it looks like they are orthogonal and can be combined.</p>



<a name="284139625"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Isabelle%20and%20neural%20theorem%20proving/near/284139625" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Isabelle.20and.20neural.20theorem.20proving.html#284139625">(May 27 2022 at 14:22)</a>:</h4>
<p>The third paper is on autoformalization in Isabelle and deserves its own topic.</p>



<a name="284142159"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Isabelle%20and%20neural%20theorem%20proving/near/284142159" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Albert Jiang <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Isabelle.20and.20neural.20theorem.20proving.html#284142159">(May 27 2022 at 14:44)</a>:</h4>
<p><span class="user-mention silent" data-user-id="115715">Jason Rute</span> <a href="#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Isabelle.20and.20neural.20theorem.20proving/near/284139477">said</a>:</p>
<blockquote>
<ul>
<li>Isabelle ENIGMA<ul>
<li>Title: The Isabelle ENIGMA</li>
<li>Authors: <span class="user-mention silent" data-user-id="343286">Zar Goertzel</span>, Jan Jakubův, Cezary Kaliszyk, <span class="user-mention silent" data-user-id="133339">Miroslav Olšák</span>, Jelle Piepenbrock, <span class="user-mention silent" data-user-id="223577">Josef Urban</span></li>
<li>arXiv: <a href="https://arxiv.org/abs/2205.01981">https://arxiv.org/abs/2205.01981</a></li>
</ul>
</li>
<li>Thor:<ul>
<li>Title: Thor: Wielding Hammers to Integrate Language Models and Automated Theorem Provers</li>
<li>Authors: <span class="user-mention silent" data-user-id="258175">Albert Jiang</span>, <span class="user-mention silent" data-user-id="240875">Yuhuai Tony Wu</span>, <span class="user-mention silent" data-user-id="366958">Szymon Kitowski</span>, Konrad Czechowski, Tomasz Odrzygóźdź, Piotr Miłoś, <span class="user-mention silent" data-user-id="240875">Yuhuai Tony Wu</span> , Mateja Jamnik</li>
<li>Twitter announcement: <a href="https://twitter.com/AlbertQJiang">https://twitter.com/AlbertQJiang</a></li>
<li>arXiv paper: <a href="https://arxiv.org/abs/2205.10893">https://arxiv.org/abs/2205.10893</a></li>
</ul>
</li>
</ul>
</blockquote>
<p>I think for Thor, you meant <span class="user-mention" data-user-id="384425">@Wenda Li</span> as the second author :)</p>



<a name="284142360"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Isabelle%20and%20neural%20theorem%20proving/near/284142360" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Isabelle.20and.20neural.20theorem.20proving.html#284142360">(May 27 2022 at 14:46)</a>:</h4>
<p>Fixed.</p>



<a name="284143256"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Isabelle%20and%20neural%20theorem%20proving/near/284143256" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Albert Jiang <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Isabelle.20and.20neural.20theorem.20proving.html#284143256">(May 27 2022 at 14:49)</a>:</h4>
<p><span class="user-mention silent" data-user-id="115715">Jason Rute</span> <a href="#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Isabelle.20and.20neural.20theorem.20proving/near/284139486">said</a>:</p>
<blockquote>
<p>My very quick understanding is that the first uses machine learning <em>inside</em> Sledgehammer to improve the first order theorem prover and premise selector (lemma selector) used by Sledgehammer.  This is similar to the previous ENGIMA projects but focusing on Isabelle and the Archive of Formal Proofs.   The second on the other hand uses machine learning <em>outside</em> Sledgehammer more similar to GPT-f and other neural tactic-guiding tools to guide tactics and Sledgehammer, but also to delegate to Sledgehammer for certain tasks like premise selection.  Superficially it looks like they are orthogonal and can be combined.</p>
</blockquote>
<p>I've read the Isabelle ENIGMA paper and agree with your understanding on both papers. The ENIGMA paper came out just when we were about to wrap up Thor. Otherwise we would have reached out to see if we can combine the two. It remains a future direction to get neural and symbolic components firmly weaved together in great granularity :)</p>



{% endraw %}

<hr><p>Last updated: Jan 25 2023 at 00:06 UTC</p>