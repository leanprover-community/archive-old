---
layout: archive
title: Zulip Chat Archive
permalink: /stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html
---

<h2>Stream: <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/index.html">Machine Learning for Theorem Proving</a></h2>
<h3>Topic: <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html">ML for Lean: How to do it?</a></h3>

<hr>

<base href="https://leanprover.zulipchat.com/">

<head><link href="/style.css" rel="stylesheet"></head>

{% raw %}

<a name="186014952"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186014952" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186014952">(Jan 18 2020 at 22:46)</a>:</h4>
<p>I want to start the conversation of how to enable machine learning for Lean 3 and Lean 4.  Of course there isn't just one application of machine learning or one type of machine learning.  Right now, I can see two immediate applications/connections of machine learning and Lean:</p>
<ul>
<li>Extending <a href="https://sites.google.com/view/holist/home" target="_blank" title="https://sites.google.com/view/holist/home">HOList</a> to Lean.  I’ve already started a <a href="https://gist.github.com/jasonrute/00109af2bdc0974d2e8e79faf26ba556" target="_blank" title="https://gist.github.com/jasonrute/00109af2bdc0974d2e8e79faf26ba556">document here</a> on what this would take (and if we are serious about doing this, the N2Formal team at Google AI would probably be willing to provide some assistance).  At first this would probably be more of a machine learning benchmark than a useable system, but I think we could also incorporate it into (a forked version of) Lean with some work.</li>
<li><a href="#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/Proposal.3A.20Apply.20premise.20selection.20to.20Hammer" title="#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/Proposal.3A.20Apply.20premise.20selection.20to.20Hammer">Adding machine learning premise selection to the Lean hammer project</a></li>
</ul>
<p>Here are the four areas where machine learning will eventually need to interface with Lean.</p>
<ol>
<li><strong>At the tactic level.</strong>  If we are to ever use ML <em>from within</em> Lean, there would be to have tactics which apply machine learning under the hood.  The tactics could behave like <code>simp</code> and close the goal, or like <code>library_search</code> and suggest a proof which doesn’t use machine learning.  Both have their uses.  <span class="user-mention" data-user-id="110043">@Gabriel Ebner</span> has <a href="http://www.andrew.cmu.edu/user/avigad/meetings/fomm2020/slides/fomm_ebner.pdf" target="_blank" title="http://www.andrew.cmu.edu/user/avigad/meetings/fomm2020/slides/fomm_ebner.pdf">already implemented something like this in Lean 3</a> with his Lean <code>hammer</code> tactic.  The tactic uses C++ for premise selection which means it could interface with TensorFlow or PyTorch instead.  However, it also sounds like to do this he had to hack Lean to make it work.  <strong>So it sounds like we know how to do this in Lean 3, and hopefully it will be easier in Lean 4 (where we don’t have to fork Lean to make this work).  However, one probably needs to document this more to see what is possible.</strong></li>
<li><strong>Theorem dependency recording and statistics.</strong> For some applications of machine learning, it is important to have training data.  The minimum needed for something like HOList is a list of theorems statements (and either their dependencies or a linear order of theorems where the dependencies come before the theorem which uses it).  For the hammer premise selection, one needs something similar, the list of premises used for the proof of each theorem (and for further training, the premises actually used in the hammer proof).  It sounds like (at least for the hammer project) <span class="user-mention" data-user-id="110043">@Gabriel Ebner</span> <a href="#narrow/stream/113488-general/topic/Hammer.20talk" title="#narrow/stream/113488-general/topic/Hammer.20talk">has a script which generates this information</a>.  It might not be in the form needed by the HOList project however.  Others have talked about how Lean stores theorems in the “environment”, although I don't understand the details. <strong>So it sounds like we have at least one way to do this in Lean 3 if not more.  Again, the question remains of what form this information is available in and what needs it meets.  I wonder if this will be easier in Lean 4.</strong></li>
<li><strong>(Optional) Full proof recording at the tactic level</strong> For supervised learning of tactics (and again this is NOT needed for HOList, but could be a nice to have), one needs recorded tactic proofs (so one needs the tactics used and their parameters).  I have no idea if there is any work done here and if this is easy or hard.</li>
<li><strong>Outside communication and control of Lean’s tactic framework</strong>  For a system like DeepHOL/HOList, one needs to (from within Python preferably) control a tactic search inside of Lean.  Let me describe how this currently works in DeepHOL/HOList.  A forked HOL Light version is put in a docker container.  This container also contains a gRPC server which takes three request types.  These requests are sent to the HOL Light docker container server from another docker container which handles the proof guidance and training.)  The three requests are as follows: ApplyTactic says “apply [tactic] with [parameters] to [goal]."  Then the server tries that in HOL Light and if it succeeds, it returns a new list of goals.  VerifyProof says “check if [list of tactics with parameters] solves [theorem/goal]."  Last, RegisterTheorem registers a theorem so that it can be called later by the system.  (Technically, in HOList it has to be the most recently verified theorem.  Also, it returns an integer fingerprint of the theorem.)  For a more detailed descriptions of how these three requests work, see <a href="https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb" target="_blank" title="https://github.com/jasonrute/holist-communication-example/blob/master/walkthrough_of_holist_api.ipynb">here</a>.  For DeepHOL/HOList or a similar system we would probably need to build something like this communication interface.  (For DeepHOL/HOList, we would probably need to implement these three commands, but it might be good to step back and think about how this could be done to support other systems besides DeepHOL.) Some have mentioned there is already <a href="https://github.com/dselsam/lean-python-bindings" target="_blank" title="https://github.com/dselsam/lean-python-bindings">Python bindings for Lean</a> which does something like this.  Others have mentioned that the LSP handles stuff like this.  It would be great to discuss this more concretely.  <strong>Is there a clear path to implementing something like this in Lean 3?  (It doesn’t need to be that fast, so we should try the easiest to implement idea first I think.)  Will this be easier in Lean 4?</strong></li>
</ol>



<a name="186070121"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186070121" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186070121">(Jan 20 2020 at 02:54)</a>:</h4>
<p>I looked a bit into <a href="https://github.com/dselsam/lean-python-bindings" target="_blank" title="https://github.com/dselsam/lean-python-bindings">Daniel's old Python bindings for Lean</a>.  They aren't documented, but the test code gives a hint at what they can do.  It looks promising.  However, I can't get them installed correctly.  (It is probably my own not understanding C++ and other things involved in the install.)  Someone suggested also that the bindings may not work with current Lean.  Has anyone got them to work recently?</p>



<a name="186070522"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186070522" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186070522">(Jan 20 2020 at 03:09)</a>:</h4>
<p>Also, I think I said something wrong about LSP.  I suggested that Lean 3 uses LSP.  That will be Lean 4 I guess.  Lean 3 I guess can communicate with <code>lean --server</code> <a href="#narrow/stream/113488-general/topic/guides/near/184985918" title="#narrow/stream/113488-general/topic/guides/near/184985918">by sending JSON messages via STDIN and reading JSON responses from STDOUT</a>.  It seems that one can deduce the Lean 3 message format from the <a href="https://github.com/leanprover/lean-client-js/tree/master/lean-client-js-core/" target="_blank" title="https://github.com/leanprover/lean-client-js/tree/master/lean-client-js-core/">lean-client-js-core</a> package.  Honestly, this is getting outside my wheelhouse, so I would have to do a lot of digging and learning to figure out how this all works.  However, if I do, I'll try to write some descriptions of what is possible here and if it fits the needs of something like DeepHOL.</p>



<a name="186070634"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186070634" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Bryan Gin-ge Chen <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186070634">(Jan 20 2020 at 03:13)</a>:</h4>
<p>Feel free to ask here if you've got questions about Lean 3's server mode!</p>



<a name="186071195"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186071195" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jesse Michael Han <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186071195">(Jan 20 2020 at 03:30)</a>:</h4>
<p>you can observe the Lean 3 server protocol in Emacs by enabling <code>M-x lean-turn-on-debug-mode</code></p>



<a name="186071312"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186071312" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Bryan Gin-ge Chen <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186071312">(Jan 20 2020 at 03:34)</a>:</h4>
<p>You can also see it action in the <a href="https://leanprover-community.github.io/lean-web-editor/" target="_blank" title="https://leanprover-community.github.io/lean-web-editor/">community web editor</a> if you click the question mark and scroll down to the "Debug settings" and then open your browser's console.</p>



<a name="186143472"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186143472" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186143472">(Jan 21 2020 at 00:37)</a>:</h4>
<p>Taking <span class="user-mention" data-user-id="123965">@Bryan Gin-ge Chen</span>'s advice, I looked at Lean's server mode through the <a href="https://leanprover-community.github.io/lean-web-editor/" target="_blank" title="https://leanprover-community.github.io/lean-web-editor/">community web editor</a>.  First, I could only get it to work on Firefox (it didn't work on Safari or Chrome on my Mac).  Second, when <span class="user-mention" data-user-id="123965">@Bryan Gin-ge Chen</span> says my "browser's console", that means go to Tools &gt; Web Developer &gt; Web Console.</p>



<a name="186143475"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186143475" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186143475">(Jan 21 2020 at 00:37)</a>:</h4>
<p>From my limited experimentation, there appears to be three requests one can make of the server, "info", "sync", and "complete".  I'm still trying to figure out what these three do.  I should probably next try to interact directly with the Lean3 server via python.  Until I do that, it appears that "sync" does most of the heavy lifting.  It appears to send the whole file contents.</p>
<div class="codehilite"><pre><span></span><span class="p">{</span>
  <span class="nt">&quot;command&quot;</span><span class="p">:</span> <span class="s2">&quot;sync&quot;</span><span class="p">,</span>
  <span class="nt">&quot;file_name&quot;</span><span class="p">:</span> <span class="s2">&quot;/test.lean&quot;</span><span class="p">,</span>
  <span class="nt">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;example (m n : ℕ) : m + n = n + m :=\nby refl&quot;</span><span class="p">,</span>
  <span class="nt">&quot;seq_num&quot;</span><span class="p">:</span> <span class="mi">40</span>
<span class="p">}</span>
</pre></div>


<p>And then one gets back responses about the state of the file, including messages about tactics which don't work.</p>
<div class="codehilite"><pre><span></span><span class="p">{</span>
  <span class="nt">&quot;msgs&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="nt">&quot;caption&quot;</span><span class="p">:</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
      <span class="nt">&quot;file_name&quot;</span><span class="p">:</span> <span class="s2">&quot;/test.lean&quot;</span><span class="p">,</span>
      <span class="nt">&quot;pos_col&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
      <span class="nt">&quot;pos_line&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
      <span class="nt">&quot;severity&quot;</span><span class="p">:</span> <span class="s2">&quot;error&quot;</span><span class="p">,</span>
      <span class="nt">&quot;text&quot;</span><span class="p">:</span> <span class="s2">&quot;invalid apply tactic, failed to unify\n  m + n = n + m\nwith\n  ?m_2 = ?m_2\nstate:\nm n : ℕ\n⊢ m + n = n + m&quot;</span>
    <span class="p">}</span>
  <span class="p">],</span>
  <span class="nt">&quot;response&quot;</span><span class="p">:</span> <span class="s2">&quot;all_messages&quot;</span>
<span class="p">}</span>
</pre></div>


<p>The "info" command seems for getting more information about variable types, squiggly lines, and other information displayed in the side bar.  I think the "complete" command is for autocompletion.  (Again, using a Python (or other) client to manually communicate with <code>lean --server</code> would make all this more clear.)</p>



<a name="186143481"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186143481" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186143481">(Jan 21 2020 at 00:38)</a>:</h4>
<p>If the "sync" command is the natural way to use try out tactics on a goal via Lean3 server, that would be a pretty blunt tool, but could be workable.  One could enter the goal with a hole (e.g. <code>example (m n : ℕ) : m + n = n + m := begin end</code>).  Then one can try filling in the hole with various tactics and see what the responses are, including the new goal state (e.g. enter <code>example (m n : ℕ) : m + n = n + m := begin induction n end</code>).  However, it seems that the agent would have to interact with the actual Lean code and parse the pretty printed human readable responses (e.g. the agent would have to parse: <code>"tactic failed, there are unsolved goals\nstate:\n2 goals\ncase nat.zero\nm : ℕ\n⊢ m + 0 = 0 + m\n\ncase nat.succ\nm n_n : ℕ,\nn_ih : m + n_n = n_n + m\n⊢ m + nat.succ n_n = nat.succ n_n + m"</code>).  This isn't impossible.  There are only a few message templates the agent would have to deal with and possibly one could turn off some pretty printers to make the formulas more machine readable.  Nonetheless, I think something like the Python bindings look more promising.</p>



<a name="186143525"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186143525" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186143525">(Jan 21 2020 at 00:38)</a>:</h4>
<p>Am I understanding this correctly, <span class="user-mention" data-user-id="123965">@Bryan Gin-ge Chen</span>?</p>



<a name="186144329"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186144329" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186144329">(Jan 21 2020 at 01:02)</a>:</h4>
<p>With pretty printing, the goal mentioned above is:</p>
<div class="codehilite"><pre><span></span>tactic failed, there are unsolved goals
state:
2 goals
case nat.zero
m : ℕ
⊢ m + 0 = 0 + m
case nat.succ
m n_n : ℕ,
n_ih : m + n_n = n_n + m
⊢ m + nat.succ n_n = nat.succ n_n + m
</pre></div>


<p>After setting <code>set_option pp.all true</code>, it becomes</p>
<div class="codehilite"><pre><span></span>tactic failed, there are unsolved goals
state:
2 goals
case nat.zero
m : nat
⊢ @eq.{1} nat (@has_add.add.{0} nat nat.has_add m nat.zero) (@has_add.add.{0} nat nat.has_add nat.zero m)

case nat.succ
m n_n : nat,
n_ih : @eq.{1} nat (@has_add.add.{0} nat nat.has_add m n_n) (@has_add.add.{0} nat nat.has_add n_n m)
⊢ @eq.{1} nat (@has_add.add.{0} nat nat.has_add m (nat.succ n_n)) (@has_add.add.{0} nat nat.has_add (nat.succ n_n) m)
</pre></div>


<p>which is fairly machine parsable (on a level similar to the s-expressions used by HOList/DeepHOL).  Given that tools like HOList don't need the fastest server, it would be interesting to see if something like the HOList server interface could be built from the Lean server.</p>



<a name="186144616"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186144616" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Bryan Gin-ge Chen <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186144616">(Jan 21 2020 at 01:10)</a>:</h4>
<p>Most of what you wrote about the commands looks correct to me. There are actually a few more commands like "search" and "hole", that are used for text editor integration. If you can read typescript, you can also get an idea of the interface for the server commands by browsing <a href="https://github.com/leanprover/lean-client-js/blob/master/lean-client-js-core/src/server.ts" target="_blank" title="https://github.com/leanprover/lean-client-js/blob/master/lean-client-js-core/src/server.ts">this</a> and <a href="https://github.com/leanprover/lean-client-js/blob/master/lean-client-js-core/src/commands.ts" target="_blank" title="https://github.com/leanprover/lean-client-js/blob/master/lean-client-js-core/src/commands.ts">this</a> from <code>lean-client-js-core</code>.</p>
<blockquote>
<p>However, it seems that the agent would have to interact with the actual Lean code and parse the pretty printed human readable responses</p>
</blockquote>
<p>I'm not a Lean metaprogramming expert, but I think it should be possible to write meta code which will return whatever info you want in machine-readable form as well. For instance, the info in the error messages you quoted is available from <code>tactic.local_context</code>. See <a href="https://github.com/leanprover-community/mathlib/blob/master/docs/extras/tactic_writing.md" target="_blank" title="https://github.com/leanprover-community/mathlib/blob/master/docs/extras/tactic_writing.md">mathlib's "tactic writing" tutorial</a> for some more info.</p>
<p>The hole commands might also be interesting to you, since they let you trigger Lean meta code at positions in the code ("holes") that are surrounded by <code>{!</code> and <code>!}</code>. Among other things, you can write meta code which returns a string in the "replacements" field of the response message; you might be able to use this to query Lean for something you're interested in and return it in JSON or some other format. <a href="https://github.com/leanprover-community/mathlib/blob/ff2a41e4579d2238b8864e2bd072831a2006a808/docs/holes.md" target="_blank" title="https://github.com/leanprover-community/mathlib/blob/ff2a41e4579d2238b8864e2bd072831a2006a808/docs/holes.md">Here's</a> some docs on the hole commands provided by mathlib.</p>



<a name="186144989"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186144989" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186144989">(Jan 21 2020 at 01:19)</a>:</h4>
<p>Ok interesting.  Thanks!</p>



<a name="186146224"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186146224" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Reid Barton <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186146224">(Jan 21 2020 at 01:51)</a>:</h4>
<p>From what I recall, if you've used Lean from inside VS Code/emacs, you've pretty much directly experienced all the functionality the server mode has to offer</p>



<a name="186146645"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186146645" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186146645">(Jan 21 2020 at 02:03)</a>:</h4>
<p>The more I think about it, this VS Code/emacs functionality is probably all that is needed to reproduce something like the HOList interface.  I think the only added thing would be to use a small amount of custom meta programming to get the outputs (such as the current goal state after applying a tactic) in the most useful form.  (And even this is optional since the current text outputs are fairly useful and parsable.)  The only worries I have is that (1) it is not fast enough, and (2) the idea I have of how to implement it is too hacky.  Maybe I'll sketch out my idea soon since it is pretty straightforward.</p>



<a name="186178485"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186178485" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186178485">(Jan 21 2020 at 12:41)</a>:</h4>
<p>Here is how one could implement something very similar to HOList’s API but for Lean, using the Lean server.  (As with the HOList API, I am assuming tactics are only applied to single goals and not to lists of goals.)</p>



<a name="186178492"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186178492" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186178492">(Jan 21 2020 at 12:41)</a>:</h4>
<p>The HOList API has an <code>ApplyTactic</code> request which sends a goal and a tactic command (with parameters).  The response is either a success or failure.  A success returns the new goal state. In the Lean Server (ignoring right now the details of how to represent formulas), all I would have to do is take my goal:</p>
<div class="codehilite"><pre><span></span><span class="n">m</span> <span class="n">n_n</span> <span class="o">:</span> <span class="bp">ℕ</span><span class="o">,</span>
<span class="n">n_ih</span> <span class="o">:</span> <span class="n">m</span> <span class="bp">+</span> <span class="n">n_n</span> <span class="bp">=</span> <span class="n">n_n</span> <span class="bp">+</span> <span class="n">m</span>
<span class="err">⊢</span> <span class="n">m</span> <span class="bp">+</span> <span class="n">nat</span><span class="bp">.</span><span class="n">succ</span> <span class="n">n_n</span> <span class="bp">=</span> <span class="n">nat</span><span class="bp">.</span><span class="n">succ</span> <span class="n">n_n</span> <span class="bp">+</span> <span class="n">m</span>
</pre></div>


<p>and my tactic (plus parameters) <code>induction m</code>.<br>
Next, I convert this all to an <code>example</code>:</p>
<div class="codehilite"><pre><span></span><span class="kn">example</span> <span class="o">(</span><span class="n">m</span> <span class="n">n_n</span> <span class="o">:</span> <span class="bp">ℕ</span><span class="o">)</span>
        <span class="o">(</span><span class="n">n_ih</span> <span class="o">:</span> <span class="n">m</span> <span class="bp">+</span> <span class="n">n_n</span> <span class="bp">=</span> <span class="n">n_n</span> <span class="bp">+</span> <span class="n">m</span><span class="o">)</span>
        <span class="o">:</span> <span class="n">m</span> <span class="bp">+</span> <span class="n">nat</span><span class="bp">.</span><span class="n">succ</span> <span class="n">n_n</span> <span class="bp">=</span> <span class="n">nat</span><span class="bp">.</span><span class="n">succ</span> <span class="n">n_n</span> <span class="bp">+</span> <span class="n">m</span> <span class="o">:=</span>
<span class="k">begin</span>
<span class="n">induction</span> <span class="n">m</span>
<span class="kn">end</span>
</pre></div>


<p>I put this in a file and run sync on it.</p>



<a name="186178541"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186178541" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186178541">(Jan 21 2020 at 12:42)</a>:</h4>
<p>Implementing HOList’s <code>VerifyProof</code> request is even more straight forward.  It is given a theorem (e.g. <code>⊢ ∀  m n : nat, m + n = n + m</code>) and a proof which is a list of tactics (with parameters) (e.g. [<code>intro</code>, <code>intro</code>, <code>simp</code>]) and returns whether that proof succeeds.  Just put it into a file and check it with the server:</p>
<div class="codehilite"><pre><span></span><span class="kn">example</span> <span class="o">:</span> <span class="bp">∀</span>  <span class="n">m</span> <span class="n">n</span> <span class="o">:</span> <span class="n">nat</span><span class="o">,</span> <span class="n">m</span> <span class="bp">+</span> <span class="n">n</span> <span class="bp">=</span> <span class="n">n</span> <span class="bp">+</span> <span class="n">m</span> <span class="o">:=</span>
<span class="k">begin</span>
<span class="n">intro</span><span class="bp">;</span>
<span class="n">intro</span><span class="bp">;</span>
<span class="n">simp</span>
<span class="kn">end</span>
</pre></div>



<a name="186178558"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186178558" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186178558">(Jan 21 2020 at 12:42)</a>:</h4>
<p>Finally there is HOList’s <code>RegisterTheorem</code>.  If one is using it to register a theorem (e.g. <code>(m n_n : ℕ) ⊢ m + n = n + m</code>) one just needs to enter the theorem into Lean with a unique identifier.  If one is ok with sorries, then</p>
<div class="codehilite"><pre><span></span><span class="kn">theorem</span> <span class="n">thm_1862938746298</span> <span class="o">(</span><span class="n">m</span> <span class="n">n_n</span> <span class="o">:</span> <span class="bp">ℕ</span><span class="o">)</span> <span class="o">:</span> <span class="n">m</span> <span class="bp">+</span> <span class="n">n</span> <span class="bp">=</span> <span class="n">n</span> <span class="bp">+</span> <span class="n">m</span> <span class="o">:=</span> <span class="n">sorry</span>
</pre></div>


<p>If like HOList, one wants to use the proof from VerifyProof (see my documentation of the HOList API), then use the proof (just [<code>simp</code>] in this case):</p>
<div class="codehilite"><pre><span></span><span class="kn">theorem</span> <span class="n">thm_1862938746298</span> <span class="o">(</span><span class="n">m</span> <span class="n">n_n</span> <span class="o">:</span> <span class="bp">ℕ</span><span class="o">)</span> <span class="o">:</span> <span class="n">m</span> <span class="bp">+</span> <span class="n">n</span> <span class="bp">=</span> <span class="n">n</span> <span class="bp">+</span> <span class="n">m</span> <span class="o">:=</span>
<span class="k">begin</span>
<span class="n">simp</span>
<span class="kn">end</span>
</pre></div>


<p>These registered theorems should probably go in another file so they don’t have to be checked every time.</p>



<a name="186178568"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186178568" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186178568">(Jan 21 2020 at 12:42)</a>:</h4>
<p>Also, there is adding definitions via <code>RegisterTheorem</code>.  Again, this seems straight forward.</p>



<a name="186178574"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186178574" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186178574">(Jan 21 2020 at 12:42)</a>:</h4>
<p>It think the next thing would be to try this out (calling the Lean server as above) in a simple Python client to make sure it works.</p>



<a name="186178580"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186178580" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186178580">(Jan 21 2020 at 12:42)</a>:</h4>
<p>I’m not saying this will 100% fulfill the HOList API since that was intended for HOL Light, but it will get 90% of the way there.  Then we can have a discussion about the other 10%.  (Ok, maybe that remaining 10% will take 90% of the time.  One still needs to catalog the Lean tactics and their parameters for example.)</p>



<a name="186228304"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186228304" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Christian Szegedy <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186228304">(Jan 21 2020 at 21:14)</a>:</h4>
<p>We would be super happy to help supporting Lean from HOList. End of last October I asked Daniel Selsam his opinion of integration. <br>
He suggested us to wait until Lean 4 is ready (suggested that it would take several months on their side to get there) . </p>
<p>I think that given the relative simplicity of our interface and the HOL Light interface as a template, it should not be a huge amount of work to integrate Lean with HOList and our team would be very happy to support this integration on our side.</p>



<a name="186236639"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186236639" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186236639">(Jan 21 2020 at 22:49)</a>:</h4>
<p>The official line of MIcrosoft Research does seem to be “wait until Lean 4”, and this makes sense.  It is a waste of their time to support Lean 3.  Nonetheless, there is a large and vibrant community using (and hacking) Lean 3, and it isn’t unreasonable to build something in Lean 3.  If nothing else, it helps make clear what we need in Lean 4.  From my investigation so far it is plausible that the lean server can be used to implement something like HOList for Lean 3.  (And there would be no need to fork Lean.)  IMO, after building a hacked together Lean 3 to DeepHOL interface (which lives safely in a Docker container), that would provide a template for a more flexible Lean-to-MLGym interface that would satisfy more researcher’s needs.</p>



<a name="186237107"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186237107" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Simon Hudon <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186237107">(Jan 21 2020 at 22:55)</a>:</h4>
<p>Speaking as someone who's both hacking on Lean 3.5 and Lean 4, I don't see using Lean 3 as a waste of time.</p>



<a name="186237316"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186237316" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Simon Hudon <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186237316">(Jan 21 2020 at 22:57)</a>:</h4>
<p>Porting code from Lean 3 to Lean 4 might not be completely straightforward but what you learned about Lean 3 should be transferable to Lean 4. Lean 4 is really an attempt at making all the goodies that the community loves in Lean 3 even better. If you discover a pain point (that others haven't discovered) you can already point it out and it could get better in Lean 4</p>



<a name="186237434"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186237434" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Simon Hudon <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186237434">(Jan 21 2020 at 22:59)</a>:</h4>
<p>(I say "it could get better" because it has to fit in the overall vision of Lean 4, we won't introduce ML-style modules for instance)</p>



<a name="186237459"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186237459" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Minchao Wu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186237459">(Jan 21 2020 at 22:59)</a>:</h4>
<p>Interacting with the Lean server is basically how Rob and I implemented the interface between Lean 3 and Mathematica. Jesse and I had also discussed the possibility of doing this for ML at last year’s ITP. Talking to Lean server should be fine, the challenging part is parsing and managing proof states from what’s returned from Lean. For that we probably want some meta-programs to do it for us, and that’s why Jesse and I have also decided (for now) to wait until Lean 4 to see if there are new meta-level tools to use.</p>



<a name="186555403"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186555403" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186555403">(Jan 25 2020 at 03:40)</a>:</h4>
<p><span class="user-mention" data-user-id="123965">@Bryan Gin-ge Chen</span> I've been playing around with the lean server.  The good news is that I can get it to behave in a back-and-forth manner where I feed it a goal and a tactic and it tells me if that tactic succeeds and what the goal state is.  The bad news is that it is really slow.  The only way I can reliably get it to work is to:</p>
<ul>
<li>feed in my partial proof to a "sync" request</li>
<li>wait for it to send back an "all_messages" response</li>
<li>parse that response</li>
</ul>
<p>This takes consistently about .1 seconds which is REALLY slow for this sort of simple round trip. I thought I can use the "info" request instead (which is much faster), but that is unreliable.  The response to an info request is often referencing a previous version of the file before the sync request.  Do you know of a faster way, or is this a fundamental limitation of the lean server that it takes .1 seconds to fully process a sync request.</p>



<a name="186555577"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186555577" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186555577">(Jan 25 2020 at 03:46)</a>:</h4>
<p>Also, a way to make the info request reliable is to use a new file for each call, but again if I do that it is still 0.1 seconds per call, so there is no speed up to use the "info" request.</p>



<a name="186555858"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186555858" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186555858">(Jan 25 2020 at 03:56)</a>:</h4>
<p>For Google research, I think 0.1 seconds would be fine (and I understand that some tactics would inherently take a while to execute), but it would make it hard for us mere mortals to do cool stuff.</p>



<a name="186556185"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186556185" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Bryan Gin-ge Chen <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186556185">(Jan 25 2020 at 04:06)</a>:</h4>
<p>Unfortunately I don't know of a faster way. Maybe <span class="user-mention" data-user-id="110043">@Gabriel Ebner</span> might have ideas?</p>



<a name="186556257"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186556257" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186556257">(Jan 25 2020 at 04:09)</a>:</h4>
<p>And, either way, I'll play more with this and put some simple code on GitHub in the hopes that:</p>
<ul>
<li>Someone with a lot of computing power (e.g. Google research) can make use of it</li>
<li>Someone who knows better can tell me a faster way</li>
<li>Those building Lean 4 know what the sort of things those in ML would like to be able to do.</li>
</ul>



<a name="186557120"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186557120" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Mario Carneiro <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186557120">(Jan 25 2020 at 04:41)</a>:</h4>
<p>I think the more sustainable option is to hack lean to have an appropriate RPC or FFI interface</p>



<a name="186559313"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186559313" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186559313">(Jan 25 2020 at 05:56)</a>:</h4>
<p>I was worried someone would say that.  I know Daniel Selsam has some old hacked <a href="https://github.com/dselsam/lean-python-bindings" target="_blank" title="https://github.com/dselsam/lean-python-bindings">Lean python bindings</a> (which I don't think currently work).  I don't know if those might be along the same lines.  Anyway, I don't think I'm going to start mucking in the Lean C++ code soon, but someone else is welcome and encouraged to try.</p>



<a name="186588867"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186588867" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186588867">(Jan 25 2020 at 21:11)</a>:</h4>
<p>Ok, with batching (sending about 32 multiple goals/tactics to the same sync request) gives me about a 15x speedup.  I don't know that I can do much better with the Lean server, but 7 ms does seem more reasonable than 100 ms.</p>



<a name="186588922"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186588922" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186588922">(Jan 25 2020 at 21:13)</a>:</h4>
<p>By comparison, HOList takes about 3ms, so it is comparable (but that is without batching).</p>



<a name="186742467"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186742467" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Christian Szegedy <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186742467">(Jan 28 2020 at 00:47)</a>:</h4>
<blockquote>
<p>For Google research, I think 0.1 seconds would be fine (and I understand that some tactics would inherently take a while to execute), but it would make it hard for us mere mortals to do cool stuff.</p>
</blockquote>
<p>Currently our timeout for proving is 5 seconds, because we make heavy use of the MESON tactic. We have a lot of other overhead, especially neural networks become the bottleneck if we go to sub-second range. We are perfectly fine with 0.1 second for now.</p>



<a name="186760471"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186760471" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Stanislas Polu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186760471">(Jan 28 2020 at 08:03)</a>:</h4>
<blockquote>
<p>Currently our timeout for proving is 5 seconds, because we make heavy use of the MESON tactic. We have a lot of other overhead, especially neural networks become the bottleneck if we go to sub-second range. We are perfectly fine with 0.1 second for now.</p>
</blockquote>
<p>On that note, are these the default config on the docker image?</p>



<a name="186839725"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186839725" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186839725">(Jan 28 2020 at 23:05)</a>:</h4>
<p>Ok, for those interested, here is a <a href="https://github.com/jasonrute/communicating-with-lean/blob/master/communicate_with_lean.ipynb" target="_blank" title="https://github.com/jasonrute/communicating-with-lean/blob/master/communicate_with_lean.ipynb">prototype of communicating with Lean via the Lean Server from an external program</a>.    It looks like it is possible to implement a Lean version of HOList's <code>ApplyTactic</code> request.  I think the next step would be to see if we can get a list of all Lean theorems and if we can plug them into this interface (specifically see if we can run the do-nothing <code>skip</code> tactic on the theorem goal).  I'm not entirely happy with how this turned out.  The Lean server is really not intended for this purpose and had to be fought with a lot, but I think it works now (if a bit slowly).</p>



<a name="186840485"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186840485" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186840485">(Jan 28 2020 at 23:15)</a>:</h4>
<p>Also, if anyone is interested in using the Lean server for another purpose (other than a text editor/IDE) I hope this would give them inspiration.</p>



<a name="186840703"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186840703" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186840703">(Jan 28 2020 at 23:19)</a>:</h4>
<p><span class="user-mention" data-user-id="116045">@Jesse Michael Han</span> I think you told me you can get a List of all theorems from the environment.  How does one do this?</p>



<a name="186840788"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186840788" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Scott Morrison <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186840788">(Jan 28 2020 at 23:20)</a>:</h4>
<p>Don't have time to go into detail now, but look at the implementation of <code>library_search</code>, which does exactly this.</p>



<a name="186841186"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186841186" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Minchao Wu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186841186">(Jan 28 2020 at 23:27)</a>:</h4>
<p>You can also find similar implementation in our Mathematica-Lean link repo</p>



<a name="186841188"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186841188" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Minchao Wu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186841188">(Jan 28 2020 at 23:27)</a>:</h4>
<p><a href="https://github.com/minchaowu/mm-lean/blob/master/src/dump.lean" target="_blank" title="https://github.com/minchaowu/mm-lean/blob/master/src/dump.lean">https://github.com/minchaowu/mm-lean/blob/master/src/dump.lean</a></p>



<a name="186841353"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186841353" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Minchao Wu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186841353">(Jan 28 2020 at 23:30)</a>:</h4>
<p>By the way, we’ve done similar things (i.e., an interface with experimental RL results) to HOL4, which is to appear in this year’s AITP.</p>



<a name="186843148"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186843148" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186843148">(Jan 28 2020 at 23:54)</a>:</h4>
<p>Oh cool.  I look forward to reading all the slides and abstracts from AITP this year.</p>



<a name="186843368"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186843368" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186843368">(Jan 28 2020 at 23:56)</a>:</h4>
<p>Also, <span class="user-mention" data-user-id="110187">@Minchao Wu</span>, did you interface with Mathematica in a similar way to how I did it above?  You used the lean server, right?</p>



<a name="186843645"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186843645" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Minchao Wu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186843645">(Jan 28 2020 at 23:59)</a>:</h4>
<p>Yes, it works the same way as I can see from you repo, except that there is no python scripts involved. The Lean server subprocess is handled directly by Mathematica.</p>



<a name="186843896"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186843896" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Minchao Wu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186843896">(Jan 29 2020 at 00:01)</a>:</h4>
<p>We also called the virtual file "dummy.lean" :-)</p>



<a name="186857523"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186857523" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186857523">(Jan 29 2020 at 05:30)</a>:</h4>
<p>Thank you <span class="user-mention" data-user-id="110187">@Minchao Wu</span> !  Your code has been very helpful, but it also points out a number of subtle flaws in my current implementation.  I was too quick to claim victory. :(</p>
<ul>
<li>I don't handle universes, so if I try to put in the goal <code>Π {α : Sort u} {a : α} {p : α → Sort v} {b : α}, a == b → p a → p b</code>, Lean will complain about <code>u</code> and <code>v</code>.  I could store the universes with the goal, and use a section to enter them, so that isn't a huge deal-breaker.</li>
<li>Lean's pretty printed goal output is not necessarily valid lean code.  Example, this is the Lean pretty printed theorem, but <code>∀ (s : list char), string.mk_iterator {data := s} = {fst := list.nil char, snd := s}</code> is not valid Lean.  The problem is that in <code>list.nil char</code>, the <code>char</code> is implicit (the type of <code>list.nil</code> is <code>Π {T : Type}, list T</code>).  I would have to know to enter it as <code>@list.nil char</code> or know that the <code>char</code> can be inferred.  Similarly, <code>and.symm = and.swap</code> isn't valid Lean.  It needs to be <code>∀ a b : Prop, @and.symm a b = @and.swap a b</code></li>
<li>Without knowing the theorems exact place, Lean can't fill in type classes.  For example, if I try to enter <code>∀ (c : Prop) [_inst_1 : decidable c] (a b : ordering), ite c a b = ordering.gt = ite c (a = ordering.gt) (b = ordering.gt)</code> I get complaints about "failed to synthesize type class instance [...]".</li>
<li>This isn't a problem with my app, but it should be noted that auto-generated equation theorems for definitions and type class instances get outputted in the dump.  For example,<code> ∀ {α : Type u₁} {β : Type u₂} (a : α) (b : β), combinator.K a b = a</code> and <code>∀ {α : Type u}, list.has_append = {append := list.append α}</code>.  They aren't really something that is "provable" except using themselves.  At least <code>refl</code> solves them.</li>
</ul>



<a name="186859952"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186859952" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jesse Michael Han <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186859952">(Jan 29 2020 at 06:39)</a>:</h4>
<blockquote>
<p><span class="user-mention silent" data-user-id="116045">Jesse Michael Han</span> I think you told me you can get a List of all theorems from the environment.  How does one do this?</p>
</blockquote>
<p><span class="user-mention" data-user-id="115715">@Jason Rute</span>  you can do something like this in Lean (the code in <code>library_search</code> is a bit more specialized, but essentially does the same thing):</p>
<div class="codehilite"><pre><span></span><span class="n">meta</span> <span class="n">def</span> <span class="n">process_thm</span> <span class="o">(</span><span class="n">d</span> <span class="o">:</span> <span class="n">declaration</span><span class="o">)</span> <span class="o">:</span> <span class="n">option</span> <span class="n">declaration</span> <span class="o">:=</span>
<span class="k">let</span> <span class="n">n</span> <span class="o">:=</span> <span class="n">d</span><span class="bp">.</span><span class="n">to_name</span> <span class="k">in</span>
  <span class="k">if</span> <span class="bp">¬</span> <span class="n">d</span><span class="bp">.</span><span class="n">is_trusted</span> <span class="bp">∨</span> <span class="n">n</span><span class="bp">.</span><span class="n">is_internal</span> <span class="k">then</span> <span class="n">none</span>
  <span class="k">else</span> <span class="k">match</span> <span class="n">d</span> <span class="k">with</span>
       <span class="bp">|</span> <span class="n">declaration</span><span class="bp">.</span><span class="n">defn</span> <span class="bp">_</span> <span class="bp">_</span> <span class="bp">_</span> <span class="bp">_</span> <span class="bp">_</span> <span class="bp">_</span> <span class="o">:=</span> <span class="n">none</span>
       <span class="bp">|</span> <span class="n">t</span><span class="bp">@</span><span class="o">(</span><span class="n">declaration</span><span class="bp">.</span><span class="n">thm</span> <span class="n">n</span> <span class="n">ns</span> <span class="n">e</span> <span class="n">te</span><span class="o">)</span> <span class="o">:=</span> <span class="n">some</span> <span class="n">t</span>
       <span class="bp">|</span> <span class="n">declaration</span><span class="bp">.</span><span class="n">cnst</span> <span class="bp">_</span> <span class="bp">_</span> <span class="bp">_</span> <span class="bp">_</span> <span class="o">:=</span> <span class="n">none</span>
       <span class="bp">|</span> <span class="n">declaration</span><span class="bp">.</span><span class="n">ax</span> <span class="bp">_</span> <span class="bp">_</span> <span class="bp">_</span> <span class="o">:=</span> <span class="n">none</span>
       <span class="kn">end</span>

<span class="n">meta</span> <span class="n">def</span> <span class="n">library_thms</span> <span class="o">:</span> <span class="n">tactic</span> <span class="err">$</span> <span class="n">list</span> <span class="n">declaration</span> <span class="o">:=</span>
  <span class="n">environment</span><span class="bp">.</span><span class="n">decl_filter_map</span> <span class="bp">&lt;</span><span class="err">$</span><span class="bp">&gt;</span> <span class="n">get_env</span> <span class="bp">&lt;*&gt;</span> <span class="n">return</span> <span class="n">process_thm</span>

<span class="n">meta</span> <span class="n">def</span> <span class="n">list_all_theorems</span> <span class="o">:</span> <span class="n">tactic</span> <span class="n">unit</span> <span class="o">:=</span>
  <span class="n">do</span> <span class="n">library_thms</span> <span class="bp">&gt;&gt;=</span> <span class="bp">λ</span> <span class="n">x</span><span class="o">,</span> <span class="n">tactic</span><span class="bp">.</span><span class="n">trace</span> <span class="o">(</span><span class="n">declaration</span><span class="bp">.</span><span class="n">to_name</span> <span class="bp">&lt;</span><span class="err">$</span><span class="bp">&gt;</span> <span class="n">x</span><span class="o">)</span>

<span class="n">run_cmd</span> <span class="n">list_all_theorems</span>
</pre></div>



<a name="186864181"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186864181" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Patrick Massot <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186864181">(Jan 29 2020 at 08:12)</a>:</h4>
<p><span class="user-mention" data-user-id="115715">@Jason Rute</span> Did you look at how format_lean and the lean crawler handle all those issues? <a href="https://github.com/leanprover-community/leancrawler" target="_blank" title="https://github.com/leanprover-community/leancrawler">leancrawler</a> is entirely devoted to listing declarations and statistics about them. And <a href="https://github.com/leanprover-community/format_lean" target="_blank" title="https://github.com/leanprover-community/format_lean">format_lean</a> does need tactic state information from python, implementing a very rough interface at <a href="https://github.com/leanprover-community/format_lean/blob/master/src/format_lean/server.py" target="_blank" title="https://github.com/leanprover-community/format_lean/blob/master/src/format_lean/server.py">https://github.com/leanprover-community/format_lean/blob/master/src/format_lean/server.py</a>.</p>



<a name="186876591"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186876591" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Minchao Wu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186876591">(Jan 29 2020 at 11:23)</a>:</h4>
<p><span class="user-mention" data-user-id="115715">@Jason Rute</span>  The issues you mentioned are exactly some of the many reasons we prefer to delay the implementation until Lean 4. There could be even more issues with parsing and managing proof states, e.g., sometimes you might also see meta-variables occurring in the local context so that you can't directly send them back (as-is) to Lean as assumptions. <br>
For toy examples, the hardcore parsing as you have done would work well, but for serious theorems we probably need a more robust (and fast) system. It seems to me that the ideal way of doing it is having a Lean meta-program that manages proof states for us, and return directly Python-readable objects containing the information we need. In that case, Python only needs to be responsible for sending proper requests and doing machine learning.</p>



<a name="186876802"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186876802" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Minchao Wu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186876802">(Jan 29 2020 at 11:26)</a>:</h4>
<p>Also this is why we prefer systems that implement a simple type theory (at current stage). Too much information about types not only increases the amount of knowledge the agent needs to learn, but also complicates proof states management.</p>



<a name="186886365"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186886365" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186886365">(Jan 29 2020 at 13:44)</a>:</h4>
<p><span class="user-mention" data-user-id="110187">@Minchao Wu</span>  When you say "the hardcore parsing", do you mean parsing the whole syntax tree of the expression?  (I assume if we have that, we could reconstruct the expression in Lean, but even then I'm not sure if it has everything to unambiguously do that.)</p>



<a name="186886846"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186886846" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Minchao Wu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186886846">(Jan 29 2020 at 13:51)</a>:</h4>
<p>I mean parsing the pretty-printed responses from the server on the Python side</p>



<a name="186887038"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186887038" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Minchao Wu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186887038">(Jan 29 2020 at 13:53)</a>:</h4>
<blockquote>
<p>...but even then I'm not sure if it has everything to unambiguously do that.)</p>
</blockquote>
<p>Yes, hopefully Lean 4 would offer us more tools.</p>



<a name="186887896"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186887896" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186887896">(Jan 29 2020 at 14:04)</a>:</h4>
<p>What is it that Lean 4 will provide that Lean 3 doesn’t have?  That is not clear to me.</p>



<a name="186888226"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186888226" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Minchao Wu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186888226">(Jan 29 2020 at 14:09)</a>:</h4>
<p>I don't know, either. But there could be more well-documented meta constants that expose more internal stuff.</p>



<a name="186940896"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186940896" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186940896">(Jan 29 2020 at 23:45)</a>:</h4>
<p><span class="user-mention" data-user-id="110187">@Minchao Wu</span>  More experiments are needed, but if I work with the Lean expressions themselves, then my above issues go away.  It might still not cover all (or most?) cases, but I think it is worth exploring more...</p>



<a name="186941210"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/186941210" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#186941210">(Jan 29 2020 at 23:50)</a>:</h4>
<p>For example, the following code allows me to create a goal from an expression.</p>
<div class="codehilite"><pre><span></span>meta def make_goal_from_expression (e : expr) : tactic unit :=
do
   v &lt;- tactic.mk_meta_var e,
   gs &lt;- tactic.get_goals,
   tactic.set_goals $ v :: gs,
   t &lt;- tactic.target,
   tactic.trace t,
   return ()

meta def my_expr : expr :=  ( expr.pi ( name.mk_string &quot;c&quot; name.anonymous ) binder_info.default  ( expr.sort level.zero ) ( expr.pi ( name.mk_string &quot;_inst_1&quot; name.anonymous ) binder_info.inst_implicit ( expr.app ( expr.const ( name.mk_string &quot;decidable&quot; name.anonymous ) list.nil ) ( expr.var 0 ) ) ( expr.pi ( name.mk_string &quot;a&quot; name.anonymous ) binder_info.default  ( expr.const ( name.mk_string &quot;ordering&quot; name.anonymous ) list.nil ) ( expr.pi ( name.mk_string &quot;b&quot; name.anonymous ) binder_info.default  ( expr.const ( name.mk_string &quot;ordering&quot; name.anonymous ) list.nil ) ( expr.app ( expr.app ( expr.app ( expr.const ( name.mk_string &quot;eq&quot; name.anonymous ) ( list.cons ( level.succ level.zero ) list.nil ) ) ( expr.sort level.zero ) ) ( expr.app ( expr.app ( expr.app ( expr.const ( name.mk_string &quot;eq&quot; name.anonymous ) ( list.cons ( level.succ level.zero ) list.nil ) ) ( expr.const ( name.mk_string &quot;ordering&quot; name.anonymous ) list.nil ) ) ( expr.app ( expr.app ( expr.app ( expr.app ( expr.app ( expr.const ( name.mk_string &quot;ite&quot; name.anonymous ) ( list.cons ( level.succ level.zero ) list.nil ) ) ( expr.var 3 ) ) ( expr.var 2 ) ) ( expr.const ( name.mk_string &quot;ordering&quot; name.anonymous ) list.nil ) ) ( expr.var 1 ) ) ( expr.var 0 ) ) ) ( expr.const ( name.mk_string &quot;gt&quot; ( name.mk_string &quot;ordering&quot; name.anonymous ) ) list.nil ) ) ) ( expr.app ( expr.app ( expr.app ( expr.app ( expr.app ( expr.const ( name.mk_string &quot;ite&quot; name.anonymous ) ( list.cons ( level.succ level.zero ) list.nil ) ) ( expr.var 3 ) ) ( expr.var 2 ) ) ( expr.sort level.zero ) ) ( expr.app ( expr.app ( expr.app ( expr.const ( name.mk_string &quot;eq&quot; name.anonymous ) ( list.cons ( level.succ level.zero ) list.nil ) ) ( expr.const ( name.mk_string &quot;ordering&quot; name.anonymous ) list.nil ) ) ( expr.var 1 ) ) ( expr.const ( name.mk_string &quot;gt&quot; ( name.mk_string &quot;ordering&quot; name.anonymous ) ) list.nil ) ) ) ( expr.app ( expr.app ( expr.app ( expr.const ( name.mk_string &quot;eq&quot; name.anonymous ) ( list.cons ( level.succ level.zero ) list.nil ) ) ( expr.const ( name.mk_string &quot;ordering&quot; name.anonymous ) list.nil ) ) ( expr.var 0 ) ) ( expr.const ( name.mk_string &quot;gt&quot; ( name.mk_string &quot;ordering&quot; name.anonymous ) ) list.nil ) ) ) ) ) ) ) )

run_cmd make_goal_from_expression my_expr
</pre></div>


<p>The trace is correctly:</p>
<div class="codehilite"><pre><span></span>∀ (c : Prop) [_inst_1 : decidable c] (a b : ordering), ite c a b = ordering.gt = ite c (a = ordering.gt) (b = ordering.gt)
</pre></div>



<a name="187044474"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187044474" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187044474">(Jan 30 2020 at 23:53)</a>:</h4>
<p>Right now I see ways to do what I am trying to do:</p>
<ol>
<li>Use the Lean server and work directly with Lean syntax.  This is flexible and easy to enter and play with stuff, but quickly runs into parsing problems.</li>
<li>Use the Lean server but work with plain text of Lean expressions for the goals.  It is no longer human readable, but works more robustly.  It is still possible to enter tactics as plain text, but that might have similar issues with robustness.</li>
<li>Use a lean program to enter serialized expressions.  This is really fast and robust.  The problem is that I don't think it is easy to enter the tactics in such an easy way.  We would have to create a custom syntax for tactics, but this is what HOList does already, so it would be similar.  This is my vote, but I think I'll build all three.</li>
</ol>



<a name="187044612"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187044612" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187044612">(Jan 30 2020 at 23:55)</a>:</h4>
<p>It might not be clear what I'm talking about, but for concreteness, see my <a href="https://github.com/jasonrute/communicating-with-lean/blob/master/communicate_with_lean.ipynb" target="_blank" title="https://github.com/jasonrute/communicating-with-lean/blob/master/communicate_with_lean.ipynb">recent notebook</a> for (1) and see <a href="#narrow/stream/113488-general/topic/Parsing.20a.20string.20into.20an.20expression" title="#narrow/stream/113488-general/topic/Parsing.20a.20string.20into.20an.20expression">this thread</a> for (3).  I'll try to prototype all three.</p>



<a name="187245741"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187245741" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Stanislas Polu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187245741">(Feb 03 2020 at 09:30)</a>:</h4>
<p><span class="user-mention" data-user-id="115715">@Jason Rute</span> really interesting to follow you progress.  (First wanted to point out that as soon as you have something ready, I'm eager to try it out). Can you elaborate a bit on the parsing problem you encounter with (1)? The speed does not seem too bad at all from what you report on your notebook. I was myself planning to fork format_lean. Are those parsing problems solved there? Why not start with it?</p>



<a name="187261627"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187261627" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187261627">(Feb 03 2020 at 13:30)</a>:</h4>
<p><span class="user-mention" data-user-id="249373">@Stanislas Polu</span> Thanks for the encouraging words.  As the "parsing problems" I'm referring to, see <a href="#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F/near/186857523" title="#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F/near/186857523">above</a>.  However, the more I think about this, I made it sound worse than it is.  One problem is universe levels.  Maybe I just need to add those to my interface.  The main problem is that when I "dump" the current theorems of Lean (as training examples), the representation I get can't always be put back into my interface.  However, as I look at this more, if use the more verbose representation given by <code>set_option pp.all true</code> then that works much better.  It is clear to me now that my next step is to dump all the Lean theorems (at least in the core Lean) to a file and test which ones I can enter into my interface successfully.</p>



<a name="187261869"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187261869" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187261869">(Feb 03 2020 at 13:33)</a>:</h4>
<p>I also have some more comments for you, but I have to run...</p>



<a name="187263596"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187263596" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Stanislas Polu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187263596">(Feb 03 2020 at 13:55)</a>:</h4>
<p>That sounds super encouraging! I'm still quite busy integrating against holist but as soon as I'm out of the woods on this one I'll gladly land a hand here <span aria-label="+1" class="emoji emoji-1f44d" role="img" title="+1">:+1:</span></p>



<a name="187267803"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187267803" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187267803">(Feb 03 2020 at 14:43)</a>:</h4>
<p>Ok, it sounds like you are busy, but since you mentioned you are eager to try it out, my notebook code is still very usable with a few caveats:</p>
<ul>
<li>I need to add support for universes and other binder types.</li>
<li>I might need to switch to another Lean output format to make it more robust (so that you can more robustly plug the output of one call into the input of the next, avoiding the issues I was talking about in my previous message).</li>
<li>It is just a bare bones low-level inference to Lean.  You would have to build your own higher-level interface for your purposes.  (However, I did provide an example of breath first search prover as an example of the ideas involved.)  In particular, it doesn't come with any of these features:<ul>
<li>A library of theorems (for either training examples or premise selection).</li>
<li>A curated list of tactics or a clear way to specify/enter their parameters (except as plain text).</li>
</ul>
</li>
</ul>
<p>Nonetheless, you can do a lot with it right away.  If you look at the breath first prover examples, this gives you a clear way to build a learned AI which works for minimal logic.  The tactics <code>apply _</code>, <code>cases _</code>, <code>intro</code>, <code>split</code>, <code>left</code>, and <code>right</code> should be complete for minimal propositional logic.  For intuitionistic propositional logic add the tactic <code>exfalso</code>.  So  you can train an intuitionistic logic AI for example.  You can also look at Buzzard's natural number game for other examples of tactic systems which one could play with.  It all depends what you are going for...</p>



<a name="187267969"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187267969" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187267969">(Feb 03 2020 at 14:45)</a>:</h4>
<p>I'll work on shoring up this prototype and I'm also working on a different prototype which directly enters the theorems to a Lean program which then parses them and runs the specified tactics.  This has some advantages and disadvantages.  I'm trying to compare and contrast both approaches.  My hope is that after I make my prototypes, someone with more time can turn them into usable systems for their (and other's) needs.</p>



<a name="187269304"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187269304" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Stanislas Polu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187269304">(Feb 03 2020 at 15:00)</a>:</h4>
<blockquote>
<p>I might need to switch to another Lean output format to make it more robust (so that you can more robustly plug the output of one call into the input of the next, avoiding the issues I was talking about in my previous message).</p>
</blockquote>
<p>That looks very promising! Can you cc me (@spolu) on this diff?</p>
<blockquote>
<p>It is just a bare bones low-level inference to Lean. You would have to build your own higher-level interface for your purposes. (However, I did provide an example of breath first search prover as an example of the ideas involved.) In particular, it doesn't come with any of these features:<br>
-  library of theorems (for either training examples or premise selection).<br>
- curated list of tactics or a clear way to specify/enter their parameters (except as plain text).</p>
</blockquote>
<p>I've seen your BFS example which looks great. First thing I would do is try to get a dump of theorems and their proofs in a format compatible with your environment. That's probably a bit involved but obviously a crucial step to enable ML work beyond pure RL.</p>



<a name="187314854"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187314854" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187314854">(Feb 03 2020 at 23:02)</a>:</h4>
<p>I don't know that proof recording (at the tactic level) is going to be possible (or at least easy) in Lean 3.   It should be possible to record proofs in terms of basic Lean inference rules (think "assembly language" for theorem proving), but not the high level tactics.  (I guess anything is possible if one modifies the C++ code, but I have no idea where to start with this.)  Instead, I'm going to record just the theorem statements.  This would be enough to do reinforcement learning (and when I talked to Markus Rabe, it seems for Google's work, this is all that they need).</p>



<a name="187314886"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187314886" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187314886">(Feb 03 2020 at 23:03)</a>:</h4>
<p>Of course, if there is a way to record proofs, this is the place to ask.  Does anyone know a way to record tactic-proofs?</p>



<a name="187343805"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187343805" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Stanislas Polu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187343805">(Feb 04 2020 at 09:54)</a>:</h4>
<p>Isn't the interaction demonstrated in format_lean[0] enough to record proofs. For each statement we have the tactic state it is applied to and the tactic sate it maps to? <br>
[0] <a href="https://leanprover-community.github.io/format_lean/example/sandwich.html" target="_blank" title="https://leanprover-community.github.io/format_lean/example/sandwich.html">https://leanprover-community.github.io/format_lean/example/sandwich.html</a></p>



<a name="187344191"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187344191" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Stanislas Polu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187344191">(Feb 04 2020 at 10:00)</a>:</h4>
<blockquote>
<p>Instead, I'm going to record just the theorem statements. This would be enough to do reinforcement learning (and when I talked to Markus Rabe, it seems for Google's work, this is all that they need).</p>
</blockquote>
<p>This is a very specific (and therefore somewhat limited) approach to AITP, I think it would be an error to over-index on that statement. Yes RL on statements works for Hammer-ish / Premise-selection-only type of automated theorem proving, but that's not everything there is to automated theorem proving, especially in Lean.</p>



<a name="187353422"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187353422" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187353422">(Feb 04 2020 at 12:19)</a>:</h4>
<p>First, to be clear, I was ignoring proof recording because (1) I didn't think it was easy and (2) we can do a lot without it (how much remains to be seen, but I don't think one can say with certainty that reinforcement learning only works on some types of projects and not others).  If it is indeed easy to get that data, then of course I want it!  (Also, remember that Lean proofs are human written and Lean hasn't been around for that long.  Right now I count about 8300 occurrences of the <code>theorem</code> keyword in mathlib.  I'm not sure it that is enough training data or not.)</p>



<a name="187354504"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187354504" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187354504">(Feb 04 2020 at 12:36)</a>:</h4>
<p>Now as for getting the theorem data, so far I have been using the above mentioned approaches which are internal to Lean (i.e. looking at the Lean environment for all the declared theorems.)  I hadn't considered doing it externally to Lean (i.e. using the Lean server to look at each line of a proof).  This is very interesting and I'm curious how well it works.  I think it would be fiddly, but it probably is the best option we have.  As an implementation detail, recall that Lean proofs don't have to be linear, so one has to take into account nested structure.  Also, recall that not all proofs are tactic proofs, some are term-mode proofs.  (The <code>format_lean</code> approach might be a bit simplistic in that it seems that the human tells the formatter where to look by adding comments to the Lean file.  We would need something that looks at the Lean file automatically, but I agree it is promising.)</p>



<a name="187354536"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187354536" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187354536">(Feb 04 2020 at 12:37)</a>:</h4>
<p>For now I am just going to focus on the bare essentials of getting the theorems and premises, but if you can get proof recording to work, I'm glad to help were I can.</p>



<a name="187357808"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187357808" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Patrick Massot <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187357808">(Feb 04 2020 at 13:27)</a>:</h4>
<blockquote>
<p>Right now I count about 8300 occurrences of the <code>theorem</code> keyword in mathlib.  I'm not sure it that is enough training data or not.)</p>
</blockquote>
<p>Most statements in mathlib are introduced by the <code>lemma</code> keyword.</p>



<a name="187357945"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187357945" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Patrick Massot <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187357945">(Feb 04 2020 at 13:28)</a>:</h4>
<blockquote>
<p>The <code>format_lean</code> approach might be a bit simplistic in that it seems that the human tells the formatter where to look by adding comments to the Lean file.  We would need something that looks at the Lean file automatically, but I agree it is promising.</p>
</blockquote>
<p>The formatter looks at the beginning and at the end of each line, without human intervention (except maybe that each proof should start with a comment, I don't remember the current status).</p>



<a name="187358099"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187358099" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Patrick Massot <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187358099">(Feb 04 2020 at 13:30)</a>:</h4>
<p>That being said, <code>format_lean</code> is openly a temporary  hack. We are all waiting for the Lean 4 parser that will give us access to everything, including white spaces and comments. Writing a formatter should be pure joy and much more powerful.</p>



<a name="187363747"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187363747" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187363747">(Feb 04 2020 at 14:42)</a>:</h4>
<blockquote>
<p>Most statements in mathlib are introduced by the lemma keyword.</p>
</blockquote>
<p>Ok.  I stand corrected.  I count about 11600 occurrences of the <code>lemma</code> keyword.</p>



<a name="187375204"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187375204" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Reid Barton <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187375204">(Feb 04 2020 at 16:45)</a>:</h4>
<blockquote>
<p>Of course, if there is a way to record proofs, this is the place to ask.  Does anyone know a way to record tactic-proofs?</p>
</blockquote>
<p>I guess it depends on exactly what you have in mind, since the set of tactics is extensible, and while the C++-Lean tactic interface is fixed, it's probably lower-level than you want. Also, mathlib-style proofs use a lot of <code>exact</code> and <code>refine</code> with terms (pre-expressions) of nontrivial complexity, maybe because we do not have much automation to deal with those parts of proofs. So the syntax you would need to model is more complicated.</p>



<a name="187375314"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187375314" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Reid Barton <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187375314">(Feb 04 2020 at 16:46)</a>:</h4>
<p>In any case, it is certainly possible to do something along these lines by replacing <code>tactic.interactive</code> or <code>begin ... end</code> by your own version. I think the natural number game does something of this sort.</p>



<a name="187417353"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187417353" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187417353">(Feb 05 2020 at 01:20)</a>:</h4>
<p>Ok, the more I think about it there is this spectrum of how to “record” proof data.  At the most “human” level one can just download all the Lean files as they are.  Of course this doesn’t contain any parsing information or intermediate goal states or any other information private to Lean, but this is the sort of messy data that data scientists and machine learning researchers are used to working with, and one can still learn a lot from this.  On the other extreme is to modify the tactic framework in Lean’s C++ code to record tactics.  It would contain very specific information about tactics and and subgoals, and hopefully let one replay a proof, but it might (???) be a lot of work to implement.  </p>
<p>The intermediate level seems to be to go through all the proof files and inspect them with the Lean server.  This seems like a good approach and is the one Stanislas is advocating for.  It involves a bit of programming but not too much and one gets information private to Lean about goal states.  </p>
<p>Even this has two extremes.  Again on the human side, one can treat each line as a “tactic” and just run the Lean server “info” command at the start of each line.  If it shows goals, then you know you are inside a tactic proof and you can record the goals and the “tactic” (i.e. the line), which might be many tactic commands in one line or the partial beginning of a tactic command spanning multiple lines.  Also we wouldn’t be keeping track of the whole proof tree, but just what tactics to apply at each intermediate goal state.  Another thing is that we will have no information about notation, implicits, or other things that Lean keeps track of. Even so, it would be <em>very</em> good training data.  On the more “computer” side one could carefully find the start and end of each tactic command and keep track of the flow status of the proof including universes, term expressions, etc. (maybe using “holes commands”) so that we could replay the whole proof perfectly.   This again seems like a lot of work.</p>
<p>Anyway, I’d be in favor of doing the happy medium where one runs the Lean server “info” command on every line of a file.  (Then later one could start to modify this to maybe look at commas/semicolons or add some hole commands until the benefits start to outweigh the cost.)</p>



<a name="187435714"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187435714" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Stanislas Polu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187435714">(Feb 05 2020 at 08:57)</a>:</h4>
<p><span class="user-mention" data-user-id="115715">@Jason Rute</span> this seems like the most amenable format to modern machine learning techniques. There's always a trade-off around the granularity of the training signal you get/use. As an example, from past experience, training a model at the kernel level (which would be one of the extreme you propose) is not very efficient because the data is too granular and the number of steps required to complete a proof too high wrt to how errors compound. At the opposite of it, as you mention as well, there's the lean code, but here the data is probably not granular enough and generating a full proof's code in one go is probably just too hard to be achievable at scale (also you give up on "search").</p>
<p>Plugging where the humans operate therefore appears as a sweet spot in that trade-off (which is kind of obvious). I wouldn't worry too much about the data not including all the internal state of Lean; humans don't have access to it either arguably. Also one can always condition its prediction on more data coming from what precedes in the lean file if need be.</p>
<p>All that to say +1 on your analysis :)</p>



<a name="187503707"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187503707" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187503707">(Feb 05 2020 at 22:54)</a>:</h4>
<p>To be clear, I don’t think anyone is talking about training at the kernel level (i.e. proof terms).  The suggestions about modifying C++ are about training at the tactic framework level.  I still think in the future, when the tools are available, this is the best approach.  (Of course, even then one can still use the hand-readable pretty printed statements if that is indeed the best representation for training.  One can just save this during the tactic-level proof recording.). However, until that is available, using the lean server to inspect the files seems the right happy medium.</p>



<a name="187517342"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187517342" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Christian Szegedy <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187517342">(Feb 06 2020 at 03:29)</a>:</h4>
<p><span class="user-mention" data-user-id="249373">@Stanislas Polu</span></p>
<blockquote>
<p>This is a very specific (and therefore somewhat limited) approach to AITP, I think it would be an error to over-index on that statement. Yes RL on statements works for Hammer-ish / Premise-selection-only type of automated theorem proving, but that's not everything there is to automated theorem proving, especially in Lean.</p>
</blockquote>
<p>DeepHOL-zero does not just focus on lemma selection. We do full proof-search with tactics without imitation. I think we could easily do forward proving without imitation and I have hopes that we can do expression synthesis as well by trying to training on (truncated) sub-trees of theorems or intermediate goal steps.</p>



<a name="187535802"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/187535802" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Stanislas Polu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#187535802">(Feb 06 2020 at 10:22)</a>:</h4>
<blockquote>
<p>We do full proof-search with tactics without imitation</p>
</blockquote>
<p>Yes totally. Sorry I wasn't implying that you were not producing full proofs, just noting that the proofs rely on TACTIC selection + premise selection which does not, as you rightfully mention, cover term generation.</p>



<a name="188289018"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/188289018" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#188289018">(Feb 15 2020 at 16:11)</a>:</h4>
<p>I improved my prototype notebook which uses the Lean server to make a theorem proving API: <a href="https://github.com/jasonrute/communicating-with-lean/blob/master/communicate_with_lean.ipynb" target="_blank" title="https://github.com/jasonrute/communicating-with-lean/blob/master/communicate_with_lean.ipynb">https://github.com/jasonrute/communicating-with-lean/blob/master/communicate_with_lean.ipynb</a>  The big changes are to the output format which makes it more robust and I've also added the ability to add universes and imports.  I also added a section mentioning all the current issues I've seen so far.</p>



<a name="188296878"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/188296878" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#188296878">(Feb 15 2020 at 20:13)</a>:</h4>
<p>I'm now working on scrapping all of the Lean files.  I should be able to get the following quite easily:</p>
<ul>
<li>Every goal state which occurs inside a Lean tactic proof in its pretty printed form (and with a tiny amount more work, in its <code>pp.all</code> form).</li>
<li>The tactic command (including arguments) used on that goal state.  (Some caveats here: if semicolons are used, that will fuse multiple tactic commands into one.  With more work, I can separate them, but then it starts to get more complicated. Also, it might take some work to make sure I get a complete tactic command with arguments if that tactic command invokes other tactics.  Parentheses matching is the first step.)</li>
<li>The doc string for each tactic used.  (I don't think I have to manually identify which keywords are tactics verse theorems, etc. which is nice.)</li>
<li>Meta information about theorems and terms used as tactic arguments.</li>
</ul>
<p>This will be a lot of really good information.  Cross your fingers that this works...</p>



<a name="188318676"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/188318676" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Stanislas Polu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#188318676">(Feb 16 2020 at 08:59)</a>:</h4>
<p>This is super exciting. Do you already have a plan towards reconstructing proofs interactively?</p>



<a name="188322909"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/188322909" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#188322909">(Feb 16 2020 at 11:41)</a>:</h4>
<p><span class="user-mention" data-user-id="249373">@Stanislas Polu</span> What do you mean by reconstructing proofs interactively (especially the <em>interactively</em> part)?</p>



<a name="188325333"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/188325333" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Stanislas Polu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#188325333">(Feb 16 2020 at 13:09)</a>:</h4>
<p><span class="user-mention" data-user-id="115715">@Jason Rute</span> the "ApplyTactic" API</p>



<a name="188411856"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/188411856" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#188411856">(Feb 17 2020 at 22:57)</a>:</h4>
<p>Sorry for the late reply <span class="user-mention" data-user-id="249373">@Stanislas Polu</span>.   I certainly have "ApplyTactic for Lean" in mind.  I've never had the plan to single-handedly make a system which is at the level needed for HOList level machine learning, but I am trying to prototype all the necessary parts so it is easy for others to make the final system.  If in the end I create a fully-functional system, then great!  To recap, the notebook at <a href="https://github.com/jasonrute/communicating-with-lean/blob/master/communicate_with_lean.ipynb" target="_blank" title="https://github.com/jasonrute/communicating-with-lean/blob/master/communicate_with_lean.ipynb">https://github.com/jasonrute/communicating-with-lean/blob/master/communicate_with_lean.ipynb</a> is a prototype for a fairly usable "state free" API for Lean.  It however is nowhere near where HOList is.  Here are next steps:</p>
<ul>
<li>See how well we can enter goals without the system breaking.  There are a couple of sources of goals: top level declared theorems and intermediate goals used in actual proofs.  I'm experimenting with entering both in and seeing how it goes.</li>
<li>Come up with a library of tactics.  Unless one wants the user to enter free-form text into the state-free API, we need to come up with a list of the most common tactics, the most common ways to use them, and an API for them.  This is by far the most tedious process.  I'm scrapping all the Lean files and this should give a lot of good data on stuff like this.</li>
<li>Figure out how to enter premises, local context variables, and other things.  Will we give the user a method to enter premises (and definitions?) or will we be more restrictive and only let the user use theorems already in the environment.</li>
<li>Make sure the tactics aren't going to cheat and use the theorem to prove the theorem.  Lean's <code>simp</code> tactic isn't really a pure function (its behavior changes as theorems are proved).  This means if we are not careful, <code>simp</code> could solve a goal because that goal was added to simp's list of usable theorems.  I guess a simple step would be to remove all <code>simp</code>-provable (and probably <code>refl</code>-provable) theorems from the list of testing examples.  Another option is to not use <code>simp</code>, but the more restrictive <code>simp only</code>.</li>
</ul>
<p>Anyway, I'm slowly working on this in my spare time.  I will also have to take a break for a number of weeks soon.  (Good personal life event coming up!)</p>



<a name="188412227"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/188412227" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#188412227">(Feb 17 2020 at 23:06)</a>:</h4>
<p>Also, in a day, I'll be done scrapping the info command on all the Lean files.  If you want access to the data (it's pretty raw!),  let me know.  Besides using it for simple analysis, statistics, and debugging, it would be a perfectly good machine learning data set:  From a goal (pretty-printed with pp.all set to true), predict the next tactic used.  (One can try to predict the tactic parameters too, but for a number of reasons this is still really messy.)</p>



<a name="188784079"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/188784079" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Stanislas Polu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#188784079">(Feb 21 2020 at 23:18)</a>:</h4>
<p>Definitely interested in getting access to the data <span aria-label="+1" class="emoji emoji-1f44d" role="img" title="+1">:+1:</span></p>



<a name="188840347"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/188840347" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#188840347">(Feb 23 2020 at 00:43)</a>:</h4>
<p>The extraction script, including a decent amount of documentation, is here: <a href="https://github.com/jasonrute/lean_info_scrapper" target="_blank" title="https://github.com/jasonrute/lean_info_scrapper">https://github.com/jasonrute/lean_info_scrapper</a>.  If you want the raw data, let me know your gmail account in a private message, and I can share the data via Google Drive (this seems easiest).  It is less than 100 MB.  I'm working on cleaning the data up to be more useful.</p>



<a name="188844944"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/188844944" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Stanislas Polu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#188844944">(Feb 23 2020 at 02:40)</a>:</h4>
<p>Fantastic! I will go through the exercise of running it <span aria-label="+1" class="emoji emoji-1f44d" role="img" title="+1">:+1:</span></p>



<a name="197157022"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/197157022" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Brando Miranda <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#197157022">(May 11 2020 at 14:55)</a>:</h4>
<p>I need to read this thread in more detail but from what I read, I am curious, <br>
1) is it worth while developing any RL Environment for any ITP given that HOList exists (or that there seems to be an interest to integrate them to HOList)?<br>
2) What are the features if HOList as a system itself that are (seem) to be superior to standard RL Gym's?<br>
3) What are the advantages of integrating Lean (or any ITP) to HOList?<br>
4) How easy is it to integrate any of these systems to HOList?</p>



<a name="197214359"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/197214359" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jalex Stark <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#197214359">(May 11 2020 at 22:42)</a>:</h4>
<p>Brando I don't understand your question 1. My understanding is that HOList currently can only help you prove theorems in Isabelle/HOL. A reason to build learners that are not HOList is so that you can build one that is compatible with Lean, since you might like to write Lean code and have a computer help.</p>



<a name="197215285"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/197215285" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Brando Miranda <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#197215285">(May 11 2020 at 22:53)</a>:</h4>
<p><span class="user-mention" data-user-id="252300">@Jalex Stark</span>  So is it only possible to incorporate ITPs that are based on higher order logic HOL into HOList? (i.e. is it trivial to incorporate Isabelle?). I was under the impression the environment for HOList only supported HOL Light. I am trying to understand when it makes sense to extend HOList and it's advantages &amp; disadvantages at supporting other ITPs (and when it's worth building a new ITP env from scratch).</p>



<a name="197215830"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/197215830" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jalex Stark <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#197215830">(May 11 2020 at 22:59)</a>:</h4>
<p>Oh I don't actually make any claim that HOList supports Isabelle, I just have always seen references to Isabelle/HOL and never figured out what it is.</p>



<a name="197215848"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/197215848" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jalex Stark <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#197215848">(May 11 2020 at 22:59)</a>:</h4>
<p>I have no idea what it would mean to "extend" HOList to support Lean</p>



<a name="197216003"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/197216003" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jalex Stark <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#197216003">(May 11 2020 at 23:00)</a>:</h4>
<p>My best guess at what one should do is write a thing that interacts with Lean "from scratch" by following the design of HOList closely</p>



<a name="197216023"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/197216023" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jalex Stark <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#197216023">(May 11 2020 at 23:00)</a>:</h4>
<p>and yeah you might be able to re-use a lot of the code</p>



<a name="197216058"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/197216058" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jalex Stark <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#197216058">(May 11 2020 at 23:00)</a>:</h4>
<p>but in the early days you shouldn't expect to usefully share weights between models trained on HOL examples and models trained on Isabelle examples</p>



<a name="197216189"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/197216189" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jalex Stark <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#197216189">(May 11 2020 at 23:02)</a>:</h4>
<p>in order for one model to be effective in both domains, you'd effectively be requiring that the model has its own "internal type theory" that it can translate between it and HOL and Lean</p>



<a name="197221364"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/197221364" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#197221364">(May 12 2020 at 00:09)</a>:</h4>
<p>First, let's address the narrow question about using HOList in Lean.  As <span class="user-mention" data-user-id="252300">@Jalex Stark</span> mentioned, HOList (and DeepHOL, the AI associated with the HOList environment) are designed for HOL-Light.  For sake of argument let's consider the different ways that Lean (or another tactic-based ITP) could "use HOList".</p>
<ul>
<li>Most directly Lean could translate a Lean goal into a HOL.  This already isn't always possible (for logical differences between HOL and DTT), but I think something similar is done in practice for Hammer systems in Coq (but I'm really not an expert here).  Then one can send that to a pertained version of DeepHOL (there are many but for sake of argument let's choose the public version). However, DeepHOL and HOList actually have the vocabulary of HOL-Light hard coded (in the same way that many NLP models have all the English words hard coded as indices for each word).  This will require that not only that we translate the goal into HOL, but HOL with a similar vocabulary to HOL-Light.  While some concepts like the natural numbers are easy to align, it is incredibly difficult to translate between all of the concepts even in the same logic.  There are academic papers written on this subject of concept aligning between ITPs.  So we would have to align some of the most common concepts (like natural numbers, logical symbols, etc) and just except that we can't align all of the vocabulary.  That however, may not be a complete bust.  HOList is capable of expanding to another vocabulary, but one just has to mask the new definitions.  Surprisingly HOL-Light still does ok in this setting, e.g. on Flyspeck trained on the core HOL-LIght library.  Ok, so taking stock, we have translated our Lean goal into an HOL-Light goal with HOL-Light syntax.  However, DeepHOL also needs premises to select.  We would have to translate Lean theorems into HOL-Light theorems and supply those as premises.  Then after all that, DeepHOL will find an HOL-Light proof.  This will need to be translated into a Lean proof, which is not straightforward either since HOL-Light has some really powerful automation (e.g. MESON_TAC).</li>
<li>Slightly less directly, we could use HOList/DeepHOL as in the previous bullet, but only one tactic at a time.  Then one would have to build a tree search in Lean and an environment to try tactics.  (We aren't using it for RL yet, but it has a similar purpose of being an RL Gym.)  This would have a better chance of guiding us to the correct proof since we can correct the proof translation as we go.</li>
<li>Now, there are a number of places we can go from here.  For example, we can use the DeepHOL architecture but with a "LeanGym".  Indeed the Google team has expressed interest in this.  Another option is to just copy the concepts in the HOList paper.  Again we need a LeanGym and maybe prerecorded proof data.</li>
<li>In the end, I think unless Google wants to support DeepHOL for Lean (retrained from scratch), the best we can directly exact from the DeepHOL algorithm is the graph embeddings.  As you know <span class="user-mention" data-user-id="246156">@Brando Miranda</span>, all the state of the art tools in image processing and natural language processing use pertained networks (e.g. Resnet trained on Imagenet, BERT trained on a large corpus of English, etc).  There isn't anything similar yet for theorem proving.  But all of Szegedy's recent works (and the talks for this years AITP) strongly suggest that his team is working on this exact problem.  In about a year or two, I bet we can have some standard graph embeddings that could work for HOL-Light, Lean, Coq,  Isabelle, etc.  I still think we are going to have the vocabulary and logic alignment issue, but maybe the embeddings will work solely on the structure of the formula graph.</li>
</ul>



<a name="197223032"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/197223032" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#197223032">(May 12 2020 at 00:34)</a>:</h4>
<p>I think I misunderstood slightly.  I think you are talking about incorporating Lean (and maybe Coq, Isabelle, etc) into HOList.  Here are my thoughts on that.  (Just a point of disambiguation here:  I'm now using HOList to only mean the HOL-Light interface, not DeepHOL.)</p>
<ul>
<li>HOList isn't much more than a thin wrapper around HOL-Light.  I've documented it already.  Honestly, to "incorporate Lean" into HOList basically means writing a completely separate wrapper around Lean, but with the same protobuf API.  It would reuse none of the current HOList code (which is just a fork of the HOL-Light directory).  I'm already working on making a prototype of such an interface.  It is not for Google directly, but it could be used by Google (and it wouldn't be more than a week's work to write a protobuf wrapper around it).</li>
<li>The HOList interface is sort of specific to HOL-Light.  Dependent type theory for example has a notion of a local context which I don't think HOList has any sense of.  This would require an extension of the API.  (And of course the tactics are different.)</li>
<li>I am 100% on board having some standardized theorem-proving gyms for the common ITPs.  Just as the Atari gym allowed a researcher to try a single algorithm on many Atari games, it would be great to make it easy to apply the same algorithm to many ITPs.  Also, it would make transfer of knowledge between separate logics an important research topic.</li>
<li>However, I don't think this should be solely under the HOList umbrella.  Google is doing AMAZING stuff and they are far ahead of anyone else, but they also don't have any interest in documenting their interface.  I've seen many good AI researchers (most of them here on Zulip) attempt to work with HOList, only to get frustrated by the difficulty and give up.  Even you <span class="user-mention" data-user-id="246156">@Brando Miranda</span> pointed out that CoqGym is the only documented API right now.  Also, no-one so far has written a paper using the HOList interface apart from Google.</li>
<li>There is something that almost none of the current ML environments do well.  None of them serve both as an RL Gym for training an algorithm and a tool for ITP researchers.  DeepHOL is unusable as a tool even in HOL-Light.  The TacticToe frameworks are designed to be usable for Coq and HOL4, but at the cost of being trained in OCaml and SML.  :(   This greatly constrains the ability to get ML researchers involved and to rapidly prototype ideas.  (Good luck using TensorFlow or PyTorch.)  My vision is a system which is both: a gym usable by ML researchers, and a tool which can be used directly in Lean.  That is what I'm trying to build (or at least prototype) and I think Lean has the tools for this.  (Lean 4 will even be better!)</li>
</ul>



<a name="197223326"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/197223326" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jalex Stark <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#197223326">(May 12 2020 at 00:39)</a>:</h4>
<p><a href="https://github.com/LaurentMazare/ocaml-torch">https://github.com/LaurentMazare/ocaml-torch</a><br>
obviously using pytorch in ocaml is harder than using it in python, but I think Laurent has done the hardest bits of work</p>



<a name="197223562"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/197223562" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#197223562">(May 12 2020 at 00:43)</a>:</h4>
<p>Ok, I might have gone a bit too far, but I think avoiding Python for experimentation will alienate ML researchers and make prototyping harder.  If however, this is not the case, then by all means...  (Also, even if the experimentation is done in Python, there is obviously value in incorporating the final ML pipeline into a "production" OCaml environment.)</p>



<a name="197223739"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/197223739" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#197223739">(May 12 2020 at 00:46)</a>:</h4>
<p><span class="user-mention" data-user-id="246156">@Brando Miranda</span>, I don't understand your question (2).  HOList addresses a complicated and interesting problem that the standard RL domains don't.  I don't however want to claim there are no other RL environments that don't share some of the difficulties of theorem proving.  (Optimization, automatic code generation, and to some degree robotics also offer model-based RL opportunities with sparse rewards.)  However, mathematical reasoning is intrinsically valuable in its own right.  In analogy, NLP and Image processing are studied both as a way to improve AI, but also because there are millions of dollars of business interests in those areas as well as hope (probably false) that it will improve society.  While mathematical reasoning isn't a lucrative, I think many see it as a holy grail of AI reasoning.  (I think no one is saying that Szegedy's team is not ambitious enough.  I usually hear the opposite.)</p>



<a name="197224126"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/197224126" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#197224126">(May 12 2020 at 00:53)</a>:</h4>
<p>Also, I should point out that, <span class="user-mention" data-user-id="246156">@Brando Miranda</span> , you come at this from the point of view of an ML researcher looking for interesting problems to work on. Many here in this community just want to advance and improve theorem proving.  I'd like to see systems like DeepHOL, TacticToe, etc be easy to work with for the typical proof engineer.  Since Lean is so popular, it makes sense to build tools to at least try to start adding powerful AI to Lean.  (For example, in another thread here, someone asked about ranking the possible rewrite theorems.  They aren't looking for SOTA graph embeddings, just some tool that works ok.  Right now, even that is hard to do in Lean.  I'd like to make that situation better.)</p>



<a name="197269164"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/197269164" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#197269164">(May 12 2020 at 12:43)</a>:</h4>
<p>(Another point before I head into work.)  HOList is implemented as a "stateless API", meaning that after all the definitions and theorems are loaded, you enter in each goal state and the tactic to apply.  This is good for tree searching.  However, I think it is much easier to do in HOL-Light than many other ITPs, including Lean.  For Lean, I tried to make this work, but ran into multiple problems.  Some of them might be fixed in Lean4, but I don't know about all of them.  Instead, I've decided to go a different route where Lean keeps track of all the visited goal states in a proof for you and gives you an index for each.  You can revisit any previously visited state by referencing that index.  (Another approach could be to use the partially built tactic script as the "state".  One can keep track of the proof scripts and use them to jump back to a previous state, but I was worried about performance here and having to re-run the tactic script every time if my tree search bounces around too much.  I wonder if this is how CoqGym does it.  Do you know <span class="user-mention" data-user-id="246156">@Brando Miranda</span>?)</p>



<a name="198483185"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/198483185" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jeremy Avigad <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#198483185">(May 22 2020 at 19:17)</a>:</h4>
<p>A colleague of mine just pointed me to this:<br>
<a href="https://www.quantamagazine.org/symbolic-mathematics-finally-yields-to-neural-networks-20200520/">https://www.quantamagazine.org/symbolic-mathematics-finally-yields-to-neural-networks-20200520/</a></p>



<a name="198484962"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/198484962" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Patrick Massot <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#198484962">(May 22 2020 at 19:31)</a>:</h4>
<p>This is the same dubious work that was discussed here a long time ago, right?</p>



<a name="198484977"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/198484977" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jalex Stark <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#198484977">(May 22 2020 at 19:31)</a>:</h4>
<p>yeah, the preprint has been out for a while</p>



<a name="198485016"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/198485016" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jalex Stark <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#198485016">(May 22 2020 at 19:31)</a>:</h4>
<p>it "just" guesses antiderivatives for a small class of functions, using neural nets and NLP architecture to power the guessing</p>



<a name="198485080"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/198485080" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Patrick Massot <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#198485080">(May 22 2020 at 19:32)</a>:</h4>
<p>If I remember correctly the paper claims were borderline so I guess the journalist version goes way over the top</p>



<a name="198485128"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/198485128" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jalex Stark <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#198485128">(May 22 2020 at 19:32)</a>:</h4>
<p>yeah the folks at quanta are good writers but i don't have any understanding on their topic selection</p>



<a name="198485290"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/198485290" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jalex Stark <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#198485290">(May 22 2020 at 19:34)</a>:</h4>
<p>one time they wrote an article about an unsurprising incremental improvement to a lower bound in incidence geometry; they did a lovely job explaining the problem, but way overstated the contribution of the paper they were responding to</p>



<a name="198485318"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/198485318" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jalex Stark <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#198485318">(May 22 2020 at 19:34)</a>:</h4>
<p>I think they're really excited by the phrase "grad student does X"</p>



<a name="198485406"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/198485406" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jeremy Avigad <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#198485406">(May 22 2020 at 19:35)</a>:</h4>
<p>Thanks for the assessment -- it's save the time of looking into it.</p>



<a name="198535871"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/198535871" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#198535871">(May 23 2020 at 13:31)</a>:</h4>
<p>This topic has been discussed  on the <a href="#narrow/stream/113488-general/topic/deep.20learning.20for.20symbolic.20mathematics">deep learning for symbolic mathematics</a> topic before.  For what it's worth, I think it overall is a good paper with interesting and thought provoking results.  I don't think it is nearly as dubious as Patrick or Jalex suggest.  (I could go into more detail, but probably in that thread or a new one.)</p>



<a name="198538787"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/198538787" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jalex Stark <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#198538787">(May 23 2020 at 14:51)</a>:</h4>
<p>Sorry, I didn't mean to be too dismissive. The paper does what it says it does, it guesses antiderivatives with a neural net, using a training loop that involves a differentiation algorithm but not an antidifferentiation algorithm. You could possibly apply the same idea to other inverse problems.</p>



<a name="198538833"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/198538833" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jalex Stark <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#198538833">(May 23 2020 at 14:52)</a>:</h4>
<p>I just meant to counterbalance the quanta article, which is too much.</p>



<a name="202044587"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/202044587" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Christian Szegedy <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#202044587">(Jun 26 2020 at 01:39)</a>:</h4>
<p><span class="user-mention silent" data-user-id="252300">Jalex Stark</span> <a href="#narrow/stream/219941-Machine-Learning.20for.20Theorem.20Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F/near/198538833">said</a>:</p>
<blockquote>
<p>I just meant to counterbalance the quanta article, which is too much.</p>
</blockquote>
<p>For people like myself, who work with neural networks a lot, this seemed like a highly surprising results as the network can predict relatively complex antiderivatives straight out of box. I think it is a great paper.</p>



<a name="207682027"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/207682027" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Stanislas Polu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#207682027">(Aug 21 2020 at 20:39)</a>:</h4>
<p><span class="user-mention" data-user-id="115715">@Jason Rute</span> I’m looking for the html file that visualize the output of the scrapper; but can’t find it anymore. Mind sharing the link here again? Thanks thanks!</p>



<a name="207711723"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/207711723" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Stanislas Polu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#207711723">(Aug 22 2020 at 07:06)</a>:</h4>
<p>Found it!</p>



<a name="207831398"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/207831398" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#207831398">(Aug 24 2020 at 11:18)</a>:</h4>
<p><span class="user-mention" data-user-id="249373">@Stanislas Polu</span> Sorry.  I’ve been preoccupied.  Do you have everything you need?</p>



<a name="207834288"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/ML%20for%20Lean%3A%20How%20to%20do%20it%3F/near/207834288" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Stanislas Polu <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/ML.20for.20Lean.3A.20How.20to.20do.20it.3F.html#207834288">(Aug 24 2020 at 11:58)</a>:</h4>
<p>Yes! All good <span aria-label="+1" class="emoji emoji-1f44d" role="img" title="+1">:+1:</span> Thanks!</p>



{% endraw %}

<hr><p>Last updated: Jan 25 2023 at 00:06 UTC</p>