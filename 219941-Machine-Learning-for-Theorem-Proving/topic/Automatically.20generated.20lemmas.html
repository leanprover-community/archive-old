---
layout: archive
title: Zulip Chat Archive
permalink: /stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas.html
---

<h2>Stream: <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/index.html">Machine Learning for Theorem Proving</a></h2>
<h3>Topic: <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas.html">Automatically generated lemmas</a></h3>

<hr>

<base href="https://leanprover.zulipchat.com/">

<head><link href="/style.css" rel="stylesheet"></head>

{% raw %}

<a name="300100097"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Automatically%20generated%20lemmas/near/300100097" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Cedric Holle <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas.html#300100097">(Sep 22 2022 at 08:29)</a>:</h4>
<p>Hey, I generated ~180k lemmas without proof. I hope someone has a use for them ;)<br>
<a href="https://github.com/todbeibrot/lemma-set">https://github.com/todbeibrot/lemma-set</a></p>



<a name="300100912"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Automatically%20generated%20lemmas/near/300100912" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Scott Morrison <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas.html#300100912">(Sep 22 2022 at 08:34)</a>:</h4>
<p>Um, are these any more useful than randomly stringing together tokens drawn from mathlib? It doesn't look like anything there would even typecheck.</p>



<a name="300101415"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Automatically%20generated%20lemmas/near/300101415" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Cedric Holle <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas.html#300101415">(Sep 22 2022 at 08:37)</a>:</h4>
<p>They all typecheck. They don't necessarily make a lot of sense.</p>



<a name="300102292"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Automatically%20generated%20lemmas/near/300102292" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Timothee Lacroix <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas.html#300102292">(Sep 22 2022 at 08:42)</a>:</h4>
<p>Hey Cedric, do you have more details / maybe some code that describes how these lemmas were generated?</p>



<a name="300104077"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Automatically%20generated%20lemmas/near/300104077" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Cedric Holle <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas.html#300104077">(Sep 22 2022 at 08:54)</a>:</h4>
<p>I used Deep Reinforcement Learning. It basically uses one definition at each step. It only optimizes for validity (and diversity). I am planning on uploading everything. But it might take a while.</p>



<a name="300106884"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Automatically%20generated%20lemmas/near/300106884" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Timothee Lacroix <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas.html#300106884">(Sep 22 2022 at 09:14)</a>:</h4>
<p>Cool, wouldn't this amount to building the proof term then?( In which case you do have the proof)</p>
<p>Is there a paper?</p>



<a name="300118746"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Automatically%20generated%20lemmas/near/300118746" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas.html#300118746">(Sep 22 2022 at 10:38)</a>:</h4>
<p>I second <span class="user-mention" data-user-id="359917">@Timothee Lacroix</span>  request for a paper or more general system description.</p>



<a name="300119239"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Automatically%20generated%20lemmas/near/300119239" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas.html#300119239">(Sep 22 2022 at 10:42)</a>:</h4>
<p>When you say optimizing for validity, you mean (1) that the lemma statement type checks (as a Prop), (2) that it has a trivial proof solvable with say <code>finish</code>, <code>tidy</code>, <code>simp</code>, or some other simp tactic or set of tactics, (3) that it produces stuff already in mathlib, or (4) that you can synthesize a proof as well also using Deep Reinforcement Learning.</p>



<a name="300119699"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Automatically%20generated%20lemmas/near/300119699" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas.html#300119699">(Sep 22 2022 at 10:46)</a>:</h4>
<p>Oh, looking at the README, I’m guessing (2), specifically you are trying <code>finish</code> on both the conjecture and it’s negation.  Then you have three possibilities: solved with <code>finish</code>, negated with <code>finish</code>, and not resolvable with<code>finish</code>.  Then I assume you give each option a reward for RL purposes.</p>



<a name="300153749"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Automatically%20generated%20lemmas/near/300153749" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas.html#300153749">(Sep 22 2022 at 13:02)</a>:</h4>
<p>Also by “uses one definition” at each step, I assume you mean you use “apply &lt;ident&gt;” tactics, right?  I also assume you are using a language model if you are using lean-gym, right?</p>



<a name="300216374"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Automatically%20generated%20lemmas/near/300216374" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Cedric Holle <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas.html#300216374">(Sep 22 2022 at 18:04)</a>:</h4>
<p><span class="user-mention silent" data-user-id="359917">Timothee Lacroix</span> <a href="#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas/near/300106884">said</a>:</p>
<blockquote>
<p>Cool, wouldn't this amount to building the proof term then?( In which case you do have the proof)</p>
<p>Is there a paper?</p>
</blockquote>
<p>Unfortunately no, I only have a proof for the really trivial lemmas. You can find the solving tactic at the end of each line in the comment.</p>
<p><span class="user-mention silent" data-user-id="115715">Jason Rute</span> <a href="#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas/near/300153749">said</a>:</p>
<blockquote>
<p>Also by “uses one definition at each step”, I assume you mean you use “apply &lt;ident&gt;” tactics, right?  I also assume you are using a language model if you are using lean-gym, right?</p>
</blockquote>
<p>Yes, I proof <code>Prop</code> by using <code>fapply &lt;ident&gt;</code>, where &lt;ident&gt; is selected from a set of definitions in mathlib. The resulting proof is then the new lemma. <br>
A language model is not required for this task. I use PPO by Stable Baselines3.</p>
<p><span class="user-mention silent" data-user-id="115715">Jason Rute</span> <a href="#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas/near/300119699">said</a>:</p>
<blockquote>
<p>Oh, looking at the README, I’m guessing (2), specifically you are trying <code>finish</code> on both the conjecture and it’s negation.  Then you have three possibilities: solved with <code>finish</code>, negated with <code>finish</code>, and not resolvable with<code>finish</code>.  Then I assume you give each option a reward for RL purposes.</p>
</blockquote>
<p>Exactly. And <code>try_finish</code>tries <code>trivial</code>, <code>refl</code>, <code>dec_trivial</code>, ...</p>
<p><span class="user-mention silent" data-user-id="115715">Jason Rute</span> <a href="#narrow/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas/near/300118746">said</a>:</p>
<blockquote>
<p>I second <span class="user-mention silent" data-user-id="359917">Timothee Lacroix</span>  request for a paper or more general system description.</p>
</blockquote>
<p>I would like to write my master's thesis about it and explain every detail. At the moment I'm stuck with the registration. So it might take some time.</p>



<a name="300222934"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Automatically%20generated%20lemmas/near/300222934" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas.html#300222934">(Sep 22 2022 at 18:44)</a>:</h4>
<p><span class="user-mention" data-user-id="452637">@Cedric Holle</span> As for PPO, of course you don’t need a language model for a classification task, but how do you process the input (i.e. the goal state) which is provided as text since PPO by Stable Baselines3 doesn’t seem to handle text input?  Do you tokenize it and extract features (e.g. n-grams)?  Also do you use the partial proof term at all?  (Feel free to wait until you have a paper to share details if you want.  I’m just curious.)</p>



<a name="300246030"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Automatically%20generated%20lemmas/near/300246030" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Cedric Holle <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas.html#300246030">(Sep 22 2022 at 21:08)</a>:</h4>
<p>I use a simple dictionary of words to numbers. And when a new word appears, I make a new entry in the dictionary. The dictionary has a limited size because I don't want to change the network architecture. Of course, this can lead to some problems. But if you only prove <code>Prop</code>, the amount of different words remains relatively small.<br>
I also ignore parts of the goals if they are too long or if there are too many goals.</p>



<a name="300549784"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Automatically%20generated%20lemmas/near/300549784" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Ziyu Zhou <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas.html#300549784">(Sep 24 2022 at 15:09)</a>:</h4>
<p>Hey Cedric, is it possible to derive natural language versions of these lemmas? I m working on autoformalization so that aligned data is much more valuable to me.</p>



<a name="300557042"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Automatically%20generated%20lemmas/near/300557042" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas.html#300557042">(Sep 24 2022 at 16:15)</a>:</h4>
<p><span class="user-mention" data-user-id="413313">@Ziyu Zhou</span> You could just use Codex as in the recent autoformalization paper.</p>



<a name="300561213"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Automatically%20generated%20lemmas/near/300561213" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas.html#300561213">(Sep 24 2022 at 16:51)</a>:</h4>
<p>To make my remark more clear, I doubt Cedric’s method would lead well to informal statements since he uses Lean to construct the formal version at the level of every token in the definition.  Of course one could systematically translate formal tokens to informal by traversing the formal term but my impression is that past attempts to do that have led to rigid, unnatural translations.  However there has been recent work showing Codex works well on “unformalizing” Isabelle (and likely Lean) code.</p>



<a name="300561220"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Automatically%20generated%20lemmas/near/300561220" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas.html#300561220">(Sep 24 2022 at 16:51)</a>:</h4>
<p>But if your goal is data for training an autoformalizer, then I guess the question is if Cedric’s data is useful for use in cycle consistency methods where one improves a model by having it translate (formalize) what it just translated (unformalized) in the other direction.</p>



<a name="300561702"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Automatically%20generated%20lemmas/near/300561702" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jason Rute <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas.html#300561702">(Sep 24 2022 at 16:56)</a>:</h4>
<p>I guess this leads to another question: how do we evaluate if a conjecturing model is useful?  What would one even use a conjecturing model for?  It would certainly be a source of synthetic data for other tasks (like automatic theorem proving).  It could also be a tool inside another tool, like a lemma creation module.  It even could be used directly for scientific discovery, but that would require a really good model.</p>



<a name="300605373"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Automatically%20generated%20lemmas/near/300605373" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Ziyu Zhou <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas.html#300605373">(Sep 25 2022 at 04:00)</a>:</h4>
<p><span class="user-mention" data-user-id="115715">@Jason Rute</span>  Thank you. Codex is powerful, but I would perfer some lightweight model to achieve similar or even better functionality. As for Cedirc's work and my question, actually I just intended to see his idea about it.</p>



<a name="300605974"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Automatically%20generated%20lemmas/near/300605974" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Ziyu Zhou <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas.html#300605974">(Sep 25 2022 at 04:12)</a>:</h4>
<p>From my experience and my intuition, Codex will have trouble generalizing to more "advanced" mathematical propositions, such as perfectoid space. I'd like to try something new, perhaps somewhat rule-based(but not rigid), but nothing has come of it yet.</p>



<a name="300622571"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/219941-Machine%20Learning%20for%20Theorem%20Proving/topic/Automatically%20generated%20lemmas/near/300622571" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Cedric Holle <a href="https://leanprover-community.github.io/archive/stream/219941-Machine-Learning-for-Theorem-Proving/topic/Automatically.20generated.20lemmas.html#300622571">(Sep 25 2022 at 08:49)</a>:</h4>
<p><span class="user-mention" data-user-id="413313">@Ziyu Zhou</span> I totally agree with Jason</p>



{% endraw %}

<hr><p>Last updated: Jan 25 2023 at 00:06 UTC</p>