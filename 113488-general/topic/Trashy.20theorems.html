---
layout: archive
title: Zulip Chat Archive
permalink: /stream/113488-general/topic/Trashy.20theorems.html
---

<h2>Stream: <a href="https://leanprover-community.github.io/archive/stream/113488-general/index.html">general</a></h2>
<h3>Topic: <a href="https://leanprover-community.github.io/archive/stream/113488-general/topic/Trashy.20theorems.html">Trashy theorems</a></h3>

<hr>

<base href="https://leanprover.zulipchat.com/">

<head><link href="/style.css" rel="stylesheet"></head>

{% raw %}

<a name="206591025"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/Trashy%20theorems/near/206591025" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Chris B <a href="https://leanprover-community.github.io/archive/stream/113488-general/topic/Trashy.20theorems.html#206591025">(Aug 11 2020 at 15:40)</a>:</h4>
<p>Wasn't sure what to call this one lol. Of the items in mathlib, <code>finset.sum_range_sub_of_monotone</code> and <code>composition_as_set_equiv._proof_5</code> produce the largest number of garbage/intermediate items while passing through the kernel (8x and 5x the runners up respectively). I don't think it's a problem or anything since in absolute terms it's not a huge amount of memory being consumed, I'm just curious if anyone with an understanding of these parts of mathlib had any insight into what about these items might be the underlying cause. Guesses/conjecture are also welcome.<br>
Thanks!</p>



<a name="206642316"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/Trashy%20theorems/near/206642316" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Scott Morrison <a href="https://leanprover-community.github.io/archive/stream/113488-general/topic/Trashy.20theorems.html#206642316">(Aug 11 2020 at 23:10)</a>:</h4>
<p>How are you measuring this?</p>



<a name="206642761"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/Trashy%20theorems/near/206642761" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Kevin Buzzard <a href="https://leanprover-community.github.io/archive/stream/113488-general/topic/Trashy.20theorems.html#206642761">(Aug 11 2020 at 23:15)</a>:</h4>
<p><a href="#narrow/stream/236449-Program-verification/topic/Arena.20allocation.20for.20ITPs/near/206617336">https://leanprover.zulipchat.com/#narrow/stream/236449-Program-verification/topic/Arena.20allocation.20for.20ITPs/near/206617336</a></p>



<a name="206643027"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/Trashy%20theorems/near/206643027" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Kevin Buzzard <a href="https://leanprover-community.github.io/archive/stream/113488-general/topic/Trashy.20theorems.html#206643027">(Aug 11 2020 at 23:18)</a>:</h4>
<p>and you're in the clear -- it's all polynomials, and computing pi to 6 decimal places</p>



<a name="206645004"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/Trashy%20theorems/near/206645004" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Chris B <a href="https://leanprover-community.github.io/archive/stream/113488-general/topic/Trashy.20theorems.html#206645004">(Aug 11 2020 at 23:48)</a>:</h4>
<p><span class="user-mention silent" data-user-id="110087">Scott Morrison</span> <a href="#narrow/stream/113488-general/topic/Trashy.20theorems/near/206642316">said</a>:</p>
<blockquote>
<p>How are you measuring this?</p>
</blockquote>
<p>He beat me to it, but it's an independent type checker. In terms of inference and equality checks it follows Lean's kernel pretty closely, so I'm  fairly confident these numbers are close to what you would actually get in Lean 3. I'm using Lean 4's strategy for inductive and quotient reduction, but not the nat stuff yet.</p>



<a name="206645481"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/Trashy%20theorems/near/206645481" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Chris B <a href="https://leanprover-community.github.io/archive/stream/113488-general/topic/Trashy.20theorems.html#206645481">(Aug 11 2020 at 23:54)</a>:</h4>
<p>Also it seems like suspicions in the other thread are converging on the <code>omega</code> tactic.</p>



<a name="207047297"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/Trashy%20theorems/near/207047297" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jalex Stark <a href="https://leanprover-community.github.io/archive/stream/113488-general/topic/Trashy.20theorems.html#207047297">(Aug 16 2020 at 00:50)</a>:</h4>
<p>from my experience writing the <code>next_coeff</code> proof, the <code>omega</code>s were the part I was saddest about. I tried extracting specialized arithmetic statements, stuff that really seemed to me like they shouldn't be named lemmas, and I had difficulty proving them concisely without <code>omega</code>.</p>



<a name="207048320"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/Trashy%20theorems/near/207048320" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Jalex Stark <a href="https://leanprover-community.github.io/archive/stream/113488-general/topic/Trashy.20theorems.html#207048320">(Aug 16 2020 at 01:23)</a>:</h4>
<p>i think a slightly better "control flow" in the argument could cut down on duplicated <code>omega</code> work, among other things. The whole proof feels like it's screaming out for more automation. I think i recently saw a pair of Coq tactics for "pull the nth summation symbol to be the innermost / outermost sum". I guess that really doesn't apply to the thing we're doing with the double sum here.</p>



{% endraw %}

<hr><p>Last updated: Jan 25 2023 at 00:06 UTC</p>