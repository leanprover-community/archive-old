---
layout: archive
title: Zulip Chat Archive
permalink: /stream/113488-general/topic/Benchmarking.html
---

<h2>Stream: <a href="https://leanprover-community.github.io/archive/stream/113488-general/index.html">general</a></h2>
<h3>Topic: <a href="https://leanprover-community.github.io/archive/stream/113488-general/topic/Benchmarking.html">Benchmarking</a></h3>

<hr>

<base href="https://leanprover.zulipchat.com/">

<head><link href="/style.css" rel="stylesheet"></head>

{% raw %}

<a name="177872572"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/Benchmarking/near/177872572" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Miguel Raz Guzm√°n Macedo <a href="https://leanprover-community.github.io/archive/stream/113488-general/topic/Benchmarking.html#177872572">(Oct 11 2019 at 02:35)</a>:</h4>
<p>Also, are there any benchmarks of performance vs Coq?</p>



<a name="177872828"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/Benchmarking/near/177872828" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Mario Carneiro <a href="https://leanprover-community.github.io/archive/stream/113488-general/topic/Benchmarking.html#177872828">(Oct 11 2019 at 02:41)</a>:</h4>
<p>It sounds pretty difficult to make any fair comparison</p>



<a name="177872885"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/Benchmarking/near/177872885" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Mario Carneiro <a href="https://leanprover-community.github.io/archive/stream/113488-general/topic/Benchmarking.html#177872885">(Oct 11 2019 at 02:42)</a>:</h4>
<p>there would be a thousand confounding factors in any test</p>



<a name="177872972"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/Benchmarking/near/177872972" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Mario Carneiro <a href="https://leanprover-community.github.io/archive/stream/113488-general/topic/Benchmarking.html#177872972">(Oct 11 2019 at 02:44)</a>:</h4>
<p>In my experience I don't think there is an order of magnitude difference in either direction, but I don't think I could get more specific than that</p>



<a name="177880147"></a>
<h4><a href="https://leanprover.zulipchat.com/#narrow/stream/113488-general/topic/Benchmarking/near/177880147" class="zl"><img src="https://leanprover-community.github.io/archive/assets/img/zulip2.png" alt="view this post on Zulip"></a> Floris van Doorn <a href="https://leanprover-community.github.io/archive/stream/113488-general/topic/Benchmarking.html#177880147">(Oct 11 2019 at 05:51)</a>:</h4>
<p>From my subjective experience, executing a single tactic in Lean is a lot faster than in Coq (I wouldn't be surprised if it was an order of magnitude faster). However, the Coq editor modes (I used CoqIDE, but I believe ProofGeneral works the same) ensure that when you are working on proofs, you rarely rerun your tactics, by storing the state in the middle of your tactic proof. On the other hand in Lean, if you change anything in a proof, it will re-elaborate the whole proof, which negates this speed gain.</p>



{% endraw %}

<hr><p>Last updated: Jan 25 2023 at 00:06 UTC</p>